{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "#GRAIN_TYPE = 'Wheat'\n",
        "#GRAIN_TYPE = 'newWheatData'\n",
        "#GRAIN_TYPE = 'CornAdded_Type'\n",
        "GRAIN_TYPE = 'cleaned_data'\n",
        "# GRAIN_TYPE = 'Oats'\n",
        "\n",
        "# GRAIN_TYPE = 'Barley'\n",
        "# GRAIN_TYPE = 'Sorghum'\n",
        "# GRAIN_TYPE = 'Soybeans'\n",
        "# GRAIN_TYPE = 'Corn'\n",
        "\n",
        "FILENAME_BEST_MODEL = 'Best models/target_2/hybrid_models/' + GRAIN_TYPE + '_t2_kcv_dnn_mc.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNGoIGbc0kw_",
        "outputId": "279cc9c8-32fd-4f89-e56b-83a0a31081dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ]
        }
      ],
      "source": [
        "#Import libraries\n",
        "import requests\n",
        "import pydot\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Data visualization\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "#Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Machine Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Activation, BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "np.random.seed(39)\n",
        "random.seed(39)\n",
        "tf.random.set_seed(39)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "# print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nxHO_qH0Zi5J"
      },
      "outputs": [],
      "source": [
        "def calculate_r_squared(y_true, y_pred):\n",
        "   corr_matrix = np.corrcoef(y_true, y_pred)\n",
        "   corr = corr_matrix[0,1]\n",
        "   R_sq = corr**2\n",
        "   return R_sq\n",
        "\n",
        "def plot_loss_curve(history, epoch_size):\n",
        "    loss_train = history.history['loss']\n",
        "    loss_val = history.history['val_loss']\n",
        "    epochs = range(0,epoch_size)\n",
        "    \n",
        "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "    \n",
        "    plt.title('Training and Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_line(metric, title, xlabel):\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.title(title, fontsize = 16)\n",
        "    plt.plot(metric)\n",
        "    plt.xlabel(xlabel, fontsize = 14)\n",
        "    plt.grid()\n",
        "    plt.legend(loc= \"best\")\n",
        "    plt.show()\n",
        "\n",
        "def scatter_plot(trueValues, predictions, title):\n",
        "  plt.figure(figsize=(8,3))\n",
        "  ax = plt.axes()\n",
        "  maxVal = max( max(trueValues), max(predictions) )\n",
        "\n",
        "  ax.scatter(x=predictions, y=trueValues)\n",
        "  ax.plot([0, 1, maxVal], [0, 1, maxVal], label=\"Ideal fit\")\n",
        "  print('Maxval here is: ', maxVal)\n",
        "  plt.title(title, fontsize = 16)\n",
        "  plt.xlabel(\"Predictions\", fontsize = 14)\n",
        "  plt.ylabel(\"Real\", fontsize = 14)\n",
        "  plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "s3pvA5g-zdgv",
        "outputId": "7a7208f1-6b68-4eba-ad1d-9108d0df66ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From USDA:  ../Datasets/processed/cleaned_data.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variety</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>8.8258</td>\n",
              "      <td>-55.973</td>\n",
              "      <td>-415.973</td>\n",
              "      <td>2.416</td>\n",
              "      <td>0.243</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-6.341975</td>\n",
              "      <td>62.3</td>\n",
              "      <td>61.7806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>10.2572</td>\n",
              "      <td>-114.289</td>\n",
              "      <td>-474.289</td>\n",
              "      <td>2.412</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-11.142320</td>\n",
              "      <td>71.2</td>\n",
              "      <td>82.0576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>11.5679</td>\n",
              "      <td>-168.171</td>\n",
              "      <td>-528.171</td>\n",
              "      <td>2.395</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-14.537729</td>\n",
              "      <td>80.1</td>\n",
              "      <td>104.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>12.8795</td>\n",
              "      <td>134.849</td>\n",
              "      <td>-585.151</td>\n",
              "      <td>2.390</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>10.470049</td>\n",
              "      <td>89.0</td>\n",
              "      <td>128.7950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>13.7649</td>\n",
              "      <td>83.502</td>\n",
              "      <td>-636.498</td>\n",
              "      <td>2.371</td>\n",
              "      <td>0.238</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>6.066299</td>\n",
              "      <td>97.9</td>\n",
              "      <td>151.4139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Variety  Freq  d(cm)    M%  Density     Attn    Phase  Phase_Corr  \\\n",
              "0  KANSAS   7.0    8.9  11.3   0.7356   8.8258  -55.973    -415.973   \n",
              "1  KANSAS   8.0    8.9  11.3   0.7356  10.2572 -114.289    -474.289   \n",
              "2  KANSAS   9.0    8.9  11.3   0.7356  11.5679 -168.171    -528.171   \n",
              "3  KANSAS  10.0    8.9  11.3   0.7356  12.8795  134.849    -585.151   \n",
              "4  KANSAS  11.0    8.9  11.3   0.7356  13.7649   83.502    -636.498   \n",
              "\n",
              "   Permittivity_real  Permittivity_imaginary       Type  Phase/Attn  \\\n",
              "0              2.416                   0.243  15.855506   -6.341975   \n",
              "1              2.412                   0.246  15.855506  -11.142320   \n",
              "2              2.395                   0.246  15.855506  -14.537729   \n",
              "3              2.390                   0.246  15.855506   10.470049   \n",
              "4              2.371                   0.238  15.855506    6.066299   \n",
              "\n",
              "   Freq*d(cm)  Freq*Attn  \n",
              "0        62.3    61.7806  \n",
              "1        71.2    82.0576  \n",
              "2        80.1   104.1111  \n",
              "3        89.0   128.7950  \n",
              "4        97.9   151.4139  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#url dataset\n",
        "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
        "\n",
        "#read in excel format\n",
        "df = pd.read_csv(URL)\n",
        "#df = df[df['Variety'] == 'SOUTH DAKOTA']\n",
        "#df = df[(df['Density'] >= 0.72) & (df['Density'] <= 0.88)]\n",
        "\n",
        "print(\"From USDA: \", URL)\n",
        "\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUzjHHV2stm"
      },
      "source": [
        "# 2. Overview of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Xohz7dGh2sXH",
        "outputId": "7d018cd8-018a-45d3-b1b7-ba9fc14aa5e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10.811414</td>\n",
              "      <td>7.088834</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>0.796298</td>\n",
              "      <td>18.410033</td>\n",
              "      <td>-4.604663</td>\n",
              "      <td>-633.488065</td>\n",
              "      <td>2.912112</td>\n",
              "      <td>0.499187</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>-0.377074</td>\n",
              "      <td>77.159677</td>\n",
              "      <td>215.799030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.530055</td>\n",
              "      <td>1.554604</td>\n",
              "      <td>3.794772</td>\n",
              "      <td>0.067384</td>\n",
              "      <td>5.946835</td>\n",
              "      <td>101.951444</td>\n",
              "      <td>219.510760</td>\n",
              "      <td>0.305758</td>\n",
              "      <td>0.186739</td>\n",
              "      <td>0.629743</td>\n",
              "      <td>6.071761</td>\n",
              "      <td>32.552200</td>\n",
              "      <td>124.108325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>10.260000</td>\n",
              "      <td>0.625400</td>\n",
              "      <td>8.002300</td>\n",
              "      <td>-179.335000</td>\n",
              "      <td>-1274.435000</td>\n",
              "      <td>2.340000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>15.352809</td>\n",
              "      <td>-17.418676</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>40.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>13.680000</td>\n",
              "      <td>0.745400</td>\n",
              "      <td>13.524700</td>\n",
              "      <td>-88.842000</td>\n",
              "      <td>-793.405750</td>\n",
              "      <td>2.688500</td>\n",
              "      <td>0.337000</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-5.077754</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>107.817375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>16.225000</td>\n",
              "      <td>0.801300</td>\n",
              "      <td>18.131600</td>\n",
              "      <td>-9.838500</td>\n",
              "      <td>-602.380500</td>\n",
              "      <td>2.861500</td>\n",
              "      <td>0.470500</td>\n",
              "      <td>16.400366</td>\n",
              "      <td>-0.589378</td>\n",
              "      <td>71.200000</td>\n",
              "      <td>195.600450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>18.810000</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>23.098000</td>\n",
              "      <td>80.957250</td>\n",
              "      <td>-456.055750</td>\n",
              "      <td>3.109750</td>\n",
              "      <td>0.639000</td>\n",
              "      <td>16.401988</td>\n",
              "      <td>4.300734</td>\n",
              "      <td>100.100000</td>\n",
              "      <td>310.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>24.410000</td>\n",
              "      <td>0.927800</td>\n",
              "      <td>29.897000</td>\n",
              "      <td>179.048000</td>\n",
              "      <td>-235.044000</td>\n",
              "      <td>4.038000</td>\n",
              "      <td>0.987000</td>\n",
              "      <td>17.344167</td>\n",
              "      <td>14.827701</td>\n",
              "      <td>160.200000</td>\n",
              "      <td>538.146000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Freq       d(cm)          M%     Density        Attn       Phase  \\\n",
              "count  806.000000  806.000000  806.000000  806.000000  806.000000  806.000000   \n",
              "mean    10.811414    7.088834   16.189541    0.796298   18.410033   -4.604663   \n",
              "std      3.530055    1.554604    3.794772    0.067384    5.946835  101.951444   \n",
              "min      5.000000    4.400000   10.260000    0.625400    8.002300 -179.335000   \n",
              "25%      8.000000    6.500000   13.680000    0.745400   13.524700  -88.842000   \n",
              "50%     11.000000    7.700000   16.225000    0.801300   18.131600   -9.838500   \n",
              "75%     13.000000    7.700000   18.810000    0.842000   23.098000   80.957250   \n",
              "max     18.000000    8.900000   24.410000    0.927800   29.897000  179.048000   \n",
              "\n",
              "        Phase_Corr  Permittivity_real  Permittivity_imaginary        Type  \\\n",
              "count   806.000000         806.000000              806.000000  806.000000   \n",
              "mean   -633.488065           2.912112                0.499187   16.189541   \n",
              "std     219.510760           0.305758                0.186739    0.629743   \n",
              "min   -1274.435000           2.340000                0.220000   15.352809   \n",
              "25%    -793.405750           2.688500                0.337000   15.855506   \n",
              "50%    -602.380500           2.861500                0.470500   16.400366   \n",
              "75%    -456.055750           3.109750                0.639000   16.401988   \n",
              "max    -235.044000           4.038000                0.987000   17.344167   \n",
              "\n",
              "       Phase/Attn  Freq*d(cm)   Freq*Attn  \n",
              "count  806.000000  806.000000  806.000000  \n",
              "mean    -0.377074   77.159677  215.799030  \n",
              "std      6.071761   32.552200  124.108325  \n",
              "min    -17.418676   22.000000   40.011500  \n",
              "25%     -5.077754   52.800000  107.817375  \n",
              "50%     -0.589378   71.200000  195.600450  \n",
              "75%      4.300734  100.100000  310.863000  \n",
              "max     14.827701  160.200000  538.146000  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data summary\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmFqsYQyGnM",
        "outputId": "54445a7f-a2c8-452a-9651-42dbbe682d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(806, 14)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimension of the dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fep-GIv4yUuf",
        "outputId": "c46072fa-aa7f-4549-9a1d-4c5b05d11112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Variety                   0\n",
              "Freq                      0\n",
              "d(cm)                     0\n",
              "M%                        0\n",
              "Density                   0\n",
              "Attn                      0\n",
              "Phase                     0\n",
              "Phase_Corr                0\n",
              "Permittivity_real         0\n",
              "Permittivity_imaginary    0\n",
              "Type                      0\n",
              "Phase/Attn                0\n",
              "Freq*d(cm)                0\n",
              "Freq*Attn                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check info about missing values in dataframe\n",
        "df.isnull().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_TKP9VymuK"
      },
      "source": [
        "# Exploratory Data Analysis\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz1g9T3FzhF0"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "\n",
        "1.   Convert dataframe to numpy array for flexibility.\n",
        "2. Split our data into training and testing datasets and store the target values in different variables.\n",
        "3.   Normalize the features by applying some operations in the data sets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "T0juhagf1M2I"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy array\n",
        "df_features = df[['Freq', \n",
        "                    'd(cm)', \n",
        "                   # 'Attn', \n",
        "                    'Phase_Corr', \n",
        "                    'Permittivity_real', \n",
        "                    'Permittivity_imaginary',\n",
        "                    'Type',\n",
        "                    ]]\n",
        "\n",
        "df_targets = df[['M%', 'Density']]\n",
        "# df_targets = df[['Density', 'M%']]\n",
        "\n",
        "dataset_x = df_features.to_numpy()\n",
        "dataset_y = df_targets.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting dataset to test and train+validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform train-test split on RAW DATA\n",
        "X_trainVal, X_test, y_trainVal, y_test = train_test_split(dataset_x, dataset_y, \n",
        "                                                    test_size=0.15\n",
        "                                                    ,random_state=42\n",
        "                                                    )\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainVal, y_trainVal, \n",
        "                                                    test_size=0.15 #validation split\n",
        "                                                    ,random_state=42\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Normalizing the data set\n",
        "scaler_input = MinMaxScaler()\n",
        "scaler_output = MinMaxScaler()\n",
        "\n",
        "# Normalize Train set\n",
        "X_train_norm = scaler_input.fit_transform(X_train)\n",
        "y_train_norm = scaler_output.fit_transform(y_train)\n",
        "\n",
        "# Normalize Validation set\n",
        "X_val_norm = scaler_input.fit_transform(X_val)\n",
        "y_val_norm = scaler_output.fit_transform(y_val)\n",
        "\n",
        "# Normalize the entire dataset (input features)\n",
        "dataset_x_norm = scaler_input.transform(dataset_x)  # Use transform, NOT fit_transform\n",
        "\n",
        "# Normalize the entire dataset (output targets)\n",
        "dataset_y_norm = scaler_output.transform(dataset_y)  # Use transform, NOT fit_transform\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKfjwMP0Tzn"
      },
      "source": [
        "# K-cross Validation\n",
        "* Input features: 7\n",
        "* Output targets: 2\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "l31WJZ7Z0ONb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 49)                343       \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 49)                2450      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 49)                2450      \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 2)                 100       \n",
            "=================================================================\n",
            "Total params: 5,343\n",
            "Trainable params: 5,343\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import layers, Sequential, regularizers\n",
        "\n",
        "# Define the model-building function\n",
        "def my_model():\n",
        "  my_model = Sequential([\n",
        "    \n",
        "    layers.Dense(49, input_shape=(6,), activation='relu',),\n",
        "    layers.Dense(49, activation='relu', ),\n",
        "    layers.Dense(49, activation='relu',),\n",
        "    layers.Dense(2, activation='linear')  # Output layer with 2 neurons for the two regression targets\n",
        "  ])\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.00061205) # 0.0006 \n",
        "  my_model.compile(\n",
        "      optimizer = opt,\n",
        "      loss = 'mse',\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "\n",
        "  return my_model\n",
        "\n",
        "plot_model(my_model(), show_shapes=True, show_layer_names=True)\n",
        "my_model().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_dataset(features, labels, batch_size=10, shuffle=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(features))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# Create TensorFlow datasets for training and validation\n",
        "batch_size = 10  # You can adjust this size as necessary\n",
        "train_dataset = make_dataset(X_train_norm, y_train_norm, batch_size=batch_size, shuffle=True)\n",
        "val_dataset = make_dataset(X_val_norm, y_val_norm, batch_size=batch_size)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running model with KCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khCKKB74hFVT",
        "outputId": "37e79cdf-4183-4559-f560-fceb2fc0c630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "####################### Iteration   0  #######################\n",
            "Fold 1/10\n",
            "Epoch 1/185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-22 11:58:23.849163: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2024-02-22 11:58:23.850162: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 4491295000 Hz\n",
            "2024-02-22 11:58:23.895001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 1s 2ms/step - loss: 0.1601 - accuracy: 0.8085 - val_loss: 0.0204 - val_accuracy: 0.8983\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.8310 - val_loss: 0.0153 - val_accuracy: 0.8475\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.8267 - val_loss: 0.0117 - val_accuracy: 0.8814\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9115 - val_loss: 0.0086 - val_accuracy: 0.9661\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 0.9411 - val_loss: 0.0096 - val_accuracy: 0.9153\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 0.9227 - val_loss: 0.0070 - val_accuracy: 0.9492\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 0.9216 - val_loss: 0.0063 - val_accuracy: 0.9322\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.9491 - val_loss: 0.0053 - val_accuracy: 0.9322\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.9203 - val_loss: 0.0052 - val_accuracy: 0.9492\n",
            "Epoch 10/185\n",
            "43/53 [=======================>......] - ETA: 0s - loss: 0.0049 - accuracy: 0.9352"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9337 - val_loss: 0.0062 - val_accuracy: 0.8983\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9430 - val_loss: 0.0042 - val_accuracy: 0.9492\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.9270 - val_loss: 0.0040 - val_accuracy: 0.9492\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 991us/step - loss: 0.0042 - accuracy: 0.9483 - val_loss: 0.0039 - val_accuracy: 0.9492\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 932us/step - loss: 0.0034 - accuracy: 0.9358 - val_loss: 0.0049 - val_accuracy: 0.9153\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 998us/step - loss: 0.0036 - accuracy: 0.9379 - val_loss: 0.0035 - val_accuracy: 0.9492\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 921us/step - loss: 0.0034 - accuracy: 0.9445 - val_loss: 0.0039 - val_accuracy: 0.8983\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 926us/step - loss: 0.0032 - accuracy: 0.9370 - val_loss: 0.0035 - val_accuracy: 0.9492\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9260 - val_loss: 0.0029 - val_accuracy: 0.9492\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9216 - val_loss: 0.0030 - val_accuracy: 0.9492\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9362 - val_loss: 0.0028 - val_accuracy: 0.9661\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.9487 - val_loss: 0.0026 - val_accuracy: 0.9492\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9525 - val_loss: 0.0024 - val_accuracy: 0.9492\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9494 - val_loss: 0.0033 - val_accuracy: 0.8983\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9287 - val_loss: 0.0023 - val_accuracy: 0.9492\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9553 - val_loss: 0.0023 - val_accuracy: 0.9661\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9464 - val_loss: 0.0021 - val_accuracy: 0.9492\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9512 - val_loss: 0.0020 - val_accuracy: 0.9492\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9513 - val_loss: 0.0021 - val_accuracy: 0.9492\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9604 - val_loss: 0.0022 - val_accuracy: 0.9492\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9624 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9425 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9658 - val_loss: 0.0019 - val_accuracy: 0.9322\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9376 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9363 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9584 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9608 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9579 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9675 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9557 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9524 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9686 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9671 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9737 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9514 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9572 - val_loss: 0.0028 - val_accuracy: 0.9322\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9544 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.4023e-04 - accuracy: 0.9672 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9697 - val_loss: 9.9555e-04 - val_accuracy: 0.9492\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.8957e-04 - accuracy: 0.9787 - val_loss: 9.9792e-04 - val_accuracy: 0.9661\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2643e-04 - accuracy: 0.9851 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.6053e-04 - accuracy: 0.9705 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5458e-04 - accuracy: 0.9787 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5509e-04 - accuracy: 0.9846 - val_loss: 9.1274e-04 - val_accuracy: 0.9492\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.7108e-04 - accuracy: 0.9851 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5730e-04 - accuracy: 0.9843 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2608e-04 - accuracy: 0.9765 - val_loss: 8.5221e-04 - val_accuracy: 0.9661\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7405e-04 - accuracy: 0.9700 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3701e-04 - accuracy: 0.9874 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.5145e-04 - accuracy: 0.9832 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7399e-04 - accuracy: 0.9791 - val_loss: 8.6775e-04 - val_accuracy: 0.9661\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8804e-04 - accuracy: 0.9844 - val_loss: 8.7473e-04 - val_accuracy: 0.9661\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5374e-04 - accuracy: 0.9862 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.9191e-04 - accuracy: 0.9855 - val_loss: 7.2600e-04 - val_accuracy: 0.9831\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4121e-04 - accuracy: 0.9751 - val_loss: 8.1262e-04 - val_accuracy: 0.9831\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3236e-04 - accuracy: 0.9852 - val_loss: 7.6098e-04 - val_accuracy: 0.9661\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3760e-04 - accuracy: 0.9904 - val_loss: 7.6342e-04 - val_accuracy: 0.9661\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.6571e-04 - accuracy: 0.9777 - val_loss: 7.9836e-04 - val_accuracy: 0.9492\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3288e-04 - accuracy: 0.9812 - val_loss: 8.3894e-04 - val_accuracy: 0.9661\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5667e-04 - accuracy: 0.9729 - val_loss: 7.9150e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9222e-04 - accuracy: 0.9889 - val_loss: 7.6642e-04 - val_accuracy: 0.9661\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2345e-04 - accuracy: 0.9914 - val_loss: 7.2404e-04 - val_accuracy: 0.9831\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0479e-04 - accuracy: 0.9895 - val_loss: 6.9517e-04 - val_accuracy: 0.9831\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.8954e-04 - accuracy: 0.9776 - val_loss: 7.3886e-04 - val_accuracy: 0.9661\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1743e-04 - accuracy: 0.9785 - val_loss: 8.1771e-04 - val_accuracy: 0.9831\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.9285e-04 - accuracy: 0.9792 - val_loss: 7.5590e-04 - val_accuracy: 0.9661\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5695e-04 - accuracy: 0.9877 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9654 - val_loss: 8.1497e-04 - val_accuracy: 0.9831\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7979e-04 - accuracy: 0.9658 - val_loss: 6.8494e-04 - val_accuracy: 0.9661\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7598e-04 - accuracy: 0.9887 - val_loss: 8.2512e-04 - val_accuracy: 0.9661\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9506e-04 - accuracy: 0.9897 - val_loss: 6.9460e-04 - val_accuracy: 0.9661\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6155e-04 - accuracy: 0.9839 - val_loss: 7.0197e-04 - val_accuracy: 0.9661\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0058e-04 - accuracy: 0.9761 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1595e-04 - accuracy: 0.9823 - val_loss: 8.0140e-04 - val_accuracy: 0.9661\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4117e-04 - accuracy: 0.9886 - val_loss: 7.4672e-04 - val_accuracy: 0.9831\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.7389e-04 - accuracy: 0.9815 - val_loss: 7.8303e-04 - val_accuracy: 0.9661\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6842e-04 - accuracy: 0.9811 - val_loss: 7.2769e-04 - val_accuracy: 0.9831\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.6535e-04 - accuracy: 0.9891 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0049e-04 - accuracy: 0.9837 - val_loss: 6.1667e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1207e-04 - accuracy: 0.9702 - val_loss: 6.4598e-04 - val_accuracy: 0.9661\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1973e-04 - accuracy: 0.9886 - val_loss: 6.0579e-04 - val_accuracy: 0.9661\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1297e-04 - accuracy: 0.9887 - val_loss: 6.7232e-04 - val_accuracy: 0.9661\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0241e-04 - accuracy: 0.9919 - val_loss: 5.7070e-04 - val_accuracy: 0.9831\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0032e-04 - accuracy: 0.9805 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.3622e-04 - accuracy: 0.9724 - val_loss: 6.8581e-04 - val_accuracy: 0.9831\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2643e-04 - accuracy: 0.9650 - val_loss: 8.7715e-04 - val_accuracy: 0.9831\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1704e-04 - accuracy: 0.9935 - val_loss: 8.0539e-04 - val_accuracy: 0.9831\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3336e-04 - accuracy: 0.9894 - val_loss: 7.3517e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9787e-04 - accuracy: 0.9894 - val_loss: 7.3287e-04 - val_accuracy: 0.9661\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2083e-04 - accuracy: 0.9901 - val_loss: 6.0530e-04 - val_accuracy: 0.9831\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0909e-04 - accuracy: 0.9761 - val_loss: 9.9585e-04 - val_accuracy: 0.9831\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5933e-04 - accuracy: 0.9841 - val_loss: 6.5893e-04 - val_accuracy: 0.9831\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6026e-04 - accuracy: 0.9890 - val_loss: 7.6674e-04 - val_accuracy: 0.9661\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5568e-04 - accuracy: 0.9828 - val_loss: 5.8675e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2000e-04 - accuracy: 0.9899 - val_loss: 6.1572e-04 - val_accuracy: 0.9831\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.2986e-04 - accuracy: 0.9923 - val_loss: 5.9010e-04 - val_accuracy: 0.9661\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0740e-04 - accuracy: 0.9735 - val_loss: 9.4723e-04 - val_accuracy: 0.9492\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0314e-04 - accuracy: 0.9849 - val_loss: 5.7714e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7561e-04 - accuracy: 0.9843 - val_loss: 6.3168e-04 - val_accuracy: 0.9661\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8271e-04 - accuracy: 0.9783 - val_loss: 6.6084e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.6812e-04 - accuracy: 0.9981 - val_loss: 5.3553e-04 - val_accuracy: 0.9661\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7149e-04 - accuracy: 0.9917 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0772e-04 - accuracy: 0.9906 - val_loss: 9.0778e-04 - val_accuracy: 0.9322\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4868e-04 - accuracy: 0.9928 - val_loss: 7.6621e-04 - val_accuracy: 0.9661\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9223e-04 - accuracy: 0.9953 - val_loss: 5.6207e-04 - val_accuracy: 0.9661\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5881e-04 - accuracy: 0.9907 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.7053e-04 - accuracy: 0.9683 - val_loss: 6.4206e-04 - val_accuracy: 0.9661\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5236e-04 - accuracy: 0.9851 - val_loss: 6.7574e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9871e-04 - accuracy: 0.9809 - val_loss: 6.0148e-04 - val_accuracy: 0.9661\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.8353e-04 - accuracy: 0.9850 - val_loss: 6.3042e-04 - val_accuracy: 0.9661\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4869e-04 - accuracy: 0.9844 - val_loss: 8.5739e-04 - val_accuracy: 0.9661\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.9573e-04 - accuracy: 0.9848 - val_loss: 8.0786e-04 - val_accuracy: 0.9661\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4178e-04 - accuracy: 0.9887 - val_loss: 5.6481e-04 - val_accuracy: 0.9831\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2676e-04 - accuracy: 0.9701 - val_loss: 8.1811e-04 - val_accuracy: 0.9661\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7604e-04 - accuracy: 0.9767 - val_loss: 5.8537e-04 - val_accuracy: 0.9661\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1252e-04 - accuracy: 0.9839 - val_loss: 7.5055e-04 - val_accuracy: 0.9831\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9861e-04 - accuracy: 0.9877 - val_loss: 6.9491e-04 - val_accuracy: 0.9492\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3064e-04 - accuracy: 0.9864 - val_loss: 5.5417e-04 - val_accuracy: 0.9831\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.6475e-04 - accuracy: 0.9889 - val_loss: 6.0190e-04 - val_accuracy: 0.9661\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2347e-04 - accuracy: 0.9763 - val_loss: 5.3685e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0909e-04 - accuracy: 0.9947 - val_loss: 8.5657e-04 - val_accuracy: 0.9831\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0972e-04 - accuracy: 0.9849 - val_loss: 8.3967e-04 - val_accuracy: 0.9661\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6706e-04 - accuracy: 0.9903 - val_loss: 5.8467e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3228e-04 - accuracy: 0.9860 - val_loss: 5.0246e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.7891e-04 - accuracy: 0.9985 - val_loss: 5.1685e-04 - val_accuracy: 0.9831\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5240e-04 - accuracy: 0.9913 - val_loss: 5.7752e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.2575e-04 - accuracy: 0.9898 - val_loss: 0.0016 - val_accuracy: 0.8814\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8202e-04 - accuracy: 0.9883 - val_loss: 7.1325e-04 - val_accuracy: 0.9661\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.6194e-04 - accuracy: 0.9795 - val_loss: 5.9983e-04 - val_accuracy: 0.9661\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4882e-04 - accuracy: 0.9891 - val_loss: 5.6466e-04 - val_accuracy: 0.9661\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.5538e-04 - accuracy: 0.9927 - val_loss: 7.9232e-04 - val_accuracy: 0.9661\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.4441e-04 - accuracy: 0.9902 - val_loss: 6.4262e-04 - val_accuracy: 0.9661\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3629e-04 - accuracy: 0.9843 - val_loss: 5.4162e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3254e-04 - accuracy: 0.9849 - val_loss: 6.3284e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0257e-04 - accuracy: 0.9793 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2966e-04 - accuracy: 0.9759 - val_loss: 6.3416e-04 - val_accuracy: 0.9661\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9366e-04 - accuracy: 0.9901 - val_loss: 5.3753e-04 - val_accuracy: 0.9831\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5648e-04 - accuracy: 0.9959 - val_loss: 5.5465e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9110e-04 - accuracy: 0.9860 - val_loss: 7.8444e-04 - val_accuracy: 0.9661\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1111e-04 - accuracy: 0.9876 - val_loss: 7.7765e-04 - val_accuracy: 0.9661\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9491e-04 - accuracy: 0.9927 - val_loss: 6.2050e-04 - val_accuracy: 0.9831\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7696e-04 - accuracy: 0.9843 - val_loss: 9.3627e-04 - val_accuracy: 0.9492\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1341e-04 - accuracy: 0.9826 - val_loss: 5.9930e-04 - val_accuracy: 0.9661\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7344e-04 - accuracy: 0.9788 - val_loss: 4.9824e-04 - val_accuracy: 0.9831\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0413e-04 - accuracy: 0.9678 - val_loss: 6.8694e-04 - val_accuracy: 0.9661\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4683e-04 - accuracy: 0.9916 - val_loss: 5.1339e-04 - val_accuracy: 0.9831\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3916e-04 - accuracy: 0.9880 - val_loss: 7.6027e-04 - val_accuracy: 0.9831\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2635e-04 - accuracy: 0.9897 - val_loss: 6.5122e-04 - val_accuracy: 0.9661\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4417e-04 - accuracy: 0.9879 - val_loss: 5.3357e-04 - val_accuracy: 0.9831\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4211e-04 - accuracy: 0.9896 - val_loss: 5.1561e-04 - val_accuracy: 0.9661\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.2597e-04 - accuracy: 0.9905 - val_loss: 6.5392e-04 - val_accuracy: 0.9661\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3814e-04 - accuracy: 0.9930 - val_loss: 5.3455e-04 - val_accuracy: 0.9831\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.7379e-04 - accuracy: 0.9897 - val_loss: 6.6909e-04 - val_accuracy: 0.9661\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.9872e-04 - accuracy: 0.9955 - val_loss: 5.5917e-04 - val_accuracy: 0.9831\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1887e-04 - accuracy: 0.9949 - val_loss: 5.9517e-04 - val_accuracy: 0.9661\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.9963e-04 - accuracy: 0.9875 - val_loss: 5.7218e-04 - val_accuracy: 0.9661\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.9212e-04 - accuracy: 0.9777 - val_loss: 6.1354e-04 - val_accuracy: 0.9831\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.4496e-04 - accuracy: 0.9910 - val_loss: 5.6978e-04 - val_accuracy: 0.9831\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.6120e-04 - accuracy: 0.9982 - val_loss: 6.6517e-04 - val_accuracy: 0.9661\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3984e-04 - accuracy: 0.9932 - val_loss: 6.8067e-04 - val_accuracy: 0.9831\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2800e-04 - accuracy: 0.9918 - val_loss: 7.4467e-04 - val_accuracy: 0.9661\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0870e-04 - accuracy: 0.9864 - val_loss: 7.1214e-04 - val_accuracy: 0.9831\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.2264e-04 - accuracy: 0.9911 - val_loss: 5.9473e-04 - val_accuracy: 0.9831\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9039e-04 - accuracy: 0.9956 - val_loss: 6.6198e-04 - val_accuracy: 0.9661\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5297e-04 - accuracy: 0.9966 - val_loss: 5.3539e-04 - val_accuracy: 0.9831\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6509e-04 - accuracy: 0.9864 - val_loss: 7.0550e-04 - val_accuracy: 0.9831\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.1262e-04 - accuracy: 0.9836 - val_loss: 5.7202e-04 - val_accuracy: 0.9831\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.7323e-04 - accuracy: 0.9901 - val_loss: 5.1144e-04 - val_accuracy: 0.9661\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.9556e-04 - accuracy: 0.9897 - val_loss: 5.8713e-04 - val_accuracy: 0.9661\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.0123e-04 - accuracy: 0.9966 - val_loss: 5.0898e-04 - val_accuracy: 1.0000\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8273e-04 - accuracy: 0.9826 - val_loss: 7.1517e-04 - val_accuracy: 1.0000\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8269e-04 - accuracy: 0.9831 - val_loss: 5.7954e-04 - val_accuracy: 0.9831\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3763e-04 - accuracy: 0.9909 - val_loss: 6.1978e-04 - val_accuracy: 0.9661\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.6498e-04 - accuracy: 0.9966 - val_loss: 6.4630e-04 - val_accuracy: 0.9831\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1938e-04 - accuracy: 0.9739 - val_loss: 4.8529e-04 - val_accuracy: 0.9831\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.6702e-04 - accuracy: 0.9973 - val_loss: 5.4801e-04 - val_accuracy: 0.9661\n",
            "6/6 [==============================] - 0s 623us/step - loss: 5.4801e-04 - accuracy: 0.9661\n",
            "Loss = 0.0005480118561536074, Accuracy = 0.9661017060279846\n",
            "Loss array:  [0.0005480118561536074]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 2/10\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.6849 - val_loss: 0.0408 - val_accuracy: 0.7288\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.8525 - val_loss: 0.0188 - val_accuracy: 0.8136\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.9113 - val_loss: 0.0149 - val_accuracy: 0.8644\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 0.9151 - val_loss: 0.0127 - val_accuracy: 0.8644\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.9270 - val_loss: 0.0112 - val_accuracy: 0.8644\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 0.9270 - val_loss: 0.0090 - val_accuracy: 0.8814\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 0.9281 - val_loss: 0.0080 - val_accuracy: 0.8814\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 939us/step - loss: 0.0059 - accuracy: 0.9249 - val_loss: 0.0071 - val_accuracy: 0.8814\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 0.9450 - val_loss: 0.0061 - val_accuracy: 0.8814\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 0.9305 - val_loss: 0.0067 - val_accuracy: 0.8983\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9461 - val_loss: 0.0058 - val_accuracy: 0.8644\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 993us/step - loss: 0.0041 - accuracy: 0.9475 - val_loss: 0.0068 - val_accuracy: 0.8814\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0037 - accuracy: 0.9280 - val_loss: 0.0049 - val_accuracy: 0.8983\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9370 - val_loss: 0.0052 - val_accuracy: 0.8475\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.9200 - val_loss: 0.0048 - val_accuracy: 0.8814\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.9525 - val_loss: 0.0043 - val_accuracy: 0.8814\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.9385 - val_loss: 0.0039 - val_accuracy: 0.8644\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9559 - val_loss: 0.0040 - val_accuracy: 0.8644\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.9438 - val_loss: 0.0038 - val_accuracy: 0.8475\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9315 - val_loss: 0.0036 - val_accuracy: 0.8644\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.9383 - val_loss: 0.0032 - val_accuracy: 0.8644\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9420 - val_loss: 0.0032 - val_accuracy: 0.8475\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9375 - val_loss: 0.0039 - val_accuracy: 0.8644\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9466 - val_loss: 0.0029 - val_accuracy: 0.8644\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9605 - val_loss: 0.0027 - val_accuracy: 0.8814\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9422 - val_loss: 0.0031 - val_accuracy: 0.8814\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9551 - val_loss: 0.0026 - val_accuracy: 0.8983\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9561 - val_loss: 0.0029 - val_accuracy: 0.8814\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9502 - val_loss: 0.0030 - val_accuracy: 0.8983\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9509 - val_loss: 0.0028 - val_accuracy: 0.8475\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9587 - val_loss: 0.0030 - val_accuracy: 0.8814\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9628 - val_loss: 0.0024 - val_accuracy: 0.8644\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9484 - val_loss: 0.0025 - val_accuracy: 0.8814\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9637 - val_loss: 0.0019 - val_accuracy: 0.9153\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9578 - val_loss: 0.0025 - val_accuracy: 0.8814\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9514 - val_loss: 0.0028 - val_accuracy: 0.8814\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9652 - val_loss: 0.0023 - val_accuracy: 0.9322\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9637 - val_loss: 0.0020 - val_accuracy: 0.9153\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9592 - val_loss: 0.0021 - val_accuracy: 0.8983\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9573 - val_loss: 0.0025 - val_accuracy: 0.9153\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.9654 - val_loss: 0.0023 - val_accuracy: 0.8814\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9675 - val_loss: 0.0026 - val_accuracy: 0.8814\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9711 - val_loss: 0.0039 - val_accuracy: 0.8814\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9604 - val_loss: 0.0020 - val_accuracy: 0.8983\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9675 - val_loss: 0.0024 - val_accuracy: 0.8983\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9633 - val_loss: 0.0017 - val_accuracy: 0.8983\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9576 - val_loss: 0.0018 - val_accuracy: 0.8983\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9716 - val_loss: 0.0024 - val_accuracy: 0.8983\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9501 - val_loss: 0.0019 - val_accuracy: 0.9153\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9715 - val_loss: 0.0022 - val_accuracy: 0.8983\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9543 - val_loss: 0.0022 - val_accuracy: 0.8983\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9655 - val_loss: 0.0021 - val_accuracy: 0.9153\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9537 - val_loss: 0.0021 - val_accuracy: 0.9153\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9588 - val_loss: 0.0020 - val_accuracy: 0.9322\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.4824e-04 - accuracy: 0.9654 - val_loss: 0.0018 - val_accuracy: 0.9153\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9653 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.3743e-04 - accuracy: 0.9526 - val_loss: 0.0024 - val_accuracy: 0.9322\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9542 - val_loss: 0.0019 - val_accuracy: 0.9322\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9750 - val_loss: 0.0018 - val_accuracy: 0.8983\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9494 - val_loss: 0.0019 - val_accuracy: 0.8983\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9536 - val_loss: 0.0019 - val_accuracy: 0.9322\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9552 - val_loss: 0.0018 - val_accuracy: 0.9322\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0558e-04 - accuracy: 0.9695 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.7243e-04 - accuracy: 0.9651 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.2829e-04 - accuracy: 0.9696 - val_loss: 0.0019 - val_accuracy: 0.9322\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9632 - val_loss: 0.0019 - val_accuracy: 0.9153\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9583 - val_loss: 0.0018 - val_accuracy: 0.9153\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9714 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.6771e-04 - accuracy: 0.9611 - val_loss: 0.0018 - val_accuracy: 0.9322\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9643 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2485e-04 - accuracy: 0.9654 - val_loss: 0.0016 - val_accuracy: 0.9153\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9654 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.5552e-04 - accuracy: 0.9808 - val_loss: 0.0020 - val_accuracy: 0.9153\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9803 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2561e-04 - accuracy: 0.9562 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.1732e-04 - accuracy: 0.9753 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.4672e-04 - accuracy: 0.9499 - val_loss: 0.0019 - val_accuracy: 0.9153\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6492e-04 - accuracy: 0.9618 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.5637e-04 - accuracy: 0.9641 - val_loss: 0.0015 - val_accuracy: 0.9322\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.7106e-04 - accuracy: 0.9816 - val_loss: 0.0026 - val_accuracy: 0.9153\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.9379e-04 - accuracy: 0.9742 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.0401e-04 - accuracy: 0.9658 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.4403e-04 - accuracy: 0.9722 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1604e-04 - accuracy: 0.9740 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9736 - val_loss: 0.0018 - val_accuracy: 0.8983\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5575e-04 - accuracy: 0.9699 - val_loss: 0.0019 - val_accuracy: 0.9492\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.2362e-04 - accuracy: 0.9688 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.9148e-04 - accuracy: 0.9796 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5206e-04 - accuracy: 0.9696 - val_loss: 0.0022 - val_accuracy: 0.9322\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.0554e-04 - accuracy: 0.9670 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1429e-04 - accuracy: 0.9734 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1296e-04 - accuracy: 0.9701 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1360e-04 - accuracy: 0.9696 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.4548e-04 - accuracy: 0.9810 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1256e-04 - accuracy: 0.9804 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.6781e-04 - accuracy: 0.9830 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6171e-04 - accuracy: 0.9775 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.6148e-04 - accuracy: 0.9783 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7916e-04 - accuracy: 0.9651 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3140e-04 - accuracy: 0.9858 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.9903e-04 - accuracy: 0.9803 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.8533e-04 - accuracy: 0.9862 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8750e-04 - accuracy: 0.9717 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.4066e-04 - accuracy: 0.9844 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.3033e-04 - accuracy: 0.9777 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.8589e-04 - accuracy: 0.9820 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.6488e-04 - accuracy: 0.9647 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8174e-04 - accuracy: 0.9764 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5565e-04 - accuracy: 0.9804 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.5824e-04 - accuracy: 0.9692 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5064e-04 - accuracy: 0.9756 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2973e-04 - accuracy: 0.9680 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1416e-04 - accuracy: 0.9659 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0780e-04 - accuracy: 0.9804 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5638e-04 - accuracy: 0.9606 - val_loss: 0.0020 - val_accuracy: 0.9492\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0287e-04 - accuracy: 0.9746 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3201e-04 - accuracy: 0.9703 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.8777e-04 - accuracy: 0.9747 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.1103e-04 - accuracy: 0.9695 - val_loss: 0.0021 - val_accuracy: 0.9492\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.3506e-04 - accuracy: 0.9817 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4250e-04 - accuracy: 0.9880 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.8212e-04 - accuracy: 0.9901 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4627e-04 - accuracy: 0.9772 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4512e-04 - accuracy: 0.9780 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2318e-04 - accuracy: 0.9811 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0524e-04 - accuracy: 0.9820 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.8130e-04 - accuracy: 0.9775 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5431e-04 - accuracy: 0.9845 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5541e-04 - accuracy: 0.9840 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6476e-04 - accuracy: 0.9842 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0962e-04 - accuracy: 0.9783 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2790e-04 - accuracy: 0.9679 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2554e-04 - accuracy: 0.9820 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2003e-04 - accuracy: 0.9785 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3499e-04 - accuracy: 0.9826 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4414e-04 - accuracy: 0.9798 - val_loss: 0.0020 - val_accuracy: 0.9831\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.7975e-04 - accuracy: 0.9918 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.9313e-04 - accuracy: 0.9735 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2434e-04 - accuracy: 0.9702 - val_loss: 9.7920e-04 - val_accuracy: 0.9831\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.3218e-04 - accuracy: 0.9635 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5676e-04 - accuracy: 0.9783 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0108e-04 - accuracy: 0.9873 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5907e-04 - accuracy: 0.9717 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.4954e-04 - accuracy: 0.9692 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0474e-04 - accuracy: 0.9810 - val_loss: 9.2284e-04 - val_accuracy: 0.9661\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.6473e-04 - accuracy: 0.9804 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2231e-04 - accuracy: 0.9706 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.8178e-04 - accuracy: 0.9838 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.3470e-04 - accuracy: 0.9837 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.9678e-04 - accuracy: 0.9742 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0429e-04 - accuracy: 0.9867 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5899e-04 - accuracy: 0.9736 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6973e-04 - accuracy: 0.9765 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.4654e-04 - accuracy: 0.9746 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0813e-04 - accuracy: 0.9843 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0697e-04 - accuracy: 0.9882 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5894e-04 - accuracy: 0.9827 - val_loss: 0.0025 - val_accuracy: 0.9322\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0799e-04 - accuracy: 0.9682 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9768e-04 - accuracy: 0.9795 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.7661e-04 - accuracy: 0.9861 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.8340e-04 - accuracy: 0.9817 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3881e-04 - accuracy: 0.9668 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0363e-04 - accuracy: 0.9892 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.2190e-04 - accuracy: 0.9906 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1930e-04 - accuracy: 0.9802 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.9690e-04 - accuracy: 0.9814 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4310e-04 - accuracy: 0.9805 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0054e-04 - accuracy: 0.9868 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5706e-04 - accuracy: 0.9791 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.8468e-04 - accuracy: 0.9728 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2658e-04 - accuracy: 0.9820 - val_loss: 9.7484e-04 - val_accuracy: 0.9831\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0039e-04 - accuracy: 0.9887 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.8127e-04 - accuracy: 0.9872 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5522e-04 - accuracy: 0.9706 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1541e-04 - accuracy: 0.9843 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1332e-04 - accuracy: 0.9759 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 960us/step - loss: 7.1729e-04 - accuracy: 0.9598 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.6099e-04 - accuracy: 0.9758 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 973us/step - loss: 4.9274e-04 - accuracy: 0.9872 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4490e-04 - accuracy: 0.9752 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5018e-04 - accuracy: 0.9822 - val_loss: 9.7343e-04 - val_accuracy: 0.9661\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3744e-04 - accuracy: 0.9712 - val_loss: 9.1144e-04 - val_accuracy: 0.9831\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.8765e-04 - accuracy: 0.9918 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4253e-04 - accuracy: 0.9779 - val_loss: 8.9640e-04 - val_accuracy: 0.9831\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5011e-04 - accuracy: 0.9839 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9831\n",
            "Loss = 0.0014485771534964442, Accuracy = 0.9830508232116699\n",
            "Loss array:  [0.0005480118561536074, 0.0014485771534964442]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 3/10\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.4458 - val_loss: 0.0429 - val_accuracy: 0.8103\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.8407 - val_loss: 0.0168 - val_accuracy: 0.9138\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 0.8771 - val_loss: 0.0117 - val_accuracy: 0.9138\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 0.9140 - val_loss: 0.0077 - val_accuracy: 0.9483\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9015 - val_loss: 0.0055 - val_accuracy: 0.9655\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.9262 - val_loss: 0.0044 - val_accuracy: 0.9655\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 0.9080 - val_loss: 0.0037 - val_accuracy: 0.9655\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.9141 - val_loss: 0.0033 - val_accuracy: 0.9655\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9202 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.9318 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.9373 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 0.9491 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0034 - accuracy: 0.9336 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9272 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9194 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9344 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9397 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.9375 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9409 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9319 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9371 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9474 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9519 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9308 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9450 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9583 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9646 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9579 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9580 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9389 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9469 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9497 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9524 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9545 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9541 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9579 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9599 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9621 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9572 - val_loss: 9.3493e-04 - val_accuracy: 0.9828\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9520 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9535 - val_loss: 9.0351e-04 - val_accuracy: 0.9655\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9601 - val_loss: 9.4079e-04 - val_accuracy: 0.9828\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9549 - val_loss: 8.8875e-04 - val_accuracy: 0.9828\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9566 - val_loss: 9.3489e-04 - val_accuracy: 0.9828\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9617 - val_loss: 8.9174e-04 - val_accuracy: 0.9655\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9765 - val_loss: 9.6210e-04 - val_accuracy: 0.9655\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9578 - val_loss: 7.8044e-04 - val_accuracy: 0.9828\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.3033e-04 - accuracy: 0.9712 - val_loss: 7.6420e-04 - val_accuracy: 0.9655\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.4173e-04 - accuracy: 0.9639 - val_loss: 7.5781e-04 - val_accuracy: 0.9828\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6732e-04 - accuracy: 0.9634 - val_loss: 8.8197e-04 - val_accuracy: 1.0000\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.6886e-04 - accuracy: 0.9683 - val_loss: 8.3216e-04 - val_accuracy: 0.9655\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5667e-04 - accuracy: 0.9515 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.9247e-04 - accuracy: 0.9687 - val_loss: 9.6812e-04 - val_accuracy: 0.9655\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9302 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9736 - val_loss: 9.2776e-04 - val_accuracy: 0.9655\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1058e-04 - accuracy: 0.9756 - val_loss: 7.2918e-04 - val_accuracy: 0.9828\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.5925e-04 - accuracy: 0.9615 - val_loss: 8.2329e-04 - val_accuracy: 0.9828\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8986e-04 - accuracy: 0.9776 - val_loss: 8.2669e-04 - val_accuracy: 0.9828\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1232e-04 - accuracy: 0.9828 - val_loss: 7.0107e-04 - val_accuracy: 0.9828\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 985us/step - loss: 8.5743e-04 - accuracy: 0.9692 - val_loss: 9.8149e-04 - val_accuracy: 0.9483\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2325e-04 - accuracy: 0.9767 - val_loss: 8.1222e-04 - val_accuracy: 0.9483\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5667e-04 - accuracy: 0.9789 - val_loss: 7.4200e-04 - val_accuracy: 0.9828\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2737e-04 - accuracy: 0.9770 - val_loss: 7.4033e-04 - val_accuracy: 0.9483\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.3143e-04 - accuracy: 0.9590 - val_loss: 7.0709e-04 - val_accuracy: 0.9655\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.4235e-04 - accuracy: 0.9825 - val_loss: 8.2617e-04 - val_accuracy: 0.9483\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7960e-04 - accuracy: 0.9736 - val_loss: 7.1439e-04 - val_accuracy: 0.9828\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7985e-04 - accuracy: 0.9716 - val_loss: 7.9627e-04 - val_accuracy: 0.9655\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5356e-04 - accuracy: 0.9856 - val_loss: 6.9789e-04 - val_accuracy: 0.9483\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1721e-04 - accuracy: 0.9797 - val_loss: 6.8465e-04 - val_accuracy: 0.9655\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2426e-04 - accuracy: 0.9711 - val_loss: 7.5790e-04 - val_accuracy: 0.9655\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 989us/step - loss: 9.4920e-04 - accuracy: 0.9664 - val_loss: 9.4508e-04 - val_accuracy: 0.9483\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 947us/step - loss: 9.5242e-04 - accuracy: 0.9550 - val_loss: 6.8235e-04 - val_accuracy: 0.9828\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.8254e-04 - accuracy: 0.9610 - val_loss: 7.4547e-04 - val_accuracy: 0.9828\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1524e-04 - accuracy: 0.9769 - val_loss: 9.0090e-04 - val_accuracy: 0.9483\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5189e-04 - accuracy: 0.9888 - val_loss: 6.6829e-04 - val_accuracy: 0.9828\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1232e-04 - accuracy: 0.9828 - val_loss: 7.3668e-04 - val_accuracy: 0.9828\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.7900e-04 - accuracy: 0.9653 - val_loss: 7.6497e-04 - val_accuracy: 0.9828\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7486e-04 - accuracy: 0.9714 - val_loss: 8.8853e-04 - val_accuracy: 0.9483\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7292e-04 - accuracy: 0.9866 - val_loss: 9.5321e-04 - val_accuracy: 0.9655\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5353e-04 - accuracy: 0.9665 - val_loss: 7.0433e-04 - val_accuracy: 0.9655\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3290e-04 - accuracy: 0.9825 - val_loss: 9.3701e-04 - val_accuracy: 0.9483\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1096e-04 - accuracy: 0.9707 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.6268e-04 - accuracy: 0.9668 - val_loss: 7.4516e-04 - val_accuracy: 0.9828\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1305e-04 - accuracy: 0.9813 - val_loss: 6.1110e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4396e-04 - accuracy: 0.9696 - val_loss: 5.9510e-04 - val_accuracy: 0.9828\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1494e-04 - accuracy: 0.9534 - val_loss: 7.4495e-04 - val_accuracy: 0.9655\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9284e-04 - accuracy: 0.9757 - val_loss: 6.9252e-04 - val_accuracy: 0.9655\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3824e-04 - accuracy: 0.9687 - val_loss: 8.4262e-04 - val_accuracy: 0.9828\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3373e-04 - accuracy: 0.9830 - val_loss: 6.2227e-04 - val_accuracy: 0.9828\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9400e-04 - accuracy: 0.9821 - val_loss: 7.4181e-04 - val_accuracy: 0.9828\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5162e-04 - accuracy: 0.9713 - val_loss: 7.3548e-04 - val_accuracy: 0.9828\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9686e-04 - accuracy: 0.9680 - val_loss: 6.5096e-04 - val_accuracy: 0.9828\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4787e-04 - accuracy: 0.9779 - val_loss: 7.7804e-04 - val_accuracy: 0.9828\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5749e-04 - accuracy: 0.9858 - val_loss: 8.4854e-04 - val_accuracy: 0.9828\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5725e-04 - accuracy: 0.9595 - val_loss: 6.2526e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9894e-04 - accuracy: 0.9760 - val_loss: 6.9444e-04 - val_accuracy: 0.9828\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0104e-04 - accuracy: 0.9845 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 915us/step - loss: 7.0536e-04 - accuracy: 0.9731 - val_loss: 8.9540e-04 - val_accuracy: 0.9483\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5513e-04 - accuracy: 0.9727 - val_loss: 8.8868e-04 - val_accuracy: 0.9655\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6850e-04 - accuracy: 0.9832 - val_loss: 8.4598e-04 - val_accuracy: 0.9828\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1498e-04 - accuracy: 0.9652 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9071e-04 - accuracy: 0.9827 - val_loss: 9.4319e-04 - val_accuracy: 0.9655\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2960e-04 - accuracy: 0.9717 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2717e-04 - accuracy: 0.9853 - val_loss: 6.5731e-04 - val_accuracy: 0.9655\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6921e-04 - accuracy: 0.9854 - val_loss: 9.9070e-04 - val_accuracy: 0.9828\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.5414e-04 - accuracy: 0.9838 - val_loss: 7.9106e-04 - val_accuracy: 0.9655\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9065e-04 - accuracy: 0.9712 - val_loss: 6.3300e-04 - val_accuracy: 0.9655\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1292e-04 - accuracy: 0.9783 - val_loss: 7.5824e-04 - val_accuracy: 0.9828\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1551e-04 - accuracy: 0.9759 - val_loss: 6.8472e-04 - val_accuracy: 0.9655\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3202e-04 - accuracy: 0.9776 - val_loss: 7.0751e-04 - val_accuracy: 0.9828\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4674e-04 - accuracy: 0.9857 - val_loss: 6.1692e-04 - val_accuracy: 0.9828\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9205e-04 - accuracy: 0.9881 - val_loss: 7.3836e-04 - val_accuracy: 0.9828\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1366e-04 - accuracy: 0.9783 - val_loss: 7.2201e-04 - val_accuracy: 0.9655\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5825e-04 - accuracy: 0.9853 - val_loss: 7.7539e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9570e-04 - accuracy: 0.9782 - val_loss: 7.1562e-04 - val_accuracy: 0.9828\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0401e-04 - accuracy: 0.9902 - val_loss: 9.5894e-04 - val_accuracy: 0.9310\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2904e-04 - accuracy: 0.9728 - val_loss: 6.5169e-04 - val_accuracy: 0.9655\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4309e-04 - accuracy: 0.9871 - val_loss: 6.1274e-04 - val_accuracy: 0.9828\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6571e-04 - accuracy: 0.9778 - val_loss: 7.6060e-04 - val_accuracy: 0.9655\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7073e-04 - accuracy: 0.9944 - val_loss: 8.9278e-04 - val_accuracy: 0.9828\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4254e-04 - accuracy: 0.9863 - val_loss: 8.1289e-04 - val_accuracy: 0.9655\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5490e-04 - accuracy: 0.9811 - val_loss: 8.6559e-04 - val_accuracy: 0.9655\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1395e-04 - accuracy: 0.9804 - val_loss: 7.8604e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8631e-04 - accuracy: 0.9590 - val_loss: 8.0573e-04 - val_accuracy: 0.9828\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9450e-04 - accuracy: 0.9820 - val_loss: 6.7513e-04 - val_accuracy: 0.9828\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6133e-04 - accuracy: 0.9895 - val_loss: 6.5772e-04 - val_accuracy: 0.9828\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9340e-04 - accuracy: 0.9921 - val_loss: 6.4274e-04 - val_accuracy: 0.9828\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0484e-04 - accuracy: 0.9731 - val_loss: 6.8370e-04 - val_accuracy: 0.9655\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7742e-04 - accuracy: 0.9900 - val_loss: 6.3585e-04 - val_accuracy: 0.9655\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8387e-04 - accuracy: 0.9831 - val_loss: 8.4657e-04 - val_accuracy: 0.9828\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8468e-04 - accuracy: 0.9940 - val_loss: 7.3807e-04 - val_accuracy: 0.9828\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 789us/step - loss: 5.2821e-04 - accuracy: 0.9943 - val_loss: 5.7785e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.2935e-04 - accuracy: 0.9869 - val_loss: 5.5525e-04 - val_accuracy: 0.9828\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 816us/step - loss: 5.4226e-04 - accuracy: 0.9874 - val_loss: 6.4029e-04 - val_accuracy: 0.9828\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2904e-04 - accuracy: 0.9805 - val_loss: 9.2550e-04 - val_accuracy: 0.9483\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9327e-04 - accuracy: 0.9778 - val_loss: 7.6776e-04 - val_accuracy: 0.9655\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0848e-04 - accuracy: 0.9867 - val_loss: 6.8650e-04 - val_accuracy: 0.9828\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3939e-04 - accuracy: 0.9684 - val_loss: 6.3565e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8208e-04 - accuracy: 0.9855 - val_loss: 5.7847e-04 - val_accuracy: 0.9828\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0076e-04 - accuracy: 0.9937 - val_loss: 6.8702e-04 - val_accuracy: 0.9828\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7140e-04 - accuracy: 0.9746 - val_loss: 8.7534e-04 - val_accuracy: 0.9483\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1169e-04 - accuracy: 0.9810 - val_loss: 5.9740e-04 - val_accuracy: 0.9828\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8617e-04 - accuracy: 0.9853 - val_loss: 7.3996e-04 - val_accuracy: 0.9828\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8952e-04 - accuracy: 0.9911 - val_loss: 6.8170e-04 - val_accuracy: 0.9828\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4650e-04 - accuracy: 0.9925 - val_loss: 7.9742e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6493e-04 - accuracy: 0.9798 - val_loss: 7.4523e-04 - val_accuracy: 0.9828\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2192e-04 - accuracy: 0.9723 - val_loss: 6.1077e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7959e-04 - accuracy: 0.9742 - val_loss: 6.6402e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9749e-04 - accuracy: 0.9873 - val_loss: 8.6440e-04 - val_accuracy: 0.9483\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7860e-04 - accuracy: 0.9888 - val_loss: 5.8882e-04 - val_accuracy: 0.9828\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6836e-04 - accuracy: 0.9819 - val_loss: 6.3806e-04 - val_accuracy: 0.9828\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1808e-04 - accuracy: 0.9759 - val_loss: 7.5689e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2002e-04 - accuracy: 0.9891 - val_loss: 5.7253e-04 - val_accuracy: 0.9828\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3792e-04 - accuracy: 0.9975 - val_loss: 5.8087e-04 - val_accuracy: 0.9828\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5468e-04 - accuracy: 0.9879 - val_loss: 6.2485e-04 - val_accuracy: 0.9828\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4791e-04 - accuracy: 0.9918 - val_loss: 6.3052e-04 - val_accuracy: 0.9828\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5095e-04 - accuracy: 0.9720 - val_loss: 6.9613e-04 - val_accuracy: 0.9828\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5642e-04 - accuracy: 0.9886 - val_loss: 6.3462e-04 - val_accuracy: 0.9828\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6828e-04 - accuracy: 0.9752 - val_loss: 7.1613e-04 - val_accuracy: 0.9828\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1255e-04 - accuracy: 0.9950 - val_loss: 5.8661e-04 - val_accuracy: 0.9828\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8852e-04 - accuracy: 0.9769 - val_loss: 5.8153e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.6639e-04 - accuracy: 0.9935 - val_loss: 6.9335e-04 - val_accuracy: 0.9828\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6425e-04 - accuracy: 0.9856 - val_loss: 6.4574e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2425e-04 - accuracy: 0.9885 - val_loss: 6.2529e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4518e-04 - accuracy: 0.9709 - val_loss: 6.4003e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7538e-04 - accuracy: 0.9864 - val_loss: 6.0982e-04 - val_accuracy: 0.9828\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1058e-04 - accuracy: 0.9611 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4550e-04 - accuracy: 0.9845 - val_loss: 5.9937e-04 - val_accuracy: 0.9828\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4790e-04 - accuracy: 0.9969 - val_loss: 7.1466e-04 - val_accuracy: 0.9828\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7263e-04 - accuracy: 0.9775 - val_loss: 6.9617e-04 - val_accuracy: 0.9828\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4427e-04 - accuracy: 0.9714 - val_loss: 5.6416e-04 - val_accuracy: 0.9828\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.7397e-04 - accuracy: 0.9958 - val_loss: 5.8841e-04 - val_accuracy: 0.9828\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4319e-04 - accuracy: 0.9806 - val_loss: 6.1885e-04 - val_accuracy: 0.9828\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 992us/step - loss: 4.0641e-04 - accuracy: 0.9852 - val_loss: 6.1832e-04 - val_accuracy: 0.9828\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7517e-04 - accuracy: 0.9817 - val_loss: 6.4052e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.0346e-04 - accuracy: 0.9919 - val_loss: 7.8934e-04 - val_accuracy: 0.9655\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5535e-04 - accuracy: 0.9906 - val_loss: 5.7755e-04 - val_accuracy: 0.9828\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1988e-04 - accuracy: 0.9986 - val_loss: 6.5597e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.9479e-04 - accuracy: 0.9888 - val_loss: 8.0016e-04 - val_accuracy: 0.9655\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7901e-04 - accuracy: 0.9744 - val_loss: 6.0802e-04 - val_accuracy: 0.9828\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1028e-04 - accuracy: 0.9886 - val_loss: 7.7480e-04 - val_accuracy: 0.9828\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9617e-04 - accuracy: 0.9840 - val_loss: 6.9341e-04 - val_accuracy: 0.9828\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9595e-04 - accuracy: 0.9930 - val_loss: 8.3129e-04 - val_accuracy: 0.9828\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8083e-04 - accuracy: 0.9797 - val_loss: 5.6157e-04 - val_accuracy: 0.9828\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.2517e-04 - accuracy: 0.9938 - val_loss: 7.5456e-04 - val_accuracy: 0.9655\n",
            "6/6 [==============================] - 0s 662us/step - loss: 7.5456e-04 - accuracy: 0.9655\n",
            "Loss = 0.0007545604603365064, Accuracy = 0.9655172228813171\n",
            "Loss array:  [0.0005480118561536074, 0.0014485771534964442, 0.0007545604603365064]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 4/10\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.4863 - val_loss: 0.0378 - val_accuracy: 0.7586\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.8420 - val_loss: 0.0210 - val_accuracy: 0.7759\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.8232 - val_loss: 0.0151 - val_accuracy: 0.8103\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 0.8661 - val_loss: 0.0114 - val_accuracy: 0.8276\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.8900 - val_loss: 0.0087 - val_accuracy: 0.9138\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 0.9219 - val_loss: 0.0073 - val_accuracy: 0.8448\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9384 - val_loss: 0.0064 - val_accuracy: 0.8621\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 0.9396 - val_loss: 0.0059 - val_accuracy: 0.9138\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 0.9353 - val_loss: 0.0048 - val_accuracy: 0.8793\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 0.9064 - val_loss: 0.0055 - val_accuracy: 0.8621\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9305 - val_loss: 0.0042 - val_accuracy: 0.9138\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.9297 - val_loss: 0.0040 - val_accuracy: 0.8966\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9362 - val_loss: 0.0035 - val_accuracy: 0.9138\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.9127 - val_loss: 0.0033 - val_accuracy: 0.9138\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9521 - val_loss: 0.0031 - val_accuracy: 0.9138\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 810us/step - loss: 0.0031 - accuracy: 0.9387 - val_loss: 0.0037 - val_accuracy: 0.8793\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9222 - val_loss: 0.0035 - val_accuracy: 0.9483\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9508 - val_loss: 0.0034 - val_accuracy: 0.8966\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 733us/step - loss: 0.0025 - accuracy: 0.9569 - val_loss: 0.0026 - val_accuracy: 0.9138\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 944us/step - loss: 0.0022 - accuracy: 0.9562 - val_loss: 0.0032 - val_accuracy: 0.8966\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0024 - accuracy: 0.9449 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 964us/step - loss: 0.0021 - accuracy: 0.9459 - val_loss: 0.0023 - val_accuracy: 0.8966\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9504 - val_loss: 0.0024 - val_accuracy: 0.8966\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9384 - val_loss: 0.0036 - val_accuracy: 0.8621\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9622 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9593 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9495 - val_loss: 0.0026 - val_accuracy: 0.8448\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 999us/step - loss: 0.0019 - accuracy: 0.9614 - val_loss: 0.0027 - val_accuracy: 0.8966\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9520 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 928us/step - loss: 0.0021 - accuracy: 0.9303 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9611 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9408 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9484 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9608 - val_loss: 0.0020 - val_accuracy: 0.9138\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9400 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9699 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9587 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9635 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9704 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9577 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9573 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9552 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9452 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9487 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9481 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9623 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9676 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9583 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9606 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9615 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9659 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1411e-04 - accuracy: 0.9558 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 985us/step - loss: 8.5908e-04 - accuracy: 0.9633 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9783 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9776 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.3212e-04 - accuracy: 0.9587 - val_loss: 9.2869e-04 - val_accuracy: 0.9483\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.4284e-04 - accuracy: 0.9673 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9769 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0011 - accuracy: 0.9381 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2264e-04 - accuracy: 0.9760 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9752 - val_loss: 9.8906e-04 - val_accuracy: 0.9483\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7797e-04 - accuracy: 0.9748 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.9316e-04 - accuracy: 0.9634 - val_loss: 8.5799e-04 - val_accuracy: 0.9828\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2860e-04 - accuracy: 0.9767 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8524e-04 - accuracy: 0.9551 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 998us/step - loss: 8.7723e-04 - accuracy: 0.9768 - val_loss: 8.6689e-04 - val_accuracy: 0.9655\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2798e-04 - accuracy: 0.9834 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9729 - val_loss: 8.4099e-04 - val_accuracy: 0.9655\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.0811e-04 - accuracy: 0.9697 - val_loss: 9.0587e-04 - val_accuracy: 0.9828\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.8162e-04 - accuracy: 0.9585 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.6350e-04 - accuracy: 0.9681 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9669 - val_loss: 9.4129e-04 - val_accuracy: 0.9483\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.9411e-04 - accuracy: 0.9821 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.9463e-04 - accuracy: 0.9787 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1814e-04 - accuracy: 0.9799 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 7.4159e-04 - accuracy: 0.9914 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3637e-04 - accuracy: 0.9703 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6700e-04 - accuracy: 0.9779 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1576e-04 - accuracy: 0.9734 - val_loss: 7.7707e-04 - val_accuracy: 0.9483\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1566e-04 - accuracy: 0.9773 - val_loss: 9.4467e-04 - val_accuracy: 0.9483\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.8195e-04 - accuracy: 0.9662 - val_loss: 8.4473e-04 - val_accuracy: 0.9483\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.9839e-04 - accuracy: 0.9722 - val_loss: 8.7511e-04 - val_accuracy: 0.9483\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.0978e-04 - accuracy: 0.9854 - val_loss: 8.8470e-04 - val_accuracy: 0.9828\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5205e-04 - accuracy: 0.9689 - val_loss: 8.2927e-04 - val_accuracy: 0.9483\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 926us/step - loss: 6.8714e-04 - accuracy: 0.9831 - val_loss: 9.6860e-04 - val_accuracy: 0.9483\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6662e-04 - accuracy: 0.9736 - val_loss: 8.8006e-04 - val_accuracy: 0.9483\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0443e-04 - accuracy: 0.9625 - val_loss: 8.9830e-04 - val_accuracy: 0.9483\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0822e-04 - accuracy: 0.9687 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0782e-04 - accuracy: 0.9755 - val_loss: 8.6477e-04 - val_accuracy: 0.9828\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5924e-04 - accuracy: 0.9759 - val_loss: 8.8206e-04 - val_accuracy: 0.9483\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 994us/step - loss: 7.0695e-04 - accuracy: 0.9797 - val_loss: 7.7132e-04 - val_accuracy: 0.9828\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 929us/step - loss: 6.4518e-04 - accuracy: 0.9680 - val_loss: 9.5171e-04 - val_accuracy: 0.9655\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5798e-04 - accuracy: 0.9767 - val_loss: 7.0615e-04 - val_accuracy: 0.9828\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8479e-04 - accuracy: 0.9920 - val_loss: 7.2302e-04 - val_accuracy: 0.9828\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 868us/step - loss: 6.6342e-04 - accuracy: 0.9780 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4320e-04 - accuracy: 0.9793 - val_loss: 8.9393e-04 - val_accuracy: 0.9483\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 978us/step - loss: 9.4498e-04 - accuracy: 0.9907 - val_loss: 9.5739e-04 - val_accuracy: 0.9310\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 991us/step - loss: 0.0011 - accuracy: 0.9599 - val_loss: 9.5800e-04 - val_accuracy: 0.9828\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8262e-04 - accuracy: 0.9808 - val_loss: 7.8317e-04 - val_accuracy: 0.9655\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 993us/step - loss: 6.6523e-04 - accuracy: 0.9703 - val_loss: 7.9541e-04 - val_accuracy: 0.9483\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6077e-04 - accuracy: 0.9840 - val_loss: 8.8269e-04 - val_accuracy: 0.9483\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 919us/step - loss: 8.0530e-04 - accuracy: 0.9733 - val_loss: 8.8817e-04 - val_accuracy: 0.9655\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 981us/step - loss: 5.5791e-04 - accuracy: 0.9766 - val_loss: 8.9435e-04 - val_accuracy: 0.9483\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 761us/step - loss: 6.3049e-04 - accuracy: 0.9754 - val_loss: 7.6740e-04 - val_accuracy: 0.9828\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.5250e-04 - accuracy: 0.9811 - val_loss: 8.4232e-04 - val_accuracy: 0.9483\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 979us/step - loss: 7.3129e-04 - accuracy: 0.9777 - val_loss: 8.1793e-04 - val_accuracy: 0.9483\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.4281e-04 - accuracy: 0.9637 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 979us/step - loss: 5.7857e-04 - accuracy: 0.9832 - val_loss: 7.6111e-04 - val_accuracy: 0.9828\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9171e-04 - accuracy: 0.9854 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 856us/step - loss: 7.5118e-04 - accuracy: 0.9861 - val_loss: 7.7460e-04 - val_accuracy: 0.9483\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 972us/step - loss: 7.2155e-04 - accuracy: 0.9762 - val_loss: 9.0858e-04 - val_accuracy: 0.9655\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1014e-04 - accuracy: 0.9928 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 992us/step - loss: 9.7596e-04 - accuracy: 0.9686 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6298e-04 - accuracy: 0.9817 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3688e-04 - accuracy: 0.9779 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5024e-04 - accuracy: 0.9719 - val_loss: 8.5708e-04 - val_accuracy: 0.9828\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5215e-04 - accuracy: 0.9734 - val_loss: 7.1919e-04 - val_accuracy: 0.9828\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5171e-04 - accuracy: 0.9873 - val_loss: 9.8963e-04 - val_accuracy: 0.9655\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2088e-04 - accuracy: 0.9770 - val_loss: 7.0681e-04 - val_accuracy: 0.9483\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9543e-04 - accuracy: 0.9761 - val_loss: 9.4276e-04 - val_accuracy: 0.9483\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2613e-04 - accuracy: 0.9813 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 981us/step - loss: 9.1997e-04 - accuracy: 0.9675 - val_loss: 8.0570e-04 - val_accuracy: 0.9655\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 835us/step - loss: 0.0010 - accuracy: 0.9835 - val_loss: 7.5418e-04 - val_accuracy: 0.9483\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9152e-04 - accuracy: 0.9624 - val_loss: 9.1729e-04 - val_accuracy: 0.9655\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0126e-04 - accuracy: 0.9803 - val_loss: 6.6576e-04 - val_accuracy: 0.9828\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4233e-04 - accuracy: 0.9881 - val_loss: 6.7821e-04 - val_accuracy: 0.9828\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 844us/step - loss: 7.7079e-04 - accuracy: 0.9778 - val_loss: 7.5539e-04 - val_accuracy: 0.9828\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9779e-04 - accuracy: 0.9830 - val_loss: 6.9054e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8371e-04 - accuracy: 0.9845 - val_loss: 8.1764e-04 - val_accuracy: 0.9483\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 877us/step - loss: 7.3959e-04 - accuracy: 0.9792 - val_loss: 7.2444e-04 - val_accuracy: 0.9828\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8590e-04 - accuracy: 0.9780 - val_loss: 8.5287e-04 - val_accuracy: 0.9655\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8005e-04 - accuracy: 0.9805 - val_loss: 8.9916e-04 - val_accuracy: 0.9310\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1674e-04 - accuracy: 0.9806 - val_loss: 7.8789e-04 - val_accuracy: 0.9828\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0186e-04 - accuracy: 0.9873 - val_loss: 9.2074e-04 - val_accuracy: 0.9828\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2118e-04 - accuracy: 0.9867 - val_loss: 6.9033e-04 - val_accuracy: 0.9483\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5028e-04 - accuracy: 0.9824 - val_loss: 6.3915e-04 - val_accuracy: 0.9655\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7490e-04 - accuracy: 0.9789 - val_loss: 7.2303e-04 - val_accuracy: 0.9655\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4302e-04 - accuracy: 0.9806 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8156e-04 - accuracy: 0.9952 - val_loss: 9.5493e-04 - val_accuracy: 0.9655\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 957us/step - loss: 5.9560e-04 - accuracy: 0.9856 - val_loss: 8.3208e-04 - val_accuracy: 0.9828\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3330e-04 - accuracy: 0.9859 - val_loss: 6.5313e-04 - val_accuracy: 0.9828\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3700e-04 - accuracy: 0.9929 - val_loss: 6.9409e-04 - val_accuracy: 0.9483\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8386e-04 - accuracy: 0.9863 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 966us/step - loss: 0.0012 - accuracy: 0.9604 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7963e-04 - accuracy: 0.9884 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9140e-04 - accuracy: 0.9889 - val_loss: 6.5257e-04 - val_accuracy: 0.9483\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6648e-04 - accuracy: 0.9830 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3032e-04 - accuracy: 0.9959 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 885us/step - loss: 7.9450e-04 - accuracy: 0.9757 - val_loss: 8.3334e-04 - val_accuracy: 0.9483\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8443e-04 - accuracy: 0.9774 - val_loss: 6.4842e-04 - val_accuracy: 0.9483\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 913us/step - loss: 6.0943e-04 - accuracy: 0.9735 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5969e-04 - accuracy: 0.9772 - val_loss: 8.9678e-04 - val_accuracy: 0.9483\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2620e-04 - accuracy: 0.9852 - val_loss: 7.5987e-04 - val_accuracy: 0.9483\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3279e-04 - accuracy: 0.9855 - val_loss: 6.5649e-04 - val_accuracy: 0.9483\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7675e-04 - accuracy: 0.9862 - val_loss: 7.1803e-04 - val_accuracy: 0.9483\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8363e-04 - accuracy: 0.9884 - val_loss: 9.5038e-04 - val_accuracy: 0.9655\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3241e-04 - accuracy: 0.9754 - val_loss: 8.1540e-04 - val_accuracy: 0.9310\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 993us/step - loss: 5.7601e-04 - accuracy: 0.9866 - val_loss: 9.8408e-04 - val_accuracy: 0.9655\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0874e-04 - accuracy: 0.9817 - val_loss: 7.6618e-04 - val_accuracy: 0.9483\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7840e-04 - accuracy: 0.9829 - val_loss: 7.6940e-04 - val_accuracy: 0.9655\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7657e-04 - accuracy: 0.9835 - val_loss: 8.2846e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8056e-04 - accuracy: 0.9795 - val_loss: 5.9509e-04 - val_accuracy: 0.9655\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9950e-04 - accuracy: 0.9851 - val_loss: 8.0162e-04 - val_accuracy: 0.9483\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7585e-04 - accuracy: 0.9814 - val_loss: 7.4537e-04 - val_accuracy: 0.9483\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2846e-04 - accuracy: 0.9937 - val_loss: 9.0910e-04 - val_accuracy: 0.9655\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0020e-04 - accuracy: 0.9790 - val_loss: 8.1477e-04 - val_accuracy: 0.9483\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1037e-04 - accuracy: 0.9785 - val_loss: 6.1602e-04 - val_accuracy: 0.9655\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8913e-04 - accuracy: 0.9825 - val_loss: 7.8569e-04 - val_accuracy: 0.9310\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7501e-04 - accuracy: 0.9826 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9665 - val_loss: 7.4108e-04 - val_accuracy: 0.9828\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6806e-04 - accuracy: 0.9869 - val_loss: 7.4837e-04 - val_accuracy: 0.9483\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9781e-04 - accuracy: 0.9773 - val_loss: 6.1982e-04 - val_accuracy: 0.9655\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1660e-04 - accuracy: 0.9860 - val_loss: 9.2700e-04 - val_accuracy: 0.9483\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8301e-04 - accuracy: 0.9942 - val_loss: 6.6553e-04 - val_accuracy: 0.9483\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1225e-04 - accuracy: 0.9941 - val_loss: 7.6098e-04 - val_accuracy: 0.9828\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7348e-04 - accuracy: 0.9896 - val_loss: 7.8661e-04 - val_accuracy: 0.9655\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2451e-04 - accuracy: 0.9850 - val_loss: 7.1231e-04 - val_accuracy: 0.9483\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1923e-04 - accuracy: 0.9786 - val_loss: 7.3681e-04 - val_accuracy: 0.9655\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7837e-04 - accuracy: 0.9856 - val_loss: 7.3789e-04 - val_accuracy: 0.9655\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4177e-04 - accuracy: 0.9872 - val_loss: 6.0272e-04 - val_accuracy: 0.9483\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3711e-04 - accuracy: 0.9855 - val_loss: 7.2815e-04 - val_accuracy: 0.9310\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1855e-04 - accuracy: 0.9876 - val_loss: 7.3378e-04 - val_accuracy: 0.9655\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.3023e-04 - accuracy: 0.9865 - val_loss: 8.4665e-04 - val_accuracy: 0.9655\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5162e-04 - accuracy: 0.9623 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.7951e-04 - accuracy: 0.9685 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9655\n",
            "Loss = 0.0012650860007852316, Accuracy = 0.9655172228813171\n",
            "Loss array:  [0.0005480118561536074, 0.0014485771534964442, 0.0007545604603365064, 0.0012650860007852316]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 5/10\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.6926 - val_loss: 0.0301 - val_accuracy: 0.8966\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.8547 - val_loss: 0.0168 - val_accuracy: 0.9310\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.8923 - val_loss: 0.0119 - val_accuracy: 0.9483\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 0.9035 - val_loss: 0.0081 - val_accuracy: 0.9483\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9078 - val_loss: 0.0067 - val_accuracy: 0.9483\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9260 - val_loss: 0.0048 - val_accuracy: 0.9483\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 0.9317 - val_loss: 0.0039 - val_accuracy: 0.9483\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 0.9238 - val_loss: 0.0034 - val_accuracy: 0.9483\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.9296 - val_loss: 0.0034 - val_accuracy: 0.9483\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.9323 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.9263 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9465 - val_loss: 0.0031 - val_accuracy: 0.9138\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9437 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9367 - val_loss: 0.0028 - val_accuracy: 0.8966\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 0.9537 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.9409 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.9289 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9437 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9374 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.9455 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9482 - val_loss: 0.0025 - val_accuracy: 0.8966\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9412 - val_loss: 0.0021 - val_accuracy: 0.8966\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9591 - val_loss: 0.0019 - val_accuracy: 0.9138\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9491 - val_loss: 0.0027 - val_accuracy: 0.9138\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9645 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9439 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9422 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9402 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9549 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9738 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9688 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 954us/step - loss: 0.0017 - accuracy: 0.9588 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9594 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9728 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9724 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9660 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9639 - val_loss: 0.0029 - val_accuracy: 0.9138\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9668 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9679 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9726 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9608 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9639 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9739 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9796 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9610 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9867 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9654 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9756 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9678 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9653 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9712 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9821 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9745 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.5630e-04 - accuracy: 0.9792 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0211e-04 - accuracy: 0.9787 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9688 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9839 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2600e-04 - accuracy: 0.9769 - val_loss: 9.3783e-04 - val_accuracy: 0.9655\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.9584e-04 - accuracy: 0.9755 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9717 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.7679e-04 - accuracy: 0.9673 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9775 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2924e-04 - accuracy: 0.9795 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2617e-04 - accuracy: 0.9792 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.3261e-04 - accuracy: 0.9764 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1972e-04 - accuracy: 0.9887 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.4397e-04 - accuracy: 0.9826 - val_loss: 9.6134e-04 - val_accuracy: 0.9828\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1685e-04 - accuracy: 0.9824 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.4400e-04 - accuracy: 0.9885 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.9228e-04 - accuracy: 0.9826 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6123e-04 - accuracy: 0.9822 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.0617e-04 - accuracy: 0.9814 - val_loss: 0.0010 - val_accuracy: 0.9310\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8993e-04 - accuracy: 0.9811 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.4087e-04 - accuracy: 0.9778 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2330e-04 - accuracy: 0.9791 - val_loss: 9.2621e-04 - val_accuracy: 0.9828\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1328e-04 - accuracy: 0.9785 - val_loss: 9.3508e-04 - val_accuracy: 0.9655\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6276e-04 - accuracy: 0.9791 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 935us/step - loss: 7.4306e-04 - accuracy: 0.9863 - val_loss: 8.5058e-04 - val_accuracy: 0.9655\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2338e-04 - accuracy: 0.9831 - val_loss: 9.2875e-04 - val_accuracy: 0.9828\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1628e-04 - accuracy: 0.9870 - val_loss: 9.8906e-04 - val_accuracy: 0.9655\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0259e-04 - accuracy: 0.9732 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1580e-04 - accuracy: 0.9724 - val_loss: 9.3516e-04 - val_accuracy: 0.9655\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.6369e-04 - accuracy: 0.9689 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 887us/step - loss: 7.1485e-04 - accuracy: 0.9793 - val_loss: 8.7986e-04 - val_accuracy: 0.9655\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7262e-04 - accuracy: 0.9859 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 7.2307e-04 - accuracy: 0.9855 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7314e-04 - accuracy: 0.9759 - val_loss: 8.6076e-04 - val_accuracy: 0.9655\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.6021e-04 - accuracy: 0.9788 - val_loss: 8.7325e-04 - val_accuracy: 0.9655\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9359e-04 - accuracy: 0.9834 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5533e-04 - accuracy: 0.9689 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.7850e-04 - accuracy: 0.9742 - val_loss: 8.6264e-04 - val_accuracy: 0.9828\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5606e-04 - accuracy: 0.9856 - val_loss: 9.7332e-04 - val_accuracy: 0.9655\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1180e-04 - accuracy: 0.9691 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7557e-04 - accuracy: 0.9874 - val_loss: 8.8792e-04 - val_accuracy: 0.9655\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.9443e-04 - accuracy: 0.9779 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5563e-04 - accuracy: 0.9653 - val_loss: 9.5844e-04 - val_accuracy: 0.9655\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5736e-04 - accuracy: 0.9934 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8134e-04 - accuracy: 0.9624 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.6260e-04 - accuracy: 0.9785 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3462e-04 - accuracy: 0.9827 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8974e-04 - accuracy: 0.9762 - val_loss: 8.5304e-04 - val_accuracy: 0.9655\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8390e-04 - accuracy: 0.9820 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9137e-04 - accuracy: 0.9792 - val_loss: 9.4117e-04 - val_accuracy: 0.9655\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4579e-04 - accuracy: 0.9807 - val_loss: 9.1020e-04 - val_accuracy: 0.9655\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4284e-04 - accuracy: 0.9703 - val_loss: 8.7320e-04 - val_accuracy: 0.9655\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4874e-04 - accuracy: 0.9893 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9701e-04 - accuracy: 0.9849 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6151e-04 - accuracy: 0.9832 - val_loss: 9.4949e-04 - val_accuracy: 0.9655\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.2939e-04 - accuracy: 0.9848 - val_loss: 8.8737e-04 - val_accuracy: 0.9655\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4780e-04 - accuracy: 0.9800 - val_loss: 8.1739e-04 - val_accuracy: 0.9655\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1243e-04 - accuracy: 0.9659 - val_loss: 9.1582e-04 - val_accuracy: 0.9655\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7728e-04 - accuracy: 0.9823 - val_loss: 9.0777e-04 - val_accuracy: 0.9655\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0066e-04 - accuracy: 0.9879 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9995e-04 - accuracy: 0.9841 - val_loss: 8.4083e-04 - val_accuracy: 0.9828\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.0838e-04 - accuracy: 0.9876 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0732e-04 - accuracy: 0.9852 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4752e-04 - accuracy: 0.9922 - val_loss: 8.2172e-04 - val_accuracy: 0.9655\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9456e-04 - accuracy: 0.9877 - val_loss: 9.2796e-04 - val_accuracy: 0.9655\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4848e-04 - accuracy: 0.9983 - val_loss: 8.5565e-04 - val_accuracy: 0.9655\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 992us/step - loss: 5.0411e-04 - accuracy: 0.9921 - val_loss: 8.4357e-04 - val_accuracy: 0.9655\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8138e-04 - accuracy: 0.9884 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0216e-04 - accuracy: 0.9741 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 962us/step - loss: 5.8119e-04 - accuracy: 0.9944 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8914e-04 - accuracy: 0.9815 - val_loss: 8.3695e-04 - val_accuracy: 0.9655\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4559e-04 - accuracy: 0.9892 - val_loss: 9.4498e-04 - val_accuracy: 0.9655\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5060e-04 - accuracy: 0.9833 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6906e-04 - accuracy: 0.9882 - val_loss: 9.2078e-04 - val_accuracy: 0.9655\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6217e-04 - accuracy: 0.9842 - val_loss: 9.0362e-04 - val_accuracy: 0.9655\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7561e-04 - accuracy: 0.9816 - val_loss: 9.1049e-04 - val_accuracy: 0.9483\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1026e-04 - accuracy: 0.9920 - val_loss: 9.6182e-04 - val_accuracy: 0.9655\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9979e-04 - accuracy: 0.9863 - val_loss: 9.5111e-04 - val_accuracy: 0.9655\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0940e-04 - accuracy: 0.9781 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6441e-04 - accuracy: 0.9886 - val_loss: 8.6035e-04 - val_accuracy: 0.9655\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5398e-04 - accuracy: 0.9947 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9793 - val_loss: 8.4337e-04 - val_accuracy: 0.9655\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4131e-04 - accuracy: 0.9927 - val_loss: 8.8479e-04 - val_accuracy: 0.9655\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7463e-04 - accuracy: 0.9789 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.6099e-04 - accuracy: 0.9884 - val_loss: 9.4984e-04 - val_accuracy: 0.9828\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.6208e-04 - accuracy: 0.9845 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1844e-04 - accuracy: 0.9728 - val_loss: 8.9687e-04 - val_accuracy: 0.9655\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8674e-04 - accuracy: 0.9812 - val_loss: 8.4834e-04 - val_accuracy: 0.9655\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9480e-04 - accuracy: 0.9888 - val_loss: 9.1629e-04 - val_accuracy: 0.9655\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1529e-04 - accuracy: 0.9870 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0125e-04 - accuracy: 0.9797 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6037e-04 - accuracy: 0.9861 - val_loss: 8.9260e-04 - val_accuracy: 0.9655\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6140e-04 - accuracy: 0.9747 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2502e-04 - accuracy: 0.9807 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0257e-04 - accuracy: 0.9781 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6829e-04 - accuracy: 0.9755 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5586e-04 - accuracy: 0.9768 - val_loss: 8.8678e-04 - val_accuracy: 0.9655\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1601e-04 - accuracy: 0.9899 - val_loss: 9.9262e-04 - val_accuracy: 0.9655\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3162e-04 - accuracy: 0.9938 - val_loss: 8.6204e-04 - val_accuracy: 0.9655\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9309e-04 - accuracy: 0.9867 - val_loss: 9.7332e-04 - val_accuracy: 0.9828\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1729e-04 - accuracy: 0.9817 - val_loss: 9.8015e-04 - val_accuracy: 0.9655\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5615e-04 - accuracy: 0.9822 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7172e-04 - accuracy: 0.9891 - val_loss: 9.0691e-04 - val_accuracy: 0.9655\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5797e-04 - accuracy: 0.9828 - val_loss: 8.7355e-04 - val_accuracy: 0.9655\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2641e-04 - accuracy: 0.9909 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.7844e-04 - accuracy: 0.9844 - val_loss: 9.6520e-04 - val_accuracy: 0.9828\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.7659e-04 - accuracy: 0.9936 - val_loss: 7.9367e-04 - val_accuracy: 0.9655\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5239e-04 - accuracy: 0.9911 - val_loss: 9.2854e-04 - val_accuracy: 0.9655\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1091e-04 - accuracy: 0.9943 - val_loss: 8.3887e-04 - val_accuracy: 0.9655\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2105e-04 - accuracy: 0.9892 - val_loss: 8.2407e-04 - val_accuracy: 0.9655\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9365e-04 - accuracy: 0.9914 - val_loss: 9.4845e-04 - val_accuracy: 0.9655\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3850e-04 - accuracy: 0.9774 - val_loss: 9.3844e-04 - val_accuracy: 0.9655\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1762e-04 - accuracy: 0.9850 - val_loss: 8.5817e-04 - val_accuracy: 0.9655\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3481e-04 - accuracy: 0.9729 - val_loss: 8.7152e-04 - val_accuracy: 0.9655\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5983e-04 - accuracy: 0.9844 - val_loss: 8.6695e-04 - val_accuracy: 0.9828\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3191e-04 - accuracy: 0.9808 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2420e-04 - accuracy: 0.9847 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.8895e-04 - accuracy: 0.9930 - val_loss: 8.1526e-04 - val_accuracy: 0.9655\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.7841e-04 - accuracy: 0.9794 - val_loss: 8.9453e-04 - val_accuracy: 0.9483\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.3808e-04 - accuracy: 0.9928 - val_loss: 9.3059e-04 - val_accuracy: 0.9655\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7473e-04 - accuracy: 0.9856 - val_loss: 9.0683e-04 - val_accuracy: 0.9655\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.3040e-04 - accuracy: 0.9781 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2579e-04 - accuracy: 0.9776 - val_loss: 7.9968e-04 - val_accuracy: 0.9655\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1580e-04 - accuracy: 0.9800 - val_loss: 9.1911e-04 - val_accuracy: 0.9655\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9835e-04 - accuracy: 0.9914 - val_loss: 7.5683e-04 - val_accuracy: 0.9655\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5352e-04 - accuracy: 0.9851 - val_loss: 8.2915e-04 - val_accuracy: 0.9483\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7165e-04 - accuracy: 0.9863 - val_loss: 8.2591e-04 - val_accuracy: 0.9655\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7671e-04 - accuracy: 0.9943 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4656e-04 - accuracy: 0.9714 - val_loss: 9.9890e-04 - val_accuracy: 0.9655\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.5489e-04 - accuracy: 0.9929 - val_loss: 9.8067e-04 - val_accuracy: 0.9655\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7912e-04 - accuracy: 0.9838 - val_loss: 9.1334e-04 - val_accuracy: 0.9655\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3128e-04 - accuracy: 0.9904 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "6/6 [==============================] - 0s 379us/step - loss: 0.0010 - accuracy: 0.9828\n",
            "Loss = 0.0010126866400241852, Accuracy = 0.982758641242981\n",
            "Loss array:  [0.0005480118561536074, 0.0014485771534964442, 0.0007545604603365064, 0.0012650860007852316, 0.0010126866400241852]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 6/10\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.4701 - val_loss: 0.0257 - val_accuracy: 0.9138\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.8442 - val_loss: 0.0173 - val_accuracy: 0.8793\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.8452 - val_loss: 0.0142 - val_accuracy: 0.8966\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 974us/step - loss: 0.0133 - accuracy: 0.8838 - val_loss: 0.0112 - val_accuracy: 0.8793\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 0.9204 - val_loss: 0.0096 - val_accuracy: 0.8966\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 0.9177 - val_loss: 0.0083 - val_accuracy: 0.9310\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9203 - val_loss: 0.0071 - val_accuracy: 0.9310\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 0.9431 - val_loss: 0.0067 - val_accuracy: 0.9310\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9209 - val_loss: 0.0057 - val_accuracy: 0.9310\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.9211 - val_loss: 0.0054 - val_accuracy: 0.9310\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.9448 - val_loss: 0.0049 - val_accuracy: 0.9310\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 0.9393 - val_loss: 0.0054 - val_accuracy: 0.8793\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9298 - val_loss: 0.0046 - val_accuracy: 0.9138\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 0.9182 - val_loss: 0.0042 - val_accuracy: 0.9310\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9428 - val_loss: 0.0042 - val_accuracy: 0.9310\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.9053 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 0.9490 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.9485 - val_loss: 0.0054 - val_accuracy: 0.9483\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9294 - val_loss: 0.0034 - val_accuracy: 0.9310\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.9422 - val_loss: 0.0036 - val_accuracy: 0.8966\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9473 - val_loss: 0.0035 - val_accuracy: 0.9310\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9611 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9460 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9668 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9486 - val_loss: 0.0026 - val_accuracy: 0.9310\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9617 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9501 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9584 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9551 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9615 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9473 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9488 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9482 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9725 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.9789 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9565 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9634 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9565 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9588 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9523 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.9706 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9549 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.9797 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9449 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9553 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9553 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9565 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9681 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9677 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9600 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.2473e-04 - accuracy: 0.9727 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9567 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.4976e-04 - accuracy: 0.9688 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9599 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.2434e-04 - accuracy: 0.9682 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.8022e-04 - accuracy: 0.9817 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.8995e-04 - accuracy: 0.9625 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.3101e-04 - accuracy: 0.9751 - val_loss: 9.5324e-04 - val_accuracy: 0.9655\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.6590e-04 - accuracy: 0.9758 - val_loss: 9.6456e-04 - val_accuracy: 0.9483\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9807 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9777 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9698 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.0820e-04 - accuracy: 0.9689 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.1384e-04 - accuracy: 0.9698 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.7168e-04 - accuracy: 0.9613 - val_loss: 9.5809e-04 - val_accuracy: 0.9483\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2156e-04 - accuracy: 0.9829 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9800 - val_loss: 9.9004e-04 - val_accuracy: 0.9483\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.0480e-04 - accuracy: 0.9875 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.8364e-04 - accuracy: 0.9767 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.7758e-04 - accuracy: 0.9848 - val_loss: 8.8018e-04 - val_accuracy: 0.9828\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.0704e-04 - accuracy: 0.9721 - val_loss: 9.8945e-04 - val_accuracy: 0.9655\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9752 - val_loss: 9.1776e-04 - val_accuracy: 0.9483\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.6729e-04 - accuracy: 0.9816 - val_loss: 9.3593e-04 - val_accuracy: 0.9483\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.0565e-04 - accuracy: 0.9713 - val_loss: 9.9462e-04 - val_accuracy: 0.9828\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.4456e-04 - accuracy: 0.9916 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.5009e-04 - accuracy: 0.9817 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.3762e-04 - accuracy: 0.9712 - val_loss: 9.7212e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.8693e-04 - accuracy: 0.9666 - val_loss: 7.5427e-04 - val_accuracy: 0.9655\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.9578e-04 - accuracy: 0.9576 - val_loss: 8.7886e-04 - val_accuracy: 0.9483\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0893e-04 - accuracy: 0.9777 - val_loss: 9.4298e-04 - val_accuracy: 0.9655\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1734e-04 - accuracy: 0.9881 - val_loss: 8.7782e-04 - val_accuracy: 0.9655\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0979e-04 - accuracy: 0.9848 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5104e-04 - accuracy: 0.9748 - val_loss: 8.9101e-04 - val_accuracy: 0.9655\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.9976e-04 - accuracy: 0.9923 - val_loss: 9.1756e-04 - val_accuracy: 0.9655\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2004e-04 - accuracy: 0.9707 - val_loss: 7.8841e-04 - val_accuracy: 0.9828\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6047e-04 - accuracy: 0.9845 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.0710e-04 - accuracy: 0.9707 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.3583e-04 - accuracy: 0.9799 - val_loss: 8.4697e-04 - val_accuracy: 0.9828\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2401e-04 - accuracy: 0.9794 - val_loss: 9.5050e-04 - val_accuracy: 0.9655\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1891e-04 - accuracy: 0.9834 - val_loss: 7.9105e-04 - val_accuracy: 0.9828\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4002e-04 - accuracy: 0.9858 - val_loss: 7.0813e-04 - val_accuracy: 0.9828\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.7015e-04 - accuracy: 0.9839 - val_loss: 7.8178e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5766e-04 - accuracy: 0.9788 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9764 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.5611e-04 - accuracy: 0.9649 - val_loss: 8.3098e-04 - val_accuracy: 0.9655\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.9450e-04 - accuracy: 0.9810 - val_loss: 9.3373e-04 - val_accuracy: 0.9655\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.8650e-04 - accuracy: 0.9937 - val_loss: 7.7847e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2135e-04 - accuracy: 0.9861 - val_loss: 8.6472e-04 - val_accuracy: 0.9828\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2376e-04 - accuracy: 0.9837 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3996e-04 - accuracy: 0.9793 - val_loss: 9.8163e-04 - val_accuracy: 0.9655\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.6391e-04 - accuracy: 0.9802 - val_loss: 9.0550e-04 - val_accuracy: 0.9655\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.7446e-04 - accuracy: 0.9840 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.3083e-04 - accuracy: 0.9775 - val_loss: 8.0017e-04 - val_accuracy: 0.9828\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1488e-04 - accuracy: 0.9886 - val_loss: 8.6533e-04 - val_accuracy: 0.9655\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9897e-04 - accuracy: 0.9976 - val_loss: 8.4610e-04 - val_accuracy: 0.9655\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1676e-04 - accuracy: 0.9917 - val_loss: 9.1012e-04 - val_accuracy: 0.9483\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.9137e-04 - accuracy: 0.9740 - val_loss: 9.8893e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9887 - val_loss: 7.5298e-04 - val_accuracy: 0.9828\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0736e-04 - accuracy: 0.9867 - val_loss: 8.7230e-04 - val_accuracy: 0.9828\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7414e-04 - accuracy: 0.9870 - val_loss: 6.9346e-04 - val_accuracy: 0.9655\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3153e-04 - accuracy: 0.9857 - val_loss: 8.8767e-04 - val_accuracy: 0.9828\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0392e-04 - accuracy: 0.9908 - val_loss: 7.1717e-04 - val_accuracy: 0.9655\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.6048e-04 - accuracy: 0.9785 - val_loss: 8.5707e-04 - val_accuracy: 0.9828\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3558e-04 - accuracy: 0.9877 - val_loss: 7.1477e-04 - val_accuracy: 0.9655\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5824e-04 - accuracy: 0.9959 - val_loss: 7.4864e-04 - val_accuracy: 0.9483\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.2821e-04 - accuracy: 0.9967 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.0594e-04 - accuracy: 0.9817 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.3876e-04 - accuracy: 0.9686 - val_loss: 7.2394e-04 - val_accuracy: 0.9828\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0656e-04 - accuracy: 0.9978 - val_loss: 7.2574e-04 - val_accuracy: 0.9655\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9267e-04 - accuracy: 0.9937 - val_loss: 6.6736e-04 - val_accuracy: 0.9655\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7467e-04 - accuracy: 0.9874 - val_loss: 7.1893e-04 - val_accuracy: 0.9828\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6209e-04 - accuracy: 0.9854 - val_loss: 6.1196e-04 - val_accuracy: 0.9828\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1187e-04 - accuracy: 0.9942 - val_loss: 6.0932e-04 - val_accuracy: 0.9655\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6930e-04 - accuracy: 0.9821 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5407e-04 - accuracy: 0.9874 - val_loss: 9.1899e-04 - val_accuracy: 0.9655\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5006e-04 - accuracy: 0.9962 - val_loss: 8.0580e-04 - val_accuracy: 0.9483\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8640e-04 - accuracy: 0.9812 - val_loss: 7.0334e-04 - val_accuracy: 0.9828\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6804e-04 - accuracy: 0.9893 - val_loss: 7.7969e-04 - val_accuracy: 0.9655\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4444e-04 - accuracy: 0.9871 - val_loss: 7.4237e-04 - val_accuracy: 0.9828\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1396e-04 - accuracy: 0.9956 - val_loss: 9.5097e-04 - val_accuracy: 0.9828\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 996us/step - loss: 6.6913e-04 - accuracy: 0.9821 - val_loss: 8.5804e-04 - val_accuracy: 0.9655\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0182e-04 - accuracy: 0.9833 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3611e-04 - accuracy: 0.9844 - val_loss: 8.4281e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4163e-04 - accuracy: 0.9938 - val_loss: 7.0752e-04 - val_accuracy: 0.9828\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5969e-04 - accuracy: 0.9814 - val_loss: 7.0171e-04 - val_accuracy: 0.9655\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5625e-04 - accuracy: 0.9848 - val_loss: 9.0453e-04 - val_accuracy: 0.9655\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9126e-04 - accuracy: 0.9586 - val_loss: 6.2554e-04 - val_accuracy: 0.9483\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4550e-04 - accuracy: 0.9949 - val_loss: 7.6763e-04 - val_accuracy: 0.9828\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1899e-04 - accuracy: 0.9867 - val_loss: 6.4027e-04 - val_accuracy: 0.9655\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2925e-04 - accuracy: 0.9754 - val_loss: 7.1859e-04 - val_accuracy: 0.9828\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4455e-04 - accuracy: 0.9911 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2265e-04 - accuracy: 0.9899 - val_loss: 8.9434e-04 - val_accuracy: 0.9483\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4785e-04 - accuracy: 0.9865 - val_loss: 8.9175e-04 - val_accuracy: 0.9655\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9172e-04 - accuracy: 0.9908 - val_loss: 6.9090e-04 - val_accuracy: 0.9828\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0983e-04 - accuracy: 0.9816 - val_loss: 8.3944e-04 - val_accuracy: 0.9655\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0440e-04 - accuracy: 0.9945 - val_loss: 6.7864e-04 - val_accuracy: 0.9828\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 955us/step - loss: 5.4325e-04 - accuracy: 0.9921 - val_loss: 7.2637e-04 - val_accuracy: 0.9655\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1853e-04 - accuracy: 0.9518 - val_loss: 7.1346e-04 - val_accuracy: 0.9828\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 5.8770e-04 - accuracy: 0.9788 - val_loss: 8.0391e-04 - val_accuracy: 0.9655\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4932e-04 - accuracy: 0.9798 - val_loss: 9.1406e-04 - val_accuracy: 0.9655\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 6.6569e-04 - accuracy: 0.9857 - val_loss: 8.5494e-04 - val_accuracy: 0.9483\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7656e-04 - accuracy: 0.9881 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 992us/step - loss: 6.7848e-04 - accuracy: 0.9942 - val_loss: 9.5622e-04 - val_accuracy: 0.9483\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6651e-04 - accuracy: 0.9854 - val_loss: 7.0886e-04 - val_accuracy: 0.9655\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7659e-04 - accuracy: 0.9931 - val_loss: 9.3547e-04 - val_accuracy: 0.9655\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2652e-04 - accuracy: 0.9798 - val_loss: 8.9044e-04 - val_accuracy: 0.9655\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4767e-04 - accuracy: 0.9874 - val_loss: 7.9515e-04 - val_accuracy: 0.9655\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7218e-04 - accuracy: 0.9965 - val_loss: 7.1379e-04 - val_accuracy: 0.9828\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3673e-04 - accuracy: 0.9940 - val_loss: 7.5087e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0819e-04 - accuracy: 0.9768 - val_loss: 9.3137e-04 - val_accuracy: 0.9655\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8294e-04 - accuracy: 0.9881 - val_loss: 6.3180e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4289e-04 - accuracy: 0.9960 - val_loss: 6.4116e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4355e-04 - accuracy: 0.9894 - val_loss: 9.0080e-04 - val_accuracy: 0.9483\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3305e-04 - accuracy: 0.9870 - val_loss: 8.8451e-04 - val_accuracy: 0.9483\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 968us/step - loss: 5.8621e-04 - accuracy: 0.9788 - val_loss: 7.3972e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 970us/step - loss: 5.8739e-04 - accuracy: 0.9837 - val_loss: 6.4835e-04 - val_accuracy: 0.9655\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 955us/step - loss: 5.2772e-04 - accuracy: 0.9895 - val_loss: 6.3814e-04 - val_accuracy: 0.9828\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5915e-04 - accuracy: 0.9954 - val_loss: 7.2449e-04 - val_accuracy: 0.9655\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5670e-04 - accuracy: 0.9994 - val_loss: 8.8967e-04 - val_accuracy: 0.9483\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4939e-04 - accuracy: 0.9817 - val_loss: 6.8878e-04 - val_accuracy: 0.9828\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1070e-04 - accuracy: 0.9710 - val_loss: 7.0467e-04 - val_accuracy: 0.9828\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9908e-04 - accuracy: 0.9883 - val_loss: 5.8580e-04 - val_accuracy: 0.9828\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8992e-04 - accuracy: 0.9923 - val_loss: 6.9018e-04 - val_accuracy: 1.0000\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2382e-04 - accuracy: 0.9976 - val_loss: 8.6095e-04 - val_accuracy: 0.9655\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9551e-04 - accuracy: 0.9841 - val_loss: 6.6397e-04 - val_accuracy: 0.9655\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 936us/step - loss: 4.4558e-04 - accuracy: 0.9894 - val_loss: 6.7352e-04 - val_accuracy: 0.9828\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6863e-04 - accuracy: 0.9846 - val_loss: 6.5047e-04 - val_accuracy: 0.9828\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.0893e-04 - accuracy: 0.9893 - val_loss: 7.0154e-04 - val_accuracy: 0.9828\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7252e-04 - accuracy: 0.9858 - val_loss: 8.8373e-04 - val_accuracy: 0.9828\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7779e-04 - accuracy: 0.9874 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7678e-04 - accuracy: 0.9893 - val_loss: 7.1092e-04 - val_accuracy: 1.0000\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1817e-04 - accuracy: 0.9986 - val_loss: 5.7833e-04 - val_accuracy: 1.0000\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.0836e-04 - accuracy: 0.9940 - val_loss: 5.9596e-04 - val_accuracy: 0.9828\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.3843e-04 - accuracy: 0.9960 - val_loss: 6.3859e-04 - val_accuracy: 1.0000\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.3159e-04 - accuracy: 0.9915 - val_loss: 6.8323e-04 - val_accuracy: 0.9655\n",
            "6/6 [==============================] - 0s 420us/step - loss: 6.8323e-04 - accuracy: 0.9655\n",
            "Loss = 0.0006832343642599881, Accuracy = 0.9655172228813171\n",
            "Loss array:  [0.0005480118561536074, 0.0014485771534964442, 0.0007545604603365064, 0.0012650860007852316, 0.0010126866400241852, 0.0006832343642599881]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 7/10\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.4790 - val_loss: 0.0389 - val_accuracy: 0.7586\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 967us/step - loss: 0.0250 - accuracy: 0.8305 - val_loss: 0.0240 - val_accuracy: 0.7931\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0193 - accuracy: 0.8255 - val_loss: 0.0222 - val_accuracy: 0.8103\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 960us/step - loss: 0.0149 - accuracy: 0.8339 - val_loss: 0.0198 - val_accuracy: 0.8103\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.8870 - val_loss: 0.0160 - val_accuracy: 0.8448\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 920us/step - loss: 0.0118 - accuracy: 0.9021 - val_loss: 0.0138 - val_accuracy: 0.8621\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9144 - val_loss: 0.0131 - val_accuracy: 0.8621\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.9188 - val_loss: 0.0103 - val_accuracy: 0.8966\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 0.9209 - val_loss: 0.0090 - val_accuracy: 0.8793\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 0.9367 - val_loss: 0.0080 - val_accuracy: 0.8966\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 986us/step - loss: 0.0061 - accuracy: 0.9409 - val_loss: 0.0085 - val_accuracy: 0.8793\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 0.9292 - val_loss: 0.0077 - val_accuracy: 0.8966\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 0.9399 - val_loss: 0.0062 - val_accuracy: 0.8966\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 830us/step - loss: 0.0052 - accuracy: 0.8940 - val_loss: 0.0072 - val_accuracy: 0.8793\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.9280 - val_loss: 0.0087 - val_accuracy: 0.8966\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.9247 - val_loss: 0.0060 - val_accuracy: 0.8966\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9459 - val_loss: 0.0055 - val_accuracy: 0.9138\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9479 - val_loss: 0.0067 - val_accuracy: 0.8966\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.9110 - val_loss: 0.0062 - val_accuracy: 0.8966\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 0.9408 - val_loss: 0.0060 - val_accuracy: 0.9138\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9321 - val_loss: 0.0064 - val_accuracy: 0.9138\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9400 - val_loss: 0.0046 - val_accuracy: 0.9138\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9274 - val_loss: 0.0042 - val_accuracy: 0.9138\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9106 - val_loss: 0.0046 - val_accuracy: 0.8966\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9216 - val_loss: 0.0042 - val_accuracy: 0.9310\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9526 - val_loss: 0.0051 - val_accuracy: 0.9310\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 994us/step - loss: 0.0029 - accuracy: 0.9253 - val_loss: 0.0042 - val_accuracy: 0.9310\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9373 - val_loss: 0.0038 - val_accuracy: 0.9655\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9151 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.9406 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 837us/step - loss: 0.0022 - accuracy: 0.9482 - val_loss: 0.0050 - val_accuracy: 0.9483\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9428 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9490 - val_loss: 0.0032 - val_accuracy: 0.9655\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9253 - val_loss: 0.0030 - val_accuracy: 0.9483\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9250 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 969us/step - loss: 0.0020 - accuracy: 0.9435 - val_loss: 0.0031 - val_accuracy: 0.9483\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9617 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9326 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9215 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9582 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9472 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9629 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9390 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9576 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9493 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9459 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9443 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9482 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9641 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 976us/step - loss: 0.0015 - accuracy: 0.9370 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9376 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9421 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9604 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9188 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9546 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 950us/step - loss: 0.0014 - accuracy: 0.9492 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9558 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9503 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 990us/step - loss: 0.0013 - accuracy: 0.9694 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9590 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9617 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9489 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9642 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9703 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9742 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9729 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9591 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9740 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9781 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9699 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9684 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9779 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2037e-04 - accuracy: 0.9767 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9812 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.4288e-04 - accuracy: 0.9890 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9745 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.8962e-04 - accuracy: 0.9681 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9715 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9772 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 998us/step - loss: 8.1496e-04 - accuracy: 0.9788 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0913e-04 - accuracy: 0.9767 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 975us/step - loss: 8.5937e-04 - accuracy: 0.9719 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 964us/step - loss: 7.0941e-04 - accuracy: 0.9664 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.3264e-04 - accuracy: 0.9904 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8424e-04 - accuracy: 0.9857 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.4738e-04 - accuracy: 0.9915 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 990us/step - loss: 9.0023e-04 - accuracy: 0.9578 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7570e-04 - accuracy: 0.9729 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.3695e-04 - accuracy: 0.9886 - val_loss: 9.7640e-04 - val_accuracy: 0.9828\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1586e-04 - accuracy: 0.9588 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.9056e-04 - accuracy: 0.9803 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3969e-04 - accuracy: 0.9820 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6821e-04 - accuracy: 0.9708 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 836us/step - loss: 9.4852e-04 - accuracy: 0.9724 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 8.4926e-04 - accuracy: 0.9825 - val_loss: 9.6025e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7972e-04 - accuracy: 0.9671 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9697 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1360e-04 - accuracy: 0.9793 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6703e-04 - accuracy: 0.9860 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1771e-04 - accuracy: 0.9820 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.8851e-04 - accuracy: 0.9788 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.5011e-04 - accuracy: 0.9752 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6184e-04 - accuracy: 0.9894 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.7291e-04 - accuracy: 0.9752 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9593e-04 - accuracy: 0.9798 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5901e-04 - accuracy: 0.9848 - val_loss: 9.7333e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7713e-04 - accuracy: 0.9641 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.6737e-04 - accuracy: 0.9841 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1470e-04 - accuracy: 0.9692 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1336e-04 - accuracy: 0.9691 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7318e-04 - accuracy: 0.9831 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1177e-04 - accuracy: 0.9840 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 7.1146e-04 - accuracy: 0.9835 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8767e-04 - accuracy: 0.9836 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5104e-04 - accuracy: 0.9774 - val_loss: 8.8922e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3465e-04 - accuracy: 0.9693 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9161e-04 - accuracy: 0.9843 - val_loss: 9.1392e-04 - val_accuracy: 0.9828\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8086e-04 - accuracy: 0.9749 - val_loss: 0.0034 - val_accuracy: 0.9828\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.0296e-04 - accuracy: 0.9783 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6107e-04 - accuracy: 0.9830 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6394e-04 - accuracy: 0.9797 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8526e-04 - accuracy: 0.9784 - val_loss: 9.4253e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5237e-04 - accuracy: 0.9819 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2504e-04 - accuracy: 0.9862 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6113e-04 - accuracy: 0.9719 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 961us/step - loss: 7.4670e-04 - accuracy: 0.9851 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9983e-04 - accuracy: 0.9872 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5131e-04 - accuracy: 0.9866 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6381e-04 - accuracy: 0.9863 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2648e-04 - accuracy: 0.9705 - val_loss: 9.3151e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3252e-04 - accuracy: 0.9856 - val_loss: 9.3235e-04 - val_accuracy: 0.9828\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 974us/step - loss: 5.9145e-04 - accuracy: 0.9785 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1989e-04 - accuracy: 0.9591 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9811 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.9424e-04 - accuracy: 0.9739 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.4219e-04 - accuracy: 0.9788 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 968us/step - loss: 6.2573e-04 - accuracy: 0.9911 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1383e-04 - accuracy: 0.9727 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1469e-04 - accuracy: 0.9745 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2561e-04 - accuracy: 0.9790 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 6.5044e-04 - accuracy: 0.9738 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8917e-04 - accuracy: 0.9660 - val_loss: 8.7073e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7549e-04 - accuracy: 0.9853 - val_loss: 8.8298e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6746e-04 - accuracy: 0.9704 - val_loss: 9.5576e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7854e-04 - accuracy: 0.9864 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2851e-04 - accuracy: 0.9882 - val_loss: 8.7923e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 993us/step - loss: 5.2948e-04 - accuracy: 0.9874 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6862e-04 - accuracy: 0.9829 - val_loss: 8.2757e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3040e-04 - accuracy: 0.9857 - val_loss: 8.5818e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5029e-04 - accuracy: 0.9864 - val_loss: 9.7062e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3285e-04 - accuracy: 0.9808 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0959e-04 - accuracy: 0.9908 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9119e-04 - accuracy: 0.9819 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3886e-04 - accuracy: 0.9890 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2992e-04 - accuracy: 0.9827 - val_loss: 8.6332e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1051e-04 - accuracy: 0.9833 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1571e-04 - accuracy: 0.9832 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4263e-04 - accuracy: 0.9855 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8569e-04 - accuracy: 0.9885 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2482e-04 - accuracy: 0.9673 - val_loss: 9.4575e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4114e-04 - accuracy: 0.9885 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8601e-04 - accuracy: 0.9631 - val_loss: 9.8110e-04 - val_accuracy: 0.9828\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6797e-04 - accuracy: 0.9877 - val_loss: 8.6969e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1411e-04 - accuracy: 0.9738 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7915e-04 - accuracy: 0.9832 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7138e-04 - accuracy: 0.9821 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8638e-04 - accuracy: 0.9914 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0340e-04 - accuracy: 0.9789 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9514e-04 - accuracy: 0.9882 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9348e-04 - accuracy: 0.9699 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2498e-04 - accuracy: 0.9770 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2566e-04 - accuracy: 0.9765 - val_loss: 9.9878e-04 - val_accuracy: 0.9828\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7283e-04 - accuracy: 0.9798 - val_loss: 9.2746e-04 - val_accuracy: 1.0000\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9246e-04 - accuracy: 0.9880 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1116e-04 - accuracy: 0.9791 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0560e-04 - accuracy: 0.9761 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0912e-04 - accuracy: 0.9837 - val_loss: 9.7123e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5955e-04 - accuracy: 0.9754 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9772e-04 - accuracy: 0.9870 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5023e-04 - accuracy: 0.9832 - val_loss: 8.2513e-04 - val_accuracy: 1.0000\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8793e-04 - accuracy: 0.9916 - val_loss: 9.9412e-04 - val_accuracy: 1.0000\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0083e-04 - accuracy: 0.9859 - val_loss: 8.9588e-04 - val_accuracy: 0.9828\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1087e-04 - accuracy: 0.9836 - val_loss: 8.4134e-04 - val_accuracy: 1.0000\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4842e-04 - accuracy: 0.9756 - val_loss: 8.5108e-04 - val_accuracy: 1.0000\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2650e-04 - accuracy: 0.9758 - val_loss: 9.5913e-04 - val_accuracy: 1.0000\n",
            "6/6 [==============================] - 0s 890us/step - loss: 9.5913e-04 - accuracy: 1.0000\n",
            "Loss = 0.0009591275011189282, Accuracy = 1.0\n",
            "Loss array:  [0.0005480118561536074, 0.0014485771534964442, 0.0007545604603365064, 0.0012650860007852316, 0.0010126866400241852, 0.0006832343642599881, 0.0009591275011189282]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 8/10\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.6876 - val_loss: 0.0432 - val_accuracy: 0.8448\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.7586 - val_loss: 0.0254 - val_accuracy: 0.8793\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.8292 - val_loss: 0.0207 - val_accuracy: 0.8276\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 915us/step - loss: 0.0213 - accuracy: 0.8465 - val_loss: 0.0175 - val_accuracy: 0.8276\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.8677 - val_loss: 0.0143 - val_accuracy: 0.8621\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.8678 - val_loss: 0.0113 - val_accuracy: 0.8966\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 0.8890 - val_loss: 0.0089 - val_accuracy: 0.9655\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 0.9032 - val_loss: 0.0075 - val_accuracy: 0.9655\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.9359 - val_loss: 0.0071 - val_accuracy: 0.9483\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 0.9188 - val_loss: 0.0069 - val_accuracy: 0.9483\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9324 - val_loss: 0.0054 - val_accuracy: 0.9655\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9194 - val_loss: 0.0051 - val_accuracy: 0.9655\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9310 - val_loss: 0.0056 - val_accuracy: 0.9483\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.8932 - val_loss: 0.0076 - val_accuracy: 0.8966\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9182 - val_loss: 0.0050 - val_accuracy: 0.9483\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9312 - val_loss: 0.0044 - val_accuracy: 0.9483\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9325 - val_loss: 0.0041 - val_accuracy: 0.9483\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9014 - val_loss: 0.0044 - val_accuracy: 0.9483\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 0.9071 - val_loss: 0.0055 - val_accuracy: 0.8966\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.9293 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9235 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9330 - val_loss: 0.0042 - val_accuracy: 0.9655\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 0.9301 - val_loss: 0.0035 - val_accuracy: 0.9483\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 978us/step - loss: 0.0031 - accuracy: 0.9246 - val_loss: 0.0043 - val_accuracy: 0.8966\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.9106 - val_loss: 0.0039 - val_accuracy: 0.9310\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9131 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9142 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9412 - val_loss: 0.0038 - val_accuracy: 0.8966\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9318 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.9294 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9443 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9353 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9245 - val_loss: 0.0032 - val_accuracy: 0.9138\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9207 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9415 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9211 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9377 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9189 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9350 - val_loss: 0.0043 - val_accuracy: 0.8793\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9355 - val_loss: 0.0030 - val_accuracy: 0.8966\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9336 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9346 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9429 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9564 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9317 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9264 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9217 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9381 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9399 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9442 - val_loss: 0.0028 - val_accuracy: 0.8966\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.9412 - val_loss: 0.0044 - val_accuracy: 0.8793\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9476 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9383 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9494 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 990us/step - loss: 0.0016 - accuracy: 0.9454 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9525 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9573 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9362 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.9430 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.9436 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9160 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 783us/step - loss: 0.0015 - accuracy: 0.9358 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9355 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9437 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9481 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9476 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9541 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9361 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9610 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9379 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9621 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9571 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9627 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9602 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9433 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9700 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9668 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9598 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9525 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9538 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.8454e-04 - accuracy: 0.9646 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9591 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9455 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.7564e-04 - accuracy: 0.9526 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 947us/step - loss: 0.0011 - accuracy: 0.9523 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9664 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9439 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9668 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9614 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9586 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.6928e-04 - accuracy: 0.9602 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9581 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9481 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 972us/step - loss: 8.7463e-04 - accuracy: 0.9557 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9689 - val_loss: 9.9272e-04 - val_accuracy: 0.9828\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.9040e-04 - accuracy: 0.9613 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.9832e-04 - accuracy: 0.9790 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9544 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.7888e-04 - accuracy: 0.9612 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.4342e-04 - accuracy: 0.9604 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.4788e-04 - accuracy: 0.9567 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.8636e-04 - accuracy: 0.9737 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.6287e-04 - accuracy: 0.9807 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6122e-04 - accuracy: 0.9618 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.7771e-04 - accuracy: 0.9621 - val_loss: 9.6374e-04 - val_accuracy: 0.9828\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 979us/step - loss: 8.9324e-04 - accuracy: 0.9699 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.0535e-04 - accuracy: 0.9651 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 986us/step - loss: 8.3520e-04 - accuracy: 0.9772 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.0286e-04 - accuracy: 0.9845 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.8979e-04 - accuracy: 0.9715 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 975us/step - loss: 8.9469e-04 - accuracy: 0.9738 - val_loss: 9.4788e-04 - val_accuracy: 0.9828\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0011 - accuracy: 0.9672 - val_loss: 9.4185e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.3402e-04 - accuracy: 0.9676 - val_loss: 8.5110e-04 - val_accuracy: 1.0000\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5183e-04 - accuracy: 0.9760 - val_loss: 9.3539e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1840e-04 - accuracy: 0.9633 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5844e-04 - accuracy: 0.9707 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.4565e-04 - accuracy: 0.9603 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9707 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.9031e-04 - accuracy: 0.9718 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.8604e-04 - accuracy: 0.9583 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2667e-04 - accuracy: 0.9644 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9654 - val_loss: 9.0963e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9033e-04 - accuracy: 0.9797 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5996e-04 - accuracy: 0.9758 - val_loss: 9.3378e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.7140e-04 - accuracy: 0.9600 - val_loss: 8.8858e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.8935e-04 - accuracy: 0.9613 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 971us/step - loss: 8.9807e-04 - accuracy: 0.9760 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 963us/step - loss: 8.0529e-04 - accuracy: 0.9605 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 983us/step - loss: 8.8663e-04 - accuracy: 0.9683 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.2118e-04 - accuracy: 0.9803 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.1905e-04 - accuracy: 0.9865 - val_loss: 9.7937e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7951e-04 - accuracy: 0.9825 - val_loss: 9.1851e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.6892e-04 - accuracy: 0.9822 - val_loss: 9.0520e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3888e-04 - accuracy: 0.9675 - val_loss: 9.5839e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2115e-04 - accuracy: 0.9777 - val_loss: 8.3202e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2882e-04 - accuracy: 0.9678 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7325e-04 - accuracy: 0.9754 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9714 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.3973e-04 - accuracy: 0.9839 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.7479e-04 - accuracy: 0.9792 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5897e-04 - accuracy: 0.9910 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2634e-04 - accuracy: 0.9731 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8438e-04 - accuracy: 0.9578 - val_loss: 9.1406e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3523e-04 - accuracy: 0.9740 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5263e-04 - accuracy: 0.9847 - val_loss: 9.9342e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5049e-04 - accuracy: 0.9738 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.8949e-04 - accuracy: 0.9825 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5934e-04 - accuracy: 0.9824 - val_loss: 8.3655e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.7933e-04 - accuracy: 0.9782 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8978e-04 - accuracy: 0.9880 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1045e-04 - accuracy: 0.9757 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0800e-04 - accuracy: 0.9771 - val_loss: 9.2009e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9256e-04 - accuracy: 0.9791 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0768e-04 - accuracy: 0.9738 - val_loss: 0.0031 - val_accuracy: 0.9138\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9571 - val_loss: 8.6277e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5908e-04 - accuracy: 0.9653 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7439e-04 - accuracy: 0.9892 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.8793e-04 - accuracy: 0.9852 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.9432e-04 - accuracy: 0.9750 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0398e-04 - accuracy: 0.9673 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4255e-04 - accuracy: 0.9785 - val_loss: 8.2186e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4074e-04 - accuracy: 0.9924 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5873e-04 - accuracy: 0.9674 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1911e-04 - accuracy: 0.9725 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7426e-04 - accuracy: 0.9844 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9060e-04 - accuracy: 0.9823 - val_loss: 8.6666e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.5412e-04 - accuracy: 0.9824 - val_loss: 8.6305e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6593e-04 - accuracy: 0.9744 - val_loss: 8.9663e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.8502e-04 - accuracy: 0.9682 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7683e-04 - accuracy: 0.9706 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1089e-04 - accuracy: 0.9831 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9720e-04 - accuracy: 0.9754 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.3499e-04 - accuracy: 0.9772 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.7048e-04 - accuracy: 0.9814 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.7181e-04 - accuracy: 0.9831 - val_loss: 9.2477e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8648e-04 - accuracy: 0.9855 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7315e-04 - accuracy: 0.9903 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7589e-04 - accuracy: 0.9855 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6123e-04 - accuracy: 0.9937 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.8918e-04 - accuracy: 0.9927 - val_loss: 9.1417e-04 - val_accuracy: 1.0000\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1927e-04 - accuracy: 0.9813 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7216e-04 - accuracy: 0.9852 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3490e-04 - accuracy: 0.9845 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.4629e-04 - accuracy: 0.9808 - val_loss: 9.8043e-04 - val_accuracy: 1.0000\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6110e-04 - accuracy: 0.9654 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "6/6 [==============================] - 0s 835us/step - loss: 0.0013 - accuracy: 0.9655\n",
            "Loss = 0.0012636143947020173, Accuracy = 0.9655172228813171\n",
            "Loss array:  [0.0005480118561536074, 0.0014485771534964442, 0.0007545604603365064, 0.0012650860007852316, 0.0010126866400241852, 0.0006832343642599881, 0.0009591275011189282, 0.0012636143947020173]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 9/10\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.7307 - val_loss: 0.0289 - val_accuracy: 0.8621\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.8818 - val_loss: 0.0176 - val_accuracy: 0.8621\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9023 - val_loss: 0.0115 - val_accuracy: 0.9138\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.9275 - val_loss: 0.0102 - val_accuracy: 0.8966\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9289 - val_loss: 0.0069 - val_accuracy: 0.9483\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.9149 - val_loss: 0.0053 - val_accuracy: 0.9483\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0056 - accuracy: 0.9360 - val_loss: 0.0046 - val_accuracy: 0.9483\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 0.9491 - val_loss: 0.0046 - val_accuracy: 0.9483\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.9358 - val_loss: 0.0037 - val_accuracy: 0.9655\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.9436 - val_loss: 0.0032 - val_accuracy: 0.9655\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9540 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.9533 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9482 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9383 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9574 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9540 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9538 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9460 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9615 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9412 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9625 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9531 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9545 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9585 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9349 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9557 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9531 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9512 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9659 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9290 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9574 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9717 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9574 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9643 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9608 - val_loss: 9.3977e-04 - val_accuracy: 0.9828\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9583 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9687 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9626 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9692 - val_loss: 9.1006e-04 - val_accuracy: 0.9828\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.8755e-04 - accuracy: 0.9598 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9573 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.7818e-04 - accuracy: 0.9807 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9886 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9692 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.5289e-04 - accuracy: 0.9641 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1528e-04 - accuracy: 0.9797 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.7680e-04 - accuracy: 0.9702 - val_loss: 9.8557e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.9432e-04 - accuracy: 0.9628 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.0994e-04 - accuracy: 0.9754 - val_loss: 9.9639e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2084e-04 - accuracy: 0.9879 - val_loss: 8.4519e-04 - val_accuracy: 1.0000\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.8396e-04 - accuracy: 0.9887 - val_loss: 9.3457e-04 - val_accuracy: 1.0000\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2330e-04 - accuracy: 0.9788 - val_loss: 9.2937e-04 - val_accuracy: 1.0000\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8374e-04 - accuracy: 0.9718 - val_loss: 8.4610e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 7.6365e-04 - accuracy: 0.9847 - val_loss: 8.8992e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3817e-04 - accuracy: 0.9767 - val_loss: 9.1290e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.0157e-04 - accuracy: 0.9879 - val_loss: 8.8218e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5181e-04 - accuracy: 0.9804 - val_loss: 8.4521e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.4388e-04 - accuracy: 0.9802 - val_loss: 7.2932e-04 - val_accuracy: 1.0000\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5183e-04 - accuracy: 0.9922 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2604e-04 - accuracy: 0.9873 - val_loss: 9.9814e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2938e-04 - accuracy: 0.9878 - val_loss: 8.9533e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.7140e-04 - accuracy: 0.9760 - val_loss: 8.7062e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1967e-04 - accuracy: 0.9844 - val_loss: 7.9919e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3055e-04 - accuracy: 0.9812 - val_loss: 9.2552e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1219e-04 - accuracy: 0.9900 - val_loss: 9.3395e-04 - val_accuracy: 1.0000\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6666e-04 - accuracy: 0.9836 - val_loss: 9.6121e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5002e-04 - accuracy: 0.9608 - val_loss: 7.4906e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8546e-04 - accuracy: 0.9813 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.9037e-04 - accuracy: 0.9772 - val_loss: 9.1892e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8714e-04 - accuracy: 0.9828 - val_loss: 9.1643e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1828e-04 - accuracy: 0.9796 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.4365e-04 - accuracy: 0.9864 - val_loss: 8.4530e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2181e-04 - accuracy: 0.9799 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.4500e-04 - accuracy: 0.9794 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.5729e-04 - accuracy: 0.9813 - val_loss: 9.9218e-04 - val_accuracy: 1.0000\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3508e-04 - accuracy: 0.9766 - val_loss: 7.7876e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2024e-04 - accuracy: 0.9882 - val_loss: 8.3589e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4624e-04 - accuracy: 0.9861 - val_loss: 7.5011e-04 - val_accuracy: 1.0000\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0640e-04 - accuracy: 0.9840 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0728e-04 - accuracy: 0.9801 - val_loss: 7.4250e-04 - val_accuracy: 1.0000\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3651e-04 - accuracy: 0.9796 - val_loss: 8.2797e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0807e-04 - accuracy: 0.9905 - val_loss: 7.3251e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5712e-04 - accuracy: 0.9839 - val_loss: 9.0453e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.5928e-04 - accuracy: 0.9864 - val_loss: 7.3473e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2354e-04 - accuracy: 0.9833 - val_loss: 8.5096e-04 - val_accuracy: 1.0000\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.4658e-04 - accuracy: 0.9741 - val_loss: 6.7716e-04 - val_accuracy: 1.0000\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9018e-04 - accuracy: 0.9823 - val_loss: 7.1559e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5729e-04 - accuracy: 0.9916 - val_loss: 8.9801e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.9722e-04 - accuracy: 0.9894 - val_loss: 7.2414e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6776e-04 - accuracy: 0.9920 - val_loss: 8.9158e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.1534e-04 - accuracy: 0.9754 - val_loss: 7.8147e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0592e-04 - accuracy: 0.9859 - val_loss: 8.5487e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.1072e-04 - accuracy: 0.9807 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9672 - val_loss: 6.7980e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9404e-04 - accuracy: 0.9876 - val_loss: 8.6850e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9186e-04 - accuracy: 0.9825 - val_loss: 8.2735e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5329e-04 - accuracy: 0.9836 - val_loss: 7.2887e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6455e-04 - accuracy: 0.9845 - val_loss: 7.1694e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 995us/step - loss: 7.0722e-04 - accuracy: 0.9823 - val_loss: 8.7233e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7804e-04 - accuracy: 0.9938 - val_loss: 9.6722e-04 - val_accuracy: 1.0000\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7413e-04 - accuracy: 0.9812 - val_loss: 7.6844e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1809e-04 - accuracy: 0.9877 - val_loss: 9.9728e-04 - val_accuracy: 1.0000\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1607e-04 - accuracy: 0.9766 - val_loss: 6.7362e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4007e-04 - accuracy: 0.9863 - val_loss: 7.3719e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8727e-04 - accuracy: 0.9803 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1060e-04 - accuracy: 0.9804 - val_loss: 8.1452e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2887e-04 - accuracy: 0.9830 - val_loss: 6.8685e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0228e-04 - accuracy: 0.9781 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5964e-04 - accuracy: 0.9862 - val_loss: 6.4580e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0562e-04 - accuracy: 0.9883 - val_loss: 7.9098e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5278e-04 - accuracy: 0.9740 - val_loss: 5.9681e-04 - val_accuracy: 1.0000\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0513e-04 - accuracy: 0.9904 - val_loss: 5.6010e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7929e-04 - accuracy: 0.9919 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9801e-04 - accuracy: 0.9832 - val_loss: 8.1166e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9267e-04 - accuracy: 0.9906 - val_loss: 6.7551e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9120e-04 - accuracy: 0.9769 - val_loss: 7.5437e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8511e-04 - accuracy: 0.9697 - val_loss: 6.7390e-04 - val_accuracy: 0.9828\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3406e-04 - accuracy: 0.9874 - val_loss: 6.2675e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2846e-04 - accuracy: 0.9779 - val_loss: 6.6172e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5185e-04 - accuracy: 0.9825 - val_loss: 7.4274e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0261e-04 - accuracy: 0.9880 - val_loss: 5.8565e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7705e-04 - accuracy: 0.9749 - val_loss: 5.4956e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2911e-04 - accuracy: 0.9843 - val_loss: 7.6220e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5777e-04 - accuracy: 0.9926 - val_loss: 6.2241e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6633e-04 - accuracy: 0.9744 - val_loss: 6.3941e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9931e-04 - accuracy: 0.9807 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3637e-04 - accuracy: 0.9837 - val_loss: 8.2255e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2315e-04 - accuracy: 0.9863 - val_loss: 5.9941e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3205e-04 - accuracy: 0.9880 - val_loss: 6.3766e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6904e-04 - accuracy: 0.9784 - val_loss: 5.7124e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6969e-04 - accuracy: 0.9883 - val_loss: 7.4532e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1729e-04 - accuracy: 0.9743 - val_loss: 7.0944e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2914e-04 - accuracy: 0.9824 - val_loss: 9.5999e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4460e-04 - accuracy: 0.9924 - val_loss: 7.6412e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2053e-04 - accuracy: 0.9822 - val_loss: 5.7505e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 4.8106e-04 - accuracy: 0.9843 - val_loss: 5.2415e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4410e-04 - accuracy: 0.9874 - val_loss: 6.4875e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0658e-04 - accuracy: 0.9935 - val_loss: 5.4464e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4298e-04 - accuracy: 0.9935 - val_loss: 5.8837e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7286e-04 - accuracy: 0.9806 - val_loss: 5.4417e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4515e-04 - accuracy: 0.9915 - val_loss: 5.2723e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3684e-04 - accuracy: 0.9752 - val_loss: 5.5590e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4354e-04 - accuracy: 0.9845 - val_loss: 4.5023e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9422e-04 - accuracy: 0.9833 - val_loss: 5.2358e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1633e-04 - accuracy: 0.9988 - val_loss: 5.3485e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8619e-04 - accuracy: 0.9926 - val_loss: 8.8734e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6778e-04 - accuracy: 0.9818 - val_loss: 6.6313e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8956e-04 - accuracy: 0.9852 - val_loss: 4.8554e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5469e-04 - accuracy: 0.9923 - val_loss: 4.5710e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3790e-04 - accuracy: 0.9927 - val_loss: 8.4400e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.4185e-04 - accuracy: 0.9815 - val_loss: 5.9883e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8811e-04 - accuracy: 0.9963 - val_loss: 5.5053e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0527e-04 - accuracy: 0.9806 - val_loss: 4.8710e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0749e-04 - accuracy: 0.9932 - val_loss: 8.4639e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6130e-04 - accuracy: 0.9684 - val_loss: 6.0644e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3110e-04 - accuracy: 0.9977 - val_loss: 4.5628e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.2815e-04 - accuracy: 0.9965 - val_loss: 3.8576e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 987us/step - loss: 4.6386e-04 - accuracy: 0.9934 - val_loss: 5.7833e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6328e-04 - accuracy: 0.9904 - val_loss: 5.6026e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5177e-04 - accuracy: 0.9916 - val_loss: 4.8798e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5267e-04 - accuracy: 0.9948 - val_loss: 6.1850e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3339e-04 - accuracy: 0.9939 - val_loss: 6.8540e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1607e-04 - accuracy: 0.9963 - val_loss: 4.7176e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6736e-04 - accuracy: 0.9808 - val_loss: 4.4423e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1351e-04 - accuracy: 0.9975 - val_loss: 4.8124e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4217e-04 - accuracy: 0.9869 - val_loss: 6.3088e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0373e-04 - accuracy: 0.9959 - val_loss: 5.8729e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4495e-04 - accuracy: 0.9833 - val_loss: 5.3657e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 944us/step - loss: 4.6571e-04 - accuracy: 0.9845 - val_loss: 5.3092e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.0983e-04 - accuracy: 0.9959 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4777e-04 - accuracy: 0.9877 - val_loss: 5.1200e-04 - val_accuracy: 1.0000\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7736e-04 - accuracy: 0.9880 - val_loss: 9.4833e-04 - val_accuracy: 0.9828\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4196e-04 - accuracy: 0.9876 - val_loss: 4.4714e-04 - val_accuracy: 1.0000\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5012e-04 - accuracy: 0.9953 - val_loss: 9.7128e-04 - val_accuracy: 1.0000\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3963e-04 - accuracy: 0.9877 - val_loss: 5.0682e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.4021e-04 - accuracy: 0.9973 - val_loss: 6.1729e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.1222e-04 - accuracy: 0.9758 - val_loss: 6.9932e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9939e-04 - accuracy: 0.9773 - val_loss: 5.1425e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3433e-04 - accuracy: 0.9897 - val_loss: 5.7739e-04 - val_accuracy: 1.0000\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.7740e-04 - accuracy: 0.9966 - val_loss: 6.6642e-04 - val_accuracy: 1.0000\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.2500e-04 - accuracy: 0.9956 - val_loss: 6.6243e-04 - val_accuracy: 1.0000\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8473e-04 - accuracy: 0.9900 - val_loss: 9.6759e-04 - val_accuracy: 0.9828\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1670e-04 - accuracy: 0.9772 - val_loss: 4.7006e-04 - val_accuracy: 1.0000\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5235e-04 - accuracy: 0.9847 - val_loss: 5.7322e-04 - val_accuracy: 1.0000\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 4.2953e-04 - accuracy: 0.9918 - val_loss: 6.0172e-04 - val_accuracy: 1.0000\n",
            "6/6 [==============================] - 0s 763us/step - loss: 6.0172e-04 - accuracy: 1.0000\n",
            "Loss = 0.0006017223931849003, Accuracy = 1.0\n",
            "Loss array:  [0.0005480118561536074, 0.0014485771534964442, 0.0007545604603365064, 0.0012650860007852316, 0.0010126866400241852, 0.0006832343642599881, 0.0009591275011189282, 0.0012636143947020173, 0.0006017223931849003]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 10/10\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.6031 - val_loss: 0.0308 - val_accuracy: 0.9310\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.8059 - val_loss: 0.0165 - val_accuracy: 0.9138\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.8501 - val_loss: 0.0127 - val_accuracy: 0.9310\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9282 - val_loss: 0.0077 - val_accuracy: 0.9483\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 0.9293 - val_loss: 0.0057 - val_accuracy: 0.9483\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 0.9103 - val_loss: 0.0053 - val_accuracy: 0.9310\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 977us/step - loss: 0.0048 - accuracy: 0.9283 - val_loss: 0.0055 - val_accuracy: 0.9483\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9328 - val_loss: 0.0045 - val_accuracy: 0.9483\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9299 - val_loss: 0.0048 - val_accuracy: 0.9483\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.9383 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 830us/step - loss: 0.0038 - accuracy: 0.9324 - val_loss: 0.0035 - val_accuracy: 0.9483\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 999us/step - loss: 0.0036 - accuracy: 0.9187 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0038 - accuracy: 0.9324 - val_loss: 0.0030 - val_accuracy: 0.9483\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.9200 - val_loss: 0.0035 - val_accuracy: 0.9483\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.9470 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9451 - val_loss: 0.0030 - val_accuracy: 0.9483\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.9272 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9318 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.9365 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9297 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9581 - val_loss: 0.0034 - val_accuracy: 0.9310\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 912us/step - loss: 0.0023 - accuracy: 0.9555 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9467 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9699 - val_loss: 0.0034 - val_accuracy: 0.9483\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9520 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9463 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9714 - val_loss: 0.0024 - val_accuracy: 0.9828\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9533 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9652 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9354 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9412 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9506 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9599 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9683 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9712 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0015 - accuracy: 0.9607 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9680 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9657 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9572 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9548 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9502 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9515 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9638 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 999us/step - loss: 0.0011 - accuracy: 0.9681 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9488 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9698 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9755 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9802 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9655 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9811 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9670 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9566 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9779 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.5971e-04 - accuracy: 0.9803 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9782 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9726 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9748 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.9551e-04 - accuracy: 0.9866 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.5199e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 906us/step - loss: 0.0011 - accuracy: 0.9684 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9747 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.3739e-04 - accuracy: 0.9701 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2552e-04 - accuracy: 0.9845 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2965e-04 - accuracy: 0.9675 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.6016e-04 - accuracy: 0.9762 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.4856e-04 - accuracy: 0.9701 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.5199e-04 - accuracy: 0.9881 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2922e-04 - accuracy: 0.9669 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.9798e-04 - accuracy: 0.9770 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1164e-04 - accuracy: 0.9702 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.9216e-04 - accuracy: 0.9716 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 1000us/step - loss: 8.3868e-04 - accuracy: 0.9730 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1123e-04 - accuracy: 0.9709 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.9029e-04 - accuracy: 0.9692 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5389e-04 - accuracy: 0.9777 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.7692e-04 - accuracy: 0.9805 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0339e-04 - accuracy: 0.9762 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.3154e-04 - accuracy: 0.9678 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9695 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.6255e-04 - accuracy: 0.9736 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 998us/step - loss: 7.0266e-04 - accuracy: 0.9857 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2999e-04 - accuracy: 0.9736 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 1000us/step - loss: 7.7409e-04 - accuracy: 0.9710 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0873e-04 - accuracy: 0.9835 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9699e-04 - accuracy: 0.9772 - val_loss: 9.6709e-04 - val_accuracy: 0.9828\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9421e-04 - accuracy: 0.9852 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9729e-04 - accuracy: 0.9737 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8652e-04 - accuracy: 0.9817 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5285e-04 - accuracy: 0.9803 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.3045e-04 - accuracy: 0.9847 - val_loss: 9.6974e-04 - val_accuracy: 0.9828\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 992us/step - loss: 6.1604e-04 - accuracy: 0.9946 - val_loss: 9.4801e-04 - val_accuracy: 0.9655\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.0709e-04 - accuracy: 0.9834 - val_loss: 9.7140e-04 - val_accuracy: 0.9828\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0456e-04 - accuracy: 0.9923 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1217e-04 - accuracy: 0.9806 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8519e-04 - accuracy: 0.9811 - val_loss: 9.5039e-04 - val_accuracy: 0.9828\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1126e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2809e-04 - accuracy: 0.9914 - val_loss: 9.2483e-04 - val_accuracy: 0.9828\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 887us/step - loss: 5.5999e-04 - accuracy: 0.9745 - val_loss: 9.9926e-04 - val_accuracy: 0.9655\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4655e-04 - accuracy: 0.9848 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 808us/step - loss: 8.9135e-04 - accuracy: 0.9775 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8196e-04 - accuracy: 0.9860 - val_loss: 9.1279e-04 - val_accuracy: 0.9828\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3137e-04 - accuracy: 0.9851 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 962us/step - loss: 6.1136e-04 - accuracy: 0.9798 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6657e-04 - accuracy: 0.9838 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9899e-04 - accuracy: 0.9961 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7772e-04 - accuracy: 0.9907 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.8012e-04 - accuracy: 0.9764 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2025e-04 - accuracy: 0.9855 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6389e-04 - accuracy: 0.9889 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9477e-04 - accuracy: 0.9845 - val_loss: 9.9204e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4849e-04 - accuracy: 0.9906 - val_loss: 9.8283e-04 - val_accuracy: 0.9828\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3889e-04 - accuracy: 0.9835 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.6523e-04 - accuracy: 0.9729 - val_loss: 8.8277e-04 - val_accuracy: 0.9828\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5449e-04 - accuracy: 0.9770 - val_loss: 8.8901e-04 - val_accuracy: 0.9828\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1998e-04 - accuracy: 0.9838 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4261e-04 - accuracy: 0.9863 - val_loss: 8.7526e-04 - val_accuracy: 0.9828\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7460e-04 - accuracy: 0.9791 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1345e-04 - accuracy: 0.9841 - val_loss: 9.8498e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1433e-04 - accuracy: 0.9864 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6863e-04 - accuracy: 0.9749 - val_loss: 8.7900e-04 - val_accuracy: 0.9828\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0490e-04 - accuracy: 0.9854 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.3748e-04 - accuracy: 0.9705 - val_loss: 9.3348e-04 - val_accuracy: 0.9828\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1473e-04 - accuracy: 0.9953 - val_loss: 9.7112e-04 - val_accuracy: 0.9655\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1141e-04 - accuracy: 0.9861 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2268e-04 - accuracy: 0.9877 - val_loss: 8.9609e-04 - val_accuracy: 0.9828\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6774e-04 - accuracy: 0.9940 - val_loss: 9.5264e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3699e-04 - accuracy: 0.9822 - val_loss: 8.8276e-04 - val_accuracy: 0.9828\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.6289e-04 - accuracy: 0.9903 - val_loss: 9.3089e-04 - val_accuracy: 0.9655\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9159e-04 - accuracy: 0.9917 - val_loss: 8.4068e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3220e-04 - accuracy: 0.9925 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2434e-04 - accuracy: 0.9750 - val_loss: 9.1275e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2414e-04 - accuracy: 0.9807 - val_loss: 8.5196e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7910e-04 - accuracy: 0.9731 - val_loss: 8.5258e-04 - val_accuracy: 0.9828\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3013e-04 - accuracy: 0.9858 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2732e-04 - accuracy: 0.9904 - val_loss: 9.7758e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5247e-04 - accuracy: 0.9891 - val_loss: 7.8273e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3471e-04 - accuracy: 0.9907 - val_loss: 8.0589e-04 - val_accuracy: 0.9655\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3923e-04 - accuracy: 0.9826 - val_loss: 8.7570e-04 - val_accuracy: 0.9828\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.7139e-04 - accuracy: 0.9742 - val_loss: 8.6400e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3694e-04 - accuracy: 0.9814 - val_loss: 7.9715e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.1795e-04 - accuracy: 0.9941 - val_loss: 9.4194e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3346e-04 - accuracy: 0.9787 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2171e-04 - accuracy: 0.9811 - val_loss: 7.5951e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0678e-04 - accuracy: 0.9789 - val_loss: 8.7673e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3236e-04 - accuracy: 0.9837 - val_loss: 6.9768e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.6931e-04 - accuracy: 0.9849 - val_loss: 7.2226e-04 - val_accuracy: 0.9828\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6956e-04 - accuracy: 0.9885 - val_loss: 7.2493e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0291e-04 - accuracy: 0.9848 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4224e-04 - accuracy: 0.9787 - val_loss: 7.4122e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3259e-04 - accuracy: 0.9898 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1910e-04 - accuracy: 0.9865 - val_loss: 7.4326e-04 - val_accuracy: 0.9828\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9139e-04 - accuracy: 0.9938 - val_loss: 6.3294e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4454e-04 - accuracy: 0.9820 - val_loss: 7.1174e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3221e-04 - accuracy: 0.9876 - val_loss: 6.9269e-04 - val_accuracy: 0.9828\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 984us/step - loss: 5.1040e-04 - accuracy: 0.9838 - val_loss: 7.4665e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1338e-04 - accuracy: 0.9814 - val_loss: 9.6087e-04 - val_accuracy: 0.9655\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7835e-04 - accuracy: 0.9859 - val_loss: 6.9099e-04 - val_accuracy: 0.9828\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2536e-04 - accuracy: 0.9823 - val_loss: 7.1258e-04 - val_accuracy: 0.9655\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0325e-04 - accuracy: 0.9909 - val_loss: 7.0166e-04 - val_accuracy: 0.9828\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7200e-04 - accuracy: 0.9872 - val_loss: 7.0779e-04 - val_accuracy: 0.9828\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3155e-04 - accuracy: 0.9861 - val_loss: 6.8694e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6785e-04 - accuracy: 0.9864 - val_loss: 6.8380e-04 - val_accuracy: 0.9828\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2415e-04 - accuracy: 0.9882 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8878e-04 - accuracy: 0.9896 - val_loss: 6.7405e-04 - val_accuracy: 0.9828\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.7848e-04 - accuracy: 0.9944 - val_loss: 7.1046e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4646e-04 - accuracy: 0.9928 - val_loss: 7.2626e-04 - val_accuracy: 0.9828\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.3816e-04 - accuracy: 0.9955 - val_loss: 8.4797e-04 - val_accuracy: 0.9655\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7806e-04 - accuracy: 0.9889 - val_loss: 7.9484e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.2528e-04 - accuracy: 0.9915 - val_loss: 6.7021e-04 - val_accuracy: 0.9828\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7702e-04 - accuracy: 0.9836 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.4666e-04 - accuracy: 0.9643 - val_loss: 6.7016e-04 - val_accuracy: 1.0000\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3360e-04 - accuracy: 0.9912 - val_loss: 6.6326e-04 - val_accuracy: 1.0000\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4074e-04 - accuracy: 0.9925 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 972us/step - loss: 4.6711e-04 - accuracy: 0.9970 - val_loss: 7.1981e-04 - val_accuracy: 1.0000\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6236e-04 - accuracy: 0.9901 - val_loss: 7.7552e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.8790e-04 - accuracy: 0.9848 - val_loss: 6.4093e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.1308e-04 - accuracy: 0.9873 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2941e-04 - accuracy: 0.9873 - val_loss: 6.7580e-04 - val_accuracy: 0.9828\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3869e-04 - accuracy: 0.9883 - val_loss: 7.2673e-04 - val_accuracy: 1.0000\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1819e-04 - accuracy: 0.9950 - val_loss: 9.5684e-04 - val_accuracy: 1.0000\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5646e-04 - accuracy: 0.9887 - val_loss: 7.2517e-04 - val_accuracy: 1.0000\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3566e-04 - accuracy: 0.9960 - val_loss: 6.1255e-04 - val_accuracy: 0.9828\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.0952e-04 - accuracy: 0.9882 - val_loss: 7.4855e-04 - val_accuracy: 0.9655\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8888e-04 - accuracy: 0.9800 - val_loss: 7.6354e-04 - val_accuracy: 1.0000\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 983us/step - loss: 3.7789e-04 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "6/6 [==============================] - 0s 566us/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Loss = 0.0011452294420450926, Accuracy = 1.0\n",
            "Loss array:  [0.0005480118561536074, 0.0014485771534964442, 0.0007545604603365064, 0.0012650860007852316, 0.0010126866400241852, 0.0006832343642599881, 0.0009591275011189282, 0.0012636143947020173, 0.0006017223931849003, 0.0011452294420450926]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "NUM_EPOCHS = 185# 180\n",
        "BATCH_SIZE = 10\n",
        "K_FOLD_SPLITS = 10\n",
        "\n",
        "\n",
        "# Define the cross-validation process to be used inside cross_val_Score evaluation\n",
        "cv = KFold(n_splits=K_FOLD_SPLITS)\n",
        "\n",
        "# Handling for accommodating multiple targets\n",
        "Y1 = y_train_norm[:,0]\n",
        "Y2 = y_train_norm[:,1]\n",
        "targets = (Y1, Y2)\n",
        "\n",
        "X = X_train_norm\n",
        "\n",
        "i = 0\n",
        "arr_loss = list()\n",
        "arr_rmse = list()\n",
        "min_loss = 1000000\n",
        "best_model = None\n",
        "history = None\n",
        "history_best_model = None\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_indices, val_indices) in enumerate(cv.split(X_train_norm)):\n",
        "  print('####################### Iteration  ', i, ' #######################')\n",
        "  print(f'Fold {fold+1}/{K_FOLD_SPLITS}')\n",
        "  X_train_fold, y_train_fold = X_train_norm[train_indices], y_train_norm[train_indices]\n",
        "  X_val_fold, y_val_fold = X_train_norm[val_indices], y_train_norm[val_indices]\n",
        "\n",
        "  # Convert the folds into tf.data.Dataset\n",
        "  train_dataset_fold = make_dataset(X_train_fold, y_train_fold, batch_size=batch_size, shuffle=True)\n",
        "  val_dataset_fold = make_dataset(X_val_fold, y_val_fold, batch_size=batch_size)\n",
        "\n",
        "\n",
        "  model = my_model()\n",
        "  history = model.fit(train_dataset_fold, epochs=NUM_EPOCHS, validation_data=val_dataset_fold)\n",
        "\n",
        "  #testing on validation set process\n",
        "  loss, accuracy = model.evaluate(val_dataset_fold, verbose=1)\n",
        "  print(f\"Loss = {loss}, Accuracy = {accuracy}\")\n",
        "\n",
        "  # Check if this is the best model based on validation loss\n",
        "  if loss < min_loss:\n",
        "      best_model = model\n",
        "      history_best_model = history.history\n",
        "      min_loss = loss\n",
        "\n",
        "  # Append the current fold's loss and accuracy to the tracking lists\n",
        "  arr_loss.append(loss)\n",
        "  arr_rmse.append(accuracy)  # Assuming you want to track accuracy; change if needed\n",
        "  print('Loss array: ', arr_loss)\n",
        "\n",
        "# Saving the best model within the k folds\n",
        "best_model.save(FILENAME_BEST_MODEL)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results\n",
        "- Plot of k-cross validation performance\n",
        "- Scatter Plot of prediction results against true values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "xKSkPnO4ETWD",
        "outputId": "564ee694-d414-4d21-bbd9-f838e7249dd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loss across k folds\n",
        "plot_line(arr_loss, \"Loss across k-folds\", \"Value of k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'history'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1720660/1961013319.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training and Validation Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_loss_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_1720660/2330671866.py\u001b[0m in \u001b[0;36mplot_loss_curve\u001b[0;34m(history, epoch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_loss_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'history'"
          ]
        }
      ],
      "source": [
        "# Training and Validation Loss\n",
        "plot_loss_curve(history_best_model, NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the test dataset\n",
        "X_test_norm = scaler_input.transform(X_test)\n",
        "y_test_norm = scaler_output.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-erJ0l_Yu4P",
        "outputId": "9cff94b2-e4ca-491b-8459-aeaa1eff7606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time: 0.0269 seconds\n",
            "Maxval here is:  25.217321\n",
            "Maxval here is:  0.9278\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "Y_pred_normalized = best_model.predict(X_test_norm)\n",
        "end_time = time.time()\n",
        "Y_pred_normalized_entire = best_model.predict(dataset_x_norm)\n",
        "# Calculate elapsed time in seconds\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Elapsed time:\", round(elapsed_time, 3), \"seconds\")\n",
        "\n",
        "\n",
        "Y_pred = scaler_output.inverse_transform(Y_pred_normalized)\n",
        "Y_pred_entire = scaler_output.inverse_transform(Y_pred_normalized_entire)\n",
        "Y_actual = np.array(y_test)\n",
        "Y_actual_entire = np.array(df_targets)\n",
        "# Moisture Content\n",
        "scatter_plot(trueValues=Y_actual[:,0], \n",
        "             predictions=Y_pred[:,0], \n",
        "             title=\"Moisture Content\")\n",
        "a, b = np.polyfit(Y_pred[:, 0], Y_actual[:, 0], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,0]), max(Y_actual[:,0])), 1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_MC.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)\n",
        "\n",
        "# Bulk Density\n",
        "scatter_plot(trueValues=Y_actual[:,1], \n",
        "             predictions=Y_pred[:,1], \n",
        "             title=\"Bulk Density\")\n",
        "plt.xlim([min(min(Y_pred[:,1]), min(Y_actual[:,1]))-0.1, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1])\n",
        "a, b = np.polyfit(Y_pred[:, 1], Y_actual[:, 1], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1, 0.1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_BD.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Error analysis\n",
        "- R squared calculation\n",
        "- Mean accuracy error"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### R squared calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9919\n",
            "0.9215\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# MOISTURE CONTENT\n",
        "#   - R-squared\n",
        "# mc_r2_score = r2_score(Y_actual[:, 0], Y_pred[:, 0])\n",
        "mc_r2_score = calculate_r_squared(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"{:#.4g}\".format(mc_r2_score))\n",
        "\n",
        "# BULK DENSITY\n",
        "#   - R-squared\n",
        "# bd_r2_score = r2_score(Y_actual[:, 1], Y_pred[:, 1])\n",
        "bd_r2_score = calculate_r_squared(y_true=Y_actual[:, 1], y_pred=Y_pred[:, 1])\n",
        "print(\"{:#.4g}\".format(bd_r2_score))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE_MC:  0.3401\n",
            "RMSE_BD:  0.03374\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sigfig import round\n",
        "\n",
        "#MC\n",
        "rmse_mc = np.sqrt(mean_squared_error(Y_actual[:, 0], Y_pred[:, 0]))\n",
        "print('RMSE_MC: ', \"{0:.4g}\".format(rmse_mc))\n",
        "\n",
        "#BD\n",
        "rmse_bd = np.sqrt(mean_squared_error(Y_actual[:, 1], Y_pred[:, 1]))\n",
        "print('RMSE_BD: ', \"{0:.4g}\".format(rmse_bd))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will compare with the results from Trabelsi's paper. This is single moisture prediction \n",
        "\n",
        "R^2 : 0.993\\\n",
        "Mean Squared Error: 0.028\\\n",
        "Mean absolute Error: 0.135\\\n",
        "Min. Absolute Error: 0.004\\\n",
        "Max Absolute Error: 0.441"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9912\n",
            "Mean Squared Error:  0.1157\n",
            "Mean Absolute Error:  0.2514\n",
            "Min Absolute Error:  0.0011185455322255677\n",
            "Max Absolute Error:  1.2350922775268547\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,max_error, r2_score\n",
        "from sigfig import round\n",
        "\n",
        "mc_r2_score = r2_score(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual[:, 0], Y_pred[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual[:, 0], Y_pred[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual[:,0])):\n",
        "    sum = Y_actual[:,0][i] - Y_pred[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9947\n",
            "Mean Squared Error:  0.07685\n",
            "Mean Absolute Error:  0.2091\n",
            "Min Absolute Error:  0.0008379364013677559\n",
            "Max Absolute Error:  1.2350922775268547\n"
          ]
        }
      ],
      "source": [
        "mc_r2_score = r2_score(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual_entire[:,0])):\n",
        "    sum = Y_actual_entire[:,0][i] - Y_pred_entire[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
