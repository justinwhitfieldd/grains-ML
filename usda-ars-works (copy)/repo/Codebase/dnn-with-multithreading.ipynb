{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "#GRAIN_TYPE = 'Wheat'\n",
        "#GRAIN_TYPE = 'newWheatData'\n",
        "#GRAIN_TYPE = 'CornAdded_Type'\n",
        "GRAIN_TYPE = 'cleaned_data'\n",
        "# GRAIN_TYPE = 'Oats'\n",
        "\n",
        "# GRAIN_TYPE = 'Barley'\n",
        "# GRAIN_TYPE = 'Sorghum'\n",
        "# GRAIN_TYPE = 'Soybeans'\n",
        "# GRAIN_TYPE = 'Corn'\n",
        "\n",
        "FILENAME_BEST_MODEL = 'Best models/target_2/hybrid_models/' + GRAIN_TYPE + '_t2_kcv_dnn_mc.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNGoIGbc0kw_",
        "outputId": "279cc9c8-32fd-4f89-e56b-83a0a31081dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ]
        }
      ],
      "source": [
        "#Import libraries\n",
        "import requests\n",
        "import pydot\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Data visualization\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "#Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Machine Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Activation, BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "np.random.seed(39)\n",
        "random.seed(39)\n",
        "tf.random.set_seed(39)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "# print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "nxHO_qH0Zi5J"
      },
      "outputs": [],
      "source": [
        "def calculate_r_squared(y_true, y_pred):\n",
        "   corr_matrix = np.corrcoef(y_true, y_pred)\n",
        "   corr = corr_matrix[0,1]\n",
        "   R_sq = corr**2\n",
        "   return R_sq\n",
        "\n",
        "def plot_loss_curve(history, epoch_size):\n",
        "    loss_train = history.history['loss']\n",
        "    loss_val = history.history['val_loss']\n",
        "    epochs = range(0,epoch_size)\n",
        "    \n",
        "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "    \n",
        "    plt.title('Training and Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_line(metric, title, xlabel):\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.title(title, fontsize = 16)\n",
        "    plt.plot(metric)\n",
        "    plt.xlabel(xlabel, fontsize = 14)\n",
        "    plt.grid()\n",
        "    plt.legend(loc= \"best\")\n",
        "    plt.show()\n",
        "\n",
        "def scatter_plot(trueValues, predictions, title):\n",
        "  plt.figure(figsize=(8,3))\n",
        "  ax = plt.axes()\n",
        "  maxVal = max( max(trueValues), max(predictions) )\n",
        "\n",
        "  ax.scatter(x=predictions, y=trueValues)\n",
        "  ax.plot([0, 1, maxVal], [0, 1, maxVal], label=\"Ideal fit\")\n",
        "  print('Maxval here is: ', maxVal)\n",
        "  plt.title(title, fontsize = 16)\n",
        "  plt.xlabel(\"Predictions\", fontsize = 14)\n",
        "  plt.ylabel(\"Real\", fontsize = 14)\n",
        "  plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "s3pvA5g-zdgv",
        "outputId": "7a7208f1-6b68-4eba-ad1d-9108d0df66ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From USDA:  ../Datasets/processed/cleaned_data.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variety</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>8.8258</td>\n",
              "      <td>-55.973</td>\n",
              "      <td>-415.973</td>\n",
              "      <td>2.416</td>\n",
              "      <td>0.243</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-6.341975</td>\n",
              "      <td>62.3</td>\n",
              "      <td>61.7806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>10.2572</td>\n",
              "      <td>-114.289</td>\n",
              "      <td>-474.289</td>\n",
              "      <td>2.412</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-11.142320</td>\n",
              "      <td>71.2</td>\n",
              "      <td>82.0576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>11.5679</td>\n",
              "      <td>-168.171</td>\n",
              "      <td>-528.171</td>\n",
              "      <td>2.395</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-14.537729</td>\n",
              "      <td>80.1</td>\n",
              "      <td>104.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>12.8795</td>\n",
              "      <td>134.849</td>\n",
              "      <td>-585.151</td>\n",
              "      <td>2.390</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>10.470049</td>\n",
              "      <td>89.0</td>\n",
              "      <td>128.7950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>13.7649</td>\n",
              "      <td>83.502</td>\n",
              "      <td>-636.498</td>\n",
              "      <td>2.371</td>\n",
              "      <td>0.238</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>6.066299</td>\n",
              "      <td>97.9</td>\n",
              "      <td>151.4139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Variety  Freq  d(cm)    M%  Density     Attn    Phase  Phase_Corr  \\\n",
              "0  KANSAS   7.0    8.9  11.3   0.7356   8.8258  -55.973    -415.973   \n",
              "1  KANSAS   8.0    8.9  11.3   0.7356  10.2572 -114.289    -474.289   \n",
              "2  KANSAS   9.0    8.9  11.3   0.7356  11.5679 -168.171    -528.171   \n",
              "3  KANSAS  10.0    8.9  11.3   0.7356  12.8795  134.849    -585.151   \n",
              "4  KANSAS  11.0    8.9  11.3   0.7356  13.7649   83.502    -636.498   \n",
              "\n",
              "   Permittivity_real  Permittivity_imaginary       Type  Phase/Attn  \\\n",
              "0              2.416                   0.243  15.855506   -6.341975   \n",
              "1              2.412                   0.246  15.855506  -11.142320   \n",
              "2              2.395                   0.246  15.855506  -14.537729   \n",
              "3              2.390                   0.246  15.855506   10.470049   \n",
              "4              2.371                   0.238  15.855506    6.066299   \n",
              "\n",
              "   Freq*d(cm)  Freq*Attn  \n",
              "0        62.3    61.7806  \n",
              "1        71.2    82.0576  \n",
              "2        80.1   104.1111  \n",
              "3        89.0   128.7950  \n",
              "4        97.9   151.4139  "
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#url dataset\n",
        "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
        "\n",
        "#read in excel format\n",
        "df = pd.read_csv(URL)\n",
        "#df = df[df['Variety'] == 'SOUTH DAKOTA']\n",
        "#df = df[(df['Density'] >= 0.72) & (df['Density'] <= 0.88)]\n",
        "\n",
        "print(\"From USDA: \", URL)\n",
        "\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUzjHHV2stm"
      },
      "source": [
        "# 2. Overview of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Xohz7dGh2sXH",
        "outputId": "7d018cd8-018a-45d3-b1b7-ba9fc14aa5e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10.811414</td>\n",
              "      <td>7.088834</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>0.796298</td>\n",
              "      <td>18.410033</td>\n",
              "      <td>-4.604663</td>\n",
              "      <td>-633.488065</td>\n",
              "      <td>2.912112</td>\n",
              "      <td>0.499187</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>-0.377074</td>\n",
              "      <td>77.159677</td>\n",
              "      <td>215.799030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.530055</td>\n",
              "      <td>1.554604</td>\n",
              "      <td>3.794772</td>\n",
              "      <td>0.067384</td>\n",
              "      <td>5.946835</td>\n",
              "      <td>101.951444</td>\n",
              "      <td>219.510760</td>\n",
              "      <td>0.305758</td>\n",
              "      <td>0.186739</td>\n",
              "      <td>0.629743</td>\n",
              "      <td>6.071761</td>\n",
              "      <td>32.552200</td>\n",
              "      <td>124.108325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>10.260000</td>\n",
              "      <td>0.625400</td>\n",
              "      <td>8.002300</td>\n",
              "      <td>-179.335000</td>\n",
              "      <td>-1274.435000</td>\n",
              "      <td>2.340000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>15.352809</td>\n",
              "      <td>-17.418676</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>40.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>13.680000</td>\n",
              "      <td>0.745400</td>\n",
              "      <td>13.524700</td>\n",
              "      <td>-88.842000</td>\n",
              "      <td>-793.405750</td>\n",
              "      <td>2.688500</td>\n",
              "      <td>0.337000</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-5.077754</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>107.817375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>16.225000</td>\n",
              "      <td>0.801300</td>\n",
              "      <td>18.131600</td>\n",
              "      <td>-9.838500</td>\n",
              "      <td>-602.380500</td>\n",
              "      <td>2.861500</td>\n",
              "      <td>0.470500</td>\n",
              "      <td>16.400366</td>\n",
              "      <td>-0.589378</td>\n",
              "      <td>71.200000</td>\n",
              "      <td>195.600450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>18.810000</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>23.098000</td>\n",
              "      <td>80.957250</td>\n",
              "      <td>-456.055750</td>\n",
              "      <td>3.109750</td>\n",
              "      <td>0.639000</td>\n",
              "      <td>16.401988</td>\n",
              "      <td>4.300734</td>\n",
              "      <td>100.100000</td>\n",
              "      <td>310.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>24.410000</td>\n",
              "      <td>0.927800</td>\n",
              "      <td>29.897000</td>\n",
              "      <td>179.048000</td>\n",
              "      <td>-235.044000</td>\n",
              "      <td>4.038000</td>\n",
              "      <td>0.987000</td>\n",
              "      <td>17.344167</td>\n",
              "      <td>14.827701</td>\n",
              "      <td>160.200000</td>\n",
              "      <td>538.146000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Freq       d(cm)          M%     Density        Attn       Phase  \\\n",
              "count  806.000000  806.000000  806.000000  806.000000  806.000000  806.000000   \n",
              "mean    10.811414    7.088834   16.189541    0.796298   18.410033   -4.604663   \n",
              "std      3.530055    1.554604    3.794772    0.067384    5.946835  101.951444   \n",
              "min      5.000000    4.400000   10.260000    0.625400    8.002300 -179.335000   \n",
              "25%      8.000000    6.500000   13.680000    0.745400   13.524700  -88.842000   \n",
              "50%     11.000000    7.700000   16.225000    0.801300   18.131600   -9.838500   \n",
              "75%     13.000000    7.700000   18.810000    0.842000   23.098000   80.957250   \n",
              "max     18.000000    8.900000   24.410000    0.927800   29.897000  179.048000   \n",
              "\n",
              "        Phase_Corr  Permittivity_real  Permittivity_imaginary        Type  \\\n",
              "count   806.000000         806.000000              806.000000  806.000000   \n",
              "mean   -633.488065           2.912112                0.499187   16.189541   \n",
              "std     219.510760           0.305758                0.186739    0.629743   \n",
              "min   -1274.435000           2.340000                0.220000   15.352809   \n",
              "25%    -793.405750           2.688500                0.337000   15.855506   \n",
              "50%    -602.380500           2.861500                0.470500   16.400366   \n",
              "75%    -456.055750           3.109750                0.639000   16.401988   \n",
              "max    -235.044000           4.038000                0.987000   17.344167   \n",
              "\n",
              "       Phase/Attn  Freq*d(cm)   Freq*Attn  \n",
              "count  806.000000  806.000000  806.000000  \n",
              "mean    -0.377074   77.159677  215.799030  \n",
              "std      6.071761   32.552200  124.108325  \n",
              "min    -17.418676   22.000000   40.011500  \n",
              "25%     -5.077754   52.800000  107.817375  \n",
              "50%     -0.589378   71.200000  195.600450  \n",
              "75%      4.300734  100.100000  310.863000  \n",
              "max     14.827701  160.200000  538.146000  "
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data summary\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmFqsYQyGnM",
        "outputId": "54445a7f-a2c8-452a-9651-42dbbe682d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(806, 14)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimension of the dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fep-GIv4yUuf",
        "outputId": "c46072fa-aa7f-4549-9a1d-4c5b05d11112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Variety                   0\n",
              "Freq                      0\n",
              "d(cm)                     0\n",
              "M%                        0\n",
              "Density                   0\n",
              "Attn                      0\n",
              "Phase                     0\n",
              "Phase_Corr                0\n",
              "Permittivity_real         0\n",
              "Permittivity_imaginary    0\n",
              "Type                      0\n",
              "Phase/Attn                0\n",
              "Freq*d(cm)                0\n",
              "Freq*Attn                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check info about missing values in dataframe\n",
        "df.isnull().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_TKP9VymuK"
      },
      "source": [
        "# Exploratory Data Analysis\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz1g9T3FzhF0"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "\n",
        "1.   Convert dataframe to numpy array for flexibility.\n",
        "2. Split our data into training and testing datasets and store the target values in different variables.\n",
        "3.   Normalize the features by applying some operations in the data sets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "T0juhagf1M2I"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy array\n",
        "df_features = df[['Freq', \n",
        "                    'd(cm)', \n",
        "                   # 'Attn', \n",
        "                    'Phase_Corr', \n",
        "                    'Permittivity_real', \n",
        "                    'Permittivity_imaginary',\n",
        "                    'Type',\n",
        "                    ]]\n",
        "\n",
        "df_targets = df[['M%', 'Density']]\n",
        "# df_targets = df[['Density', 'M%']]\n",
        "\n",
        "dataset_x = df_features.to_numpy()\n",
        "dataset_y = df_targets.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting dataset to test and train+validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform train-test split on RAW DATA\n",
        "X_trainVal, X_test, y_trainVal, y_test = train_test_split(dataset_x, dataset_y, \n",
        "                                                    test_size=0.15\n",
        "                                                    ,random_state=42\n",
        "                                                    )\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainVal, y_trainVal, \n",
        "                                                    test_size=0.15 #validation split\n",
        "                                                    ,random_state=42\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Normalizing the data set\n",
        "scaler_input = MinMaxScaler()\n",
        "scaler_output = MinMaxScaler()\n",
        "\n",
        "# Normalize Train set\n",
        "X_train_norm = scaler_input.fit_transform(X_train)\n",
        "y_train_norm = scaler_output.fit_transform(y_train)\n",
        "\n",
        "# Normalize Validation set\n",
        "X_val_norm = scaler_input.fit_transform(X_val)\n",
        "y_val_norm = scaler_output.fit_transform(y_val)\n",
        "\n",
        "# Normalize the entire dataset (input features)\n",
        "dataset_x_norm = scaler_input.transform(dataset_x)  # Use transform, NOT fit_transform\n",
        "\n",
        "# Normalize the entire dataset (output targets)\n",
        "dataset_y_norm = scaler_output.transform(dataset_y)  # Use transform, NOT fit_transform\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKfjwMP0Tzn"
      },
      "source": [
        "# K-cross Validation\n",
        "* Input features: 7\n",
        "* Output targets: 2\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "l31WJZ7Z0ONb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_148 (Dense)            (None, 89)                623       \n",
            "_________________________________________________________________\n",
            "dense_149 (Dense)            (None, 89)                8010      \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 89)                8010      \n",
            "_________________________________________________________________\n",
            "dense_151 (Dense)            (None, 2)                 180       \n",
            "=================================================================\n",
            "Total params: 16,823\n",
            "Trainable params: 16,823\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import layers, Sequential, regularizers\n",
        "\n",
        "# Define the model-building function\n",
        "def my_model():\n",
        "  my_model = Sequential([\n",
        "    \n",
        "    layers.Dense(89, input_shape=(6,), activation='relu',),\n",
        "    layers.Dense(89, activation='relu', ),\n",
        "    layers.Dense(89, activation='relu',),\n",
        "    layers.Dense(2, activation='linear')  # Output layer with 2 neurons for the two regression targets\n",
        "  ])\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.00091) # 0.0006 \n",
        "  my_model.compile(\n",
        "      optimizer = opt,\n",
        "      loss = 'mse',\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "\n",
        "  return my_model\n",
        "\n",
        "plot_model(my_model(), show_shapes=True, show_layer_names=True)\n",
        "my_model().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_dataset(features, labels, batch_size, shuffle=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(features))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# Create TensorFlow datasets for training and validation\n",
        "batch_size = 10 \n",
        "train_dataset = make_dataset(X_train_norm, y_train_norm, batch_size, shuffle=True)\n",
        "val_dataset = make_dataset(X_val_norm, y_val_norm, batch_size)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running model with KCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khCKKB74hFVT",
        "outputId": "37e79cdf-4183-4559-f560-fceb2fc0c630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "####################### Iteration   0  #######################\n",
            "Fold 1/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.7223 - val_loss: 0.0185 - val_accuracy: 0.8814\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 901us/step - loss: 0.0172 - accuracy: 0.8447 - val_loss: 0.0173 - val_accuracy: 0.8814\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 915us/step - loss: 0.0099 - accuracy: 0.8992 - val_loss: 0.0079 - val_accuracy: 0.9492\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 902us/step - loss: 0.0066 - accuracy: 0.9411 - val_loss: 0.0077 - val_accuracy: 0.9153\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 906us/step - loss: 0.0053 - accuracy: 0.9223 - val_loss: 0.0050 - val_accuracy: 0.9492\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 917us/step - loss: 0.0050 - accuracy: 0.9074 - val_loss: 0.0051 - val_accuracy: 0.9322\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0038 - accuracy: 0.9084 - val_loss: 0.0047 - val_accuracy: 0.9153\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 887us/step - loss: 0.0032 - accuracy: 0.9334 - val_loss: 0.0039 - val_accuracy: 0.9322\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 927us/step - loss: 0.0038 - accuracy: 0.9217 - val_loss: 0.0043 - val_accuracy: 0.9153\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 910us/step - loss: 0.0029 - accuracy: 0.9357 - val_loss: 0.0036 - val_accuracy: 0.9322\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 917us/step - loss: 0.0027 - accuracy: 0.9540 - val_loss: 0.0037 - val_accuracy: 0.8983\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 899us/step - loss: 0.0029 - accuracy: 0.9367 - val_loss: 0.0029 - val_accuracy: 0.9153\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 915us/step - loss: 0.0026 - accuracy: 0.9447 - val_loss: 0.0022 - val_accuracy: 0.9492\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 901us/step - loss: 0.0027 - accuracy: 0.9475 - val_loss: 0.0034 - val_accuracy: 0.9322\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 872us/step - loss: 0.0026 - accuracy: 0.9456 - val_loss: 0.0025 - val_accuracy: 0.9492\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0022 - accuracy: 0.9493 - val_loss: 0.0019 - val_accuracy: 0.9492\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 838us/step - loss: 0.0021 - accuracy: 0.9395 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 821us/step - loss: 0.0022 - accuracy: 0.9482 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 0.0021 - accuracy: 0.9450 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0017 - accuracy: 0.9477 - val_loss: 0.0022 - val_accuracy: 0.9322\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.0018 - accuracy: 0.9620 - val_loss: 0.0024 - val_accuracy: 0.8983\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 861us/step - loss: 0.0023 - accuracy: 0.9430 - val_loss: 0.0022 - val_accuracy: 0.9661\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 812us/step - loss: 0.0019 - accuracy: 0.9473 - val_loss: 0.0025 - val_accuracy: 0.9322\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 0.0017 - accuracy: 0.9571 - val_loss: 0.0031 - val_accuracy: 0.9492\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 841us/step - loss: 0.0026 - accuracy: 0.9573 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0014 - accuracy: 0.9625 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 892us/step - loss: 0.0011 - accuracy: 0.9805 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0012 - accuracy: 0.9603 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0013 - accuracy: 0.9788 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 858us/step - loss: 0.0012 - accuracy: 0.9723 - val_loss: 0.0021 - val_accuracy: 0.9322\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0017 - accuracy: 0.9500 - val_loss: 0.0020 - val_accuracy: 0.9492\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 844us/step - loss: 0.0012 - accuracy: 0.9686 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.0011 - accuracy: 0.9544 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0010 - accuracy: 0.9539 - val_loss: 0.0038 - val_accuracy: 0.8814\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 0.0014 - accuracy: 0.9566 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0014 - accuracy: 0.9691 - val_loss: 0.0021 - val_accuracy: 0.9831\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 869us/step - loss: 0.0014 - accuracy: 0.9507 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 908us/step - loss: 0.0014 - accuracy: 0.9480 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 9.8088e-04 - accuracy: 0.9740 - val_loss: 8.2712e-04 - val_accuracy: 0.9492\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 7.8040e-04 - accuracy: 0.9772 - val_loss: 7.4574e-04 - val_accuracy: 0.9831\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 889us/step - loss: 8.1498e-04 - accuracy: 0.9807 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 869us/step - loss: 9.1160e-04 - accuracy: 0.9775 - val_loss: 8.6693e-04 - val_accuracy: 0.9661\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 785us/step - loss: 0.0011 - accuracy: 0.9822 - val_loss: 0.0014 - val_accuracy: 0.9322\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 9.3542e-04 - accuracy: 0.9650 - val_loss: 0.0018 - val_accuracy: 0.9153\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 8.9800e-04 - accuracy: 0.9539 - val_loss: 8.4317e-04 - val_accuracy: 0.9661\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 679us/step - loss: 9.8574e-04 - accuracy: 0.9665 - val_loss: 7.4046e-04 - val_accuracy: 0.9831\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 735us/step - loss: 7.5656e-04 - accuracy: 0.9871 - val_loss: 0.0018 - val_accuracy: 0.9322\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.0011 - accuracy: 0.9836 - val_loss: 7.6653e-04 - val_accuracy: 0.9831\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 7.5914e-04 - accuracy: 0.9788 - val_loss: 8.6799e-04 - val_accuracy: 0.9661\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 9.4062e-04 - accuracy: 0.9850 - val_loss: 6.1692e-04 - val_accuracy: 0.9661\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 7.1599e-04 - accuracy: 0.9808 - val_loss: 7.2083e-04 - val_accuracy: 0.9661\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 838us/step - loss: 6.7540e-04 - accuracy: 0.9787 - val_loss: 8.6025e-04 - val_accuracy: 0.9661\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 7.8395e-04 - accuracy: 0.9869 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 749us/step - loss: 7.7216e-04 - accuracy: 0.9822 - val_loss: 5.9737e-04 - val_accuracy: 0.9661\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 856us/step - loss: 7.1095e-04 - accuracy: 0.9890 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 0.0020 - accuracy: 0.9532 - val_loss: 7.8033e-04 - val_accuracy: 0.9661\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 8.9063e-04 - accuracy: 0.9602 - val_loss: 6.8779e-04 - val_accuracy: 0.9831\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 864us/step - loss: 8.7586e-04 - accuracy: 0.9883 - val_loss: 5.8874e-04 - val_accuracy: 0.9661\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 7.6152e-04 - accuracy: 0.9795 - val_loss: 8.6753e-04 - val_accuracy: 0.9661\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 7.4194e-04 - accuracy: 0.9841 - val_loss: 8.6439e-04 - val_accuracy: 0.9831\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 840us/step - loss: 6.7586e-04 - accuracy: 0.9878 - val_loss: 8.6682e-04 - val_accuracy: 0.9661\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 8.3969e-04 - accuracy: 0.9753 - val_loss: 6.0335e-04 - val_accuracy: 0.9661\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 885us/step - loss: 5.3862e-04 - accuracy: 0.9902 - val_loss: 8.4472e-04 - val_accuracy: 0.9661\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 902us/step - loss: 7.0139e-04 - accuracy: 0.9924 - val_loss: 8.4057e-04 - val_accuracy: 0.9661\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 883us/step - loss: 8.0571e-04 - accuracy: 0.9905 - val_loss: 6.4345e-04 - val_accuracy: 0.9661\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 5.9628e-04 - accuracy: 0.9846 - val_loss: 6.0777e-04 - val_accuracy: 0.9661\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 834us/step - loss: 5.4985e-04 - accuracy: 0.9857 - val_loss: 8.2460e-04 - val_accuracy: 0.9831\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 762us/step - loss: 6.0977e-04 - accuracy: 0.9797 - val_loss: 6.3199e-04 - val_accuracy: 0.9661\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 862us/step - loss: 6.1208e-04 - accuracy: 0.9837 - val_loss: 7.1313e-04 - val_accuracy: 0.9661\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 846us/step - loss: 6.9413e-04 - accuracy: 0.9797 - val_loss: 7.5004e-04 - val_accuracy: 0.9661\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 843us/step - loss: 5.5971e-04 - accuracy: 0.9956 - val_loss: 5.9451e-04 - val_accuracy: 1.0000\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 742us/step - loss: 5.5651e-04 - accuracy: 0.9880 - val_loss: 8.2157e-04 - val_accuracy: 0.9831\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 846us/step - loss: 7.2552e-04 - accuracy: 0.9839 - val_loss: 6.9514e-04 - val_accuracy: 0.9661\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 892us/step - loss: 7.0411e-04 - accuracy: 0.9758 - val_loss: 7.5154e-04 - val_accuracy: 0.9661\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 884us/step - loss: 7.3443e-04 - accuracy: 0.9647 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 785us/step - loss: 7.4878e-04 - accuracy: 0.9651 - val_loss: 7.2358e-04 - val_accuracy: 0.9661\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 8.3829e-04 - accuracy: 0.9861 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0012 - accuracy: 0.9580 - val_loss: 8.8844e-04 - val_accuracy: 1.0000\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 783us/step - loss: 7.0311e-04 - accuracy: 0.9901 - val_loss: 8.8632e-04 - val_accuracy: 0.9661\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 860us/step - loss: 6.6150e-04 - accuracy: 0.9819 - val_loss: 7.1982e-04 - val_accuracy: 0.9661\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 704us/step - loss: 6.9221e-04 - accuracy: 0.9764 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 855us/step - loss: 7.3681e-04 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 784us/step - loss: 6.5832e-04 - accuracy: 0.9916 - val_loss: 6.2263e-04 - val_accuracy: 0.9831\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 709us/step - loss: 5.8770e-04 - accuracy: 0.9910 - val_loss: 5.4939e-04 - val_accuracy: 0.9831\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 6.0556e-04 - accuracy: 0.9856 - val_loss: 6.9871e-04 - val_accuracy: 0.9661\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 699us/step - loss: 6.5687e-04 - accuracy: 0.9711 - val_loss: 7.5426e-04 - val_accuracy: 0.9831\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 6.1312e-04 - accuracy: 0.9955 - val_loss: 0.0039 - val_accuracy: 0.8983\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 0.0015 - accuracy: 0.9670 - val_loss: 8.8986e-04 - val_accuracy: 0.9492\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 656us/step - loss: 8.8010e-04 - accuracy: 0.9685 - val_loss: 4.4966e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/170\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.9150e-04 - accuracy: 1.0000"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 0s 855us/step - loss: 6.0882e-04 - accuracy: 0.9834 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9878 - val_loss: 9.6071e-04 - val_accuracy: 0.9831\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.3985e-04 - accuracy: 0.9772 - val_loss: 5.6701e-04 - val_accuracy: 0.9831\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2349e-04 - accuracy: 0.9832 - val_loss: 5.9566e-04 - val_accuracy: 0.9661\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 6.5037e-04 - accuracy: 0.9824 - val_loss: 6.4095e-04 - val_accuracy: 0.9831\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 860us/step - loss: 6.3254e-04 - accuracy: 0.9912 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 842us/step - loss: 7.7374e-04 - accuracy: 0.9875 - val_loss: 9.4356e-04 - val_accuracy: 0.9831\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 5.7905e-04 - accuracy: 0.9900 - val_loss: 8.8603e-04 - val_accuracy: 0.9831\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 8.1482e-04 - accuracy: 0.9774 - val_loss: 5.3097e-04 - val_accuracy: 0.9831\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 890us/step - loss: 5.6945e-04 - accuracy: 0.9889 - val_loss: 7.0890e-04 - val_accuracy: 0.9661\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 853us/step - loss: 6.8759e-04 - accuracy: 0.9815 - val_loss: 5.9621e-04 - val_accuracy: 1.0000\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 754us/step - loss: 6.6270e-04 - accuracy: 0.9833 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 698us/step - loss: 6.4535e-04 - accuracy: 0.9880 - val_loss: 8.8821e-04 - val_accuracy: 0.9492\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 733us/step - loss: 6.0496e-04 - accuracy: 0.9907 - val_loss: 4.9347e-04 - val_accuracy: 0.9831\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 705us/step - loss: 6.0353e-04 - accuracy: 0.9820 - val_loss: 4.7671e-04 - val_accuracy: 0.9661\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 756us/step - loss: 4.6462e-04 - accuracy: 0.9900 - val_loss: 6.5220e-04 - val_accuracy: 0.9661\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 776us/step - loss: 6.2050e-04 - accuracy: 0.9658 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 790us/step - loss: 6.1798e-04 - accuracy: 0.9840 - val_loss: 4.6251e-04 - val_accuracy: 0.9831\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 6.2701e-04 - accuracy: 0.9924 - val_loss: 8.8597e-04 - val_accuracy: 0.9492\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 706us/step - loss: 5.1806e-04 - accuracy: 0.9947 - val_loss: 5.9143e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 4.5307e-04 - accuracy: 0.9922 - val_loss: 6.0564e-04 - val_accuracy: 0.9831\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 691us/step - loss: 7.3663e-04 - accuracy: 0.9909 - val_loss: 5.6333e-04 - val_accuracy: 0.9661\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 4.4011e-04 - accuracy: 0.9989 - val_loss: 5.6087e-04 - val_accuracy: 0.9661\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 5.4141e-04 - accuracy: 0.9900 - val_loss: 6.4834e-04 - val_accuracy: 0.9831\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 4.8421e-04 - accuracy: 0.9958 - val_loss: 5.4695e-04 - val_accuracy: 0.9492\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 4.9962e-04 - accuracy: 0.9833 - val_loss: 0.0017 - val_accuracy: 0.9153\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 7.9576e-04 - accuracy: 0.9790 - val_loss: 6.7940e-04 - val_accuracy: 0.9661\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 6.9897e-04 - accuracy: 0.9825 - val_loss: 6.8134e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 5.7092e-04 - accuracy: 0.9883 - val_loss: 5.2759e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 776us/step - loss: 5.0561e-04 - accuracy: 0.9833 - val_loss: 5.6444e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 680us/step - loss: 7.4223e-04 - accuracy: 0.9876 - val_loss: 4.9344e-04 - val_accuracy: 0.9661\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 5.3383e-04 - accuracy: 0.9858 - val_loss: 5.9110e-04 - val_accuracy: 0.9661\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 691us/step - loss: 4.8164e-04 - accuracy: 0.9853 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 5.5749e-04 - accuracy: 0.9864 - val_loss: 7.8128e-04 - val_accuracy: 0.9661\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 4.8149e-04 - accuracy: 0.9828 - val_loss: 5.5416e-04 - val_accuracy: 0.9492\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 700us/step - loss: 4.2845e-04 - accuracy: 0.9862 - val_loss: 9.1750e-04 - val_accuracy: 0.9831\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 5.6542e-04 - accuracy: 0.9834 - val_loss: 4.9167e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 5.2516e-04 - accuracy: 0.9852 - val_loss: 4.7916e-04 - val_accuracy: 0.9831\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 819us/step - loss: 4.7960e-04 - accuracy: 0.9893 - val_loss: 5.2324e-04 - val_accuracy: 0.9831\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 676us/step - loss: 5.9857e-04 - accuracy: 0.9967 - val_loss: 5.8987e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 815us/step - loss: 4.0902e-04 - accuracy: 0.9846 - val_loss: 5.1501e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 6.7354e-04 - accuracy: 0.9704 - val_loss: 5.2064e-04 - val_accuracy: 0.9831\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 786us/step - loss: 4.5435e-04 - accuracy: 0.9909 - val_loss: 5.1560e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 4.3526e-04 - accuracy: 0.9983 - val_loss: 6.7761e-04 - val_accuracy: 0.9661\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 709us/step - loss: 4.7927e-04 - accuracy: 0.9823 - val_loss: 5.1228e-04 - val_accuracy: 0.9661\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 4.6459e-04 - accuracy: 0.9813 - val_loss: 5.8418e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 3.8385e-04 - accuracy: 0.9915 - val_loss: 7.0648e-04 - val_accuracy: 0.9661\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 842us/step - loss: 4.8467e-04 - accuracy: 0.9909 - val_loss: 7.2706e-04 - val_accuracy: 0.9492\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 5.9200e-04 - accuracy: 0.9810 - val_loss: 6.6281e-04 - val_accuracy: 0.9661\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 6.2377e-04 - accuracy: 0.9800 - val_loss: 5.6735e-04 - val_accuracy: 0.9831\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 4.1725e-04 - accuracy: 0.9968 - val_loss: 5.5183e-04 - val_accuracy: 0.9661\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 910us/step - loss: 4.8810e-04 - accuracy: 0.9742 - val_loss: 4.7530e-04 - val_accuracy: 0.9661\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 862us/step - loss: 5.2862e-04 - accuracy: 0.9785 - val_loss: 4.0956e-04 - val_accuracy: 0.9831\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 3.6351e-04 - accuracy: 0.9811 - val_loss: 4.7431e-04 - val_accuracy: 0.9831\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 834us/step - loss: 4.7620e-04 - accuracy: 0.9832 - val_loss: 6.1193e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 711us/step - loss: 4.3362e-04 - accuracy: 0.9817 - val_loss: 7.0028e-04 - val_accuracy: 0.9661\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 841us/step - loss: 4.8300e-04 - accuracy: 0.9843 - val_loss: 5.9641e-04 - val_accuracy: 0.9661\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 7.1261e-04 - accuracy: 0.9677 - val_loss: 4.6177e-04 - val_accuracy: 0.9831\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 749us/step - loss: 4.0809e-04 - accuracy: 0.9925 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 843us/step - loss: 3.8156e-04 - accuracy: 0.9861 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 7.1060e-04 - accuracy: 0.9846 - val_loss: 6.6531e-04 - val_accuracy: 0.9831\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 5.5802e-04 - accuracy: 0.9849 - val_loss: 9.3886e-04 - val_accuracy: 0.9831\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 5.9565e-04 - accuracy: 0.9897 - val_loss: 3.5889e-04 - val_accuracy: 0.9831\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 696us/step - loss: 3.8508e-04 - accuracy: 0.9949 - val_loss: 4.5089e-04 - val_accuracy: 0.9831\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 749us/step - loss: 4.7258e-04 - accuracy: 0.9810 - val_loss: 5.7931e-04 - val_accuracy: 0.9661\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 3.5061e-04 - accuracy: 0.9952 - val_loss: 4.7008e-04 - val_accuracy: 0.9831\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 3.9643e-04 - accuracy: 0.9882 - val_loss: 4.1420e-04 - val_accuracy: 0.9831\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 701us/step - loss: 4.1436e-04 - accuracy: 0.9877 - val_loss: 5.5274e-04 - val_accuracy: 0.9831\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 855us/step - loss: 4.8400e-04 - accuracy: 0.9940 - val_loss: 7.4644e-04 - val_accuracy: 0.9661\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 749us/step - loss: 4.1507e-04 - accuracy: 0.9911 - val_loss: 3.9801e-04 - val_accuracy: 0.9831\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 3.5971e-04 - accuracy: 0.9906 - val_loss: 5.0158e-04 - val_accuracy: 0.9831\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 754us/step - loss: 3.7028e-04 - accuracy: 0.9849 - val_loss: 5.0133e-04 - val_accuracy: 0.9661\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 3.6115e-04 - accuracy: 0.9873 - val_loss: 5.6365e-04 - val_accuracy: 0.9661\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 3.5338e-04 - accuracy: 0.9939 - val_loss: 4.0989e-04 - val_accuracy: 0.9831\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 701us/step - loss: 4.6305e-04 - accuracy: 0.9860 - val_loss: 5.3146e-04 - val_accuracy: 0.9831\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 3.7977e-04 - accuracy: 0.9908 - val_loss: 4.1520e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 699us/step - loss: 5.4881e-04 - accuracy: 0.9828 - val_loss: 5.1676e-04 - val_accuracy: 0.9831\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 734us/step - loss: 4.0001e-04 - accuracy: 0.9910 - val_loss: 4.6495e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 2.7463e-04 - accuracy: 0.9968 - val_loss: 4.9578e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 3.5523e-04 - accuracy: 0.9959 - val_loss: 4.2450e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 3.3474e-04 - accuracy: 0.9893 - val_loss: 5.1835e-04 - val_accuracy: 0.9661\n",
            "6/6 [==============================] - 0s 407us/step - loss: 5.1835e-04 - accuracy: 0.9661\n",
            "Loss = 0.0005183520261198282, Accuracy = 0.9661017060279846\n",
            "Loss array:  [0.0005183520261198282]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 2/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.7497 - val_loss: 0.0260 - val_accuracy: 0.7797\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0191 - accuracy: 0.8545 - val_loss: 0.0124 - val_accuracy: 0.8475\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 779us/step - loss: 0.0085 - accuracy: 0.9120 - val_loss: 0.0085 - val_accuracy: 0.8644\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.0074 - accuracy: 0.9203 - val_loss: 0.0095 - val_accuracy: 0.8644\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.0061 - accuracy: 0.9238 - val_loss: 0.0062 - val_accuracy: 0.8644\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0043 - accuracy: 0.9198 - val_loss: 0.0050 - val_accuracy: 0.8644\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0036 - accuracy: 0.9390 - val_loss: 0.0041 - val_accuracy: 0.8814\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 0.0036 - accuracy: 0.9260 - val_loss: 0.0047 - val_accuracy: 0.8644\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.0029 - accuracy: 0.9500 - val_loss: 0.0049 - val_accuracy: 0.8644\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 0.0045 - accuracy: 0.9344 - val_loss: 0.0039 - val_accuracy: 0.8814\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0029 - accuracy: 0.9363 - val_loss: 0.0035 - val_accuracy: 0.8814\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0023 - accuracy: 0.9552 - val_loss: 0.0048 - val_accuracy: 0.8983\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.0028 - accuracy: 0.9298 - val_loss: 0.0026 - val_accuracy: 0.8983\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 0.0023 - accuracy: 0.9437 - val_loss: 0.0038 - val_accuracy: 0.9153\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 0.0021 - accuracy: 0.9320 - val_loss: 0.0046 - val_accuracy: 0.8814\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 640us/step - loss: 0.0023 - accuracy: 0.9463 - val_loss: 0.0034 - val_accuracy: 0.9153\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0017 - accuracy: 0.9579 - val_loss: 0.0021 - val_accuracy: 0.9322\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 704us/step - loss: 0.0015 - accuracy: 0.9766 - val_loss: 0.0021 - val_accuracy: 0.9322\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0014 - accuracy: 0.9671 - val_loss: 0.0018 - val_accuracy: 0.9322\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0013 - accuracy: 0.9641 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 0.0014 - accuracy: 0.9557 - val_loss: 0.0022 - val_accuracy: 0.9661\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 765us/step - loss: 0.0014 - accuracy: 0.9428 - val_loss: 0.0020 - val_accuracy: 0.9492\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0013 - accuracy: 0.9546 - val_loss: 0.0019 - val_accuracy: 0.9322\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 0.0011 - accuracy: 0.9676 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 649us/step - loss: 0.0010 - accuracy: 0.9808 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 0.0011 - accuracy: 0.9581 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0013 - accuracy: 0.9724 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 706us/step - loss: 9.9650e-04 - accuracy: 0.9732 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 786us/step - loss: 9.9070e-04 - accuracy: 0.9594 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 9.8134e-04 - accuracy: 0.9676 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 0.0010 - accuracy: 0.9652 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0012 - accuracy: 0.9636 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 786us/step - loss: 7.1440e-04 - accuracy: 0.9681 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 740us/step - loss: 8.5615e-04 - accuracy: 0.9762 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 9.4634e-04 - accuracy: 0.9772 - val_loss: 0.0022 - val_accuracy: 0.9322\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 733us/step - loss: 9.4346e-04 - accuracy: 0.9633 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 7.3840e-04 - accuracy: 0.9803 - val_loss: 0.0026 - val_accuracy: 0.9492\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 9.3479e-04 - accuracy: 0.9769 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0015 - accuracy: 0.9712 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 7.1811e-04 - accuracy: 0.9788 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 7.4301e-04 - accuracy: 0.9677 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 0.0010 - accuracy: 0.9830 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 673us/step - loss: 6.7313e-04 - accuracy: 0.9867 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 704us/step - loss: 6.4667e-04 - accuracy: 0.9904 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 7.5783e-04 - accuracy: 0.9803 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 650us/step - loss: 7.4241e-04 - accuracy: 0.9853 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 720us/step - loss: 5.5418e-04 - accuracy: 0.9823 - val_loss: 9.0089e-04 - val_accuracy: 0.9661\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 672us/step - loss: 7.1661e-04 - accuracy: 0.9837 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 7.6533e-04 - accuracy: 0.9773 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 762us/step - loss: 6.7446e-04 - accuracy: 0.9708 - val_loss: 9.9189e-04 - val_accuracy: 0.9661\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.0010 - accuracy: 0.9696 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 5.8211e-04 - accuracy: 0.9721 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 725us/step - loss: 7.6274e-04 - accuracy: 0.9834 - val_loss: 0.0019 - val_accuracy: 0.9831\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 7.2775e-04 - accuracy: 0.9798 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 5.8173e-04 - accuracy: 0.9758 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 6.1899e-04 - accuracy: 0.9701 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 4.9264e-04 - accuracy: 0.9806 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 737us/step - loss: 7.3663e-04 - accuracy: 0.9755 - val_loss: 0.0019 - val_accuracy: 0.9492\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 7.4102e-04 - accuracy: 0.9895 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 756us/step - loss: 5.7590e-04 - accuracy: 0.9803 - val_loss: 9.4666e-04 - val_accuracy: 0.9831\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 6.6665e-04 - accuracy: 0.9873 - val_loss: 0.0015 - val_accuracy: 0.9153\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 7.8994e-04 - accuracy: 0.9668 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 706us/step - loss: 4.5454e-04 - accuracy: 0.9795 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 768us/step - loss: 5.7848e-04 - accuracy: 0.9843 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 659us/step - loss: 5.3608e-04 - accuracy: 0.9740 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 7.8512e-04 - accuracy: 0.9746 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 689us/step - loss: 6.3639e-04 - accuracy: 0.9809 - val_loss: 9.4981e-04 - val_accuracy: 0.9661\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 710us/step - loss: 7.4765e-04 - accuracy: 0.9748 - val_loss: 9.9624e-04 - val_accuracy: 0.9661\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7900e-04 - accuracy: 0.9686 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 902us/step - loss: 0.0010 - accuracy: 0.9741 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 902us/step - loss: 6.5232e-04 - accuracy: 0.9700 - val_loss: 9.8647e-04 - val_accuracy: 0.9661\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 883us/step - loss: 7.1139e-04 - accuracy: 0.9792 - val_loss: 9.5758e-04 - val_accuracy: 0.9831\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 907us/step - loss: 6.7304e-04 - accuracy: 0.9955 - val_loss: 9.1630e-04 - val_accuracy: 0.9661\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 939us/step - loss: 5.8216e-04 - accuracy: 0.9912 - val_loss: 8.3917e-04 - val_accuracy: 0.9661\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 859us/step - loss: 5.0913e-04 - accuracy: 0.9787 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 897us/step - loss: 7.8735e-04 - accuracy: 0.9783 - val_loss: 9.6402e-04 - val_accuracy: 0.9831\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 898us/step - loss: 5.1999e-04 - accuracy: 0.9781 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 885us/step - loss: 4.8238e-04 - accuracy: 0.9801 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 887us/step - loss: 5.2561e-04 - accuracy: 0.9830 - val_loss: 9.8682e-04 - val_accuracy: 0.9831\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 7.8668e-04 - accuracy: 0.9764 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 741us/step - loss: 4.9470e-04 - accuracy: 0.9828 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 856us/step - loss: 7.4995e-04 - accuracy: 0.9637 - val_loss: 8.9442e-04 - val_accuracy: 0.9661\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 831us/step - loss: 4.5781e-04 - accuracy: 0.9911 - val_loss: 8.8767e-04 - val_accuracy: 0.9831\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 4.6130e-04 - accuracy: 0.9882 - val_loss: 8.3312e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 831us/step - loss: 6.9420e-04 - accuracy: 0.9842 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 764us/step - loss: 5.6739e-04 - accuracy: 0.9863 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 721us/step - loss: 4.4746e-04 - accuracy: 0.9896 - val_loss: 9.2085e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 875us/step - loss: 6.6511e-04 - accuracy: 0.9829 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 792us/step - loss: 6.2508e-04 - accuracy: 0.9857 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 961us/step - loss: 4.9354e-04 - accuracy: 0.9710 - val_loss: 9.0335e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.0010 - accuracy: 0.9757 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 799us/step - loss: 7.4420e-04 - accuracy: 0.9760 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 8.1770e-04 - accuracy: 0.9833 - val_loss: 8.2369e-04 - val_accuracy: 0.9661\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 5.0456e-04 - accuracy: 0.9834 - val_loss: 8.1981e-04 - val_accuracy: 0.9661\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 817us/step - loss: 4.0354e-04 - accuracy: 0.9936 - val_loss: 8.3409e-04 - val_accuracy: 0.9661\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 4.0135e-04 - accuracy: 0.9918 - val_loss: 9.5809e-04 - val_accuracy: 0.9831\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 700us/step - loss: 5.4711e-04 - accuracy: 0.9865 - val_loss: 9.3345e-04 - val_accuracy: 0.9661\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 873us/step - loss: 6.0425e-04 - accuracy: 0.9979 - val_loss: 8.8153e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 4.2287e-04 - accuracy: 0.9826 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 4.4755e-04 - accuracy: 0.9935 - val_loss: 8.9817e-04 - val_accuracy: 0.9492\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 813us/step - loss: 4.5138e-04 - accuracy: 0.9788 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 6.3414e-04 - accuracy: 0.9888 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 6.8389e-04 - accuracy: 0.9684 - val_loss: 9.1931e-04 - val_accuracy: 0.9661\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 844us/step - loss: 4.4559e-04 - accuracy: 0.9978 - val_loss: 8.9039e-04 - val_accuracy: 0.9831\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 3.7931e-04 - accuracy: 0.9942 - val_loss: 8.6360e-04 - val_accuracy: 0.9831\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 4.8806e-04 - accuracy: 0.9868 - val_loss: 8.6776e-04 - val_accuracy: 0.9831\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 854us/step - loss: 3.9475e-04 - accuracy: 0.9821 - val_loss: 8.1441e-04 - val_accuracy: 0.9831\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 857us/step - loss: 5.5157e-04 - accuracy: 0.9851 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 793us/step - loss: 6.4810e-04 - accuracy: 0.9897 - val_loss: 8.8661e-04 - val_accuracy: 0.9831\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 701us/step - loss: 6.4472e-04 - accuracy: 0.9769 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 839us/step - loss: 4.0597e-04 - accuracy: 0.9946 - val_loss: 7.6708e-04 - val_accuracy: 0.9492\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 768us/step - loss: 4.2293e-04 - accuracy: 0.9967 - val_loss: 8.5463e-04 - val_accuracy: 0.9661\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 4.5526e-04 - accuracy: 0.9927 - val_loss: 8.2641e-04 - val_accuracy: 0.9831\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 893us/step - loss: 4.2489e-04 - accuracy: 0.9970 - val_loss: 9.2573e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 750us/step - loss: 4.3216e-04 - accuracy: 0.9735 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 700us/step - loss: 3.8966e-04 - accuracy: 0.9905 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 673us/step - loss: 4.6342e-04 - accuracy: 0.9879 - val_loss: 7.8132e-04 - val_accuracy: 0.9661\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 5.1920e-04 - accuracy: 0.9860 - val_loss: 9.8023e-04 - val_accuracy: 0.9831\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 673us/step - loss: 6.9802e-04 - accuracy: 0.9881 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 6.4976e-04 - accuracy: 0.9793 - val_loss: 8.6583e-04 - val_accuracy: 0.9831\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 677us/step - loss: 5.5252e-04 - accuracy: 0.9838 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 3.5277e-04 - accuracy: 0.9964 - val_loss: 6.9508e-04 - val_accuracy: 0.9831\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 768us/step - loss: 4.0951e-04 - accuracy: 0.9958 - val_loss: 7.1068e-04 - val_accuracy: 0.9831\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 795us/step - loss: 3.8873e-04 - accuracy: 0.9899 - val_loss: 8.2700e-04 - val_accuracy: 0.9831\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 681us/step - loss: 3.3292e-04 - accuracy: 0.9902 - val_loss: 9.3716e-04 - val_accuracy: 0.9661\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 4.5210e-04 - accuracy: 0.9888 - val_loss: 9.9743e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 4.0920e-04 - accuracy: 0.9782 - val_loss: 7.5741e-04 - val_accuracy: 0.9661\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 3.2247e-04 - accuracy: 0.9970 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 721us/step - loss: 5.6327e-04 - accuracy: 0.9750 - val_loss: 9.3927e-04 - val_accuracy: 0.9831\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 4.1470e-04 - accuracy: 0.9979 - val_loss: 7.5406e-04 - val_accuracy: 0.9661\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 681us/step - loss: 5.8986e-04 - accuracy: 0.9819 - val_loss: 7.7917e-04 - val_accuracy: 0.9322\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 3.6223e-04 - accuracy: 0.9852 - val_loss: 7.8870e-04 - val_accuracy: 0.9831\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 3.6850e-04 - accuracy: 0.9933 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 787us/step - loss: 6.2411e-04 - accuracy: 0.9834 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 3.6590e-04 - accuracy: 0.9939 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 728us/step - loss: 4.1837e-04 - accuracy: 0.9924 - val_loss: 9.2119e-04 - val_accuracy: 0.9831\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 4.5549e-04 - accuracy: 0.9871 - val_loss: 6.9909e-04 - val_accuracy: 0.9831\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 742us/step - loss: 3.9494e-04 - accuracy: 0.9877 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 699us/step - loss: 5.9920e-04 - accuracy: 0.9853 - val_loss: 8.4708e-04 - val_accuracy: 0.9661\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 652us/step - loss: 4.5968e-04 - accuracy: 0.9640 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 4.4172e-04 - accuracy: 0.9860 - val_loss: 8.1042e-04 - val_accuracy: 0.9831\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 692us/step - loss: 4.2291e-04 - accuracy: 0.9943 - val_loss: 8.6277e-04 - val_accuracy: 0.9831\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 741us/step - loss: 3.8142e-04 - accuracy: 0.9917 - val_loss: 8.0802e-04 - val_accuracy: 0.9831\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 678us/step - loss: 5.9575e-04 - accuracy: 0.9778 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 4.0869e-04 - accuracy: 0.9841 - val_loss: 7.6058e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 3.3615e-04 - accuracy: 0.9945 - val_loss: 7.7687e-04 - val_accuracy: 0.9831\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 721us/step - loss: 3.1060e-04 - accuracy: 0.9926 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 5.4165e-04 - accuracy: 0.9804 - val_loss: 8.1068e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 719us/step - loss: 4.8794e-04 - accuracy: 0.9985 - val_loss: 9.7534e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 4.3726e-04 - accuracy: 0.9910 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 4.3329e-04 - accuracy: 0.9918 - val_loss: 8.2687e-04 - val_accuracy: 0.9322\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 649us/step - loss: 4.5197e-04 - accuracy: 0.9664 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 680us/step - loss: 3.0603e-04 - accuracy: 0.9964 - val_loss: 8.8893e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 664us/step - loss: 4.3978e-04 - accuracy: 0.9957 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3168e-04 - accuracy: 0.9901 - val_loss: 6.8314e-04 - val_accuracy: 0.9661\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 909us/step - loss: 4.6348e-04 - accuracy: 0.9827 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 890us/step - loss: 5.7980e-04 - accuracy: 0.9737 - val_loss: 8.4186e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 900us/step - loss: 2.7631e-04 - accuracy: 0.9964 - val_loss: 6.4888e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 951us/step - loss: 3.2348e-04 - accuracy: 0.9873 - val_loss: 6.9212e-04 - val_accuracy: 0.9831\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 820us/step - loss: 3.4543e-04 - accuracy: 0.9915 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 4.5417e-04 - accuracy: 0.9973 - val_loss: 8.2171e-04 - val_accuracy: 0.9492\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 677us/step - loss: 4.1445e-04 - accuracy: 0.9722 - val_loss: 6.4014e-04 - val_accuracy: 0.9661\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 840us/step - loss: 4.0746e-04 - accuracy: 0.9884 - val_loss: 6.5255e-04 - val_accuracy: 0.9831\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 3.6504e-04 - accuracy: 0.9923 - val_loss: 7.2230e-04 - val_accuracy: 0.9831\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 3.6941e-04 - accuracy: 0.9913 - val_loss: 7.2211e-04 - val_accuracy: 0.9322\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 776us/step - loss: 2.9580e-04 - accuracy: 0.9946 - val_loss: 8.8933e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 3.0768e-04 - accuracy: 0.9942 - val_loss: 8.8380e-04 - val_accuracy: 0.9831\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 3.6549e-04 - accuracy: 0.9972 - val_loss: 7.8293e-04 - val_accuracy: 0.9661\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 3.5670e-04 - accuracy: 0.9918 - val_loss: 7.6625e-04 - val_accuracy: 0.9831\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 895us/step - loss: 3.4219e-04 - accuracy: 0.9938 - val_loss: 8.1101e-04 - val_accuracy: 0.9661\n",
            "6/6 [==============================] - 0s 357us/step - loss: 8.1101e-04 - accuracy: 0.9661\n",
            "Loss = 0.0008110131020657718, Accuracy = 0.9661017060279846\n",
            "Loss array:  [0.0005183520261198282, 0.0008110131020657718]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 3/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.7027 - val_loss: 0.0160 - val_accuracy: 0.9138\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 0.0148 - accuracy: 0.8967 - val_loss: 0.0061 - val_accuracy: 0.9655\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 818us/step - loss: 0.0078 - accuracy: 0.9319 - val_loss: 0.0035 - val_accuracy: 0.9655\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 790us/step - loss: 0.0055 - accuracy: 0.9339 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 839us/step - loss: 0.0046 - accuracy: 0.9218 - val_loss: 0.0035 - val_accuracy: 0.9655\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0039 - accuracy: 0.9151 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 738us/step - loss: 0.0033 - accuracy: 0.9156 - val_loss: 0.0035 - val_accuracy: 0.8966\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 832us/step - loss: 0.0037 - accuracy: 0.9112 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 826us/step - loss: 0.0029 - accuracy: 0.9301 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 0.0027 - accuracy: 0.9396 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 0.0029 - accuracy: 0.9243 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 0.0022 - accuracy: 0.9604 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0020 - accuracy: 0.9440 - val_loss: 0.0026 - val_accuracy: 0.9310\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0024 - accuracy: 0.9403 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 0.0016 - accuracy: 0.9409 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0015 - accuracy: 0.9446 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 890us/step - loss: 0.0013 - accuracy: 0.9605 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0016 - accuracy: 0.9515 - val_loss: 9.6782e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 885us/step - loss: 0.0012 - accuracy: 0.9725 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0013 - accuracy: 0.9694 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 783us/step - loss: 0.0014 - accuracy: 0.9699 - val_loss: 8.7809e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0011 - accuracy: 0.9729 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 854us/step - loss: 0.0010 - accuracy: 0.9856 - val_loss: 8.4449e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 780us/step - loss: 9.2869e-04 - accuracy: 0.9784 - val_loss: 7.4256e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 0.0012 - accuracy: 0.9784 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 844us/step - loss: 0.0013 - accuracy: 0.9729 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 666us/step - loss: 8.1958e-04 - accuracy: 0.9845 - val_loss: 8.4975e-04 - val_accuracy: 0.9828\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 835us/step - loss: 9.0403e-04 - accuracy: 0.9862 - val_loss: 9.0654e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 7.6197e-04 - accuracy: 0.9809 - val_loss: 8.5045e-04 - val_accuracy: 0.9828\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 8.2198e-04 - accuracy: 0.9844 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 8.0697e-04 - accuracy: 0.9761 - val_loss: 9.9634e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 722us/step - loss: 8.8064e-04 - accuracy: 0.9837 - val_loss: 8.5427e-04 - val_accuracy: 1.0000\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 8.4310e-04 - accuracy: 0.9907 - val_loss: 9.3987e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 669us/step - loss: 7.7324e-04 - accuracy: 0.9927 - val_loss: 6.9384e-04 - val_accuracy: 0.9828\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 754us/step - loss: 8.3554e-04 - accuracy: 0.9620 - val_loss: 9.1737e-04 - val_accuracy: 0.9828\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 699us/step - loss: 8.8659e-04 - accuracy: 0.9796 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0011 - accuracy: 0.9738 - val_loss: 7.3749e-04 - val_accuracy: 1.0000\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 8.3716e-04 - accuracy: 0.9844 - val_loss: 7.8641e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 634us/step - loss: 7.0378e-04 - accuracy: 0.9820 - val_loss: 7.8278e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 8.5751e-04 - accuracy: 0.9769 - val_loss: 6.6807e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 678us/step - loss: 7.0562e-04 - accuracy: 0.9855 - val_loss: 6.3188e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 750us/step - loss: 6.6972e-04 - accuracy: 0.9847 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 686us/step - loss: 6.8432e-04 - accuracy: 0.9927 - val_loss: 7.1697e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 624us/step - loss: 6.7383e-04 - accuracy: 0.9810 - val_loss: 6.3968e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 5.9675e-04 - accuracy: 0.9872 - val_loss: 7.5541e-04 - val_accuracy: 0.9828\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 685us/step - loss: 6.1813e-04 - accuracy: 0.9900 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 8.2366e-04 - accuracy: 0.9646 - val_loss: 5.9955e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 691us/step - loss: 6.5938e-04 - accuracy: 0.9920 - val_loss: 7.5850e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 669us/step - loss: 6.5888e-04 - accuracy: 0.9811 - val_loss: 7.7744e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 798us/step - loss: 6.5990e-04 - accuracy: 0.9823 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0014 - accuracy: 0.9685 - val_loss: 6.8736e-04 - val_accuracy: 1.0000\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 812us/step - loss: 5.2344e-04 - accuracy: 0.9825 - val_loss: 8.2950e-04 - val_accuracy: 0.9828\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 762us/step - loss: 6.4516e-04 - accuracy: 0.9968 - val_loss: 6.4039e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 722us/step - loss: 5.5326e-04 - accuracy: 0.9766 - val_loss: 9.7192e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 659us/step - loss: 7.5983e-04 - accuracy: 0.9776 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 647us/step - loss: 5.5756e-04 - accuracy: 0.9851 - val_loss: 5.5751e-04 - val_accuracy: 0.9828\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 785us/step - loss: 5.2132e-04 - accuracy: 0.9893 - val_loss: 8.3859e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6460e-04 - accuracy: 0.9890 - val_loss: 8.4471e-04 - val_accuracy: 0.9655\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7819e-04 - accuracy: 0.9930 - val_loss: 7.4796e-04 - val_accuracy: 0.9828\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 902us/step - loss: 5.9708e-04 - accuracy: 0.9966 - val_loss: 8.6148e-04 - val_accuracy: 0.9828\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 868us/step - loss: 6.5250e-04 - accuracy: 0.9888 - val_loss: 7.1339e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 906us/step - loss: 5.8211e-04 - accuracy: 0.9799 - val_loss: 5.3398e-04 - val_accuracy: 0.9828\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 885us/step - loss: 4.6749e-04 - accuracy: 0.9942 - val_loss: 7.1971e-04 - val_accuracy: 0.9828\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 6.0892e-04 - accuracy: 0.9921 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 839us/step - loss: 0.0013 - accuracy: 0.9912 - val_loss: 7.2783e-04 - val_accuracy: 0.9828\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 716us/step - loss: 5.0842e-04 - accuracy: 0.9921 - val_loss: 7.2585e-04 - val_accuracy: 0.9828\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 880us/step - loss: 5.4039e-04 - accuracy: 0.9908 - val_loss: 6.8434e-04 - val_accuracy: 0.9828\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 749us/step - loss: 6.2680e-04 - accuracy: 0.9904 - val_loss: 6.0567e-04 - val_accuracy: 0.9828\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 819us/step - loss: 4.7931e-04 - accuracy: 0.9892 - val_loss: 6.8735e-04 - val_accuracy: 0.9828\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 5.4138e-04 - accuracy: 0.9850 - val_loss: 5.1759e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 920us/step - loss: 5.8151e-04 - accuracy: 0.9887 - val_loss: 7.6979e-04 - val_accuracy: 0.9655\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 7.2249e-04 - accuracy: 0.9757 - val_loss: 9.3649e-04 - val_accuracy: 0.9655\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 741us/step - loss: 5.2928e-04 - accuracy: 0.9775 - val_loss: 7.8621e-04 - val_accuracy: 0.9828\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 841us/step - loss: 6.7183e-04 - accuracy: 0.9779 - val_loss: 6.0671e-04 - val_accuracy: 0.9828\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 5.3766e-04 - accuracy: 0.9807 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 750us/step - loss: 0.0010 - accuracy: 0.9678 - val_loss: 7.2628e-04 - val_accuracy: 0.9828\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 808us/step - loss: 4.8306e-04 - accuracy: 0.9804 - val_loss: 7.6477e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 844us/step - loss: 6.7112e-04 - accuracy: 0.9875 - val_loss: 8.9015e-04 - val_accuracy: 0.9828\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 5.0466e-04 - accuracy: 0.9946 - val_loss: 5.9881e-04 - val_accuracy: 0.9828\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 4.4488e-04 - accuracy: 0.9921 - val_loss: 7.5644e-04 - val_accuracy: 1.0000\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 833us/step - loss: 6.8035e-04 - accuracy: 0.9806 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 7.6257e-04 - accuracy: 0.9854 - val_loss: 8.0665e-04 - val_accuracy: 0.9828\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 779us/step - loss: 5.4481e-04 - accuracy: 0.9770 - val_loss: 6.2830e-04 - val_accuracy: 0.9828\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 832us/step - loss: 5.4241e-04 - accuracy: 0.9901 - val_loss: 6.5874e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 887us/step - loss: 6.5755e-04 - accuracy: 0.9775 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 6.9567e-04 - accuracy: 0.9738 - val_loss: 5.4343e-04 - val_accuracy: 0.9828\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 843us/step - loss: 4.4616e-04 - accuracy: 0.9964 - val_loss: 6.8147e-04 - val_accuracy: 0.9828\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 5.0598e-04 - accuracy: 0.9904 - val_loss: 6.8205e-04 - val_accuracy: 0.9828\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 919us/step - loss: 5.7253e-04 - accuracy: 0.9920 - val_loss: 5.2783e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 768us/step - loss: 4.1476e-04 - accuracy: 0.9953 - val_loss: 7.2827e-04 - val_accuracy: 0.9655\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 4.8695e-04 - accuracy: 0.9840 - val_loss: 4.9751e-04 - val_accuracy: 0.9828\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 838us/step - loss: 4.5523e-04 - accuracy: 0.9867 - val_loss: 4.9325e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 858us/step - loss: 3.8406e-04 - accuracy: 0.9933 - val_loss: 6.5045e-04 - val_accuracy: 1.0000\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 784us/step - loss: 4.3957e-04 - accuracy: 0.9968 - val_loss: 7.3626e-04 - val_accuracy: 0.9655\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 737us/step - loss: 6.2803e-04 - accuracy: 0.9774 - val_loss: 8.8832e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 880us/step - loss: 6.4333e-04 - accuracy: 0.9799 - val_loss: 5.7330e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 5.5087e-04 - accuracy: 0.9933 - val_loss: 5.4803e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 5.8317e-04 - accuracy: 0.9815 - val_loss: 6.0782e-04 - val_accuracy: 0.9828\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 692us/step - loss: 4.0616e-04 - accuracy: 0.9906 - val_loss: 7.1134e-04 - val_accuracy: 0.9828\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 785us/step - loss: 4.5462e-04 - accuracy: 0.9768 - val_loss: 4.1061e-04 - val_accuracy: 1.0000\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 6.3195e-04 - accuracy: 0.9888 - val_loss: 6.2936e-04 - val_accuracy: 0.9828\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 3.5018e-04 - accuracy: 0.9986 - val_loss: 8.9439e-04 - val_accuracy: 0.9828\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 3.9784e-04 - accuracy: 0.9775 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 697us/step - loss: 7.8021e-04 - accuracy: 0.9936 - val_loss: 5.2356e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 839us/step - loss: 3.8790e-04 - accuracy: 0.9827 - val_loss: 4.8573e-04 - val_accuracy: 0.9828\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 4.2033e-04 - accuracy: 0.9935 - val_loss: 5.2541e-04 - val_accuracy: 0.9828\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 821us/step - loss: 3.5501e-04 - accuracy: 0.9769 - val_loss: 6.4636e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 3.1773e-04 - accuracy: 0.9850 - val_loss: 5.1653e-04 - val_accuracy: 0.9828\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 3.7082e-04 - accuracy: 0.9821 - val_loss: 6.3047e-04 - val_accuracy: 0.9828\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 4.2481e-04 - accuracy: 0.9922 - val_loss: 5.1193e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 688us/step - loss: 4.5763e-04 - accuracy: 0.9979 - val_loss: 6.1487e-04 - val_accuracy: 0.9828\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 4.5001e-04 - accuracy: 0.9940 - val_loss: 5.8480e-04 - val_accuracy: 0.9828\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4145e-04 - accuracy: 0.9942 - val_loss: 6.0573e-04 - val_accuracy: 0.9655\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 908us/step - loss: 3.8115e-04 - accuracy: 0.9922 - val_loss: 9.2653e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 717us/step - loss: 4.3519e-04 - accuracy: 0.9924 - val_loss: 4.4748e-04 - val_accuracy: 0.9828\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 783us/step - loss: 3.5015e-04 - accuracy: 0.9892 - val_loss: 8.5022e-04 - val_accuracy: 0.9828\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 692us/step - loss: 4.8890e-04 - accuracy: 0.9890 - val_loss: 5.3895e-04 - val_accuracy: 0.9828\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 3.4521e-04 - accuracy: 0.9968 - val_loss: 4.3052e-04 - val_accuracy: 0.9828\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 3.3500e-04 - accuracy: 0.9789 - val_loss: 6.3602e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 734us/step - loss: 3.7364e-04 - accuracy: 0.9854 - val_loss: 5.1007e-04 - val_accuracy: 0.9828\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 2.9106e-04 - accuracy: 0.9843 - val_loss: 7.4501e-04 - val_accuracy: 0.9828\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 7.2067e-04 - accuracy: 0.9823 - val_loss: 7.1233e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 3.9776e-04 - accuracy: 0.9933 - val_loss: 6.1184e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 760us/step - loss: 4.9476e-04 - accuracy: 0.9743 - val_loss: 5.3169e-04 - val_accuracy: 0.9828\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 691us/step - loss: 3.3522e-04 - accuracy: 0.9919 - val_loss: 6.3478e-04 - val_accuracy: 0.9828\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 3.6381e-04 - accuracy: 0.9989 - val_loss: 5.0335e-04 - val_accuracy: 0.9828\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 3.4857e-04 - accuracy: 0.9913 - val_loss: 4.9846e-04 - val_accuracy: 0.9828\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 741us/step - loss: 3.4725e-04 - accuracy: 0.9832 - val_loss: 5.3969e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 711us/step - loss: 3.2940e-04 - accuracy: 0.9961 - val_loss: 4.2331e-04 - val_accuracy: 0.9828\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 764us/step - loss: 3.1285e-04 - accuracy: 0.9971 - val_loss: 6.7684e-04 - val_accuracy: 0.9828\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 756us/step - loss: 4.1800e-04 - accuracy: 0.9943 - val_loss: 5.5420e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 622us/step - loss: 4.0992e-04 - accuracy: 0.9921 - val_loss: 5.3487e-04 - val_accuracy: 0.9828\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 4.2616e-04 - accuracy: 0.9954 - val_loss: 6.2595e-04 - val_accuracy: 0.9828\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 682us/step - loss: 5.1999e-04 - accuracy: 0.9824 - val_loss: 6.2137e-04 - val_accuracy: 0.9828\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 3.6105e-04 - accuracy: 0.9778 - val_loss: 4.5009e-04 - val_accuracy: 0.9828\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 693us/step - loss: 3.2315e-04 - accuracy: 1.0000 - val_loss: 5.4804e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 631us/step - loss: 2.9793e-04 - accuracy: 0.9843 - val_loss: 4.8959e-04 - val_accuracy: 0.9828\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 756us/step - loss: 2.6638e-04 - accuracy: 0.9957 - val_loss: 5.9766e-04 - val_accuracy: 0.9828\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 667us/step - loss: 2.9790e-04 - accuracy: 0.9970 - val_loss: 6.5989e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 784us/step - loss: 3.4818e-04 - accuracy: 0.9943 - val_loss: 4.5089e-04 - val_accuracy: 0.9828\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 686us/step - loss: 3.6560e-04 - accuracy: 0.9831 - val_loss: 6.5648e-04 - val_accuracy: 0.9828\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 614us/step - loss: 4.2430e-04 - accuracy: 0.9947 - val_loss: 5.5659e-04 - val_accuracy: 0.9828\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 3.8866e-04 - accuracy: 0.9936 - val_loss: 8.5024e-04 - val_accuracy: 0.9828\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 4.9356e-04 - accuracy: 0.9938 - val_loss: 5.7961e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 733us/step - loss: 3.6088e-04 - accuracy: 0.9777 - val_loss: 5.1972e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 4.2573e-04 - accuracy: 0.9901 - val_loss: 6.4149e-04 - val_accuracy: 0.9828\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 618us/step - loss: 4.4728e-04 - accuracy: 0.9900 - val_loss: 5.5705e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 3.8421e-04 - accuracy: 0.9827 - val_loss: 4.6492e-04 - val_accuracy: 0.9828\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 3.4213e-04 - accuracy: 0.9986 - val_loss: 7.5526e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 3.7949e-04 - accuracy: 0.9905 - val_loss: 5.7681e-04 - val_accuracy: 0.9828\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 756us/step - loss: 5.6174e-04 - accuracy: 0.9633 - val_loss: 5.4403e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 618us/step - loss: 3.7898e-04 - accuracy: 0.9886 - val_loss: 9.3311e-04 - val_accuracy: 0.9655\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 5.2090e-04 - accuracy: 0.9989 - val_loss: 8.6228e-04 - val_accuracy: 0.9828\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 680us/step - loss: 4.6566e-04 - accuracy: 0.9946 - val_loss: 5.6502e-04 - val_accuracy: 0.9828\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 3.9543e-04 - accuracy: 0.9834 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 693us/step - loss: 6.5586e-04 - accuracy: 0.9797 - val_loss: 4.3239e-04 - val_accuracy: 0.9828\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 620us/step - loss: 3.2727e-04 - accuracy: 0.9926 - val_loss: 4.8040e-04 - val_accuracy: 0.9828\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 719us/step - loss: 2.5120e-04 - accuracy: 0.9972 - val_loss: 4.2499e-04 - val_accuracy: 0.9828\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 703us/step - loss: 3.2924e-04 - accuracy: 0.9883 - val_loss: 7.4004e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 3.9850e-04 - accuracy: 0.9982 - val_loss: 3.9794e-04 - val_accuracy: 0.9828\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 3.2531e-04 - accuracy: 0.9943 - val_loss: 4.7870e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 2.4455e-04 - accuracy: 0.9990 - val_loss: 8.5123e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 816us/step - loss: 4.8750e-04 - accuracy: 0.9864 - val_loss: 5.7058e-04 - val_accuracy: 0.9828\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 676us/step - loss: 5.3190e-04 - accuracy: 0.9887 - val_loss: 8.1509e-04 - val_accuracy: 0.9828\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 869us/step - loss: 9.0611e-04 - accuracy: 0.9695 - val_loss: 4.8150e-04 - val_accuracy: 0.9828\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 783us/step - loss: 3.2924e-04 - accuracy: 0.9962 - val_loss: 6.9891e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 8.8113e-04 - accuracy: 0.9715 - val_loss: 5.7615e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.9464e-04 - accuracy: 0.9950 - val_loss: 4.6179e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 2.8910e-04 - accuracy: 0.9940 - val_loss: 4.1559e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 3.7345e-04 - accuracy: 0.9910 - val_loss: 7.1274e-04 - val_accuracy: 0.9828\n",
            "6/6 [==============================] - 0s 451us/step - loss: 7.1274e-04 - accuracy: 0.9828\n",
            "Loss = 0.0007127364515326917, Accuracy = 0.982758641242981\n",
            "Loss array:  [0.0005183520261198282, 0.0008110131020657718, 0.0007127364515326917]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 4/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.5826 - val_loss: 0.0177 - val_accuracy: 0.7759\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 908us/step - loss: 0.0161 - accuracy: 0.8597 - val_loss: 0.0117 - val_accuracy: 0.8276\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 754us/step - loss: 0.0093 - accuracy: 0.8912 - val_loss: 0.0074 - val_accuracy: 0.9138\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 783us/step - loss: 0.0072 - accuracy: 0.9317 - val_loss: 0.0064 - val_accuracy: 0.8448\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 816us/step - loss: 0.0062 - accuracy: 0.9103 - val_loss: 0.0083 - val_accuracy: 0.8276\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.0063 - accuracy: 0.9140 - val_loss: 0.0068 - val_accuracy: 0.8276\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 0.0051 - accuracy: 0.9198 - val_loss: 0.0037 - val_accuracy: 0.9138\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0042 - accuracy: 0.9376 - val_loss: 0.0035 - val_accuracy: 0.8966\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 819us/step - loss: 0.0033 - accuracy: 0.9461 - val_loss: 0.0032 - val_accuracy: 0.8966\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 810us/step - loss: 0.0032 - accuracy: 0.9324 - val_loss: 0.0029 - val_accuracy: 0.8793\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 734us/step - loss: 0.0026 - accuracy: 0.9427 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0024 - accuracy: 0.9476 - val_loss: 0.0032 - val_accuracy: 0.8793\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0025 - accuracy: 0.9576 - val_loss: 0.0052 - val_accuracy: 0.9483\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 0.0039 - accuracy: 0.9304 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 817us/step - loss: 0.0023 - accuracy: 0.9617 - val_loss: 0.0035 - val_accuracy: 0.8793\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 870us/step - loss: 0.0027 - accuracy: 0.9435 - val_loss: 0.0021 - val_accuracy: 0.8966\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0017 - accuracy: 0.9446 - val_loss: 0.0020 - val_accuracy: 0.8966\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 864us/step - loss: 0.0016 - accuracy: 0.9678 - val_loss: 0.0017 - val_accuracy: 0.9138\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 809us/step - loss: 0.0014 - accuracy: 0.9562 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 0.0015 - accuracy: 0.9557 - val_loss: 0.0016 - val_accuracy: 0.9138\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 0.0012 - accuracy: 0.9544 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0013 - accuracy: 0.9411 - val_loss: 0.0017 - val_accuracy: 0.8966\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0015 - accuracy: 0.9604 - val_loss: 0.0017 - val_accuracy: 0.9138\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 0.0014 - accuracy: 0.9558 - val_loss: 0.0023 - val_accuracy: 0.8793\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 0.0013 - accuracy: 0.9616 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 880us/step - loss: 9.7622e-04 - accuracy: 0.9694 - val_loss: 0.0017 - val_accuracy: 0.8966\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 0.0015 - accuracy: 0.9629 - val_loss: 0.0013 - val_accuracy: 0.8966\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 0.0013 - accuracy: 0.9715 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 9.8326e-04 - accuracy: 0.9833 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0013 - accuracy: 0.9600 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 764us/step - loss: 0.0013 - accuracy: 0.9645 - val_loss: 0.0011 - val_accuracy: 0.9138\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 840us/step - loss: 7.5257e-04 - accuracy: 0.9650 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.0010 - accuracy: 0.9683 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 898us/step - loss: 9.0338e-04 - accuracy: 0.9715 - val_loss: 0.0014 - val_accuracy: 0.8966\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0010 - accuracy: 0.9740 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 887us/step - loss: 0.0011 - accuracy: 0.9661 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 862us/step - loss: 0.0012 - accuracy: 0.9667 - val_loss: 0.0010 - val_accuracy: 0.9310\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 844us/step - loss: 0.0011 - accuracy: 0.9720 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 833us/step - loss: 7.6188e-04 - accuracy: 0.9757 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 9.0336e-04 - accuracy: 0.9701 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 882us/step - loss: 7.9084e-04 - accuracy: 0.9816 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 668us/step - loss: 8.0900e-04 - accuracy: 0.9714 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9583 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 875us/step - loss: 7.7052e-04 - accuracy: 0.9735 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 916us/step - loss: 0.0010 - accuracy: 0.9402 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 860us/step - loss: 8.2772e-04 - accuracy: 0.9566 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 833us/step - loss: 6.5076e-04 - accuracy: 0.9864 - val_loss: 9.2199e-04 - val_accuracy: 0.9138\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 7.3101e-04 - accuracy: 0.9794 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 884us/step - loss: 7.8512e-04 - accuracy: 0.9830 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 6.1839e-04 - accuracy: 0.9869 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 6.7633e-04 - accuracy: 0.9819 - val_loss: 8.1168e-04 - val_accuracy: 0.9483\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 817us/step - loss: 6.3145e-04 - accuracy: 0.9759 - val_loss: 8.8761e-04 - val_accuracy: 0.9483\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 886us/step - loss: 7.0968e-04 - accuracy: 0.9735 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 9.1507e-04 - accuracy: 0.9893 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 818us/step - loss: 6.7755e-04 - accuracy: 0.9768 - val_loss: 8.2330e-04 - val_accuracy: 0.9655\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 7.5998e-04 - accuracy: 0.9810 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 8.8973e-04 - accuracy: 0.9774 - val_loss: 9.4371e-04 - val_accuracy: 0.9655\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 5.8236e-04 - accuracy: 0.9818 - val_loss: 7.8404e-04 - val_accuracy: 0.9483\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 714us/step - loss: 5.9816e-04 - accuracy: 0.9775 - val_loss: 8.1750e-04 - val_accuracy: 0.9483\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 721us/step - loss: 6.8611e-04 - accuracy: 0.9855 - val_loss: 8.5569e-04 - val_accuracy: 0.9655\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 792us/step - loss: 8.0447e-04 - accuracy: 0.9736 - val_loss: 9.0951e-04 - val_accuracy: 0.9828\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 812us/step - loss: 5.3807e-04 - accuracy: 0.9798 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0010 - accuracy: 0.9607 - val_loss: 8.0540e-04 - val_accuracy: 0.9828\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 858us/step - loss: 5.3322e-04 - accuracy: 0.9846 - val_loss: 8.5123e-04 - val_accuracy: 0.9828\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 6.3497e-04 - accuracy: 0.9705 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 818us/step - loss: 8.3952e-04 - accuracy: 0.9783 - val_loss: 8.1135e-04 - val_accuracy: 0.9828\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 5.5277e-04 - accuracy: 0.9922 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0015 - accuracy: 0.9770 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 728us/step - loss: 7.2369e-04 - accuracy: 0.9748 - val_loss: 9.7008e-04 - val_accuracy: 0.9828\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 717us/step - loss: 7.8153e-04 - accuracy: 0.9788 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 818us/step - loss: 6.6328e-04 - accuracy: 0.9858 - val_loss: 7.1672e-04 - val_accuracy: 0.9828\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 797us/step - loss: 9.4968e-04 - accuracy: 0.9778 - val_loss: 8.7562e-04 - val_accuracy: 0.9828\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 853us/step - loss: 6.7290e-04 - accuracy: 0.9909 - val_loss: 8.6173e-04 - val_accuracy: 0.9828\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 790us/step - loss: 6.1266e-04 - accuracy: 0.9754 - val_loss: 9.8240e-04 - val_accuracy: 0.9828\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 723us/step - loss: 5.8823e-04 - accuracy: 0.9923 - val_loss: 7.2878e-04 - val_accuracy: 0.9828\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 816us/step - loss: 6.5249e-04 - accuracy: 0.9885 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 662us/step - loss: 8.2115e-04 - accuracy: 0.9716 - val_loss: 8.9825e-04 - val_accuracy: 0.9483\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 868us/step - loss: 5.3348e-04 - accuracy: 0.9857 - val_loss: 9.2541e-04 - val_accuracy: 0.9828\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 7.6212e-04 - accuracy: 0.9729 - val_loss: 8.4356e-04 - val_accuracy: 0.9483\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 5.2122e-04 - accuracy: 0.9933 - val_loss: 9.3829e-04 - val_accuracy: 0.9483\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 811us/step - loss: 6.0721e-04 - accuracy: 0.9838 - val_loss: 6.6639e-04 - val_accuracy: 0.9655\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 733us/step - loss: 5.6788e-04 - accuracy: 0.9896 - val_loss: 8.3849e-04 - val_accuracy: 0.9483\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 896us/step - loss: 6.1910e-04 - accuracy: 0.9857 - val_loss: 8.1022e-04 - val_accuracy: 0.9828\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 4.8852e-04 - accuracy: 0.9929 - val_loss: 7.5110e-04 - val_accuracy: 0.9828\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 688us/step - loss: 5.6346e-04 - accuracy: 0.9881 - val_loss: 9.5505e-04 - val_accuracy: 0.9828\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 696us/step - loss: 8.6320e-04 - accuracy: 0.9813 - val_loss: 8.7096e-04 - val_accuracy: 0.9828\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3293e-04 - accuracy: 0.9819 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 6.5232e-04 - accuracy: 0.9835 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 754us/step - loss: 6.5735e-04 - accuracy: 0.9680 - val_loss: 9.2912e-04 - val_accuracy: 0.9655\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 6.1742e-04 - accuracy: 0.9718 - val_loss: 8.6278e-04 - val_accuracy: 0.9655\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 698us/step - loss: 4.9313e-04 - accuracy: 0.9932 - val_loss: 8.3403e-04 - val_accuracy: 0.9828\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 5.2777e-04 - accuracy: 0.9845 - val_loss: 9.8732e-04 - val_accuracy: 0.9655\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 8.0083e-04 - accuracy: 0.9808 - val_loss: 7.8663e-04 - val_accuracy: 0.9483\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 6.4769e-04 - accuracy: 0.9666 - val_loss: 9.5678e-04 - val_accuracy: 0.9655\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 676us/step - loss: 6.3003e-04 - accuracy: 0.9918 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 6.3307e-04 - accuracy: 0.9837 - val_loss: 7.7316e-04 - val_accuracy: 0.9828\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 740us/step - loss: 5.4202e-04 - accuracy: 0.9893 - val_loss: 8.3226e-04 - val_accuracy: 0.9310\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 7.2926e-04 - accuracy: 0.9809 - val_loss: 7.3366e-04 - val_accuracy: 0.9828\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 686us/step - loss: 4.7402e-04 - accuracy: 0.9877 - val_loss: 8.0200e-04 - val_accuracy: 0.9828\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 608us/step - loss: 5.3747e-04 - accuracy: 0.9845 - val_loss: 8.4823e-04 - val_accuracy: 0.9828\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 834us/step - loss: 4.3282e-04 - accuracy: 0.9957 - val_loss: 7.8273e-04 - val_accuracy: 0.9828\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 669us/step - loss: 4.9010e-04 - accuracy: 0.9903 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 5.9870e-04 - accuracy: 0.9846 - val_loss: 6.9688e-04 - val_accuracy: 0.9655\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 4.1932e-04 - accuracy: 0.9886 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 629us/step - loss: 0.0010 - accuracy: 0.9878 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 742us/step - loss: 8.2823e-04 - accuracy: 0.9820 - val_loss: 8.8627e-04 - val_accuracy: 0.9310\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 5.1051e-04 - accuracy: 0.9842 - val_loss: 7.1514e-04 - val_accuracy: 0.9828\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 4.0944e-04 - accuracy: 0.9965 - val_loss: 8.8075e-04 - val_accuracy: 0.9655\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 7.1674e-04 - accuracy: 0.9900 - val_loss: 7.0393e-04 - val_accuracy: 0.9483\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 632us/step - loss: 4.7596e-04 - accuracy: 0.9867 - val_loss: 6.2965e-04 - val_accuracy: 0.9655\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 5.5348e-04 - accuracy: 0.9957 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 717us/step - loss: 5.4869e-04 - accuracy: 0.9938 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 667us/step - loss: 7.2235e-04 - accuracy: 0.9832 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 7.8391e-04 - accuracy: 0.9813 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 5.9781e-04 - accuracy: 0.9913 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 8.6540e-04 - accuracy: 0.9810 - val_loss: 7.6126e-04 - val_accuracy: 0.9828\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 4.3625e-04 - accuracy: 0.9934 - val_loss: 6.7589e-04 - val_accuracy: 0.9828\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 4.2179e-04 - accuracy: 0.9886 - val_loss: 7.0184e-04 - val_accuracy: 0.9655\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 5.8771e-04 - accuracy: 0.9710 - val_loss: 6.6798e-04 - val_accuracy: 0.9828\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 603us/step - loss: 7.4489e-04 - accuracy: 0.9841 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 9.4557e-04 - accuracy: 0.9806 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 655us/step - loss: 6.9210e-04 - accuracy: 0.9721 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 672us/step - loss: 8.3731e-04 - accuracy: 0.9868 - val_loss: 8.4665e-04 - val_accuracy: 0.9655\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 6.7742e-04 - accuracy: 0.9846 - val_loss: 7.2307e-04 - val_accuracy: 0.9655\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 634us/step - loss: 4.5430e-04 - accuracy: 0.9871 - val_loss: 7.6036e-04 - val_accuracy: 0.9828\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 5.3317e-04 - accuracy: 0.9903 - val_loss: 7.8604e-04 - val_accuracy: 0.9828\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2957e-04 - accuracy: 0.9809 - val_loss: 6.0583e-04 - val_accuracy: 0.9483\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5652e-04 - accuracy: 0.9910 - val_loss: 6.5431e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 877us/step - loss: 6.0377e-04 - accuracy: 0.9808 - val_loss: 8.5842e-04 - val_accuracy: 0.9483\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 871us/step - loss: 4.3086e-04 - accuracy: 0.9925 - val_loss: 6.0892e-04 - val_accuracy: 0.9828\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 841us/step - loss: 4.6186e-04 - accuracy: 0.9855 - val_loss: 6.7615e-04 - val_accuracy: 0.9828\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 864us/step - loss: 5.9038e-04 - accuracy: 0.9729 - val_loss: 7.3597e-04 - val_accuracy: 0.9828\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 5.5970e-04 - accuracy: 0.9908 - val_loss: 7.1557e-04 - val_accuracy: 0.9828\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 3.8812e-04 - accuracy: 0.9949 - val_loss: 7.8078e-04 - val_accuracy: 0.9828\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 3.7171e-04 - accuracy: 0.9994 - val_loss: 7.6747e-04 - val_accuracy: 0.9655\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 925us/step - loss: 3.9941e-04 - accuracy: 0.9917 - val_loss: 6.0326e-04 - val_accuracy: 0.9483\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 4.4268e-04 - accuracy: 0.9960 - val_loss: 5.9389e-04 - val_accuracy: 0.9828\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 888us/step - loss: 4.0554e-04 - accuracy: 0.9929 - val_loss: 9.2425e-04 - val_accuracy: 0.9828\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 784us/step - loss: 4.4727e-04 - accuracy: 0.9884 - val_loss: 8.5731e-04 - val_accuracy: 0.9655\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 845us/step - loss: 4.4479e-04 - accuracy: 0.9825 - val_loss: 9.5124e-04 - val_accuracy: 0.9655\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 3.7680e-04 - accuracy: 0.9994 - val_loss: 5.5630e-04 - val_accuracy: 0.9655\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 3.4757e-04 - accuracy: 0.9919 - val_loss: 5.7910e-04 - val_accuracy: 0.9655\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 4.0493e-04 - accuracy: 0.9971 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 8.2364e-04 - accuracy: 0.9747 - val_loss: 8.5398e-04 - val_accuracy: 0.9828\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 4.7964e-04 - accuracy: 0.9899 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 780us/step - loss: 5.9226e-04 - accuracy: 0.9953 - val_loss: 6.8759e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 892us/step - loss: 4.4771e-04 - accuracy: 0.9870 - val_loss: 6.6481e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 776us/step - loss: 2.9851e-04 - accuracy: 0.9920 - val_loss: 6.8876e-04 - val_accuracy: 0.9828\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 3.9004e-04 - accuracy: 0.9847 - val_loss: 6.2938e-04 - val_accuracy: 0.9655\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 4.3351e-04 - accuracy: 0.9908 - val_loss: 4.8619e-04 - val_accuracy: 0.9655\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 839us/step - loss: 4.5074e-04 - accuracy: 0.9920 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 902us/step - loss: 5.4647e-04 - accuracy: 0.9809 - val_loss: 6.0200e-04 - val_accuracy: 0.9828\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 882us/step - loss: 5.8943e-04 - accuracy: 0.9873 - val_loss: 4.7398e-04 - val_accuracy: 0.9483\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 764us/step - loss: 3.6792e-04 - accuracy: 0.9927 - val_loss: 5.3789e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 772us/step - loss: 3.7400e-04 - accuracy: 0.9940 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 808us/step - loss: 6.7816e-04 - accuracy: 0.9878 - val_loss: 9.9041e-04 - val_accuracy: 0.9655\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 886us/step - loss: 5.1982e-04 - accuracy: 0.9778 - val_loss: 5.0275e-04 - val_accuracy: 0.9828\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 3.0084e-04 - accuracy: 0.9958 - val_loss: 6.6327e-04 - val_accuracy: 0.9828\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 786us/step - loss: 4.2821e-04 - accuracy: 0.9886 - val_loss: 5.4925e-04 - val_accuracy: 0.9655\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 814us/step - loss: 3.1270e-04 - accuracy: 0.9971 - val_loss: 8.6803e-04 - val_accuracy: 0.9828\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 4.2946e-04 - accuracy: 0.9910 - val_loss: 8.0040e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 756us/step - loss: 3.3750e-04 - accuracy: 0.9935 - val_loss: 4.5179e-04 - val_accuracy: 0.9828\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 811us/step - loss: 3.2375e-04 - accuracy: 0.9834 - val_loss: 6.6808e-04 - val_accuracy: 0.9655\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 3.3718e-04 - accuracy: 0.9941 - val_loss: 6.2452e-04 - val_accuracy: 0.9655\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 3.0813e-04 - accuracy: 0.9976 - val_loss: 6.0251e-04 - val_accuracy: 0.9828\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 881us/step - loss: 3.5567e-04 - accuracy: 0.9938 - val_loss: 6.5502e-04 - val_accuracy: 0.9828\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 3.4850e-04 - accuracy: 0.9860 - val_loss: 5.5955e-04 - val_accuracy: 0.9828\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 716us/step - loss: 3.1742e-04 - accuracy: 0.9983 - val_loss: 7.3248e-04 - val_accuracy: 0.9828\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 840us/step - loss: 3.3680e-04 - accuracy: 0.9986 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 628us/step - loss: 6.2038e-04 - accuracy: 0.9921 - val_loss: 6.9912e-04 - val_accuracy: 0.9828\n",
            "6/6 [==============================] - 0s 374us/step - loss: 6.9912e-04 - accuracy: 0.9828\n",
            "Loss = 0.0006991206319071352, Accuracy = 0.982758641242981\n",
            "Loss array:  [0.0005183520261198282, 0.0008110131020657718, 0.0007127364515326917, 0.0006991206319071352]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 5/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.7743 - val_loss: 0.0162 - val_accuracy: 0.9483\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 993us/step - loss: 0.0149 - accuracy: 0.8854 - val_loss: 0.0084 - val_accuracy: 0.9483\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 860us/step - loss: 0.0086 - accuracy: 0.9264 - val_loss: 0.0051 - val_accuracy: 0.9655\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 856us/step - loss: 0.0064 - accuracy: 0.9196 - val_loss: 0.0030 - val_accuracy: 0.9483\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0047 - accuracy: 0.9159 - val_loss: 0.0036 - val_accuracy: 0.8966\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 800us/step - loss: 0.0039 - accuracy: 0.9273 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 802us/step - loss: 0.0030 - accuracy: 0.9403 - val_loss: 0.0029 - val_accuracy: 0.8966\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0030 - accuracy: 0.9351 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.0030 - accuracy: 0.9325 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 0.0026 - accuracy: 0.9247 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 0.0029 - accuracy: 0.9281 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 870us/step - loss: 0.0019 - accuracy: 0.9675 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.0023 - accuracy: 0.9532 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 817us/step - loss: 0.0019 - accuracy: 0.9387 - val_loss: 0.0017 - val_accuracy: 0.9138\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0020 - accuracy: 0.9545 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0015 - accuracy: 0.9591 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.0021 - accuracy: 0.9438 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 0.0012 - accuracy: 0.9487 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 824us/step - loss: 0.0017 - accuracy: 0.9510 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 792us/step - loss: 0.0014 - accuracy: 0.9560 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 845us/step - loss: 0.0014 - accuracy: 0.9464 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0015 - accuracy: 0.9415 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 9.7828e-04 - accuracy: 0.9813 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 0.0013 - accuracy: 0.9484 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 0.0013 - accuracy: 0.9760 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 857us/step - loss: 0.0013 - accuracy: 0.9543 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.0010 - accuracy: 0.9294 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0011 - accuracy: 0.9447 - val_loss: 9.9048e-04 - val_accuracy: 0.9655\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 9.3503e-04 - accuracy: 0.9722 - val_loss: 9.2931e-04 - val_accuracy: 0.9483\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 891us/step - loss: 0.0011 - accuracy: 0.9686 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 772us/step - loss: 8.5441e-04 - accuracy: 0.9780 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 841us/step - loss: 0.0011 - accuracy: 0.9767 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9670 - val_loss: 9.3812e-04 - val_accuracy: 0.9655\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 981us/step - loss: 8.1939e-04 - accuracy: 0.9638 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 972us/step - loss: 7.7808e-04 - accuracy: 0.9795 - val_loss: 8.2241e-04 - val_accuracy: 0.9483\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 861us/step - loss: 7.4729e-04 - accuracy: 0.9841 - val_loss: 9.1898e-04 - val_accuracy: 0.9655\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 881us/step - loss: 8.1078e-04 - accuracy: 0.9779 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 0.0010 - accuracy: 0.9850 - val_loss: 7.6357e-04 - val_accuracy: 0.9483\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 719us/step - loss: 9.1837e-04 - accuracy: 0.9681 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 8.8140e-04 - accuracy: 0.9811 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 850us/step - loss: 9.7877e-04 - accuracy: 0.9728 - val_loss: 9.4176e-04 - val_accuracy: 0.9828\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 6.9652e-04 - accuracy: 0.9768 - val_loss: 9.6269e-04 - val_accuracy: 0.9655\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 826us/step - loss: 9.2547e-04 - accuracy: 0.9794 - val_loss: 9.8334e-04 - val_accuracy: 0.9655\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 812us/step - loss: 7.8484e-04 - accuracy: 0.9910 - val_loss: 9.2945e-04 - val_accuracy: 0.9310\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 6.9232e-04 - accuracy: 0.9888 - val_loss: 9.4725e-04 - val_accuracy: 0.9483\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 862us/step - loss: 0.0010 - accuracy: 0.9815 - val_loss: 9.8087e-04 - val_accuracy: 0.9655\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 7.0741e-04 - accuracy: 0.9858 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 7.1901e-04 - accuracy: 0.9802 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 832us/step - loss: 9.1778e-04 - accuracy: 0.9906 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 8.3585e-04 - accuracy: 0.9786 - val_loss: 9.7318e-04 - val_accuracy: 0.9828\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 812us/step - loss: 8.8905e-04 - accuracy: 0.9803 - val_loss: 7.3649e-04 - val_accuracy: 0.9655\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 741us/step - loss: 9.6414e-04 - accuracy: 0.9893 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 7.4002e-04 - accuracy: 0.9886 - val_loss: 7.2935e-04 - val_accuracy: 0.9483\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 819us/step - loss: 8.8129e-04 - accuracy: 0.9690 - val_loss: 8.0609e-04 - val_accuracy: 0.9483\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 856us/step - loss: 7.3497e-04 - accuracy: 0.9867 - val_loss: 9.4751e-04 - val_accuracy: 0.9655\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 8.7615e-04 - accuracy: 0.9774 - val_loss: 8.7181e-04 - val_accuracy: 0.9483\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 6.2434e-04 - accuracy: 0.9884 - val_loss: 7.4820e-04 - val_accuracy: 0.9655\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 845us/step - loss: 5.8630e-04 - accuracy: 0.9840 - val_loss: 8.3255e-04 - val_accuracy: 0.9655\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0012 - accuracy: 0.9663 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0012 - accuracy: 0.9694 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 817us/step - loss: 9.7209e-04 - accuracy: 0.9568 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0011 - accuracy: 0.9861 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 7.1106e-04 - accuracy: 0.9821 - val_loss: 7.0958e-04 - val_accuracy: 0.9483\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 842us/step - loss: 6.4844e-04 - accuracy: 0.9800 - val_loss: 8.8359e-04 - val_accuracy: 0.9828\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0401e-04 - accuracy: 0.9852 - val_loss: 8.2222e-04 - val_accuracy: 0.9655\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 909us/step - loss: 6.8233e-04 - accuracy: 0.9828 - val_loss: 7.7764e-04 - val_accuracy: 0.9828\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 922us/step - loss: 7.0984e-04 - accuracy: 0.9753 - val_loss: 6.8594e-04 - val_accuracy: 0.9483\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 896us/step - loss: 6.2608e-04 - accuracy: 0.9865 - val_loss: 8.4293e-04 - val_accuracy: 0.9483\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 836us/step - loss: 6.3606e-04 - accuracy: 0.9873 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 890us/step - loss: 0.0011 - accuracy: 0.9805 - val_loss: 9.3171e-04 - val_accuracy: 0.9828\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 6.3708e-04 - accuracy: 0.9893 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 6.3638e-04 - accuracy: 0.9893 - val_loss: 7.6462e-04 - val_accuracy: 0.9655\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 807us/step - loss: 6.1169e-04 - accuracy: 0.9902 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 790us/step - loss: 5.8812e-04 - accuracy: 0.9870 - val_loss: 6.8138e-04 - val_accuracy: 0.9828\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 0.0011 - accuracy: 0.9846 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 786us/step - loss: 8.3269e-04 - accuracy: 0.9890 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 8.5091e-04 - accuracy: 0.9789 - val_loss: 7.3549e-04 - val_accuracy: 0.9483\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 677us/step - loss: 7.6079e-04 - accuracy: 0.9741 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 7.6572e-04 - accuracy: 0.9762 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 7.9725e-04 - accuracy: 0.9747 - val_loss: 6.7406e-04 - val_accuracy: 0.9483\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 711us/step - loss: 6.6733e-04 - accuracy: 0.9796 - val_loss: 9.2673e-04 - val_accuracy: 0.9655\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 6.8808e-04 - accuracy: 0.9804 - val_loss: 7.6069e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 6.4116e-04 - accuracy: 0.9715 - val_loss: 9.5798e-04 - val_accuracy: 0.9655\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 5.1572e-04 - accuracy: 0.9779 - val_loss: 7.6418e-04 - val_accuracy: 0.9655\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 6.0910e-04 - accuracy: 0.9876 - val_loss: 6.5800e-04 - val_accuracy: 0.9655\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 5.8816e-04 - accuracy: 0.9770 - val_loss: 8.9848e-04 - val_accuracy: 0.9828\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 5.7053e-04 - accuracy: 0.9947 - val_loss: 8.6339e-04 - val_accuracy: 0.9828\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 589us/step - loss: 6.8359e-04 - accuracy: 0.9835 - val_loss: 7.5192e-04 - val_accuracy: 0.9828\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 6.5790e-04 - accuracy: 0.9869 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 7.8624e-04 - accuracy: 0.9586 - val_loss: 8.3241e-04 - val_accuracy: 0.9655\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 666us/step - loss: 5.9364e-04 - accuracy: 0.9815 - val_loss: 0.0010 - val_accuracy: 0.9310\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 813us/step - loss: 5.8814e-04 - accuracy: 0.9862 - val_loss: 5.9370e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 612us/step - loss: 5.8999e-04 - accuracy: 0.9801 - val_loss: 6.1846e-04 - val_accuracy: 0.9828\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 5.7379e-04 - accuracy: 0.9843 - val_loss: 7.7199e-04 - val_accuracy: 0.9655\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 677us/step - loss: 8.2343e-04 - accuracy: 0.9712 - val_loss: 6.0642e-04 - val_accuracy: 0.9828\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 880us/step - loss: 6.2185e-04 - accuracy: 0.9793 - val_loss: 9.7733e-04 - val_accuracy: 0.9655\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 660us/step - loss: 5.9706e-04 - accuracy: 0.9926 - val_loss: 7.9967e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6169e-04 - accuracy: 0.9868 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 852us/step - loss: 7.2804e-04 - accuracy: 0.9806 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 955us/step - loss: 5.4312e-04 - accuracy: 0.9980 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 7.4048e-04 - accuracy: 0.9857 - val_loss: 6.3468e-04 - val_accuracy: 0.9828\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 900us/step - loss: 4.7184e-04 - accuracy: 0.9928 - val_loss: 9.0021e-04 - val_accuracy: 0.9483\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 6.6304e-04 - accuracy: 0.9808 - val_loss: 7.2573e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 792us/step - loss: 5.2391e-04 - accuracy: 0.9839 - val_loss: 6.3627e-04 - val_accuracy: 0.9828\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 704us/step - loss: 7.4312e-04 - accuracy: 0.9769 - val_loss: 8.9204e-04 - val_accuracy: 0.9828\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 711us/step - loss: 8.5328e-04 - accuracy: 0.9759 - val_loss: 8.3772e-04 - val_accuracy: 0.9655\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 5.2972e-04 - accuracy: 0.9912 - val_loss: 6.8640e-04 - val_accuracy: 0.9828\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 4.9327e-04 - accuracy: 0.9814 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 6.0330e-04 - accuracy: 0.9817 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 5.7213e-04 - accuracy: 0.9748 - val_loss: 6.8795e-04 - val_accuracy: 0.9828\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 9.0322e-04 - accuracy: 0.9640 - val_loss: 6.4857e-04 - val_accuracy: 0.9828\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 844us/step - loss: 5.5618e-04 - accuracy: 0.9786 - val_loss: 6.8553e-04 - val_accuracy: 0.9828\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 652us/step - loss: 4.7173e-04 - accuracy: 0.9862 - val_loss: 6.3053e-04 - val_accuracy: 0.9828\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 5.1028e-04 - accuracy: 0.9839 - val_loss: 7.2761e-04 - val_accuracy: 0.9655\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 689us/step - loss: 6.0479e-04 - accuracy: 0.9919 - val_loss: 6.6590e-04 - val_accuracy: 0.9655\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 3.8158e-04 - accuracy: 0.9936 - val_loss: 6.0140e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 779us/step - loss: 4.5514e-04 - accuracy: 0.9949 - val_loss: 5.9988e-04 - val_accuracy: 0.9828\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 4.9587e-04 - accuracy: 0.9873 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 780us/step - loss: 8.7712e-04 - accuracy: 0.9612 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 667us/step - loss: 7.3758e-04 - accuracy: 0.9822 - val_loss: 7.8506e-04 - val_accuracy: 0.9655\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 4.9838e-04 - accuracy: 0.9892 - val_loss: 8.6390e-04 - val_accuracy: 0.9655\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 6.6322e-04 - accuracy: 0.9865 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 5.7310e-04 - accuracy: 0.9893 - val_loss: 7.4309e-04 - val_accuracy: 0.9655\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 800us/step - loss: 4.5268e-04 - accuracy: 0.9870 - val_loss: 6.5003e-04 - val_accuracy: 0.9828\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 7.1053e-04 - accuracy: 0.9912 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 7.4065e-04 - accuracy: 0.9795 - val_loss: 7.3501e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 663us/step - loss: 4.2197e-04 - accuracy: 0.9936 - val_loss: 7.4096e-04 - val_accuracy: 0.9655\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 892us/step - loss: 6.1518e-04 - accuracy: 0.9900 - val_loss: 6.3045e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 719us/step - loss: 4.4998e-04 - accuracy: 0.9955 - val_loss: 9.1662e-04 - val_accuracy: 0.9655\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 786us/step - loss: 5.3421e-04 - accuracy: 0.9992 - val_loss: 7.7417e-04 - val_accuracy: 0.9828\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3096e-04 - accuracy: 0.9890 - val_loss: 5.6347e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 963us/step - loss: 4.2593e-04 - accuracy: 0.9855 - val_loss: 9.4168e-04 - val_accuracy: 0.9655\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 832us/step - loss: 4.9467e-04 - accuracy: 0.9903 - val_loss: 6.9866e-04 - val_accuracy: 0.9655\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 842us/step - loss: 5.5654e-04 - accuracy: 0.9879 - val_loss: 6.2016e-04 - val_accuracy: 0.9828\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 719us/step - loss: 7.5196e-04 - accuracy: 0.9816 - val_loss: 7.1056e-04 - val_accuracy: 0.9655\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 859us/step - loss: 6.4143e-04 - accuracy: 0.9594 - val_loss: 7.9997e-04 - val_accuracy: 0.9655\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 5.4751e-04 - accuracy: 0.9865 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 780us/step - loss: 6.1672e-04 - accuracy: 0.9925 - val_loss: 7.1482e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 4.6948e-04 - accuracy: 0.9889 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 6.9552e-04 - accuracy: 0.9713 - val_loss: 8.6682e-04 - val_accuracy: 0.9655\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 856us/step - loss: 6.5362e-04 - accuracy: 0.9822 - val_loss: 6.0743e-04 - val_accuracy: 0.9828\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 735us/step - loss: 4.2024e-04 - accuracy: 0.9927 - val_loss: 7.1482e-04 - val_accuracy: 0.9828\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 810us/step - loss: 6.3710e-04 - accuracy: 0.9904 - val_loss: 8.6384e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 868us/step - loss: 6.5751e-04 - accuracy: 0.9792 - val_loss: 7.5235e-04 - val_accuracy: 0.9828\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 878us/step - loss: 8.8204e-04 - accuracy: 0.9860 - val_loss: 7.3182e-04 - val_accuracy: 0.9828\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 734us/step - loss: 7.0734e-04 - accuracy: 0.9838 - val_loss: 8.9074e-04 - val_accuracy: 0.9655\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 7.4121e-04 - accuracy: 0.9812 - val_loss: 7.3541e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 792us/step - loss: 7.0033e-04 - accuracy: 0.9750 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 9.2152e-04 - accuracy: 0.9660 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 5.2747e-04 - accuracy: 0.9803 - val_loss: 6.4043e-04 - val_accuracy: 0.9828\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 735us/step - loss: 5.3393e-04 - accuracy: 0.9871 - val_loss: 7.3776e-04 - val_accuracy: 0.9655\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 768us/step - loss: 5.1106e-04 - accuracy: 0.9905 - val_loss: 5.9652e-04 - val_accuracy: 0.9828\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 5.4070e-04 - accuracy: 0.9790 - val_loss: 5.5074e-04 - val_accuracy: 0.9828\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 941us/step - loss: 3.8355e-04 - accuracy: 0.9940 - val_loss: 6.0637e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 765us/step - loss: 3.6699e-04 - accuracy: 0.9871 - val_loss: 5.5082e-04 - val_accuracy: 0.9828\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 3.8535e-04 - accuracy: 0.9980 - val_loss: 7.9774e-04 - val_accuracy: 0.9655\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 807us/step - loss: 4.0038e-04 - accuracy: 0.9848 - val_loss: 5.6075e-04 - val_accuracy: 0.9828\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 867us/step - loss: 4.7475e-04 - accuracy: 0.9900 - val_loss: 7.0897e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 809us/step - loss: 4.9337e-04 - accuracy: 0.9951 - val_loss: 7.2672e-04 - val_accuracy: 0.9483\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 818us/step - loss: 5.2680e-04 - accuracy: 0.9946 - val_loss: 5.7596e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 911us/step - loss: 4.2740e-04 - accuracy: 0.9964 - val_loss: 6.0757e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.6154e-04 - accuracy: 0.9990 - val_loss: 6.7238e-04 - val_accuracy: 0.9483\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 877us/step - loss: 4.3571e-04 - accuracy: 0.9918 - val_loss: 5.3396e-04 - val_accuracy: 0.9828\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 973us/step - loss: 3.3658e-04 - accuracy: 0.9991 - val_loss: 5.9674e-04 - val_accuracy: 0.9828\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 680us/step - loss: 3.9406e-04 - accuracy: 0.9900 - val_loss: 6.1662e-04 - val_accuracy: 0.9828\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 877us/step - loss: 5.1489e-04 - accuracy: 0.9931 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 5.4722e-04 - accuracy: 0.9811 - val_loss: 7.5359e-04 - val_accuracy: 0.9828\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 4.6693e-04 - accuracy: 0.9987 - val_loss: 7.1423e-04 - val_accuracy: 0.9828\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 4.2108e-04 - accuracy: 0.9930 - val_loss: 9.3548e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 6.1091e-04 - accuracy: 0.9837 - val_loss: 6.4904e-04 - val_accuracy: 0.9655\n",
            "6/6 [==============================] - 0s 378us/step - loss: 6.4904e-04 - accuracy: 0.9655\n",
            "Loss = 0.0006490395753644407, Accuracy = 0.9655172228813171\n",
            "Loss array:  [0.0005183520261198282, 0.0008110131020657718, 0.0007127364515326917, 0.0006991206319071352, 0.0006490395753644407]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 6/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.8583 - val_loss: 0.0176 - val_accuracy: 0.8966\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 890us/step - loss: 0.0161 - accuracy: 0.9075 - val_loss: 0.0095 - val_accuracy: 0.9138\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 874us/step - loss: 0.0085 - accuracy: 0.9276 - val_loss: 0.0059 - val_accuracy: 0.8966\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 814us/step - loss: 0.0059 - accuracy: 0.9351 - val_loss: 0.0047 - val_accuracy: 0.9310\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0046 - accuracy: 0.9450 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 884us/step - loss: 0.0038 - accuracy: 0.9396 - val_loss: 0.0039 - val_accuracy: 0.9310\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 0.0037 - accuracy: 0.9272 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 0.0031 - accuracy: 0.9464 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 819us/step - loss: 0.0029 - accuracy: 0.9275 - val_loss: 0.0029 - val_accuracy: 0.8621\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 924us/step - loss: 0.0027 - accuracy: 0.9420 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 812us/step - loss: 0.0022 - accuracy: 0.9435 - val_loss: 0.0026 - val_accuracy: 0.9138\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 749us/step - loss: 0.0022 - accuracy: 0.9585 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 835us/step - loss: 0.0020 - accuracy: 0.9528 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 0.0022 - accuracy: 0.9460 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 816us/step - loss: 0.0018 - accuracy: 0.9524 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 772us/step - loss: 0.0017 - accuracy: 0.9244 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0019 - accuracy: 0.9554 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 0.0017 - accuracy: 0.9541 - val_loss: 0.0017 - val_accuracy: 0.9138\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 0.0016 - accuracy: 0.9428 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9572 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 955us/step - loss: 0.0016 - accuracy: 0.9568 - val_loss: 0.0015 - val_accuracy: 0.9138\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 947us/step - loss: 0.0015 - accuracy: 0.9531 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 839us/step - loss: 0.0014 - accuracy: 0.9683 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 908us/step - loss: 9.8605e-04 - accuracy: 0.9788 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 798us/step - loss: 0.0012 - accuracy: 0.9712 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 0.0012 - accuracy: 0.9530 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 0.0012 - accuracy: 0.9638 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 0.0013 - accuracy: 0.9726 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 765us/step - loss: 0.0016 - accuracy: 0.9567 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 0.0012 - accuracy: 0.9770 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 797us/step - loss: 0.0020 - accuracy: 0.9382 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.0011 - accuracy: 0.9441 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 842us/step - loss: 0.0011 - accuracy: 0.9641 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 0.0013 - accuracy: 0.9696 - val_loss: 0.0036 - val_accuracy: 0.9655\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 946us/step - loss: 0.0019 - accuracy: 0.9730 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 821us/step - loss: 0.0010 - accuracy: 0.9915 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 8.3201e-04 - accuracy: 0.9616 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 869us/step - loss: 9.2158e-04 - accuracy: 0.9743 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 8.1054e-04 - accuracy: 0.9806 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 786us/step - loss: 0.0011 - accuracy: 0.9691 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 8.9997e-04 - accuracy: 0.9783 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 800us/step - loss: 9.2196e-04 - accuracy: 0.9712 - val_loss: 8.2617e-04 - val_accuracy: 0.9655\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 7.8806e-04 - accuracy: 0.9757 - val_loss: 8.8587e-04 - val_accuracy: 0.9655\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 892us/step - loss: 0.0010 - accuracy: 0.9544 - val_loss: 6.8060e-04 - val_accuracy: 0.9655\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 7.6001e-04 - accuracy: 0.9804 - val_loss: 8.8306e-04 - val_accuracy: 0.9655\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 859us/step - loss: 7.6834e-04 - accuracy: 0.9722 - val_loss: 8.2957e-04 - val_accuracy: 0.9483\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0641e-04 - accuracy: 0.9736 - val_loss: 8.1062e-04 - val_accuracy: 0.9655\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 977us/step - loss: 7.1258e-04 - accuracy: 0.9852 - val_loss: 7.2459e-04 - val_accuracy: 0.9655\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4613e-04 - accuracy: 0.9799 - val_loss: 8.2135e-04 - val_accuracy: 0.9655\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0815e-04 - accuracy: 0.9883 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0010 - accuracy: 0.9472 - val_loss: 8.3673e-04 - val_accuracy: 0.9655\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 820us/step - loss: 8.8283e-04 - accuracy: 0.9811 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 8.4932e-04 - accuracy: 0.9706 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 877us/step - loss: 0.0010 - accuracy: 0.9716 - val_loss: 9.4607e-04 - val_accuracy: 0.9828\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 8.3295e-04 - accuracy: 0.9800 - val_loss: 7.6783e-04 - val_accuracy: 0.9655\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 6.5794e-04 - accuracy: 0.9792 - val_loss: 6.5251e-04 - val_accuracy: 0.9655\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 5.7096e-04 - accuracy: 0.9797 - val_loss: 6.9205e-04 - val_accuracy: 0.9655\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 809us/step - loss: 6.4645e-04 - accuracy: 0.9824 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 8.3416e-04 - accuracy: 0.9738 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 867us/step - loss: 9.8747e-04 - accuracy: 0.9654 - val_loss: 8.8019e-04 - val_accuracy: 0.9828\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 6.6567e-04 - accuracy: 0.9796 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0012 - accuracy: 0.9781 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 845us/step - loss: 7.7320e-04 - accuracy: 0.9740 - val_loss: 6.4978e-04 - val_accuracy: 0.9655\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 6.0466e-04 - accuracy: 0.9886 - val_loss: 7.0659e-04 - val_accuracy: 0.9655\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 768us/step - loss: 5.4783e-04 - accuracy: 0.9907 - val_loss: 7.9073e-04 - val_accuracy: 0.9655\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 845us/step - loss: 5.8948e-04 - accuracy: 0.9790 - val_loss: 7.1910e-04 - val_accuracy: 0.9483\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 882us/step - loss: 7.1489e-04 - accuracy: 0.9784 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 760us/step - loss: 7.2665e-04 - accuracy: 0.9885 - val_loss: 6.8002e-04 - val_accuracy: 0.9828\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 812us/step - loss: 5.1497e-04 - accuracy: 0.9853 - val_loss: 7.4711e-04 - val_accuracy: 0.9655\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 831us/step - loss: 6.2506e-04 - accuracy: 0.9847 - val_loss: 6.0878e-04 - val_accuracy: 0.9828\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 6.4216e-04 - accuracy: 0.9856 - val_loss: 6.5314e-04 - val_accuracy: 0.9828\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 813us/step - loss: 7.3029e-04 - accuracy: 0.9837 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 794us/step - loss: 8.0109e-04 - accuracy: 0.9719 - val_loss: 7.5006e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 810us/step - loss: 6.1446e-04 - accuracy: 0.9845 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0768e-04 - accuracy: 0.9958 - val_loss: 7.5454e-04 - val_accuracy: 0.9483\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 860us/step - loss: 5.6046e-04 - accuracy: 0.9870 - val_loss: 5.6967e-04 - val_accuracy: 0.9655\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1935e-04 - accuracy: 0.9835 - val_loss: 5.5859e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 768us/step - loss: 6.5785e-04 - accuracy: 0.9858 - val_loss: 5.3743e-04 - val_accuracy: 0.9655\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 838us/step - loss: 6.8689e-04 - accuracy: 0.9861 - val_loss: 6.1746e-04 - val_accuracy: 0.9655\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 6.7090e-04 - accuracy: 0.9844 - val_loss: 8.1252e-04 - val_accuracy: 0.9655\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 880us/step - loss: 6.4374e-04 - accuracy: 0.9884 - val_loss: 5.8463e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 845us/step - loss: 5.0259e-04 - accuracy: 0.9923 - val_loss: 6.2959e-04 - val_accuracy: 0.9655\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 861us/step - loss: 4.7448e-04 - accuracy: 0.9925 - val_loss: 8.8690e-04 - val_accuracy: 0.9655\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 826us/step - loss: 6.8849e-04 - accuracy: 0.9814 - val_loss: 5.6454e-04 - val_accuracy: 0.9828\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 946us/step - loss: 5.4534e-04 - accuracy: 0.9843 - val_loss: 5.8599e-04 - val_accuracy: 0.9828\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 911us/step - loss: 6.7043e-04 - accuracy: 0.9920 - val_loss: 8.4635e-04 - val_accuracy: 0.9828\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 885us/step - loss: 6.7972e-04 - accuracy: 0.9676 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 8.8487e-04 - accuracy: 0.9738 - val_loss: 6.2972e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 5.8131e-04 - accuracy: 0.9852 - val_loss: 9.7272e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 869us/step - loss: 5.1135e-04 - accuracy: 0.9886 - val_loss: 4.4444e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 728us/step - loss: 4.9900e-04 - accuracy: 0.9865 - val_loss: 7.3181e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 820us/step - loss: 8.0705e-04 - accuracy: 0.9889 - val_loss: 7.5287e-04 - val_accuracy: 0.9828\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 820us/step - loss: 7.3735e-04 - accuracy: 0.9845 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 0.0014 - accuracy: 0.9600 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 722us/step - loss: 7.8946e-04 - accuracy: 0.9673 - val_loss: 5.6553e-04 - val_accuracy: 0.9655\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 847us/step - loss: 4.3787e-04 - accuracy: 0.9902 - val_loss: 6.6957e-04 - val_accuracy: 0.9828\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 6.5230e-04 - accuracy: 0.9889 - val_loss: 4.6303e-04 - val_accuracy: 0.9828\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 772us/step - loss: 5.0481e-04 - accuracy: 0.9841 - val_loss: 4.7581e-04 - val_accuracy: 0.9828\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3854e-04 - accuracy: 0.9962 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6658e-04 - accuracy: 0.9926 - val_loss: 9.4079e-04 - val_accuracy: 0.9655\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 895us/step - loss: 0.0010 - accuracy: 0.9660 - val_loss: 7.3577e-04 - val_accuracy: 0.9655\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 971us/step - loss: 5.4808e-04 - accuracy: 0.9842 - val_loss: 5.7211e-04 - val_accuracy: 0.9828\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 3.5783e-04 - accuracy: 0.9902 - val_loss: 6.2777e-04 - val_accuracy: 0.9655\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 799us/step - loss: 5.6389e-04 - accuracy: 0.9772 - val_loss: 8.6593e-04 - val_accuracy: 0.9310\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 4.7685e-04 - accuracy: 0.9976 - val_loss: 4.8473e-04 - val_accuracy: 0.9828\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 848us/step - loss: 4.6280e-04 - accuracy: 0.9896 - val_loss: 8.2243e-04 - val_accuracy: 0.9310\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 764us/step - loss: 5.1205e-04 - accuracy: 0.9804 - val_loss: 4.8580e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 4.9004e-04 - accuracy: 0.9898 - val_loss: 5.8549e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 728us/step - loss: 4.1054e-04 - accuracy: 0.9911 - val_loss: 5.7480e-04 - val_accuracy: 0.9828\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 4.0930e-04 - accuracy: 0.9870 - val_loss: 5.6849e-04 - val_accuracy: 0.9655\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 658us/step - loss: 6.8785e-04 - accuracy: 0.9820 - val_loss: 5.1520e-04 - val_accuracy: 1.0000\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 5.0130e-04 - accuracy: 0.9876 - val_loss: 6.6223e-04 - val_accuracy: 0.9828\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 3.9679e-04 - accuracy: 0.9854 - val_loss: 5.9262e-04 - val_accuracy: 0.9828\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 663us/step - loss: 5.4134e-04 - accuracy: 0.9982 - val_loss: 4.5340e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 652us/step - loss: 4.0087e-04 - accuracy: 0.9933 - val_loss: 5.3713e-04 - val_accuracy: 0.9828\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 5.3929e-04 - accuracy: 0.9806 - val_loss: 8.6292e-04 - val_accuracy: 0.9655\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 686us/step - loss: 8.2953e-04 - accuracy: 0.9823 - val_loss: 9.0897e-04 - val_accuracy: 0.9483\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 615us/step - loss: 7.0225e-04 - accuracy: 0.9595 - val_loss: 5.3705e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 4.1374e-04 - accuracy: 0.9901 - val_loss: 5.4552e-04 - val_accuracy: 0.9655\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 664us/step - loss: 4.8284e-04 - accuracy: 0.9863 - val_loss: 5.1096e-04 - val_accuracy: 0.9655\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 655us/step - loss: 3.4299e-04 - accuracy: 0.9978 - val_loss: 5.2088e-04 - val_accuracy: 0.9828\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 720us/step - loss: 3.4936e-04 - accuracy: 0.9905 - val_loss: 4.1381e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 657us/step - loss: 4.3996e-04 - accuracy: 0.9930 - val_loss: 6.2727e-04 - val_accuracy: 0.9655\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 5.5159e-04 - accuracy: 0.9857 - val_loss: 8.9634e-04 - val_accuracy: 0.9483\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3205e-04 - accuracy: 0.9800 - val_loss: 5.8673e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 979us/step - loss: 3.8752e-04 - accuracy: 0.9962 - val_loss: 5.3655e-04 - val_accuracy: 0.9828\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 998us/step - loss: 4.3844e-04 - accuracy: 0.9883 - val_loss: 4.6946e-04 - val_accuracy: 0.9655\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 988us/step - loss: 4.2544e-04 - accuracy: 0.9902 - val_loss: 5.4697e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 891us/step - loss: 4.1755e-04 - accuracy: 0.9886 - val_loss: 4.7609e-04 - val_accuracy: 0.9828\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 842us/step - loss: 3.7643e-04 - accuracy: 0.9853 - val_loss: 6.5782e-04 - val_accuracy: 0.9655\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 679us/step - loss: 4.7586e-04 - accuracy: 0.9948 - val_loss: 5.8075e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 3.9518e-04 - accuracy: 0.9890 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 5.3635e-04 - accuracy: 0.9891 - val_loss: 5.4318e-04 - val_accuracy: 0.9828\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 800us/step - loss: 4.2230e-04 - accuracy: 0.9901 - val_loss: 5.3044e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 787us/step - loss: 3.6226e-04 - accuracy: 0.9882 - val_loss: 6.1302e-04 - val_accuracy: 0.9828\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 4.3098e-04 - accuracy: 0.9964 - val_loss: 5.4172e-04 - val_accuracy: 0.9828\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 879us/step - loss: 4.8092e-04 - accuracy: 0.9833 - val_loss: 4.5614e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 4.3595e-04 - accuracy: 0.9927 - val_loss: 6.0830e-04 - val_accuracy: 0.9655\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 4.5469e-04 - accuracy: 0.9979 - val_loss: 4.7270e-04 - val_accuracy: 0.9828\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 5.3778e-04 - accuracy: 0.9898 - val_loss: 7.2281e-04 - val_accuracy: 0.9655\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 780us/step - loss: 3.9849e-04 - accuracy: 0.9922 - val_loss: 4.0962e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 2.7517e-04 - accuracy: 0.9943 - val_loss: 5.7467e-04 - val_accuracy: 0.9655\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 840us/step - loss: 3.9218e-04 - accuracy: 0.9824 - val_loss: 5.1642e-04 - val_accuracy: 0.9828\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 3.9529e-04 - accuracy: 0.9924 - val_loss: 3.5547e-04 - val_accuracy: 0.9828\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 4.0490e-04 - accuracy: 0.9835 - val_loss: 4.2044e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 740us/step - loss: 4.7100e-04 - accuracy: 0.9890 - val_loss: 5.8643e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 4.4769e-04 - accuracy: 0.9994 - val_loss: 3.6857e-04 - val_accuracy: 0.9655\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 754us/step - loss: 3.1348e-04 - accuracy: 0.9752 - val_loss: 4.1555e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 3.5124e-04 - accuracy: 0.9984 - val_loss: 5.8257e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 3.9283e-04 - accuracy: 0.9986 - val_loss: 3.9629e-04 - val_accuracy: 0.9828\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 4.6284e-04 - accuracy: 0.9908 - val_loss: 7.5176e-04 - val_accuracy: 0.9483\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 665us/step - loss: 4.4137e-04 - accuracy: 0.9920 - val_loss: 3.9355e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 816us/step - loss: 3.6035e-04 - accuracy: 0.9949 - val_loss: 6.3188e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 705us/step - loss: 3.7351e-04 - accuracy: 0.9944 - val_loss: 5.0675e-04 - val_accuracy: 0.9828\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 3.4731e-04 - accuracy: 0.9915 - val_loss: 4.9003e-04 - val_accuracy: 0.9655\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 4.1903e-04 - accuracy: 0.9762 - val_loss: 4.3326e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 2.9644e-04 - accuracy: 0.9993 - val_loss: 5.8247e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 902us/step - loss: 3.7485e-04 - accuracy: 0.9934 - val_loss: 7.4198e-04 - val_accuracy: 0.9655\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 937us/step - loss: 3.4986e-04 - accuracy: 0.9956 - val_loss: 5.3289e-04 - val_accuracy: 0.9828\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 793us/step - loss: 4.7731e-04 - accuracy: 0.9954 - val_loss: 6.1239e-04 - val_accuracy: 0.9828\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 848us/step - loss: 3.5050e-04 - accuracy: 0.9929 - val_loss: 4.2686e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 776us/step - loss: 3.3332e-04 - accuracy: 0.9932 - val_loss: 5.7694e-04 - val_accuracy: 0.9828\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 725us/step - loss: 3.0392e-04 - accuracy: 0.9990 - val_loss: 4.3095e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 3.9747e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9138\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 5.8337e-04 - accuracy: 0.9815 - val_loss: 7.0522e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 4.8232e-04 - accuracy: 0.9871 - val_loss: 3.1415e-04 - val_accuracy: 0.9828\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 701us/step - loss: 3.4689e-04 - accuracy: 0.9969 - val_loss: 7.9693e-04 - val_accuracy: 0.9655\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 826us/step - loss: 3.1997e-04 - accuracy: 0.9797 - val_loss: 3.5715e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 779us/step - loss: 2.4943e-04 - accuracy: 0.9966 - val_loss: 3.4804e-04 - val_accuracy: 0.9828\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 2.6725e-04 - accuracy: 0.9868 - val_loss: 4.6510e-04 - val_accuracy: 0.9828\n",
            "6/6 [==============================] - 0s 399us/step - loss: 4.6510e-04 - accuracy: 0.9828\n",
            "Loss = 0.00046510298852808774, Accuracy = 0.982758641242981\n",
            "Loss array:  [0.0005183520261198282, 0.0008110131020657718, 0.0007127364515326917, 0.0006991206319071352, 0.0006490395753644407, 0.00046510298852808774]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 7/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.8039 - val_loss: 0.0192 - val_accuracy: 0.8276\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 912us/step - loss: 0.0142 - accuracy: 0.8812 - val_loss: 0.0149 - val_accuracy: 0.8966\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0097 - accuracy: 0.9276 - val_loss: 0.0102 - val_accuracy: 0.8966\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 0.0069 - accuracy: 0.9159 - val_loss: 0.0081 - val_accuracy: 0.8966\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 738us/step - loss: 0.0067 - accuracy: 0.9039 - val_loss: 0.0082 - val_accuracy: 0.8793\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 0.0050 - accuracy: 0.9198 - val_loss: 0.0057 - val_accuracy: 0.9138\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 793us/step - loss: 0.0043 - accuracy: 0.9145 - val_loss: 0.0059 - val_accuracy: 0.9138\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0034 - accuracy: 0.9134 - val_loss: 0.0049 - val_accuracy: 0.9483\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 892us/step - loss: 0.0035 - accuracy: 0.9245 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 741us/step - loss: 0.0027 - accuracy: 0.9305 - val_loss: 0.0052 - val_accuracy: 0.9310\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.0030 - accuracy: 0.9323 - val_loss: 0.0035 - val_accuracy: 0.9483\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 768us/step - loss: 0.0024 - accuracy: 0.9304 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0032 - accuracy: 0.9416 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 764us/step - loss: 0.0024 - accuracy: 0.9417 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0019 - accuracy: 0.9493 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 816us/step - loss: 0.0016 - accuracy: 0.9527 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9508 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 0.0015 - accuracy: 0.9662 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 906us/step - loss: 0.0018 - accuracy: 0.9528 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0014 - accuracy: 0.9659 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.0010 - accuracy: 0.9669 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0011 - accuracy: 0.9678 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.0012 - accuracy: 0.9675 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0011 - accuracy: 0.9683 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0013 - accuracy: 0.9533 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.0014 - accuracy: 0.9819 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 647us/step - loss: 9.5129e-04 - accuracy: 0.9599 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0010 - accuracy: 0.9598 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 0.0010 - accuracy: 0.9792 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 604us/step - loss: 8.7883e-04 - accuracy: 0.9689 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 8.5563e-04 - accuracy: 0.9831 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 679us/step - loss: 8.4576e-04 - accuracy: 0.9786 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 8.7404e-04 - accuracy: 0.9806 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 8.1866e-04 - accuracy: 0.9779 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 608us/step - loss: 0.0011 - accuracy: 0.9585 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 7.6525e-04 - accuracy: 0.9767 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 660us/step - loss: 8.6484e-04 - accuracy: 0.9789 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 652us/step - loss: 7.0781e-04 - accuracy: 0.9761 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9642 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 891us/step - loss: 8.9078e-04 - accuracy: 0.9924 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 968us/step - loss: 7.7306e-04 - accuracy: 0.9742 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0014 - accuracy: 0.9620 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0012 - accuracy: 0.9636 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 799us/step - loss: 7.0531e-04 - accuracy: 0.9827 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 793us/step - loss: 6.2826e-04 - accuracy: 0.9894 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 6.8914e-04 - accuracy: 0.9812 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 819us/step - loss: 8.2679e-04 - accuracy: 0.9905 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 7.1588e-04 - accuracy: 0.9867 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 815us/step - loss: 5.9631e-04 - accuracy: 0.9928 - val_loss: 9.9612e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 810us/step - loss: 8.0981e-04 - accuracy: 0.9635 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 792us/step - loss: 8.2683e-04 - accuracy: 0.9715 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 733us/step - loss: 8.1117e-04 - accuracy: 0.9751 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 850us/step - loss: 0.0011 - accuracy: 0.9841 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 6.6629e-04 - accuracy: 0.9857 - val_loss: 9.6108e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 722us/step - loss: 6.4290e-04 - accuracy: 0.9806 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 865us/step - loss: 8.2236e-04 - accuracy: 0.9780 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 663us/step - loss: 5.2447e-04 - accuracy: 0.9907 - val_loss: 9.8743e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 839us/step - loss: 5.8319e-04 - accuracy: 0.9792 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 742us/step - loss: 7.3819e-04 - accuracy: 0.9924 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 902us/step - loss: 6.4183e-04 - accuracy: 0.9808 - val_loss: 8.3024e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 5.7182e-04 - accuracy: 0.9952 - val_loss: 9.7814e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 840us/step - loss: 6.9297e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 795us/step - loss: 7.0220e-04 - accuracy: 0.9863 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 734us/step - loss: 7.6886e-04 - accuracy: 0.9852 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0011 - accuracy: 0.9679 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 660us/step - loss: 6.8172e-04 - accuracy: 0.9756 - val_loss: 9.0804e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 858us/step - loss: 6.9728e-04 - accuracy: 0.9833 - val_loss: 7.1578e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4233e-04 - accuracy: 0.9909 - val_loss: 8.8859e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 969us/step - loss: 8.3521e-04 - accuracy: 0.9812 - val_loss: 8.9045e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8904e-04 - accuracy: 0.9670 - val_loss: 7.7350e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 987us/step - loss: 5.4654e-04 - accuracy: 0.9814 - val_loss: 8.1614e-04 - val_accuracy: 1.0000\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 893us/step - loss: 7.3449e-04 - accuracy: 0.9877 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 735us/step - loss: 6.7100e-04 - accuracy: 0.9857 - val_loss: 8.5760e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 837us/step - loss: 5.3277e-04 - accuracy: 0.9926 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 6.3561e-04 - accuracy: 0.9800 - val_loss: 9.2333e-04 - val_accuracy: 1.0000\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 6.6546e-04 - accuracy: 0.9735 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 6.8477e-04 - accuracy: 0.9816 - val_loss: 8.7993e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 714us/step - loss: 4.8011e-04 - accuracy: 0.9838 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 7.4993e-04 - accuracy: 0.9897 - val_loss: 9.0769e-04 - val_accuracy: 1.0000\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 5.0596e-04 - accuracy: 0.9947 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 4.4868e-04 - accuracy: 0.9955 - val_loss: 7.9369e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 6.8144e-04 - accuracy: 0.9795 - val_loss: 8.1460e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 685us/step - loss: 4.6217e-04 - accuracy: 0.9968 - val_loss: 9.6682e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 6.1740e-04 - accuracy: 0.9940 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 676us/step - loss: 4.2983e-04 - accuracy: 0.9946 - val_loss: 8.9055e-04 - val_accuracy: 1.0000\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 760us/step - loss: 5.5683e-04 - accuracy: 0.9952 - val_loss: 7.8628e-04 - val_accuracy: 1.0000\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 5.2475e-04 - accuracy: 0.9915 - val_loss: 9.0616e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 844us/step - loss: 5.0332e-04 - accuracy: 0.9888 - val_loss: 9.5220e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 768us/step - loss: 5.3833e-04 - accuracy: 0.9929 - val_loss: 8.3480e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 4.9630e-04 - accuracy: 0.9822 - val_loss: 9.1684e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.4168e-04 - accuracy: 0.9877 - val_loss: 9.0221e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.5084e-04 - accuracy: 0.9962 - val_loss: 8.2860e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 901us/step - loss: 7.1571e-04 - accuracy: 0.9685 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 957us/step - loss: 5.0834e-04 - accuracy: 0.9867 - val_loss: 8.9931e-04 - val_accuracy: 0.9828\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 856us/step - loss: 5.4322e-04 - accuracy: 0.9921 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 855us/step - loss: 6.8048e-04 - accuracy: 0.9670 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 6.1180e-04 - accuracy: 0.9874 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 802us/step - loss: 4.5900e-04 - accuracy: 0.9824 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 750us/step - loss: 6.1486e-04 - accuracy: 0.9925 - val_loss: 9.1360e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0010 - accuracy: 0.9809 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 8.0856e-04 - accuracy: 0.9851 - val_loss: 7.0950e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 5.1484e-04 - accuracy: 0.9966 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 4.1794e-04 - accuracy: 0.9931 - val_loss: 7.3294e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 693us/step - loss: 5.1708e-04 - accuracy: 0.9920 - val_loss: 7.5588e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 656us/step - loss: 6.2112e-04 - accuracy: 0.9940 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 704us/step - loss: 7.2505e-04 - accuracy: 0.9853 - val_loss: 6.9931e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 681us/step - loss: 4.1854e-04 - accuracy: 0.9876 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 650us/step - loss: 7.2705e-04 - accuracy: 0.9845 - val_loss: 8.8015e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 4.4539e-04 - accuracy: 0.9939 - val_loss: 8.9310e-04 - val_accuracy: 0.9828\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 687us/step - loss: 5.4844e-04 - accuracy: 0.9916 - val_loss: 7.6253e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 647us/step - loss: 4.0388e-04 - accuracy: 0.9906 - val_loss: 6.9893e-04 - val_accuracy: 1.0000\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 655us/step - loss: 4.8617e-04 - accuracy: 0.9880 - val_loss: 7.7696e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 790us/step - loss: 6.9708e-04 - accuracy: 0.9855 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 3.5651e-04 - accuracy: 0.9894 - val_loss: 9.7954e-04 - val_accuracy: 0.9828\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 3.1314e-04 - accuracy: 0.9937 - val_loss: 8.1189e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 737us/step - loss: 4.3674e-04 - accuracy: 0.9856 - val_loss: 8.2605e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 3.5760e-04 - accuracy: 0.9899 - val_loss: 7.0439e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 738us/step - loss: 6.6394e-04 - accuracy: 0.9932 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.0941e-04 - accuracy: 0.9934 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 859us/step - loss: 5.8242e-04 - accuracy: 0.9857 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 817us/step - loss: 4.8636e-04 - accuracy: 0.9872 - val_loss: 9.6027e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 4.9186e-04 - accuracy: 0.9837 - val_loss: 8.7164e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 756us/step - loss: 3.9070e-04 - accuracy: 0.9901 - val_loss: 7.5870e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 7.4150e-04 - accuracy: 0.9878 - val_loss: 9.7912e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 691us/step - loss: 4.1486e-04 - accuracy: 0.9865 - val_loss: 8.6956e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 866us/step - loss: 4.2969e-04 - accuracy: 0.9885 - val_loss: 7.2415e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 4.0117e-04 - accuracy: 0.9932 - val_loss: 7.9857e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 4.6249e-04 - accuracy: 0.9901 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 7.5025e-04 - accuracy: 0.9719 - val_loss: 8.1242e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 671us/step - loss: 3.1929e-04 - accuracy: 0.9849 - val_loss: 8.9795e-04 - val_accuracy: 0.9828\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 4.5670e-04 - accuracy: 0.9909 - val_loss: 7.6911e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 4.6842e-04 - accuracy: 0.9889 - val_loss: 8.7060e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 829us/step - loss: 5.6567e-04 - accuracy: 0.9812 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 3.5818e-04 - accuracy: 0.9990 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 742us/step - loss: 5.0674e-04 - accuracy: 0.9913 - val_loss: 7.5482e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8949e-04 - accuracy: 0.9827 - val_loss: 8.9411e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 972us/step - loss: 2.9025e-04 - accuracy: 0.9967 - val_loss: 7.9307e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.0716e-04 - accuracy: 0.9868 - val_loss: 8.0898e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 945us/step - loss: 3.7696e-04 - accuracy: 0.9881 - val_loss: 8.8857e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 885us/step - loss: 3.8777e-04 - accuracy: 0.9894 - val_loss: 6.9466e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 900us/step - loss: 3.5380e-04 - accuracy: 0.9951 - val_loss: 6.5352e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 887us/step - loss: 3.7747e-04 - accuracy: 0.9986 - val_loss: 6.2774e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 921us/step - loss: 3.9475e-04 - accuracy: 0.9837 - val_loss: 7.3563e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 3.4345e-04 - accuracy: 0.9967 - val_loss: 8.5619e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 810us/step - loss: 3.0200e-04 - accuracy: 0.9915 - val_loss: 8.1502e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 792us/step - loss: 2.7051e-04 - accuracy: 0.9973 - val_loss: 9.1607e-04 - val_accuracy: 0.9828\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 854us/step - loss: 3.4132e-04 - accuracy: 0.9911 - val_loss: 7.9004e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 6.1223e-04 - accuracy: 0.9888 - val_loss: 7.3642e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 734us/step - loss: 3.7430e-04 - accuracy: 0.9893 - val_loss: 6.8737e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 785us/step - loss: 3.2932e-04 - accuracy: 0.9973 - val_loss: 6.5507e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 8.1836e-04 - accuracy: 0.9638 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 4.9571e-04 - accuracy: 0.9873 - val_loss: 8.2987e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 728us/step - loss: 4.2025e-04 - accuracy: 0.9883 - val_loss: 7.9545e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 3.1294e-04 - accuracy: 0.9920 - val_loss: 7.9952e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 2.9276e-04 - accuracy: 0.9906 - val_loss: 5.6640e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 2.9253e-04 - accuracy: 0.9906 - val_loss: 5.7184e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 848us/step - loss: 2.8683e-04 - accuracy: 0.9922 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 3.8148e-04 - accuracy: 0.9919 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 826us/step - loss: 5.1099e-04 - accuracy: 0.9971 - val_loss: 8.8660e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 4.6530e-04 - accuracy: 0.9620 - val_loss: 6.3950e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 845us/step - loss: 3.4062e-04 - accuracy: 0.9968 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0921e-04 - accuracy: 0.9959 - val_loss: 6.6810e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 982us/step - loss: 3.1601e-04 - accuracy: 0.9910 - val_loss: 7.1878e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 741us/step - loss: 3.4393e-04 - accuracy: 0.9785 - val_loss: 7.6793e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 982us/step - loss: 4.2637e-04 - accuracy: 0.9892 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 740us/step - loss: 5.2357e-04 - accuracy: 0.9721 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 4.4547e-04 - accuracy: 0.9940 - val_loss: 7.8603e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 685us/step - loss: 3.8666e-04 - accuracy: 0.9954 - val_loss: 6.4046e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 784us/step - loss: 3.1230e-04 - accuracy: 0.9941 - val_loss: 8.4734e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 3.9434e-04 - accuracy: 0.9883 - val_loss: 8.2447e-04 - val_accuracy: 1.0000\n",
            "6/6 [==============================] - 0s 396us/step - loss: 8.2447e-04 - accuracy: 1.0000\n",
            "Loss = 0.0008244721684604883, Accuracy = 1.0\n",
            "Loss array:  [0.0005183520261198282, 0.0008110131020657718, 0.0007127364515326917, 0.0006991206319071352, 0.0006490395753644407, 0.00046510298852808774, 0.0008244721684604883]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 8/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.5994 - val_loss: 0.0168 - val_accuracy: 0.8448\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0164 - accuracy: 0.8741 - val_loss: 0.0119 - val_accuracy: 0.8966\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0104 - accuracy: 0.9092 - val_loss: 0.0069 - val_accuracy: 0.9483\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 0.0063 - accuracy: 0.9285 - val_loss: 0.0051 - val_accuracy: 0.9655\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 643us/step - loss: 0.0047 - accuracy: 0.9323 - val_loss: 0.0060 - val_accuracy: 0.9138\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 0.0041 - accuracy: 0.9438 - val_loss: 0.0065 - val_accuracy: 0.8966\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0034 - accuracy: 0.9163 - val_loss: 0.0087 - val_accuracy: 0.8621\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 834us/step - loss: 0.0046 - accuracy: 0.9231 - val_loss: 0.0047 - val_accuracy: 0.9138\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9219 - val_loss: 0.0033 - val_accuracy: 0.9655\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.9289 - val_loss: 0.0055 - val_accuracy: 0.8966\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 864us/step - loss: 0.0026 - accuracy: 0.9421 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0025 - accuracy: 0.9507 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 0.0024 - accuracy: 0.9543 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0021 - accuracy: 0.9370 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0021 - accuracy: 0.9328 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 879us/step - loss: 0.0024 - accuracy: 0.9476 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 0.0018 - accuracy: 0.9406 - val_loss: 0.0029 - val_accuracy: 0.8966\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 0.0019 - accuracy: 0.9408 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0014 - accuracy: 0.9266 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 798us/step - loss: 0.0017 - accuracy: 0.9706 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 0.0017 - accuracy: 0.9331 - val_loss: 0.0036 - val_accuracy: 0.8966\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 799us/step - loss: 0.0014 - accuracy: 0.9516 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 906us/step - loss: 0.0013 - accuracy: 0.9655 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.0015 - accuracy: 0.9599 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 817us/step - loss: 0.0012 - accuracy: 0.9588 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 9.9040e-04 - accuracy: 0.9573 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 0.0012 - accuracy: 0.9694 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 0.0013 - accuracy: 0.9466 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9708 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 887us/step - loss: 0.0014 - accuracy: 0.9681 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9695 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 997us/step - loss: 0.0010 - accuracy: 0.9718 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 843us/step - loss: 9.0501e-04 - accuracy: 0.9704 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 0.0011 - accuracy: 0.9678 - val_loss: 9.9219e-04 - val_accuracy: 1.0000\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0016 - accuracy: 0.9639 - val_loss: 9.2146e-04 - val_accuracy: 0.9828\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 847us/step - loss: 9.0466e-04 - accuracy: 0.9826 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 8.2041e-04 - accuracy: 0.9782 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 8.1138e-04 - accuracy: 0.9839 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 8.6458e-04 - accuracy: 0.9759 - val_loss: 9.7076e-04 - val_accuracy: 0.9828\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 8.0721e-04 - accuracy: 0.9765 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 0.0011 - accuracy: 0.9761 - val_loss: 8.8512e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 681us/step - loss: 8.2465e-04 - accuracy: 0.9754 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 590us/step - loss: 7.4217e-04 - accuracy: 0.9778 - val_loss: 8.1163e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 696us/step - loss: 8.8353e-04 - accuracy: 0.9824 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 734us/step - loss: 7.3835e-04 - accuracy: 0.9930 - val_loss: 8.4275e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 708us/step - loss: 7.5475e-04 - accuracy: 0.9853 - val_loss: 7.9289e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 793us/step - loss: 7.2062e-04 - accuracy: 0.9731 - val_loss: 9.5657e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1592e-04 - accuracy: 0.9773 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 871us/step - loss: 0.0011 - accuracy: 0.9830 - val_loss: 0.0027 - val_accuracy: 0.9138\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 919us/step - loss: 0.0010 - accuracy: 0.9896 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 6.4079e-04 - accuracy: 0.9717 - val_loss: 9.7989e-04 - val_accuracy: 1.0000\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 717us/step - loss: 8.6239e-04 - accuracy: 0.9786 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 734us/step - loss: 9.8686e-04 - accuracy: 0.9705 - val_loss: 9.5478e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 669us/step - loss: 6.3977e-04 - accuracy: 0.9862 - val_loss: 7.2054e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 714us/step - loss: 5.5280e-04 - accuracy: 0.9842 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 5.6374e-04 - accuracy: 0.9942 - val_loss: 9.3809e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 674us/step - loss: 6.0619e-04 - accuracy: 0.9878 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 735us/step - loss: 6.3606e-04 - accuracy: 0.9804 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 693us/step - loss: 7.2747e-04 - accuracy: 0.9885 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 7.1012e-04 - accuracy: 0.9883 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 6.8486e-04 - accuracy: 0.9942 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 7.1478e-04 - accuracy: 0.9818 - val_loss: 7.4691e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 811us/step - loss: 7.2022e-04 - accuracy: 0.9752 - val_loss: 9.7311e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0010 - accuracy: 0.9785 - val_loss: 7.0928e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 4.7640e-04 - accuracy: 0.9958 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 7.0053e-04 - accuracy: 0.9839 - val_loss: 7.1899e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 719us/step - loss: 6.5206e-04 - accuracy: 0.9883 - val_loss: 7.1489e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 689us/step - loss: 5.3396e-04 - accuracy: 0.9803 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 628us/step - loss: 8.9321e-04 - accuracy: 0.9701 - val_loss: 7.7634e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 6.5780e-04 - accuracy: 0.9903 - val_loss: 6.7651e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 6.5106e-04 - accuracy: 0.9874 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 816us/step - loss: 7.9358e-04 - accuracy: 0.9917 - val_loss: 8.0560e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 6.7264e-04 - accuracy: 0.9758 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 737us/step - loss: 6.0565e-04 - accuracy: 0.9841 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 680us/step - loss: 5.9140e-04 - accuracy: 0.9924 - val_loss: 6.4360e-04 - val_accuracy: 1.0000\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 689us/step - loss: 6.7424e-04 - accuracy: 0.9933 - val_loss: 6.5410e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9665e-04 - accuracy: 0.9850 - val_loss: 7.6052e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 897us/step - loss: 7.2714e-04 - accuracy: 0.9738 - val_loss: 9.6703e-04 - val_accuracy: 1.0000\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 985us/step - loss: 5.2142e-04 - accuracy: 0.9915 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 7.9549e-04 - accuracy: 0.9902 - val_loss: 8.4980e-04 - val_accuracy: 0.9828\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 860us/step - loss: 6.1833e-04 - accuracy: 0.9803 - val_loss: 9.0547e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 649us/step - loss: 8.2948e-04 - accuracy: 0.9884 - val_loss: 8.4740e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 853us/step - loss: 4.7019e-04 - accuracy: 0.9830 - val_loss: 6.7923e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 4.5355e-04 - accuracy: 0.9954 - val_loss: 8.9442e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 814us/step - loss: 5.8631e-04 - accuracy: 0.9981 - val_loss: 8.9640e-04 - val_accuracy: 1.0000\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 7.2141e-04 - accuracy: 0.9845 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 6.5659e-04 - accuracy: 0.9774 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 5.0598e-04 - accuracy: 0.9933 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 733us/step - loss: 5.7075e-04 - accuracy: 0.9863 - val_loss: 7.1708e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 7.0836e-04 - accuracy: 0.9865 - val_loss: 9.1994e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 851us/step - loss: 5.2062e-04 - accuracy: 0.9889 - val_loss: 9.1574e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 876us/step - loss: 4.6387e-04 - accuracy: 0.9960 - val_loss: 8.0572e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 6.4104e-04 - accuracy: 0.9823 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 797us/step - loss: 5.2382e-04 - accuracy: 0.9813 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 6.6528e-04 - accuracy: 0.9926 - val_loss: 7.4757e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 722us/step - loss: 5.3558e-04 - accuracy: 0.9873 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 870us/step - loss: 4.7669e-04 - accuracy: 0.9978 - val_loss: 7.4333e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 5.6756e-04 - accuracy: 0.9818 - val_loss: 8.6870e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 5.7730e-04 - accuracy: 0.9910 - val_loss: 8.2649e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 5.4689e-04 - accuracy: 0.9885 - val_loss: 8.8601e-04 - val_accuracy: 1.0000\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 4.4858e-04 - accuracy: 0.9978 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 4.9824e-04 - accuracy: 0.9903 - val_loss: 6.3941e-04 - val_accuracy: 1.0000\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 4.3515e-04 - accuracy: 0.9936 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 4.1042e-04 - accuracy: 0.9947 - val_loss: 7.1494e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 785us/step - loss: 5.8362e-04 - accuracy: 0.9721 - val_loss: 9.2999e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 797us/step - loss: 7.4820e-04 - accuracy: 0.9794 - val_loss: 7.5214e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 671us/step - loss: 4.7763e-04 - accuracy: 0.9856 - val_loss: 7.3411e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 787us/step - loss: 4.1061e-04 - accuracy: 0.9908 - val_loss: 6.4873e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 3.5119e-04 - accuracy: 0.9971 - val_loss: 7.8426e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4469e-04 - accuracy: 0.9937 - val_loss: 8.6215e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 916us/step - loss: 4.1773e-04 - accuracy: 0.9936 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3672e-04 - accuracy: 0.9913 - val_loss: 9.7235e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 4.4811e-04 - accuracy: 0.9947 - val_loss: 7.5493e-04 - val_accuracy: 1.0000\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 952us/step - loss: 4.2557e-04 - accuracy: 0.9916 - val_loss: 8.5445e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 701us/step - loss: 7.6428e-04 - accuracy: 0.9838 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 920us/step - loss: 8.6037e-04 - accuracy: 0.9862 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 8.6717e-04 - accuracy: 0.9779 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 914us/step - loss: 7.6017e-04 - accuracy: 0.9854 - val_loss: 7.0553e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 842us/step - loss: 4.2455e-04 - accuracy: 0.9954 - val_loss: 7.5314e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 814us/step - loss: 4.5688e-04 - accuracy: 0.9865 - val_loss: 7.3034e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 792us/step - loss: 3.8909e-04 - accuracy: 0.9926 - val_loss: 9.9652e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 860us/step - loss: 5.8324e-04 - accuracy: 0.9935 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 845us/step - loss: 4.8753e-04 - accuracy: 0.9983 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 889us/step - loss: 4.8120e-04 - accuracy: 0.9936 - val_loss: 7.5625e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 854us/step - loss: 5.1383e-04 - accuracy: 0.9887 - val_loss: 7.9082e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 839us/step - loss: 4.7295e-04 - accuracy: 0.9932 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 876us/step - loss: 5.1236e-04 - accuracy: 0.9942 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 9.0121e-04 - accuracy: 0.9759 - val_loss: 6.5430e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 923us/step - loss: 3.1320e-04 - accuracy: 0.9999 - val_loss: 6.8592e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 799us/step - loss: 4.2126e-04 - accuracy: 0.9999 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.2210e-04 - accuracy: 0.9963 - val_loss: 6.3651e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 956us/step - loss: 3.6005e-04 - accuracy: 0.9981 - val_loss: 8.1876e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 794us/step - loss: 3.2503e-04 - accuracy: 0.9970 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 787us/step - loss: 5.8047e-04 - accuracy: 0.9757 - val_loss: 6.4800e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 3.5006e-04 - accuracy: 0.9970 - val_loss: 6.2536e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 3.9064e-04 - accuracy: 0.9975 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 5.7895e-04 - accuracy: 0.9993 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 671us/step - loss: 4.9946e-04 - accuracy: 0.9888 - val_loss: 7.3118e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 4.1135e-04 - accuracy: 0.9990 - val_loss: 7.7269e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 698us/step - loss: 3.8223e-04 - accuracy: 0.9977 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 754us/step - loss: 5.0190e-04 - accuracy: 0.9934 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 3.9775e-04 - accuracy: 0.9955 - val_loss: 9.5184e-04 - val_accuracy: 0.9483\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 647us/step - loss: 4.4777e-04 - accuracy: 0.9826 - val_loss: 8.7992e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 838us/step - loss: 5.0633e-04 - accuracy: 0.9753 - val_loss: 5.6722e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 678us/step - loss: 3.1990e-04 - accuracy: 0.9983 - val_loss: 6.7477e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.1959e-04 - accuracy: 0.9938 - val_loss: 7.5836e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.1048e-04 - accuracy: 0.9944 - val_loss: 7.8747e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.9709e-04 - accuracy: 0.9916 - val_loss: 6.6767e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 975us/step - loss: 5.3748e-04 - accuracy: 0.9926 - val_loss: 6.4818e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 793us/step - loss: 2.9388e-04 - accuracy: 0.9955 - val_loss: 6.4660e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 3.2303e-04 - accuracy: 0.9942 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 797us/step - loss: 5.7858e-04 - accuracy: 0.9751 - val_loss: 6.3011e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 720us/step - loss: 3.7256e-04 - accuracy: 0.9927 - val_loss: 7.0832e-04 - val_accuracy: 0.9828\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 866us/step - loss: 3.0277e-04 - accuracy: 0.9954 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 674us/step - loss: 6.4528e-04 - accuracy: 0.9805 - val_loss: 6.9179e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 815us/step - loss: 3.1166e-04 - accuracy: 0.9943 - val_loss: 7.4852e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 682us/step - loss: 5.0563e-04 - accuracy: 0.9928 - val_loss: 5.9708e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 3.3158e-04 - accuracy: 0.9875 - val_loss: 7.3796e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 3.4912e-04 - accuracy: 0.9949 - val_loss: 7.5770e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 3.5117e-04 - accuracy: 0.9985 - val_loss: 7.7136e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 765us/step - loss: 3.9973e-04 - accuracy: 0.9912 - val_loss: 7.4158e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 4.1713e-04 - accuracy: 0.9911 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 738us/step - loss: 3.5634e-04 - accuracy: 0.9844 - val_loss: 7.1584e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 666us/step - loss: 3.5995e-04 - accuracy: 0.9957 - val_loss: 6.4179e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 654us/step - loss: 4.1539e-04 - accuracy: 0.9882 - val_loss: 7.8448e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 4.9300e-04 - accuracy: 0.9802 - val_loss: 6.5072e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 665us/step - loss: 4.5499e-04 - accuracy: 0.9981 - val_loss: 6.9893e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 664us/step - loss: 4.0368e-04 - accuracy: 0.9831 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 723us/step - loss: 3.6891e-04 - accuracy: 0.9886 - val_loss: 6.4940e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 2.6988e-04 - accuracy: 0.9938 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "6/6 [==============================] - 0s 364us/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Loss = 0.0010358222061768174, Accuracy = 1.0\n",
            "Loss array:  [0.0005183520261198282, 0.0008110131020657718, 0.0007127364515326917, 0.0006991206319071352, 0.0006490395753644407, 0.00046510298852808774, 0.0008244721684604883, 0.0010358222061768174]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 9/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.7653 - val_loss: 0.0181 - val_accuracy: 0.8276\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 855us/step - loss: 0.0138 - accuracy: 0.8749 - val_loss: 0.0094 - val_accuracy: 0.9138\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0080 - accuracy: 0.9529 - val_loss: 0.0063 - val_accuracy: 0.9138\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0060 - accuracy: 0.9332 - val_loss: 0.0047 - val_accuracy: 0.9310\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0047 - accuracy: 0.9243 - val_loss: 0.0049 - val_accuracy: 0.9310\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0046 - accuracy: 0.9137 - val_loss: 0.0055 - val_accuracy: 0.9310\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.0046 - accuracy: 0.9075 - val_loss: 0.0046 - val_accuracy: 0.9138\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.0042 - accuracy: 0.9350 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 772us/step - loss: 0.0033 - accuracy: 0.9086 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 0.0029 - accuracy: 0.9356 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.0025 - accuracy: 0.9539 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 0.0022 - accuracy: 0.9442 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0023 - accuracy: 0.9497 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.0018 - accuracy: 0.9356 - val_loss: 0.0026 - val_accuracy: 0.9828\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9414 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9439 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9173 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9375 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 926us/step - loss: 0.0017 - accuracy: 0.9597 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 876us/step - loss: 0.0016 - accuracy: 0.9447 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 874us/step - loss: 0.0013 - accuracy: 0.9730 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 996us/step - loss: 0.0012 - accuracy: 0.9581 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 869us/step - loss: 0.0015 - accuracy: 0.9471 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 798us/step - loss: 0.0014 - accuracy: 0.9590 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 862us/step - loss: 0.0021 - accuracy: 0.9367 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0013 - accuracy: 0.9633 - val_loss: 8.5569e-04 - val_accuracy: 0.9655\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 853us/step - loss: 0.0011 - accuracy: 0.9452 - val_loss: 7.6606e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 820us/step - loss: 8.8930e-04 - accuracy: 0.9640 - val_loss: 7.2940e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 810us/step - loss: 0.0010 - accuracy: 0.9735 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 787us/step - loss: 0.0016 - accuracy: 0.9317 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 821us/step - loss: 0.0010 - accuracy: 0.9535 - val_loss: 7.3008e-04 - val_accuracy: 0.9828\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 867us/step - loss: 9.5866e-04 - accuracy: 0.9592 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 614us/step - loss: 0.0012 - accuracy: 0.9598 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 9.9174e-04 - accuracy: 0.9616 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 711us/step - loss: 8.8140e-04 - accuracy: 0.9780 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 657us/step - loss: 8.3097e-04 - accuracy: 0.9595 - val_loss: 7.8988e-04 - val_accuracy: 1.0000\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 675us/step - loss: 8.8914e-04 - accuracy: 0.9589 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 660us/step - loss: 8.9324e-04 - accuracy: 0.9723 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 8.3267e-04 - accuracy: 0.9745 - val_loss: 7.4998e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 697us/step - loss: 6.4433e-04 - accuracy: 0.9554 - val_loss: 8.1686e-04 - val_accuracy: 0.9828\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 653us/step - loss: 9.1318e-04 - accuracy: 0.9535 - val_loss: 7.1189e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 673us/step - loss: 9.2138e-04 - accuracy: 0.9729 - val_loss: 8.5542e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 657us/step - loss: 8.9697e-04 - accuracy: 0.9820 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 783us/step - loss: 7.8633e-04 - accuracy: 0.9672 - val_loss: 7.5203e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 7.2360e-04 - accuracy: 0.9590 - val_loss: 9.0828e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 6.3193e-04 - accuracy: 0.9857 - val_loss: 8.3360e-04 - val_accuracy: 0.9828\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 7.6372e-04 - accuracy: 0.9708 - val_loss: 8.1048e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0010 - accuracy: 0.9581 - val_loss: 6.3735e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 811us/step - loss: 9.6978e-04 - accuracy: 0.9721 - val_loss: 8.7854e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 681us/step - loss: 6.6905e-04 - accuracy: 0.9884 - val_loss: 5.9716e-04 - val_accuracy: 0.9828\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0990e-04 - accuracy: 0.9844 - val_loss: 7.8912e-04 - val_accuracy: 1.0000\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 994us/step - loss: 6.8136e-04 - accuracy: 0.9784 - val_loss: 9.8860e-04 - val_accuracy: 1.0000\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.9715e-04 - accuracy: 0.9750 - val_loss: 6.1119e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9639e-04 - accuracy: 0.9797 - val_loss: 8.3731e-04 - val_accuracy: 0.9828\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 969us/step - loss: 6.8193e-04 - accuracy: 0.9732 - val_loss: 6.3719e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 890us/step - loss: 6.4545e-04 - accuracy: 0.9851 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 890us/step - loss: 9.0109e-04 - accuracy: 0.9538 - val_loss: 6.3091e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 833us/step - loss: 0.0013 - accuracy: 0.9520 - val_loss: 8.1258e-04 - val_accuracy: 0.9828\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 893us/step - loss: 6.6149e-04 - accuracy: 0.9805 - val_loss: 5.6126e-04 - val_accuracy: 1.0000\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 843us/step - loss: 7.2502e-04 - accuracy: 0.9792 - val_loss: 5.9875e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 948us/step - loss: 5.8572e-04 - accuracy: 0.9865 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 877us/step - loss: 6.6366e-04 - accuracy: 0.9760 - val_loss: 5.2633e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 930us/step - loss: 6.9273e-04 - accuracy: 0.9839 - val_loss: 6.5502e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 721us/step - loss: 7.4393e-04 - accuracy: 0.9632 - val_loss: 6.8066e-04 - val_accuracy: 0.9828\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 841us/step - loss: 5.9922e-04 - accuracy: 0.9832 - val_loss: 6.6074e-04 - val_accuracy: 0.9828\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 7.8379e-04 - accuracy: 0.9687 - val_loss: 7.1613e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 889us/step - loss: 5.4212e-04 - accuracy: 0.9732 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 750us/step - loss: 9.8448e-04 - accuracy: 0.9673 - val_loss: 6.4016e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 795us/step - loss: 5.8908e-04 - accuracy: 0.9897 - val_loss: 5.6247e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 6.3158e-04 - accuracy: 0.9729 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 0.0011 - accuracy: 0.9734 - val_loss: 6.8310e-04 - val_accuracy: 0.9828\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 826us/step - loss: 7.2529e-04 - accuracy: 0.9765 - val_loss: 5.5601e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 604us/step - loss: 6.4089e-04 - accuracy: 0.9736 - val_loss: 4.8234e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 738us/step - loss: 6.5803e-04 - accuracy: 0.9842 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 676us/step - loss: 8.2690e-04 - accuracy: 0.9865 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 665us/step - loss: 6.3333e-04 - accuracy: 0.9759 - val_loss: 6.1573e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 738us/step - loss: 5.3244e-04 - accuracy: 0.9719 - val_loss: 8.3264e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 665us/step - loss: 5.3792e-04 - accuracy: 0.9935 - val_loss: 5.3761e-04 - val_accuracy: 1.0000\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 4.3999e-04 - accuracy: 0.9936 - val_loss: 6.7043e-04 - val_accuracy: 1.0000\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.3684e-04 - accuracy: 0.9809 - val_loss: 7.4072e-04 - val_accuracy: 1.0000\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 986us/step - loss: 5.9849e-04 - accuracy: 0.9692 - val_loss: 5.7006e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 916us/step - loss: 4.9939e-04 - accuracy: 0.9899 - val_loss: 5.2467e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 857us/step - loss: 4.6908e-04 - accuracy: 0.9848 - val_loss: 6.8863e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 780us/step - loss: 6.1783e-04 - accuracy: 0.9900 - val_loss: 6.1577e-04 - val_accuracy: 0.9828\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 847us/step - loss: 5.7455e-04 - accuracy: 0.9855 - val_loss: 8.7511e-04 - val_accuracy: 0.9828\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 633us/step - loss: 7.6237e-04 - accuracy: 0.9668 - val_loss: 4.9256e-04 - val_accuracy: 1.0000\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 841us/step - loss: 4.3871e-04 - accuracy: 0.9908 - val_loss: 4.2242e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 4.1027e-04 - accuracy: 0.9828 - val_loss: 7.9519e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 800us/step - loss: 8.1227e-04 - accuracy: 0.9820 - val_loss: 7.8436e-04 - val_accuracy: 0.9828\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 6.2321e-04 - accuracy: 0.9854 - val_loss: 5.1818e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 6.5637e-04 - accuracy: 0.9697 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 842us/step - loss: 6.2260e-04 - accuracy: 0.9832 - val_loss: 4.6943e-04 - val_accuracy: 0.9828\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 762us/step - loss: 4.8814e-04 - accuracy: 0.9846 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 880us/step - loss: 9.8126e-04 - accuracy: 0.9610 - val_loss: 5.2782e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 5.7535e-04 - accuracy: 0.9789 - val_loss: 6.2928e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 846us/step - loss: 6.9042e-04 - accuracy: 0.9854 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 701us/step - loss: 6.7050e-04 - accuracy: 0.9916 - val_loss: 5.2782e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 896us/step - loss: 5.1340e-04 - accuracy: 0.9775 - val_loss: 9.9703e-04 - val_accuracy: 0.9483\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 8.4641e-04 - accuracy: 0.9731 - val_loss: 6.9215e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 824us/step - loss: 6.9273e-04 - accuracy: 0.9839 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 821us/step - loss: 7.7250e-04 - accuracy: 0.9885 - val_loss: 5.0305e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 840us/step - loss: 5.4319e-04 - accuracy: 0.9852 - val_loss: 6.9850e-04 - val_accuracy: 0.9828\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 6.6294e-04 - accuracy: 0.9892 - val_loss: 5.7761e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 821us/step - loss: 5.9211e-04 - accuracy: 0.9849 - val_loss: 4.3060e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 860us/step - loss: 5.6209e-04 - accuracy: 0.9955 - val_loss: 5.4711e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 762us/step - loss: 5.7499e-04 - accuracy: 0.9949 - val_loss: 5.5125e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 858us/step - loss: 7.3297e-04 - accuracy: 0.9798 - val_loss: 5.0945e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.0970e-04 - accuracy: 0.9798 - val_loss: 6.8087e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 954us/step - loss: 4.8915e-04 - accuracy: 0.9900 - val_loss: 5.8281e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 999us/step - loss: 6.4575e-04 - accuracy: 0.9924 - val_loss: 5.0725e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 932us/step - loss: 4.6882e-04 - accuracy: 0.9779 - val_loss: 6.7779e-04 - val_accuracy: 1.0000\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0353e-04 - accuracy: 0.9669 - val_loss: 5.1265e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 870us/step - loss: 4.1446e-04 - accuracy: 0.9948 - val_loss: 8.6936e-04 - val_accuracy: 0.9828\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 913us/step - loss: 7.4760e-04 - accuracy: 0.9734 - val_loss: 6.6081e-04 - val_accuracy: 0.9828\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 5.5236e-04 - accuracy: 0.9958 - val_loss: 4.3811e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 905us/step - loss: 5.6746e-04 - accuracy: 0.9860 - val_loss: 5.6196e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 728us/step - loss: 5.4523e-04 - accuracy: 0.9543 - val_loss: 7.4053e-04 - val_accuracy: 0.9828\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 846us/step - loss: 6.3914e-04 - accuracy: 0.9892 - val_loss: 4.7232e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 887us/step - loss: 4.3296e-04 - accuracy: 0.9891 - val_loss: 5.0664e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 909us/step - loss: 4.3310e-04 - accuracy: 0.9882 - val_loss: 8.1479e-04 - val_accuracy: 0.9828\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 784us/step - loss: 6.8573e-04 - accuracy: 0.9639 - val_loss: 5.5674e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 842us/step - loss: 4.9787e-04 - accuracy: 0.9714 - val_loss: 8.0076e-04 - val_accuracy: 0.9828\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 5.3577e-04 - accuracy: 0.9873 - val_loss: 6.8591e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 862us/step - loss: 5.1861e-04 - accuracy: 0.9888 - val_loss: 8.1061e-04 - val_accuracy: 0.9828\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 848us/step - loss: 4.8524e-04 - accuracy: 0.9763 - val_loss: 4.4182e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 909us/step - loss: 3.3788e-04 - accuracy: 0.9944 - val_loss: 5.3082e-04 - val_accuracy: 0.9828\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 850us/step - loss: 3.9788e-04 - accuracy: 0.9956 - val_loss: 7.1385e-04 - val_accuracy: 0.9828\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4718e-04 - accuracy: 0.9810 - val_loss: 4.6338e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 882us/step - loss: 4.0317e-04 - accuracy: 0.9930 - val_loss: 5.9675e-04 - val_accuracy: 0.9828\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 943us/step - loss: 6.1837e-04 - accuracy: 0.9815 - val_loss: 5.5627e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 8.4729e-04 - accuracy: 0.9842 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 898us/step - loss: 6.2299e-04 - accuracy: 0.9773 - val_loss: 6.2721e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 886us/step - loss: 4.3973e-04 - accuracy: 0.9920 - val_loss: 5.1461e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 916us/step - loss: 3.7520e-04 - accuracy: 0.9921 - val_loss: 4.9233e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 820us/step - loss: 4.5176e-04 - accuracy: 0.9843 - val_loss: 5.9696e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 913us/step - loss: 4.2281e-04 - accuracy: 0.9910 - val_loss: 5.1168e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 764us/step - loss: 4.9962e-04 - accuracy: 0.9912 - val_loss: 4.0866e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 875us/step - loss: 4.7691e-04 - accuracy: 0.9903 - val_loss: 4.8658e-04 - val_accuracy: 0.9828\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 820us/step - loss: 4.3532e-04 - accuracy: 0.9848 - val_loss: 4.4097e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 888us/step - loss: 4.1074e-04 - accuracy: 0.9899 - val_loss: 4.3896e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 807us/step - loss: 3.5315e-04 - accuracy: 0.9942 - val_loss: 5.0015e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 4.4547e-04 - accuracy: 0.9872 - val_loss: 6.9704e-04 - val_accuracy: 0.9828\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 831us/step - loss: 4.3782e-04 - accuracy: 0.9849 - val_loss: 4.6670e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 816us/step - loss: 3.8841e-04 - accuracy: 0.9913 - val_loss: 4.7188e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 880us/step - loss: 4.0590e-04 - accuracy: 0.9954 - val_loss: 5.2227e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 711us/step - loss: 4.0280e-04 - accuracy: 0.9984 - val_loss: 5.7801e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 833us/step - loss: 5.2826e-04 - accuracy: 0.9904 - val_loss: 5.6345e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 6.7716e-04 - accuracy: 0.9778 - val_loss: 4.4750e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.1968e-04 - accuracy: 0.9869 - val_loss: 5.3726e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.5529e-04 - accuracy: 0.9955 - val_loss: 3.8575e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 918us/step - loss: 3.8787e-04 - accuracy: 0.9930 - val_loss: 4.4984e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 884us/step - loss: 4.0887e-04 - accuracy: 0.9985 - val_loss: 4.7207e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 872us/step - loss: 5.2876e-04 - accuracy: 0.9767 - val_loss: 3.4752e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 879us/step - loss: 3.8050e-04 - accuracy: 0.9966 - val_loss: 7.9668e-04 - val_accuracy: 0.9828\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 5.5274e-04 - accuracy: 0.9820 - val_loss: 3.8730e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 762us/step - loss: 4.1655e-04 - accuracy: 0.9731 - val_loss: 5.3236e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 829us/step - loss: 3.6963e-04 - accuracy: 0.9706 - val_loss: 3.7242e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 4.5468e-04 - accuracy: 0.9948 - val_loss: 4.1450e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 3.8719e-04 - accuracy: 0.9954 - val_loss: 4.6552e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 809us/step - loss: 3.1397e-04 - accuracy: 0.9969 - val_loss: 4.1457e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 851us/step - loss: 3.7144e-04 - accuracy: 0.9948 - val_loss: 4.1935e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 3.7505e-04 - accuracy: 0.9970 - val_loss: 7.4660e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 829us/step - loss: 3.9936e-04 - accuracy: 0.9885 - val_loss: 3.8762e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 815us/step - loss: 3.7756e-04 - accuracy: 0.9948 - val_loss: 4.5845e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 836us/step - loss: 5.7108e-04 - accuracy: 0.9795 - val_loss: 4.0486e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 882us/step - loss: 3.4575e-04 - accuracy: 0.9973 - val_loss: 5.2696e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 5.4949e-04 - accuracy: 0.9881 - val_loss: 4.4953e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 820us/step - loss: 4.2100e-04 - accuracy: 0.9917 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 685us/step - loss: 6.7098e-04 - accuracy: 0.9622 - val_loss: 6.7002e-04 - val_accuracy: 0.9828\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 4.3820e-04 - accuracy: 0.9981 - val_loss: 6.4670e-04 - val_accuracy: 0.9828\n",
            "6/6 [==============================] - 0s 378us/step - loss: 6.4670e-04 - accuracy: 0.9828\n",
            "Loss = 0.0006466967752203345, Accuracy = 0.982758641242981\n",
            "Loss array:  [0.0005183520261198282, 0.0008110131020657718, 0.0007127364515326917, 0.0006991206319071352, 0.0006490395753644407, 0.00046510298852808774, 0.0008244721684604883, 0.0010358222061768174, 0.0006466967752203345]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 10/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.6625 - val_loss: 0.0256 - val_accuracy: 0.8793\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 814us/step - loss: 0.0214 - accuracy: 0.8351 - val_loss: 0.0159 - val_accuracy: 0.8966\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0149 - accuracy: 0.8762 - val_loss: 0.0114 - val_accuracy: 0.9483\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 0.0101 - accuracy: 0.9414 - val_loss: 0.0070 - val_accuracy: 0.9310\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 0.9287 - val_loss: 0.0042 - val_accuracy: 0.9483\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 735us/step - loss: 0.0054 - accuracy: 0.9209 - val_loss: 0.0039 - val_accuracy: 0.9310\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 952us/step - loss: 0.0037 - accuracy: 0.9333 - val_loss: 0.0036 - val_accuracy: 0.9310\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.0033 - accuracy: 0.9435 - val_loss: 0.0032 - val_accuracy: 0.9483\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 0.0029 - accuracy: 0.9170 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 0.0026 - accuracy: 0.9580 - val_loss: 0.0030 - val_accuracy: 0.9483\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 750us/step - loss: 0.0033 - accuracy: 0.9185 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 780us/step - loss: 0.0024 - accuracy: 0.9264 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0033 - accuracy: 0.9498 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.0021 - accuracy: 0.9320 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0021 - accuracy: 0.9672 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0017 - accuracy: 0.9571 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 0.0024 - accuracy: 0.9347 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 0.0017 - accuracy: 0.9325 - val_loss: 0.0024 - val_accuracy: 0.9828\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.0019 - accuracy: 0.9554 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0017 - accuracy: 0.9473 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0015 - accuracy: 0.9654 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0016 - accuracy: 0.9513 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9644 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 938us/step - loss: 0.0018 - accuracy: 0.9593 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9472 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 809us/step - loss: 0.0014 - accuracy: 0.9612 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 834us/step - loss: 0.0011 - accuracy: 0.9770 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0014 - accuracy: 0.9525 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 9.8077e-04 - accuracy: 0.9765 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 0.0014 - accuracy: 0.9541 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 835us/step - loss: 0.0012 - accuracy: 0.9511 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 811us/step - loss: 0.0011 - accuracy: 0.9737 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 939us/step - loss: 0.0011 - accuracy: 0.9825 - val_loss: 9.6263e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 0.0010 - accuracy: 0.9778 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 8.6626e-04 - accuracy: 0.9816 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 0.0011 - accuracy: 0.9762 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 682us/step - loss: 8.7201e-04 - accuracy: 0.9766 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 9.6912e-04 - accuracy: 0.9855 - val_loss: 0.0015 - val_accuracy: 0.8966\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 0.0011 - accuracy: 0.9680 - val_loss: 9.1696e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 852us/step - loss: 7.5350e-04 - accuracy: 0.9767 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 779us/step - loss: 8.4035e-04 - accuracy: 0.9789 - val_loss: 9.3450e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 7.1855e-04 - accuracy: 0.9748 - val_loss: 9.9102e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.9157e-04 - accuracy: 0.9804 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9790 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 909us/step - loss: 8.0757e-04 - accuracy: 0.9786 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 983us/step - loss: 9.6362e-04 - accuracy: 0.9668 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 760us/step - loss: 0.0011 - accuracy: 0.9737 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 821us/step - loss: 0.0011 - accuracy: 0.9783 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 810us/step - loss: 7.6564e-04 - accuracy: 0.9743 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 896us/step - loss: 6.4093e-04 - accuracy: 0.9879 - val_loss: 8.9726e-04 - val_accuracy: 0.9828\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 765us/step - loss: 7.9250e-04 - accuracy: 0.9845 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 7.3404e-04 - accuracy: 0.9687 - val_loss: 9.4815e-04 - val_accuracy: 0.9828\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 816us/step - loss: 7.2540e-04 - accuracy: 0.9937 - val_loss: 9.2149e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 862us/step - loss: 8.2029e-04 - accuracy: 0.9886 - val_loss: 8.9744e-04 - val_accuracy: 0.9828\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 839us/step - loss: 6.6071e-04 - accuracy: 0.9693 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 887us/step - loss: 7.2774e-04 - accuracy: 0.9813 - val_loss: 9.0825e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 867us/step - loss: 6.7236e-04 - accuracy: 0.9897 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 7.0266e-04 - accuracy: 0.9813 - val_loss: 8.4606e-04 - val_accuracy: 1.0000\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 7.4463e-04 - accuracy: 0.9874 - val_loss: 8.8505e-04 - val_accuracy: 0.9655\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 812us/step - loss: 9.7994e-04 - accuracy: 0.9836 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 892us/step - loss: 9.6315e-04 - accuracy: 0.9854 - val_loss: 9.1227e-04 - val_accuracy: 0.9828\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6192e-04 - accuracy: 0.9712 - val_loss: 6.9848e-04 - val_accuracy: 0.9828\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 824us/step - loss: 6.1280e-04 - accuracy: 0.9874 - val_loss: 7.2989e-04 - val_accuracy: 0.9828\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1331e-04 - accuracy: 0.9890 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 873us/step - loss: 8.3210e-04 - accuracy: 0.9740 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 858us/step - loss: 8.0255e-04 - accuracy: 0.9829 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 0.0011 - accuracy: 0.9715 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 710us/step - loss: 0.0012 - accuracy: 0.9772 - val_loss: 9.1609e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 819us/step - loss: 6.0462e-04 - accuracy: 0.9882 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 662us/step - loss: 6.1613e-04 - accuracy: 0.9828 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 6.4192e-04 - accuracy: 0.9781 - val_loss: 9.6537e-04 - val_accuracy: 0.9828\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 810us/step - loss: 6.6440e-04 - accuracy: 0.9773 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 5.6963e-04 - accuracy: 0.9932 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 808us/step - loss: 8.7768e-04 - accuracy: 0.9818 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 862us/step - loss: 7.8012e-04 - accuracy: 0.9551 - val_loss: 8.3869e-04 - val_accuracy: 1.0000\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 785us/step - loss: 6.3681e-04 - accuracy: 0.9846 - val_loss: 7.0508e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 5.3765e-04 - accuracy: 0.9831 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 6.3032e-04 - accuracy: 0.9924 - val_loss: 8.1486e-04 - val_accuracy: 1.0000\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 673us/step - loss: 5.9676e-04 - accuracy: 0.9861 - val_loss: 6.7712e-04 - val_accuracy: 0.9828\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 879us/step - loss: 7.3833e-04 - accuracy: 0.9699 - val_loss: 9.4699e-04 - val_accuracy: 0.9483\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 723us/step - loss: 8.8672e-04 - accuracy: 0.9806 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 8.2681e-04 - accuracy: 0.9686 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 7.4435e-04 - accuracy: 0.9937 - val_loss: 7.7391e-04 - val_accuracy: 0.9655\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 5.1990e-04 - accuracy: 0.9902 - val_loss: 7.5766e-04 - val_accuracy: 0.9828\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 855us/step - loss: 6.0746e-04 - accuracy: 0.9830 - val_loss: 7.9630e-04 - val_accuracy: 1.0000\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 667us/step - loss: 6.9280e-04 - accuracy: 0.9818 - val_loss: 6.6432e-04 - val_accuracy: 1.0000\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 5.8010e-04 - accuracy: 0.9817 - val_loss: 7.3453e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4853e-04 - accuracy: 0.9805 - val_loss: 6.9150e-04 - val_accuracy: 0.9828\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 945us/step - loss: 6.4224e-04 - accuracy: 0.9838 - val_loss: 9.2655e-04 - val_accuracy: 0.9483\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 944us/step - loss: 5.6907e-04 - accuracy: 0.9834 - val_loss: 7.3143e-04 - val_accuracy: 0.9655\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 5.5036e-04 - accuracy: 0.9888 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 853us/step - loss: 7.1500e-04 - accuracy: 0.9842 - val_loss: 7.8912e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 799us/step - loss: 4.8615e-04 - accuracy: 0.9898 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 6.4541e-04 - accuracy: 0.9816 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 850us/step - loss: 5.9023e-04 - accuracy: 0.9773 - val_loss: 6.4639e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 3.8313e-04 - accuracy: 0.9838 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 9.7252e-04 - accuracy: 0.9826 - val_loss: 7.3057e-04 - val_accuracy: 0.9828\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 815us/step - loss: 6.7793e-04 - accuracy: 0.9672 - val_loss: 8.1857e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 906us/step - loss: 5.2368e-04 - accuracy: 0.9828 - val_loss: 7.7142e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 6.2188e-04 - accuracy: 0.9817 - val_loss: 7.2007e-04 - val_accuracy: 0.9828\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 821us/step - loss: 6.2064e-04 - accuracy: 0.9862 - val_loss: 9.7349e-04 - val_accuracy: 0.9310\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 818us/step - loss: 6.8095e-04 - accuracy: 0.9831 - val_loss: 7.5694e-04 - val_accuracy: 1.0000\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 885us/step - loss: 6.2750e-04 - accuracy: 0.9851 - val_loss: 7.1147e-04 - val_accuracy: 0.9828\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 826us/step - loss: 5.1435e-04 - accuracy: 0.9789 - val_loss: 7.2744e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 795us/step - loss: 6.0219e-04 - accuracy: 0.9936 - val_loss: 7.7568e-04 - val_accuracy: 0.9483\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9561e-04 - accuracy: 0.9895 - val_loss: 7.3323e-04 - val_accuracy: 0.9828\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 957us/step - loss: 6.1766e-04 - accuracy: 0.9787 - val_loss: 7.4388e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 833us/step - loss: 5.8860e-04 - accuracy: 0.9908 - val_loss: 6.6096e-04 - val_accuracy: 0.9828\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 4.7047e-04 - accuracy: 0.9892 - val_loss: 6.3634e-04 - val_accuracy: 0.9828\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 714us/step - loss: 6.1621e-04 - accuracy: 0.9881 - val_loss: 9.2577e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 5.8284e-04 - accuracy: 0.9943 - val_loss: 7.5159e-04 - val_accuracy: 0.9655\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 776us/step - loss: 5.4600e-04 - accuracy: 0.9858 - val_loss: 9.8149e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 723us/step - loss: 9.5551e-04 - accuracy: 0.9771 - val_loss: 7.9441e-04 - val_accuracy: 0.9310\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 7.9687e-04 - accuracy: 0.9736 - val_loss: 9.1107e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 5.2862e-04 - accuracy: 0.9744 - val_loss: 6.1948e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 802us/step - loss: 4.6998e-04 - accuracy: 0.9878 - val_loss: 6.3418e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 5.5227e-04 - accuracy: 0.9826 - val_loss: 8.1086e-04 - val_accuracy: 0.9483\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 754us/step - loss: 5.8776e-04 - accuracy: 0.9866 - val_loss: 7.5303e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 4.7820e-04 - accuracy: 0.9903 - val_loss: 7.0179e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 653us/step - loss: 6.8691e-04 - accuracy: 0.9745 - val_loss: 6.0292e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 891us/step - loss: 4.9419e-04 - accuracy: 0.9944 - val_loss: 7.2157e-04 - val_accuracy: 0.9655\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 814us/step - loss: 7.2651e-04 - accuracy: 0.9817 - val_loss: 8.2427e-04 - val_accuracy: 0.9828\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 792us/step - loss: 4.6456e-04 - accuracy: 0.9942 - val_loss: 6.8096e-04 - val_accuracy: 0.9828\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8778e-04 - accuracy: 0.9827 - val_loss: 6.2319e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 976us/step - loss: 4.8715e-04 - accuracy: 0.9889 - val_loss: 6.9599e-04 - val_accuracy: 0.9483\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 961us/step - loss: 4.3458e-04 - accuracy: 0.9945 - val_loss: 7.5281e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 950us/step - loss: 4.2078e-04 - accuracy: 0.9894 - val_loss: 6.4673e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 945us/step - loss: 4.1558e-04 - accuracy: 0.9855 - val_loss: 6.4116e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 861us/step - loss: 4.6835e-04 - accuracy: 0.9927 - val_loss: 5.3883e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 839us/step - loss: 3.7815e-04 - accuracy: 0.9934 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 5.5175e-04 - accuracy: 0.9853 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 780us/step - loss: 5.3169e-04 - accuracy: 0.9763 - val_loss: 8.3825e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 906us/step - loss: 5.1210e-04 - accuracy: 0.9843 - val_loss: 6.1183e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 4.3745e-04 - accuracy: 0.9967 - val_loss: 6.5445e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 813us/step - loss: 4.8719e-04 - accuracy: 0.9950 - val_loss: 6.3572e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 811us/step - loss: 4.4239e-04 - accuracy: 0.9923 - val_loss: 7.2934e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 864us/step - loss: 4.9803e-04 - accuracy: 0.9926 - val_loss: 5.8164e-04 - val_accuracy: 0.9828\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 3.7134e-04 - accuracy: 0.9797 - val_loss: 7.0901e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 6.5671e-04 - accuracy: 0.9670 - val_loss: 6.2012e-04 - val_accuracy: 0.9828\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 5.8133e-04 - accuracy: 0.9925 - val_loss: 6.2159e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 793us/step - loss: 8.3697e-04 - accuracy: 0.9891 - val_loss: 8.0540e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 4.0572e-04 - accuracy: 0.9857 - val_loss: 7.0907e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 4.0225e-04 - accuracy: 0.9964 - val_loss: 6.0372e-04 - val_accuracy: 0.9828\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 800us/step - loss: 4.1495e-04 - accuracy: 0.9880 - val_loss: 6.4094e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 709us/step - loss: 4.2276e-04 - accuracy: 0.9969 - val_loss: 5.5642e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 866us/step - loss: 3.4744e-04 - accuracy: 0.9964 - val_loss: 5.4996e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 3.4616e-04 - accuracy: 0.9906 - val_loss: 5.7834e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 3.5156e-04 - accuracy: 0.9946 - val_loss: 8.4071e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.1833e-04 - accuracy: 0.9837 - val_loss: 6.6089e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8822e-04 - accuracy: 0.9977 - val_loss: 5.7113e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1012e-04 - accuracy: 0.9925 - val_loss: 6.2825e-04 - val_accuracy: 0.9655\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 970us/step - loss: 4.7635e-04 - accuracy: 0.9906 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 859us/step - loss: 7.7949e-04 - accuracy: 0.9855 - val_loss: 7.1030e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 4.6397e-04 - accuracy: 0.9840 - val_loss: 5.3701e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 710us/step - loss: 4.3312e-04 - accuracy: 0.9778 - val_loss: 6.4998e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 800us/step - loss: 5.0232e-04 - accuracy: 0.9879 - val_loss: 6.3656e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 644us/step - loss: 3.4882e-04 - accuracy: 0.9941 - val_loss: 6.9572e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 834us/step - loss: 7.1542e-04 - accuracy: 0.9816 - val_loss: 6.2389e-04 - val_accuracy: 0.9655\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 705us/step - loss: 4.0639e-04 - accuracy: 0.9928 - val_loss: 7.7144e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 799us/step - loss: 5.8092e-04 - accuracy: 0.9932 - val_loss: 6.2235e-04 - val_accuracy: 0.9828\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 692us/step - loss: 5.9925e-04 - accuracy: 0.9764 - val_loss: 9.1513e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 6.7750e-04 - accuracy: 0.9740 - val_loss: 5.3180e-04 - val_accuracy: 0.9655\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 711us/step - loss: 4.2850e-04 - accuracy: 0.9903 - val_loss: 7.6178e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 783us/step - loss: 5.2832e-04 - accuracy: 0.9938 - val_loss: 5.3310e-04 - val_accuracy: 0.9828\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 2.7763e-04 - accuracy: 0.9963 - val_loss: 5.1953e-04 - val_accuracy: 0.9828\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 3.6340e-04 - accuracy: 0.9955 - val_loss: 6.7308e-04 - val_accuracy: 0.9828\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4675e-04 - accuracy: 0.9814 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 927us/step - loss: 4.7508e-04 - accuracy: 0.9790 - val_loss: 5.9447e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 981us/step - loss: 4.0788e-04 - accuracy: 0.9834 - val_loss: 5.3037e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 4.8776e-04 - accuracy: 0.9920 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Loss = 0.0010580925736576319, Accuracy = 1.0\n",
            "Loss array:  [0.0005183520261198282, 0.0008110131020657718, 0.0007127364515326917, 0.0006991206319071352, 0.0006490395753644407, 0.00046510298852808774, 0.0008244721684604883, 0.0010358222061768174, 0.0006466967752203345, 0.0010580925736576319]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "NUM_EPOCHS = 170# 180\n",
        "BATCH_SIZE = 8\n",
        "K_FOLD_SPLITS = 10\n",
        "\n",
        "\n",
        "# Define the cross-validation process to be used inside cross_val_Score evaluation\n",
        "cv = KFold(n_splits=K_FOLD_SPLITS)\n",
        "\n",
        "# Handling for accommodating multiple targets\n",
        "Y1 = y_train_norm[:,0]\n",
        "Y2 = y_train_norm[:,1]\n",
        "targets = (Y1, Y2)\n",
        "\n",
        "X = X_train_norm\n",
        "\n",
        "i = 0\n",
        "arr_loss = list()\n",
        "arr_rmse = list()\n",
        "min_loss = 1000000\n",
        "best_model = None\n",
        "history = None\n",
        "history_best_model = None\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_indices, val_indices) in enumerate(cv.split(X_train_norm)):\n",
        "  print('####################### Iteration  ', i, ' #######################')\n",
        "  print(f'Fold {fold+1}/{K_FOLD_SPLITS}')\n",
        "  X_train_fold, y_train_fold = X_train_norm[train_indices], y_train_norm[train_indices]\n",
        "  X_val_fold, y_val_fold = X_train_norm[val_indices], y_train_norm[val_indices]\n",
        "\n",
        "  # Convert the folds into tf.data.Dataset\n",
        "  train_dataset_fold = make_dataset(X_train_fold, y_train_fold, batch_size=batch_size, shuffle=True)\n",
        "  val_dataset_fold = make_dataset(X_val_fold, y_val_fold, batch_size=batch_size)\n",
        "\n",
        "\n",
        "  model = my_model()\n",
        "  history = model.fit(train_dataset_fold, epochs=NUM_EPOCHS, validation_data=val_dataset_fold)\n",
        "\n",
        "  #testing on validation set process\n",
        "  loss, accuracy = model.evaluate(val_dataset_fold, verbose=1)\n",
        "  print(f\"Loss = {loss}, Accuracy = {accuracy}\")\n",
        "\n",
        "  # Check if this is the best model based on validation loss\n",
        "  if loss < min_loss:\n",
        "      best_model = model\n",
        "      history_best_model = history.history\n",
        "      min_loss = loss\n",
        "\n",
        "  # Append the current fold's loss and accuracy to the tracking lists\n",
        "  arr_loss.append(loss)\n",
        "  arr_rmse.append(accuracy)  # Assuming you want to track accuracy; change if needed\n",
        "  print('Loss array: ', arr_loss)\n",
        "\n",
        "# Saving the best model within the k folds\n",
        "best_model.save(FILENAME_BEST_MODEL)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results\n",
        "- Plot of k-cross validation performance\n",
        "- Scatter Plot of prediction results against true values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "xKSkPnO4ETWD",
        "outputId": "564ee694-d414-4d21-bbd9-f838e7249dd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loss across k folds\n",
        "plot_line(arr_loss, \"Loss across k-folds\", \"Value of k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training and Validation Loss\n",
        "#plot_loss_curve(history_best_model, NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the test dataset\n",
        "X_test_norm = scaler_input.transform(X_test)\n",
        "y_test_norm = scaler_output.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-erJ0l_Yu4P",
        "outputId": "9cff94b2-e4ca-491b-8459-aeaa1eff7606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time: 0.0232 seconds\n",
            "Maxval here is:  24.846647\n",
            "Maxval here is:  0.9278\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "Y_pred_normalized = best_model.predict(X_test_norm)\n",
        "end_time = time.time()\n",
        "Y_pred_normalized_entire = best_model.predict(dataset_x_norm)\n",
        "# Calculate elapsed time in seconds\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Elapsed time:\", round(elapsed_time, 3), \"seconds\")\n",
        "\n",
        "\n",
        "Y_pred = scaler_output.inverse_transform(Y_pred_normalized)\n",
        "Y_pred_entire = scaler_output.inverse_transform(Y_pred_normalized_entire)\n",
        "Y_actual = np.array(y_test)\n",
        "Y_actual_entire = np.array(df_targets)\n",
        "# Moisture Content\n",
        "scatter_plot(trueValues=Y_actual[:,0], \n",
        "             predictions=Y_pred[:,0], \n",
        "             title=\"Moisture Content\")\n",
        "a, b = np.polyfit(Y_pred[:, 0], Y_actual[:, 0], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,0]), max(Y_actual[:,0])), 1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_MC.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)\n",
        "\n",
        "# Bulk Density\n",
        "scatter_plot(trueValues=Y_actual[:,1], \n",
        "             predictions=Y_pred[:,1], \n",
        "             title=\"Bulk Density\")\n",
        "plt.xlim([min(min(Y_pred[:,1]), min(Y_actual[:,1]))-0.1, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1])\n",
        "a, b = np.polyfit(Y_pred[:, 1], Y_actual[:, 1], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1, 0.1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_BD.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Error analysis\n",
        "- R squared calculation\n",
        "- Mean accuracy error"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### R squared calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9958\n",
            "0.9283\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# MOISTURE CONTENT\n",
        "#   - R-squared\n",
        "# mc_r2_score = r2_score(Y_actual[:, 0], Y_pred[:, 0])\n",
        "mc_r2_score = calculate_r_squared(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"{:#.4g}\".format(mc_r2_score))\n",
        "\n",
        "# BULK DENSITY\n",
        "#   - R-squared\n",
        "# bd_r2_score = r2_score(Y_actual[:, 1], Y_pred[:, 1])\n",
        "bd_r2_score = calculate_r_squared(y_true=Y_actual[:, 1], y_pred=Y_pred[:, 1])\n",
        "print(\"{:#.4g}\".format(bd_r2_score))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE_MC:  0.2362\n",
            "RMSE_BD:  0.02831\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sigfig import round\n",
        "\n",
        "#MC\n",
        "rmse_mc = np.sqrt(mean_squared_error(Y_actual[:, 0], Y_pred[:, 0]))\n",
        "print('RMSE_MC: ', \"{0:.4g}\".format(rmse_mc))\n",
        "\n",
        "#BD\n",
        "rmse_bd = np.sqrt(mean_squared_error(Y_actual[:, 1], Y_pred[:, 1]))\n",
        "print('RMSE_BD: ', \"{0:.4g}\".format(rmse_bd))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will compare with the results from Trabelsi's paper. This is single moisture prediction \n",
        "\n",
        "R^2 : 0.993\\\n",
        "Mean Squared Error: 0.028\\\n",
        "Mean absolute Error: 0.135\\\n",
        "Min. Absolute Error: 0.004\\\n",
        "Max Absolute Error: 0.441"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9957\n",
            "Mean Squared Error:  0.05579\n",
            "Mean Absolute Error:  0.1729\n",
            "Min Absolute Error:  0.0014754486083994323\n",
            "Max Absolute Error:  0.7224675750732423\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,max_error, r2_score\n",
        "from sigfig import round\n",
        "\n",
        "mc_r2_score = r2_score(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual[:, 0], Y_pred[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual[:, 0], Y_pred[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual[:,0])):\n",
        "    sum = Y_actual[:,0][i] - Y_pred[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9968\n",
            "Mean Squared Error:  0.0455\n",
            "Mean Absolute Error:  0.1598\n",
            "Min Absolute Error:  0.000593948364258523\n",
            "Max Absolute Error:  0.8726056289672854\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "mc_r2_score = r2_score(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual_entire[:,0])):\n",
        "    sum = Y_actual_entire[:,0][i] - Y_pred_entire[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
