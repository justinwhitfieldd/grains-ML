{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "#GRAIN_TYPE = 'Wheat'\n",
        "#GRAIN_TYPE = 'newWheatData'\n",
        "#GRAIN_TYPE = 'CornAdded_Type'\n",
        "GRAIN_TYPE = 'cleaned_data'\n",
        "# GRAIN_TYPE = 'Oats'\n",
        "\n",
        "# GRAIN_TYPE = 'Barley'\n",
        "# GRAIN_TYPE = 'Sorghum'\n",
        "# GRAIN_TYPE = 'Soybeans'\n",
        "# GRAIN_TYPE = 'Corn'\n",
        "\n",
        "FILENAME_BEST_MODEL = 'Best models/target_2/hybrid_models/' + GRAIN_TYPE + '_t2_kcv_dnn_mc.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNGoIGbc0kw_",
        "outputId": "279cc9c8-32fd-4f89-e56b-83a0a31081dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ]
        }
      ],
      "source": [
        "#Import libraries\n",
        "import requests\n",
        "import pydot\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Data visualization\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "#Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Machine Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Activation, BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "np.random.seed(39)\n",
        "random.seed(39)\n",
        "tf.random.set_seed(39)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "# print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nxHO_qH0Zi5J"
      },
      "outputs": [],
      "source": [
        "def calculate_r_squared(y_true, y_pred):\n",
        "   corr_matrix = np.corrcoef(y_true, y_pred)\n",
        "   corr = corr_matrix[0,1]\n",
        "   R_sq = corr**2\n",
        "   return R_sq\n",
        "\n",
        "def plot_loss_curve(history, epoch_size):\n",
        "    loss_train = history.history['loss']\n",
        "    loss_val = history.history['val_loss']\n",
        "    epochs = range(0,epoch_size)\n",
        "    \n",
        "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "    \n",
        "    plt.title('Training and Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_line(metric, title, xlabel):\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.title(title, fontsize = 16)\n",
        "    plt.plot(metric)\n",
        "    plt.xlabel(xlabel, fontsize = 14)\n",
        "    plt.grid()\n",
        "    plt.legend(loc= \"best\")\n",
        "    plt.show()\n",
        "\n",
        "def scatter_plot(trueValues, predictions, title):\n",
        "  plt.figure(figsize=(8,3))\n",
        "  ax = plt.axes()\n",
        "  maxVal = max( max(trueValues), max(predictions) )\n",
        "\n",
        "  ax.scatter(x=predictions, y=trueValues)\n",
        "  ax.plot([0, 1, maxVal], [0, 1, maxVal], label=\"Ideal fit\")\n",
        "  print('Maxval here is: ', maxVal)\n",
        "  plt.title(title, fontsize = 16)\n",
        "  plt.xlabel(\"Predictions\", fontsize = 14)\n",
        "  plt.ylabel(\"Real\", fontsize = 14)\n",
        "  plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "s3pvA5g-zdgv",
        "outputId": "7a7208f1-6b68-4eba-ad1d-9108d0df66ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From USDA:  ../Datasets/processed/cleaned_data.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variety</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>8.8258</td>\n",
              "      <td>-55.973</td>\n",
              "      <td>-415.973</td>\n",
              "      <td>2.416</td>\n",
              "      <td>0.243</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-6.341975</td>\n",
              "      <td>62.3</td>\n",
              "      <td>61.7806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>10.2572</td>\n",
              "      <td>-114.289</td>\n",
              "      <td>-474.289</td>\n",
              "      <td>2.412</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-11.142320</td>\n",
              "      <td>71.2</td>\n",
              "      <td>82.0576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>11.5679</td>\n",
              "      <td>-168.171</td>\n",
              "      <td>-528.171</td>\n",
              "      <td>2.395</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-14.537729</td>\n",
              "      <td>80.1</td>\n",
              "      <td>104.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>12.8795</td>\n",
              "      <td>134.849</td>\n",
              "      <td>-585.151</td>\n",
              "      <td>2.390</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>10.470049</td>\n",
              "      <td>89.0</td>\n",
              "      <td>128.7950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>13.7649</td>\n",
              "      <td>83.502</td>\n",
              "      <td>-636.498</td>\n",
              "      <td>2.371</td>\n",
              "      <td>0.238</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>6.066299</td>\n",
              "      <td>97.9</td>\n",
              "      <td>151.4139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Variety  Freq  d(cm)    M%  Density     Attn    Phase  Phase_Corr  \\\n",
              "0  KANSAS   7.0    8.9  11.3   0.7356   8.8258  -55.973    -415.973   \n",
              "1  KANSAS   8.0    8.9  11.3   0.7356  10.2572 -114.289    -474.289   \n",
              "2  KANSAS   9.0    8.9  11.3   0.7356  11.5679 -168.171    -528.171   \n",
              "3  KANSAS  10.0    8.9  11.3   0.7356  12.8795  134.849    -585.151   \n",
              "4  KANSAS  11.0    8.9  11.3   0.7356  13.7649   83.502    -636.498   \n",
              "\n",
              "   Permittivity_real  Permittivity_imaginary       Type  Phase/Attn  \\\n",
              "0              2.416                   0.243  15.855506   -6.341975   \n",
              "1              2.412                   0.246  15.855506  -11.142320   \n",
              "2              2.395                   0.246  15.855506  -14.537729   \n",
              "3              2.390                   0.246  15.855506   10.470049   \n",
              "4              2.371                   0.238  15.855506    6.066299   \n",
              "\n",
              "   Freq*d(cm)  Freq*Attn  \n",
              "0        62.3    61.7806  \n",
              "1        71.2    82.0576  \n",
              "2        80.1   104.1111  \n",
              "3        89.0   128.7950  \n",
              "4        97.9   151.4139  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#url dataset\n",
        "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
        "\n",
        "#read in excel format\n",
        "df = pd.read_csv(URL)\n",
        "#df = df[df['Variety'] == 'SOUTH DAKOTA']\n",
        "#df = df[(df['Density'] >= 0.72) & (df['Density'] <= 0.88)]\n",
        "\n",
        "print(\"From USDA: \", URL)\n",
        "\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUzjHHV2stm"
      },
      "source": [
        "# 2. Overview of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Xohz7dGh2sXH",
        "outputId": "7d018cd8-018a-45d3-b1b7-ba9fc14aa5e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10.811414</td>\n",
              "      <td>7.088834</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>0.796298</td>\n",
              "      <td>18.410033</td>\n",
              "      <td>-4.604663</td>\n",
              "      <td>-633.488065</td>\n",
              "      <td>2.912112</td>\n",
              "      <td>0.499187</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>-0.377074</td>\n",
              "      <td>77.159677</td>\n",
              "      <td>215.799030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.530055</td>\n",
              "      <td>1.554604</td>\n",
              "      <td>3.794772</td>\n",
              "      <td>0.067384</td>\n",
              "      <td>5.946835</td>\n",
              "      <td>101.951444</td>\n",
              "      <td>219.510760</td>\n",
              "      <td>0.305758</td>\n",
              "      <td>0.186739</td>\n",
              "      <td>0.629743</td>\n",
              "      <td>6.071761</td>\n",
              "      <td>32.552200</td>\n",
              "      <td>124.108325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>10.260000</td>\n",
              "      <td>0.625400</td>\n",
              "      <td>8.002300</td>\n",
              "      <td>-179.335000</td>\n",
              "      <td>-1274.435000</td>\n",
              "      <td>2.340000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>15.352809</td>\n",
              "      <td>-17.418676</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>40.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>13.680000</td>\n",
              "      <td>0.745400</td>\n",
              "      <td>13.524700</td>\n",
              "      <td>-88.842000</td>\n",
              "      <td>-793.405750</td>\n",
              "      <td>2.688500</td>\n",
              "      <td>0.337000</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-5.077754</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>107.817375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>16.225000</td>\n",
              "      <td>0.801300</td>\n",
              "      <td>18.131600</td>\n",
              "      <td>-9.838500</td>\n",
              "      <td>-602.380500</td>\n",
              "      <td>2.861500</td>\n",
              "      <td>0.470500</td>\n",
              "      <td>16.400366</td>\n",
              "      <td>-0.589378</td>\n",
              "      <td>71.200000</td>\n",
              "      <td>195.600450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>18.810000</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>23.098000</td>\n",
              "      <td>80.957250</td>\n",
              "      <td>-456.055750</td>\n",
              "      <td>3.109750</td>\n",
              "      <td>0.639000</td>\n",
              "      <td>16.401988</td>\n",
              "      <td>4.300734</td>\n",
              "      <td>100.100000</td>\n",
              "      <td>310.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>24.410000</td>\n",
              "      <td>0.927800</td>\n",
              "      <td>29.897000</td>\n",
              "      <td>179.048000</td>\n",
              "      <td>-235.044000</td>\n",
              "      <td>4.038000</td>\n",
              "      <td>0.987000</td>\n",
              "      <td>17.344167</td>\n",
              "      <td>14.827701</td>\n",
              "      <td>160.200000</td>\n",
              "      <td>538.146000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Freq       d(cm)          M%     Density        Attn       Phase  \\\n",
              "count  806.000000  806.000000  806.000000  806.000000  806.000000  806.000000   \n",
              "mean    10.811414    7.088834   16.189541    0.796298   18.410033   -4.604663   \n",
              "std      3.530055    1.554604    3.794772    0.067384    5.946835  101.951444   \n",
              "min      5.000000    4.400000   10.260000    0.625400    8.002300 -179.335000   \n",
              "25%      8.000000    6.500000   13.680000    0.745400   13.524700  -88.842000   \n",
              "50%     11.000000    7.700000   16.225000    0.801300   18.131600   -9.838500   \n",
              "75%     13.000000    7.700000   18.810000    0.842000   23.098000   80.957250   \n",
              "max     18.000000    8.900000   24.410000    0.927800   29.897000  179.048000   \n",
              "\n",
              "        Phase_Corr  Permittivity_real  Permittivity_imaginary        Type  \\\n",
              "count   806.000000         806.000000              806.000000  806.000000   \n",
              "mean   -633.488065           2.912112                0.499187   16.189541   \n",
              "std     219.510760           0.305758                0.186739    0.629743   \n",
              "min   -1274.435000           2.340000                0.220000   15.352809   \n",
              "25%    -793.405750           2.688500                0.337000   15.855506   \n",
              "50%    -602.380500           2.861500                0.470500   16.400366   \n",
              "75%    -456.055750           3.109750                0.639000   16.401988   \n",
              "max    -235.044000           4.038000                0.987000   17.344167   \n",
              "\n",
              "       Phase/Attn  Freq*d(cm)   Freq*Attn  \n",
              "count  806.000000  806.000000  806.000000  \n",
              "mean    -0.377074   77.159677  215.799030  \n",
              "std      6.071761   32.552200  124.108325  \n",
              "min    -17.418676   22.000000   40.011500  \n",
              "25%     -5.077754   52.800000  107.817375  \n",
              "50%     -0.589378   71.200000  195.600450  \n",
              "75%      4.300734  100.100000  310.863000  \n",
              "max     14.827701  160.200000  538.146000  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data summary\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmFqsYQyGnM",
        "outputId": "54445a7f-a2c8-452a-9651-42dbbe682d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(806, 14)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimension of the dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fep-GIv4yUuf",
        "outputId": "c46072fa-aa7f-4549-9a1d-4c5b05d11112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Variety                   0\n",
              "Freq                      0\n",
              "d(cm)                     0\n",
              "M%                        0\n",
              "Density                   0\n",
              "Attn                      0\n",
              "Phase                     0\n",
              "Phase_Corr                0\n",
              "Permittivity_real         0\n",
              "Permittivity_imaginary    0\n",
              "Type                      0\n",
              "Phase/Attn                0\n",
              "Freq*d(cm)                0\n",
              "Freq*Attn                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check info about missing values in dataframe\n",
        "df.isnull().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_TKP9VymuK"
      },
      "source": [
        "# Exploratory Data Analysis\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz1g9T3FzhF0"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "\n",
        "1.   Convert dataframe to numpy array for flexibility.\n",
        "2. Split our data into training and testing datasets and store the target values in different variables.\n",
        "3.   Normalize the features by applying some operations in the data sets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "T0juhagf1M2I"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy array\n",
        "df_features = df[['Freq', \n",
        "                    'd(cm)', \n",
        "                   # 'Attn', \n",
        "                    'Phase_Corr', \n",
        "                    'Permittivity_real', \n",
        "                    'Permittivity_imaginary',\n",
        "                    'Type',\n",
        "                    ]]\n",
        "\n",
        "df_targets = df[['M%', 'Density']]\n",
        "# df_targets = df[['Density', 'M%']]\n",
        "\n",
        "dataset_x = df_features.to_numpy()\n",
        "dataset_y = df_targets.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting dataset to test and train+validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform train-test split on RAW DATA\n",
        "X_trainVal, X_test, y_trainVal, y_test = train_test_split(dataset_x, dataset_y, \n",
        "                                                    test_size=0.15\n",
        "                                                    ,random_state=42\n",
        "                                                    )\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainVal, y_trainVal, \n",
        "                                                    test_size=0.15 #validation split\n",
        "                                                    ,random_state=42\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Normalizing the data set\n",
        "scaler_input = MinMaxScaler()\n",
        "scaler_output = MinMaxScaler()\n",
        "\n",
        "# Normalize Train set\n",
        "X_train_norm = scaler_input.fit_transform(X_train)\n",
        "y_train_norm = scaler_output.fit_transform(y_train)\n",
        "\n",
        "# Normalize Validation set\n",
        "X_val_norm = scaler_input.fit_transform(X_val)\n",
        "y_val_norm = scaler_output.fit_transform(y_val)\n",
        "\n",
        "# Normalize the entire dataset (input features)\n",
        "dataset_x_norm = scaler_input.transform(dataset_x)  # Use transform, NOT fit_transform\n",
        "\n",
        "# Normalize the entire dataset (output targets)\n",
        "dataset_y_norm = scaler_output.transform(dataset_y)  # Use transform, NOT fit_transform\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKfjwMP0Tzn"
      },
      "source": [
        "# K-cross Validation\n",
        "* Input features: 7\n",
        "* Output targets: 2\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "l31WJZ7Z0ONb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_52 (Dense)             (None, 89)                623       \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 89)                8010      \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 89)                8010      \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 2)                 180       \n",
            "=================================================================\n",
            "Total params: 16,823\n",
            "Trainable params: 16,823\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import layers, Sequential, regularizers\n",
        "\n",
        "# Define the model-building function\n",
        "def my_model():\n",
        "  my_model = Sequential([\n",
        "    \n",
        "    layers.Dense(89, input_shape=(6,), activation='relu',),\n",
        "    layers.Dense(89, activation='relu', ),\n",
        "    layers.Dense(89, activation='relu',),\n",
        "    layers.Dense(2, activation='linear')  # Output layer with 2 neurons for the two regression targets\n",
        "  ])\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.00091) # 0.0006 \n",
        "  my_model.compile(\n",
        "      optimizer = opt,\n",
        "      loss = 'mse',\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "\n",
        "  return my_model\n",
        "\n",
        "plot_model(my_model(), show_shapes=True, show_layer_names=True)\n",
        "my_model().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_dataset(features, labels, batch_size, shuffle=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(features))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# Create TensorFlow datasets for training and validation\n",
        "batch_size = 10 \n",
        "train_dataset = make_dataset(X_train_norm, y_train_norm, batch_size, shuffle=True)\n",
        "val_dataset = make_dataset(X_val_norm, y_val_norm, batch_size)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running model with KCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khCKKB74hFVT",
        "outputId": "37e79cdf-4183-4559-f560-fceb2fc0c630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "####################### Iteration   0  #######################\n",
            "Fold 1/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.7223 - val_loss: 0.0186 - val_accuracy: 0.8644\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.8437 - val_loss: 0.0171 - val_accuracy: 0.8814\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.8932 - val_loss: 0.0078 - val_accuracy: 0.9492\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9428 - val_loss: 0.0077 - val_accuracy: 0.9153\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9228 - val_loss: 0.0049 - val_accuracy: 0.9492\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9072 - val_loss: 0.0048 - val_accuracy: 0.9322\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9088 - val_loss: 0.0047 - val_accuracy: 0.9153\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9313 - val_loss: 0.0040 - val_accuracy: 0.9153\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9190 - val_loss: 0.0044 - val_accuracy: 0.9153\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9449 - val_loss: 0.0037 - val_accuracy: 0.9322\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9577 - val_loss: 0.0038 - val_accuracy: 0.8983\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9342 - val_loss: 0.0029 - val_accuracy: 0.9322\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9381 - val_loss: 0.0022 - val_accuracy: 0.9492\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9481 - val_loss: 0.0032 - val_accuracy: 0.9492\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9498 - val_loss: 0.0025 - val_accuracy: 0.9492\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9489 - val_loss: 0.0019 - val_accuracy: 0.9492\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9377 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9493 - val_loss: 0.0019 - val_accuracy: 0.9492\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9388 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9401 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9588 - val_loss: 0.0024 - val_accuracy: 0.9322\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9444 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9462 - val_loss: 0.0027 - val_accuracy: 0.9322\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9571 - val_loss: 0.0030 - val_accuracy: 0.9322\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9631 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.9588 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9752 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9639 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9861 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9671 - val_loss: 0.0023 - val_accuracy: 0.9322\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9491 - val_loss: 0.0020 - val_accuracy: 0.9492\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9667 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9594 - val_loss: 8.9956e-04 - val_accuracy: 0.9492\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.4181e-04 - accuracy: 0.9484 - val_loss: 0.0036 - val_accuracy: 0.8814\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9499 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9755 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9597 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9402 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 39/170\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.7755e-04 - accuracy: 1.0000"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1297e-04 - accuracy: 0.9761 - val_loss: 7.8899e-04 - val_accuracy: 0.9661\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.0022e-04 - accuracy: 0.9756 - val_loss: 7.1541e-04 - val_accuracy: 0.9831\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.0242e-04 - accuracy: 0.9751 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.9556e-04 - accuracy: 0.9747 - val_loss: 8.0320e-04 - val_accuracy: 0.9661\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9825 - val_loss: 0.0012 - val_accuracy: 0.9153\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.7415e-04 - accuracy: 0.9471 - val_loss: 0.0018 - val_accuracy: 0.9153\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.9021e-04 - accuracy: 0.9538 - val_loss: 7.6656e-04 - val_accuracy: 0.9661\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9691 - val_loss: 7.2994e-04 - val_accuracy: 0.9831\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.6948e-04 - accuracy: 0.9875 - val_loss: 0.0019 - val_accuracy: 0.9322\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9882 - val_loss: 7.3262e-04 - val_accuracy: 0.9831\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2786e-04 - accuracy: 0.9767 - val_loss: 7.3160e-04 - val_accuracy: 0.9661\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.8728e-04 - accuracy: 0.9865 - val_loss: 6.0975e-04 - val_accuracy: 0.9831\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0477e-04 - accuracy: 0.9772 - val_loss: 7.0157e-04 - val_accuracy: 0.9661\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6091e-04 - accuracy: 0.9759 - val_loss: 8.9781e-04 - val_accuracy: 0.9661\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2623e-04 - accuracy: 0.9881 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 8.3599e-04 - accuracy: 0.9826 - val_loss: 5.6701e-04 - val_accuracy: 0.9831\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5028e-04 - accuracy: 0.9894 - val_loss: 0.0011 - val_accuracy: 0.9153\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.9597 - val_loss: 7.0014e-04 - val_accuracy: 0.9661\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.7697e-04 - accuracy: 0.9689 - val_loss: 6.4418e-04 - val_accuracy: 0.9831\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.0654e-04 - accuracy: 0.9883 - val_loss: 5.7175e-04 - val_accuracy: 0.9831\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5729e-04 - accuracy: 0.9833 - val_loss: 8.7012e-04 - val_accuracy: 0.9661\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2696e-04 - accuracy: 0.9916 - val_loss: 8.2588e-04 - val_accuracy: 0.9661\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 6.5515e-04 - accuracy: 0.9894 - val_loss: 9.3894e-04 - val_accuracy: 0.9492\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.6604e-04 - accuracy: 0.9736 - val_loss: 6.0218e-04 - val_accuracy: 0.9661\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1135e-04 - accuracy: 0.9810 - val_loss: 7.3684e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6673e-04 - accuracy: 0.9856 - val_loss: 7.7091e-04 - val_accuracy: 0.9661\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1529e-04 - accuracy: 0.9847 - val_loss: 7.1220e-04 - val_accuracy: 0.9661\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 6.1467e-04 - accuracy: 0.9798 - val_loss: 6.6632e-04 - val_accuracy: 0.9661\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4734e-04 - accuracy: 0.9869 - val_loss: 8.6660e-04 - val_accuracy: 0.9492\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2033e-04 - accuracy: 0.9858 - val_loss: 7.1287e-04 - val_accuracy: 0.9322\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0649e-04 - accuracy: 0.9869 - val_loss: 6.6105e-04 - val_accuracy: 0.9831\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 6.9368e-04 - accuracy: 0.9724 - val_loss: 8.0036e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.3294e-04 - accuracy: 0.9869 - val_loss: 6.9129e-04 - val_accuracy: 0.9831\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.8670e-04 - accuracy: 0.9870 - val_loss: 7.8512e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.8060e-04 - accuracy: 0.9832 - val_loss: 5.6432e-04 - val_accuracy: 0.9661\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4277e-04 - accuracy: 0.9828 - val_loss: 7.0313e-04 - val_accuracy: 0.9492\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 7.4656e-04 - accuracy: 0.9707 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.7366e-04 - accuracy: 0.9730 - val_loss: 8.4392e-04 - val_accuracy: 0.9492\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.8172e-04 - accuracy: 0.9757 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9655 - val_loss: 7.1453e-04 - val_accuracy: 0.9831\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5284e-04 - accuracy: 0.9857 - val_loss: 8.0593e-04 - val_accuracy: 0.9831\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6328e-04 - accuracy: 0.9888 - val_loss: 6.1599e-04 - val_accuracy: 0.9831\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 5.2085e-04 - accuracy: 0.9922 - val_loss: 8.3849e-04 - val_accuracy: 0.9492\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.1086e-04 - accuracy: 0.9805 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2320e-04 - accuracy: 0.9883 - val_loss: 5.7722e-04 - val_accuracy: 0.9831\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.6056e-04 - accuracy: 0.9895 - val_loss: 6.0700e-04 - val_accuracy: 0.9661\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.3696e-04 - accuracy: 0.9870 - val_loss: 6.7461e-04 - val_accuracy: 0.9831\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9488e-04 - accuracy: 0.9724 - val_loss: 7.1684e-04 - val_accuracy: 0.9831\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2647e-04 - accuracy: 0.9964 - val_loss: 0.0033 - val_accuracy: 0.8983\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9680 - val_loss: 5.7199e-04 - val_accuracy: 0.9661\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.8183e-04 - accuracy: 0.9862 - val_loss: 4.5859e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9748e-04 - accuracy: 0.9848 - val_loss: 0.0014 - val_accuracy: 0.8983\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9864 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.9511e-04 - accuracy: 0.9751 - val_loss: 5.8010e-04 - val_accuracy: 0.9831\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5050e-04 - accuracy: 0.9918 - val_loss: 5.1323e-04 - val_accuracy: 0.9492\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4238e-04 - accuracy: 0.9828 - val_loss: 9.1571e-04 - val_accuracy: 0.9492\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0566e-04 - accuracy: 0.9788 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7156e-04 - accuracy: 0.9848 - val_loss: 9.7795e-04 - val_accuracy: 0.9661\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1784e-04 - accuracy: 0.9835 - val_loss: 8.2633e-04 - val_accuracy: 0.9831\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2441e-04 - accuracy: 0.9808 - val_loss: 5.0319e-04 - val_accuracy: 0.9831\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3357e-04 - accuracy: 0.9891 - val_loss: 7.7795e-04 - val_accuracy: 0.9661\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.6849e-04 - accuracy: 0.9836 - val_loss: 6.4549e-04 - val_accuracy: 0.9831\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6426e-04 - accuracy: 0.9847 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4907e-04 - accuracy: 0.9850 - val_loss: 9.7821e-04 - val_accuracy: 0.9322\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 5.8013e-04 - accuracy: 0.9893 - val_loss: 5.1978e-04 - val_accuracy: 0.9831\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6559e-04 - accuracy: 0.9797 - val_loss: 4.7302e-04 - val_accuracy: 0.9831\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.8343e-04 - accuracy: 0.9892 - val_loss: 8.0107e-04 - val_accuracy: 0.9492\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4523e-04 - accuracy: 0.9644 - val_loss: 0.0015 - val_accuracy: 0.9322\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.9742e-04 - accuracy: 0.9807 - val_loss: 4.9250e-04 - val_accuracy: 0.9831\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.1084e-04 - accuracy: 0.9865 - val_loss: 7.6923e-04 - val_accuracy: 0.9492\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.6450e-04 - accuracy: 0.9966 - val_loss: 5.1840e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.3000e-04 - accuracy: 0.9974 - val_loss: 6.9351e-04 - val_accuracy: 0.9831\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2905e-04 - accuracy: 0.9856 - val_loss: 7.2747e-04 - val_accuracy: 0.9661\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 4.3328e-04 - accuracy: 0.9989 - val_loss: 5.8992e-04 - val_accuracy: 0.9492\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 5.4147e-04 - accuracy: 0.9864 - val_loss: 5.9370e-04 - val_accuracy: 0.9831\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.6020e-04 - accuracy: 0.9972 - val_loss: 5.3112e-04 - val_accuracy: 0.9492\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.7344e-04 - accuracy: 0.9916 - val_loss: 0.0018 - val_accuracy: 0.8983\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7160e-04 - accuracy: 0.9773 - val_loss: 7.3811e-04 - val_accuracy: 0.9661\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.6643e-04 - accuracy: 0.9857 - val_loss: 8.1478e-04 - val_accuracy: 0.9831\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.6068e-04 - accuracy: 0.9856 - val_loss: 6.3641e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0383e-04 - accuracy: 0.9819 - val_loss: 6.5970e-04 - val_accuracy: 0.9831\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5736e-04 - accuracy: 0.9897 - val_loss: 7.5837e-04 - val_accuracy: 0.9661\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1044e-04 - accuracy: 0.9606 - val_loss: 6.3624e-04 - val_accuracy: 0.9661\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.9414e-04 - accuracy: 0.9810 - val_loss: 0.0010 - val_accuracy: 0.9153\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5971e-04 - accuracy: 0.9696 - val_loss: 7.3464e-04 - val_accuracy: 0.9661\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.2932e-04 - accuracy: 0.9897 - val_loss: 5.7111e-04 - val_accuracy: 0.9492\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.6984e-04 - accuracy: 0.9942 - val_loss: 6.9987e-04 - val_accuracy: 0.9831\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0058e-04 - accuracy: 0.9852 - val_loss: 4.8038e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.2271e-04 - accuracy: 0.9912 - val_loss: 5.3434e-04 - val_accuracy: 0.9831\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.7277e-04 - accuracy: 0.9867 - val_loss: 5.6471e-04 - val_accuracy: 0.9661\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9680e-04 - accuracy: 0.9964 - val_loss: 6.6787e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.4479e-04 - accuracy: 0.9836 - val_loss: 5.4649e-04 - val_accuracy: 0.9831\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0408e-04 - accuracy: 0.9707 - val_loss: 7.0061e-04 - val_accuracy: 0.9831\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 5.4198e-04 - accuracy: 0.9858 - val_loss: 5.2441e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.2311e-04 - accuracy: 0.9931 - val_loss: 7.1661e-04 - val_accuracy: 0.9661\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1210e-04 - accuracy: 0.9746 - val_loss: 6.5627e-04 - val_accuracy: 0.9831\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.2769e-04 - accuracy: 0.9802 - val_loss: 7.3849e-04 - val_accuracy: 0.9831\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.3662e-04 - accuracy: 0.9980 - val_loss: 5.9609e-04 - val_accuracy: 0.9492\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.6502e-04 - accuracy: 0.9974 - val_loss: 7.6643e-04 - val_accuracy: 0.9322\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.1053e-04 - accuracy: 0.9811 - val_loss: 7.1346e-04 - val_accuracy: 0.9661\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2503e-04 - accuracy: 0.9771 - val_loss: 6.1386e-04 - val_accuracy: 0.9661\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.5583e-04 - accuracy: 0.9954 - val_loss: 5.6047e-04 - val_accuracy: 0.9831\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 5.1312e-04 - accuracy: 0.9841 - val_loss: 5.8261e-04 - val_accuracy: 0.9661\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2450e-04 - accuracy: 0.9935 - val_loss: 4.0184e-04 - val_accuracy: 0.9661\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.5471e-04 - accuracy: 0.9770 - val_loss: 4.6510e-04 - val_accuracy: 0.9831\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.7042e-04 - accuracy: 0.9904 - val_loss: 5.3485e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.8993e-04 - accuracy: 0.9762 - val_loss: 6.5055e-04 - val_accuracy: 0.9661\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.6852e-04 - accuracy: 0.9840 - val_loss: 7.2773e-04 - val_accuracy: 0.9492\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.1360e-04 - accuracy: 0.9680 - val_loss: 5.0453e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.0382e-04 - accuracy: 0.9983 - val_loss: 8.0468e-04 - val_accuracy: 0.9661\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.7156e-04 - accuracy: 0.9850 - val_loss: 9.1643e-04 - val_accuracy: 0.9831\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 7.1319e-04 - accuracy: 0.9857 - val_loss: 8.2496e-04 - val_accuracy: 0.9831\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.3846e-04 - accuracy: 0.9759 - val_loss: 8.9812e-04 - val_accuracy: 0.9831\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2160e-04 - accuracy: 0.9892 - val_loss: 4.7019e-04 - val_accuracy: 0.9831\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.7963e-04 - accuracy: 0.9946 - val_loss: 5.0286e-04 - val_accuracy: 0.9831\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.3303e-04 - accuracy: 0.9701 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.9660e-04 - accuracy: 0.9928 - val_loss: 6.1806e-04 - val_accuracy: 0.9831\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1332e-04 - accuracy: 0.9867 - val_loss: 4.5387e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.2985e-04 - accuracy: 0.9927 - val_loss: 5.7050e-04 - val_accuracy: 0.9661\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.7672e-04 - accuracy: 0.9932 - val_loss: 6.4827e-04 - val_accuracy: 0.9661\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 3.8749e-04 - accuracy: 0.9897 - val_loss: 3.9951e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 3.6272e-04 - accuracy: 0.9933 - val_loss: 4.8116e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.4115e-04 - accuracy: 0.9854 - val_loss: 5.8253e-04 - val_accuracy: 0.9492\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.8276e-04 - accuracy: 0.9848 - val_loss: 5.3273e-04 - val_accuracy: 0.9661\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.7032e-04 - accuracy: 0.9946 - val_loss: 5.5960e-04 - val_accuracy: 0.9661\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9390e-04 - accuracy: 0.9793 - val_loss: 4.8566e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.8589e-04 - accuracy: 0.9924 - val_loss: 4.3457e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.2327e-04 - accuracy: 0.9711 - val_loss: 6.5296e-04 - val_accuracy: 0.9831\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0116e-04 - accuracy: 0.9956 - val_loss: 4.0380e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 2.7509e-04 - accuracy: 0.9979 - val_loss: 4.6948e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.5810e-04 - accuracy: 0.9932 - val_loss: 4.2747e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.2919e-04 - accuracy: 0.9812 - val_loss: 5.4431e-04 - val_accuracy: 0.9661\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 5.4431e-04 - accuracy: 0.9661\n",
            "Loss = 0.0005443074041977525, Accuracy = 0.9661017060279846\n",
            "Loss array:  [0.0005443074041977525]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 2/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.7508 - val_loss: 0.0260 - val_accuracy: 0.7966\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.8530 - val_loss: 0.0127 - val_accuracy: 0.8475\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9156 - val_loss: 0.0086 - val_accuracy: 0.8644\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.9146 - val_loss: 0.0095 - val_accuracy: 0.8644\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9226 - val_loss: 0.0063 - val_accuracy: 0.8644\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9270 - val_loss: 0.0050 - val_accuracy: 0.8644\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9388 - val_loss: 0.0040 - val_accuracy: 0.8814\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9235 - val_loss: 0.0045 - val_accuracy: 0.8644\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9402 - val_loss: 0.0050 - val_accuracy: 0.8814\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 0.9428 - val_loss: 0.0037 - val_accuracy: 0.8814\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9361 - val_loss: 0.0035 - val_accuracy: 0.8814\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9569 - val_loss: 0.0043 - val_accuracy: 0.8983\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9303 - val_loss: 0.0024 - val_accuracy: 0.8983\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9483 - val_loss: 0.0036 - val_accuracy: 0.8983\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9564 - val_loss: 0.0041 - val_accuracy: 0.8983\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9556 - val_loss: 0.0026 - val_accuracy: 0.9322\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9637 - val_loss: 0.0022 - val_accuracy: 0.9153\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.9722 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9684 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9636 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9582 - val_loss: 0.0021 - val_accuracy: 0.9492\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9380 - val_loss: 0.0021 - val_accuracy: 0.9322\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9597 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9746 - val_loss: 0.0018 - val_accuracy: 0.9153\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9870 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.7395e-04 - accuracy: 0.9696 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9727 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.5370e-04 - accuracy: 0.9775 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9604 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9567 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9698 - val_loss: 0.0023 - val_accuracy: 0.9153\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9626 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5667e-04 - accuracy: 0.9659 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.4382e-04 - accuracy: 0.9788 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9738 - val_loss: 0.0024 - val_accuracy: 0.9322\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 9.6114e-04 - accuracy: 0.9733 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.6600e-04 - accuracy: 0.9789 - val_loss: 0.0031 - val_accuracy: 0.9492\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9701 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9660 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5867e-04 - accuracy: 0.9744 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.6232e-04 - accuracy: 0.9746 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9732 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1906e-04 - accuracy: 0.9833 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 7.0219e-04 - accuracy: 0.9893 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 8.1935e-04 - accuracy: 0.9855 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2432e-04 - accuracy: 0.9890 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7962e-04 - accuracy: 0.9831 - val_loss: 9.3578e-04 - val_accuracy: 0.9661\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.4709e-04 - accuracy: 0.9836 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1793e-04 - accuracy: 0.9765 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.6980e-04 - accuracy: 0.9750 - val_loss: 9.4026e-04 - val_accuracy: 0.9492\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 9.6125e-04 - accuracy: 0.9783 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2107e-04 - accuracy: 0.9746 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.6393e-04 - accuracy: 0.9838 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1355e-04 - accuracy: 0.9842 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9612e-04 - accuracy: 0.9818 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.5221e-04 - accuracy: 0.9733 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0045e-04 - accuracy: 0.9799 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2996e-04 - accuracy: 0.9728 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 7.4282e-04 - accuracy: 0.9785 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.9489e-04 - accuracy: 0.9808 - val_loss: 9.5583e-04 - val_accuracy: 0.9831\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0308e-04 - accuracy: 0.9867 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.7689e-04 - accuracy: 0.9773 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3397e-04 - accuracy: 0.9908 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.3047e-04 - accuracy: 0.9853 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.1323e-04 - accuracy: 0.9750 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.5247e-04 - accuracy: 0.9779 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 6.6956e-04 - accuracy: 0.9771 - val_loss: 9.9151e-04 - val_accuracy: 0.9831\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.7883e-04 - accuracy: 0.9742 - val_loss: 9.9911e-04 - val_accuracy: 0.9661\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.3321e-04 - accuracy: 0.9712 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.5456e-04 - accuracy: 0.9821 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0711e-04 - accuracy: 0.9684 - val_loss: 9.9969e-04 - val_accuracy: 0.9492\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.4250e-04 - accuracy: 0.9728 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0522e-04 - accuracy: 0.9909 - val_loss: 9.5056e-04 - val_accuracy: 0.9661\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0244e-04 - accuracy: 0.9952 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 5.8258e-04 - accuracy: 0.9678 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 7.7896e-04 - accuracy: 0.9752 - val_loss: 9.9803e-04 - val_accuracy: 0.9831\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.8302e-04 - accuracy: 0.9868 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1144e-04 - accuracy: 0.9832 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5634e-04 - accuracy: 0.9781 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.1726e-04 - accuracy: 0.9738 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3055e-04 - accuracy: 0.9797 - val_loss: 0.0014 - val_accuracy: 0.9153\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 8.5780e-04 - accuracy: 0.9639 - val_loss: 9.1314e-04 - val_accuracy: 0.9831\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.7469e-04 - accuracy: 0.9935 - val_loss: 9.3000e-04 - val_accuracy: 0.9831\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0052e-04 - accuracy: 0.9910 - val_loss: 9.9501e-04 - val_accuracy: 0.9661\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2252e-04 - accuracy: 0.9869 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0840e-04 - accuracy: 0.9877 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5341e-04 - accuracy: 0.9872 - val_loss: 9.6343e-04 - val_accuracy: 0.9831\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4718e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.3254e-04 - accuracy: 0.9908 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0535e-04 - accuracy: 0.9837 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9707 - val_loss: 9.6913e-04 - val_accuracy: 0.9831\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.4895e-04 - accuracy: 0.9732 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.0261e-04 - accuracy: 0.9716 - val_loss: 8.6489e-04 - val_accuracy: 0.9661\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2593e-04 - accuracy: 0.9783 - val_loss: 8.1834e-04 - val_accuracy: 0.9831\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.8538e-04 - accuracy: 0.9914 - val_loss: 9.0831e-04 - val_accuracy: 0.9661\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.9772e-04 - accuracy: 0.9882 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0362e-04 - accuracy: 0.9883 - val_loss: 9.0455e-04 - val_accuracy: 0.9661\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1089e-04 - accuracy: 0.9958 - val_loss: 9.5356e-04 - val_accuracy: 0.9831\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4095e-04 - accuracy: 0.9806 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.4953e-04 - accuracy: 0.9941 - val_loss: 8.2904e-04 - val_accuracy: 0.9661\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4685e-04 - accuracy: 0.9591 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.5601e-04 - accuracy: 0.9886 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3791e-04 - accuracy: 0.9702 - val_loss: 8.9413e-04 - val_accuracy: 0.9661\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.4091e-04 - accuracy: 0.9944 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.7770e-04 - accuracy: 0.9926 - val_loss: 8.8719e-04 - val_accuracy: 0.9661\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.9879e-04 - accuracy: 0.9854 - val_loss: 8.2231e-04 - val_accuracy: 0.9831\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.8305e-04 - accuracy: 0.9792 - val_loss: 7.9650e-04 - val_accuracy: 0.9831\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.2740e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4620e-04 - accuracy: 0.9889 - val_loss: 8.8047e-04 - val_accuracy: 0.9831\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7829e-04 - accuracy: 0.9692 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.9319e-04 - accuracy: 0.9896 - val_loss: 7.1803e-04 - val_accuracy: 0.9661\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.3616e-04 - accuracy: 0.9921 - val_loss: 8.7511e-04 - val_accuracy: 0.9492\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.2493e-04 - accuracy: 0.9905 - val_loss: 8.9303e-04 - val_accuracy: 0.9831\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.4344e-04 - accuracy: 0.9876 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.2422e-04 - accuracy: 0.9677 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 3.8111e-04 - accuracy: 0.9842 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.9762e-04 - accuracy: 0.9849 - val_loss: 7.1626e-04 - val_accuracy: 0.9661\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.3570e-04 - accuracy: 0.9872 - val_loss: 7.8362e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1040e-04 - accuracy: 0.9907 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4135e-04 - accuracy: 0.9816 - val_loss: 8.0031e-04 - val_accuracy: 0.9661\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0812e-04 - accuracy: 0.9798 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3277e-04 - accuracy: 0.9918 - val_loss: 6.4675e-04 - val_accuracy: 0.9831\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 4.4487e-04 - accuracy: 0.9910 - val_loss: 6.9625e-04 - val_accuracy: 0.9831\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 4.1401e-04 - accuracy: 0.9878 - val_loss: 7.4764e-04 - val_accuracy: 0.9831\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.6294e-04 - accuracy: 0.9759 - val_loss: 9.0832e-04 - val_accuracy: 0.9661\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.0638e-04 - accuracy: 0.9860 - val_loss: 9.8888e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.5816e-04 - accuracy: 0.9736 - val_loss: 8.8396e-04 - val_accuracy: 0.9831\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.4396e-04 - accuracy: 0.9840 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 4.6343e-04 - accuracy: 0.9862 - val_loss: 7.5802e-04 - val_accuracy: 0.9831\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 3.8963e-04 - accuracy: 0.9978 - val_loss: 7.0296e-04 - val_accuracy: 0.9831\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0191e-04 - accuracy: 0.9765 - val_loss: 7.6448e-04 - val_accuracy: 0.9322\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.7179e-04 - accuracy: 0.9894 - val_loss: 8.1579e-04 - val_accuracy: 0.9661\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.7326e-04 - accuracy: 0.9918 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.8218e-04 - accuracy: 0.9866 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.2917e-04 - accuracy: 0.9962 - val_loss: 9.2630e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.5409e-04 - accuracy: 0.9946 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4732e-04 - accuracy: 0.9814 - val_loss: 8.3958e-04 - val_accuracy: 0.9831\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1455e-04 - accuracy: 0.9757 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.8922e-04 - accuracy: 0.9837 - val_loss: 8.6628e-04 - val_accuracy: 0.9831\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.9164e-04 - accuracy: 0.9734 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.8534e-04 - accuracy: 0.9906 - val_loss: 7.4985e-04 - val_accuracy: 0.9831\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.7916e-04 - accuracy: 0.9951 - val_loss: 7.3058e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.2411e-04 - accuracy: 0.9926 - val_loss: 8.6388e-04 - val_accuracy: 0.9831\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.3273e-04 - accuracy: 0.9739 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.1958e-04 - accuracy: 0.9917 - val_loss: 7.6891e-04 - val_accuracy: 0.9831\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 3.4330e-04 - accuracy: 0.9935 - val_loss: 7.2282e-04 - val_accuracy: 0.9831\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.6717e-04 - accuracy: 0.9850 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 5.9180e-04 - accuracy: 0.9778 - val_loss: 8.9051e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.9614e-04 - accuracy: 0.9939 - val_loss: 8.9680e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.3999e-04 - accuracy: 0.9907 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 3.5262e-04 - accuracy: 0.9918 - val_loss: 7.1057e-04 - val_accuracy: 0.9492\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 4.0786e-04 - accuracy: 0.9734 - val_loss: 8.0084e-04 - val_accuracy: 0.9831\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 2.6489e-04 - accuracy: 0.9921 - val_loss: 9.0135e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.2872e-04 - accuracy: 0.9822 - val_loss: 9.8523e-04 - val_accuracy: 0.9661\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.6054e-04 - accuracy: 0.9935 - val_loss: 7.7016e-04 - val_accuracy: 0.9831\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.7518e-04 - accuracy: 0.9973 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4296e-04 - accuracy: 0.9831 - val_loss: 9.6964e-04 - val_accuracy: 0.9831\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 2.6163e-04 - accuracy: 0.9949 - val_loss: 7.9576e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.7134e-04 - accuracy: 0.9814 - val_loss: 7.3759e-04 - val_accuracy: 0.9831\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 2.7886e-04 - accuracy: 0.9924 - val_loss: 7.8796e-04 - val_accuracy: 0.9661\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.6039e-04 - accuracy: 0.9943 - val_loss: 7.4984e-04 - val_accuracy: 0.9661\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.6825e-04 - accuracy: 0.9817 - val_loss: 7.4027e-04 - val_accuracy: 0.9661\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.6792e-04 - accuracy: 0.9927 - val_loss: 6.3422e-04 - val_accuracy: 0.9831\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 2.7771e-04 - accuracy: 0.9951 - val_loss: 6.1827e-04 - val_accuracy: 0.9831\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.2563e-04 - accuracy: 0.9942 - val_loss: 8.1384e-04 - val_accuracy: 0.9322\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.6305e-04 - accuracy: 0.9887 - val_loss: 8.6698e-04 - val_accuracy: 0.9661\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 2.9065e-04 - accuracy: 0.9811 - val_loss: 8.0949e-04 - val_accuracy: 0.9831\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 2.8793e-04 - accuracy: 0.9890 - val_loss: 7.3406e-04 - val_accuracy: 0.9831\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 2.8786e-04 - accuracy: 0.9956 - val_loss: 8.5581e-04 - val_accuracy: 0.9492\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.7495e-04 - accuracy: 0.9974 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "6/6 [==============================] - 0s 747us/step - loss: 0.0010 - accuracy: 0.9661\n",
            "Loss = 0.0010317516280338168, Accuracy = 0.9661017060279846\n",
            "Loss array:  [0.0005443074041977525, 0.0010317516280338168]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 3/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.7027 - val_loss: 0.0160 - val_accuracy: 0.9310\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.8967 - val_loss: 0.0061 - val_accuracy: 0.9655\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9319 - val_loss: 0.0035 - val_accuracy: 0.9655\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9337 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.9192 - val_loss: 0.0035 - val_accuracy: 0.9655\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.9133 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.9134 - val_loss: 0.0035 - val_accuracy: 0.8966\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9142 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9375 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9468 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9256 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9579 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9450 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9389 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9451 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9542 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9599 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.9515 - val_loss: 9.8407e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9700 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9681 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9658 - val_loss: 8.8893e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.9766 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9843 - val_loss: 8.4939e-04 - val_accuracy: 0.9828\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.9701e-04 - accuracy: 0.9800 - val_loss: 7.3041e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9835 - val_loss: 0.0024 - val_accuracy: 0.9828\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9718 - val_loss: 9.9283e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.4302e-04 - accuracy: 0.9821 - val_loss: 8.9359e-04 - val_accuracy: 0.9828\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 9.1825e-04 - accuracy: 0.9878 - val_loss: 8.9679e-04 - val_accuracy: 0.9828\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1015e-04 - accuracy: 0.9809 - val_loss: 8.7564e-04 - val_accuracy: 0.9828\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1979e-04 - accuracy: 0.9885 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 8.6615e-04 - accuracy: 0.9775 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.7740e-04 - accuracy: 0.9848 - val_loss: 8.8677e-04 - val_accuracy: 1.0000\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 8.6930e-04 - accuracy: 0.9864 - val_loss: 9.5930e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.9370e-04 - accuracy: 0.9899 - val_loss: 7.1830e-04 - val_accuracy: 0.9828\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 8.8530e-04 - accuracy: 0.9663 - val_loss: 9.6190e-04 - val_accuracy: 0.9828\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.2470e-04 - accuracy: 0.9801 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9738 - val_loss: 7.7049e-04 - val_accuracy: 1.0000\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.2966e-04 - accuracy: 0.9838 - val_loss: 8.4453e-04 - val_accuracy: 0.9828\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3251e-04 - accuracy: 0.9746 - val_loss: 8.0001e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 9.3077e-04 - accuracy: 0.9685 - val_loss: 6.6803e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2735e-04 - accuracy: 0.9775 - val_loss: 6.8850e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.7786e-04 - accuracy: 0.9798 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.9453e-04 - accuracy: 0.9922 - val_loss: 7.6747e-04 - val_accuracy: 0.9828\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 6.7970e-04 - accuracy: 0.9738 - val_loss: 6.8358e-04 - val_accuracy: 0.9828\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4911e-04 - accuracy: 0.9767 - val_loss: 8.8768e-04 - val_accuracy: 0.9828\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0209e-04 - accuracy: 0.9890 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.8802e-04 - accuracy: 0.9571 - val_loss: 6.2904e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2379e-04 - accuracy: 0.9858 - val_loss: 7.3990e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.7865e-04 - accuracy: 0.9794 - val_loss: 8.0086e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0088e-04 - accuracy: 0.9824 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9625 - val_loss: 6.9918e-04 - val_accuracy: 1.0000\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 4.8956e-04 - accuracy: 0.9825 - val_loss: 9.4845e-04 - val_accuracy: 0.9828\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2324e-04 - accuracy: 0.9862 - val_loss: 6.9363e-04 - val_accuracy: 0.9828\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5339e-04 - accuracy: 0.9840 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.9538e-04 - accuracy: 0.9806 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1781e-04 - accuracy: 0.9862 - val_loss: 6.3094e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 5.5358e-04 - accuracy: 0.9914 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.0871e-04 - accuracy: 0.9790 - val_loss: 9.6963e-04 - val_accuracy: 0.9828\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5765e-04 - accuracy: 0.9931 - val_loss: 6.5920e-04 - val_accuracy: 0.9828\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.5478e-04 - accuracy: 0.9966 - val_loss: 9.8558e-04 - val_accuracy: 0.9828\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.4805e-04 - accuracy: 0.9800 - val_loss: 7.0440e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 5.5377e-04 - accuracy: 0.9873 - val_loss: 5.6379e-04 - val_accuracy: 0.9828\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 4.5594e-04 - accuracy: 0.9942 - val_loss: 7.4628e-04 - val_accuracy: 0.9828\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.4110e-04 - accuracy: 0.9845 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9919 - val_loss: 7.3900e-04 - val_accuracy: 0.9828\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4082e-04 - accuracy: 0.9900 - val_loss: 7.1170e-04 - val_accuracy: 0.9828\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 5.4828e-04 - accuracy: 0.9926 - val_loss: 7.5420e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.4126e-04 - accuracy: 0.9898 - val_loss: 5.8843e-04 - val_accuracy: 0.9828\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 4.5268e-04 - accuracy: 0.9842 - val_loss: 7.0020e-04 - val_accuracy: 0.9828\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.7064e-04 - accuracy: 0.9825 - val_loss: 5.3753e-04 - val_accuracy: 0.9828\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.8235e-04 - accuracy: 0.9823 - val_loss: 9.3693e-04 - val_accuracy: 0.9655\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1258e-04 - accuracy: 0.9663 - val_loss: 8.7515e-04 - val_accuracy: 0.9828\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 4.9623e-04 - accuracy: 0.9824 - val_loss: 7.4600e-04 - val_accuracy: 0.9828\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 7.1075e-04 - accuracy: 0.9806 - val_loss: 6.1678e-04 - val_accuracy: 0.9828\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.9147e-04 - accuracy: 0.9866 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9779 - val_loss: 6.6578e-04 - val_accuracy: 0.9828\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.6685e-04 - accuracy: 0.9804 - val_loss: 7.5974e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 6.9996e-04 - accuracy: 0.9821 - val_loss: 8.0461e-04 - val_accuracy: 0.9828\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.7958e-04 - accuracy: 0.9978 - val_loss: 6.1427e-04 - val_accuracy: 0.9828\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.5444e-04 - accuracy: 0.9906 - val_loss: 8.3662e-04 - val_accuracy: 0.9828\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.2235e-04 - accuracy: 0.9817 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1216e-04 - accuracy: 0.9855 - val_loss: 6.8909e-04 - val_accuracy: 0.9828\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.1746e-04 - accuracy: 0.9744 - val_loss: 6.4805e-04 - val_accuracy: 0.9828\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 5.4559e-04 - accuracy: 0.9915 - val_loss: 7.6048e-04 - val_accuracy: 0.9828\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3808e-04 - accuracy: 0.9818 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 8.0204e-04 - accuracy: 0.9627 - val_loss: 6.4878e-04 - val_accuracy: 0.9828\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.0581e-04 - accuracy: 0.9890 - val_loss: 7.5554e-04 - val_accuracy: 0.9828\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.9376e-04 - accuracy: 0.9843 - val_loss: 6.6629e-04 - val_accuracy: 0.9828\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 6.1451e-04 - accuracy: 0.9933 - val_loss: 5.8583e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.0098e-04 - accuracy: 0.9955 - val_loss: 6.3662e-04 - val_accuracy: 0.9828\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.6920e-04 - accuracy: 0.9925 - val_loss: 4.8975e-04 - val_accuracy: 0.9828\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.4142e-04 - accuracy: 0.9909 - val_loss: 5.3620e-04 - val_accuracy: 0.9828\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.4311e-04 - accuracy: 0.9933 - val_loss: 5.9562e-04 - val_accuracy: 1.0000\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 4.4905e-04 - accuracy: 0.9946 - val_loss: 6.0372e-04 - val_accuracy: 0.9828\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.6575e-04 - accuracy: 0.9842 - val_loss: 8.5020e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2505e-04 - accuracy: 0.9765 - val_loss: 5.8324e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6854e-04 - accuracy: 0.9933 - val_loss: 5.3767e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7070e-04 - accuracy: 0.9881 - val_loss: 6.2066e-04 - val_accuracy: 0.9828\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1650e-04 - accuracy: 0.9923 - val_loss: 6.7824e-04 - val_accuracy: 0.9828\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6990e-04 - accuracy: 0.9768 - val_loss: 5.2978e-04 - val_accuracy: 1.0000\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.7760e-04 - accuracy: 0.9846 - val_loss: 6.7016e-04 - val_accuracy: 0.9828\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.8152e-04 - accuracy: 0.9977 - val_loss: 8.7204e-04 - val_accuracy: 0.9828\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3321e-04 - accuracy: 0.9856 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8.1670e-04 - accuracy: 0.9938 - val_loss: 6.7776e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.1471e-04 - accuracy: 0.9827 - val_loss: 5.6663e-04 - val_accuracy: 0.9828\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.3087e-04 - accuracy: 0.9935 - val_loss: 5.9587e-04 - val_accuracy: 0.9828\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.0896e-04 - accuracy: 0.9918 - val_loss: 6.7968e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 3.4146e-04 - accuracy: 0.9840 - val_loss: 5.6465e-04 - val_accuracy: 0.9828\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.7202e-04 - accuracy: 0.9843 - val_loss: 5.9774e-04 - val_accuracy: 0.9828\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.9962e-04 - accuracy: 0.9886 - val_loss: 4.9529e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.2384e-04 - accuracy: 0.9980 - val_loss: 5.9968e-04 - val_accuracy: 0.9828\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.0794e-04 - accuracy: 0.9965 - val_loss: 5.2793e-04 - val_accuracy: 0.9828\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 3.6205e-04 - accuracy: 0.9984 - val_loss: 6.1869e-04 - val_accuracy: 0.9828\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.4558e-04 - accuracy: 0.9926 - val_loss: 9.4695e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.2843e-04 - accuracy: 0.9892 - val_loss: 5.1471e-04 - val_accuracy: 0.9828\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.6855e-04 - accuracy: 0.9953 - val_loss: 8.2557e-04 - val_accuracy: 0.9828\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5.0591e-04 - accuracy: 0.9923 - val_loss: 5.2777e-04 - val_accuracy: 0.9828\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.9601e-04 - accuracy: 0.9927 - val_loss: 4.8344e-04 - val_accuracy: 0.9828\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 3.5132e-04 - accuracy: 0.9898 - val_loss: 7.5646e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.0146e-04 - accuracy: 0.9883 - val_loss: 5.4701e-04 - val_accuracy: 0.9828\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.0536e-04 - accuracy: 0.9907 - val_loss: 6.7748e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5897e-04 - accuracy: 0.9937 - val_loss: 7.4345e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 929us/step - loss: 4.2218e-04 - accuracy: 0.9883 - val_loss: 6.2482e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8496e-04 - accuracy: 0.9816 - val_loss: 6.5398e-04 - val_accuracy: 0.9828\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.6831e-04 - accuracy: 0.9871 - val_loss: 6.9602e-04 - val_accuracy: 0.9828\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.5726e-04 - accuracy: 0.9992 - val_loss: 5.5089e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.7862e-04 - accuracy: 0.9913 - val_loss: 5.9120e-04 - val_accuracy: 0.9828\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.8288e-04 - accuracy: 0.9878 - val_loss: 5.6353e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.6061e-04 - accuracy: 0.9961 - val_loss: 4.9838e-04 - val_accuracy: 0.9828\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.4767e-04 - accuracy: 0.9901 - val_loss: 6.9512e-04 - val_accuracy: 0.9828\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9644e-04 - accuracy: 0.9779 - val_loss: 5.8005e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.6489e-04 - accuracy: 0.9929 - val_loss: 5.3561e-04 - val_accuracy: 0.9828\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.2836e-04 - accuracy: 0.9959 - val_loss: 6.3857e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7604e-04 - accuracy: 0.9873 - val_loss: 7.0437e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.0489e-04 - accuracy: 0.9778 - val_loss: 5.4808e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.6232e-04 - accuracy: 0.9952 - val_loss: 6.6658e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 2.8660e-04 - accuracy: 0.9872 - val_loss: 5.6108e-04 - val_accuracy: 0.9828\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.1865e-04 - accuracy: 0.9929 - val_loss: 6.6844e-04 - val_accuracy: 0.9828\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.3047e-04 - accuracy: 0.9970 - val_loss: 6.3029e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.4153e-04 - accuracy: 0.9941 - val_loss: 4.4199e-04 - val_accuracy: 0.9828\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.7619e-04 - accuracy: 0.9849 - val_loss: 7.2848e-04 - val_accuracy: 0.9828\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4274e-04 - accuracy: 0.9917 - val_loss: 6.6081e-04 - val_accuracy: 0.9828\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9414e-04 - accuracy: 0.9936 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8167e-04 - accuracy: 0.9906 - val_loss: 6.5999e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.7617e-04 - accuracy: 0.9825 - val_loss: 4.7294e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 914us/step - loss: 3.1271e-04 - accuracy: 0.9948 - val_loss: 6.2108e-04 - val_accuracy: 0.9828\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 4.1266e-04 - accuracy: 0.9915 - val_loss: 5.5188e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 669us/step - loss: 3.9973e-04 - accuracy: 0.9798 - val_loss: 5.6028e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 596us/step - loss: 3.4012e-04 - accuracy: 0.9963 - val_loss: 9.8707e-04 - val_accuracy: 0.9828\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 4.3793e-04 - accuracy: 0.9866 - val_loss: 6.9383e-04 - val_accuracy: 0.9655\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 641us/step - loss: 5.4768e-04 - accuracy: 0.9661 - val_loss: 6.1803e-04 - val_accuracy: 0.9828\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 614us/step - loss: 3.5783e-04 - accuracy: 0.9845 - val_loss: 8.5306e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 5.6218e-04 - accuracy: 0.9899 - val_loss: 7.0967e-04 - val_accuracy: 0.9828\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 662us/step - loss: 3.8442e-04 - accuracy: 0.9913 - val_loss: 5.6221e-04 - val_accuracy: 0.9828\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 637us/step - loss: 3.6919e-04 - accuracy: 0.9851 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 610us/step - loss: 6.0582e-04 - accuracy: 0.9802 - val_loss: 4.7234e-04 - val_accuracy: 0.9828\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 660us/step - loss: 3.6067e-04 - accuracy: 0.9876 - val_loss: 4.9559e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 2.5320e-04 - accuracy: 0.9988 - val_loss: 4.5637e-04 - val_accuracy: 0.9828\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 706us/step - loss: 3.3753e-04 - accuracy: 0.9976 - val_loss: 8.1533e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 674us/step - loss: 4.1938e-04 - accuracy: 0.9993 - val_loss: 4.6419e-04 - val_accuracy: 0.9828\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 874us/step - loss: 3.7823e-04 - accuracy: 0.9788 - val_loss: 5.5460e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 2.6545e-04 - accuracy: 0.9951 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.4393e-04 - accuracy: 0.9849 - val_loss: 5.2229e-04 - val_accuracy: 0.9828\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7264e-04 - accuracy: 0.9951 - val_loss: 7.7227e-04 - val_accuracy: 0.9828\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9684e-04 - accuracy: 0.9782 - val_loss: 5.6010e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.3871e-04 - accuracy: 0.9891 - val_loss: 8.3488e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.6811e-04 - accuracy: 0.9727 - val_loss: 5.7546e-04 - val_accuracy: 0.9828\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 917us/step - loss: 4.4346e-04 - accuracy: 0.9903 - val_loss: 4.6875e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 3.0937e-04 - accuracy: 0.9947 - val_loss: 4.2069e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 4.1190e-04 - accuracy: 0.9889 - val_loss: 6.9513e-04 - val_accuracy: 0.9828\n",
            "6/6 [==============================] - 0s 392us/step - loss: 6.9513e-04 - accuracy: 0.9828\n",
            "Loss = 0.000695127819199115, Accuracy = 0.982758641242981\n",
            "Loss array:  [0.0005443074041977525, 0.0010317516280338168, 0.000695127819199115]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 4/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.5811 - val_loss: 0.0178 - val_accuracy: 0.7759\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 0.0162 - accuracy: 0.8528 - val_loss: 0.0115 - val_accuracy: 0.8276\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0094 - accuracy: 0.8905 - val_loss: 0.0075 - val_accuracy: 0.9138\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0073 - accuracy: 0.9319 - val_loss: 0.0064 - val_accuracy: 0.8448\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 0.0061 - accuracy: 0.9125 - val_loss: 0.0081 - val_accuracy: 0.8276\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0063 - accuracy: 0.9094 - val_loss: 0.0068 - val_accuracy: 0.8276\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0051 - accuracy: 0.9227 - val_loss: 0.0036 - val_accuracy: 0.9138\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0042 - accuracy: 0.9396 - val_loss: 0.0034 - val_accuracy: 0.8966\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0034 - accuracy: 0.9444 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.0032 - accuracy: 0.9402 - val_loss: 0.0028 - val_accuracy: 0.8966\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 611us/step - loss: 0.0027 - accuracy: 0.9399 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 632us/step - loss: 0.0024 - accuracy: 0.9410 - val_loss: 0.0032 - val_accuracy: 0.8793\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0025 - accuracy: 0.9556 - val_loss: 0.0048 - val_accuracy: 0.9483\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0038 - accuracy: 0.9358 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0022 - accuracy: 0.9619 - val_loss: 0.0038 - val_accuracy: 0.8793\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0026 - accuracy: 0.9473 - val_loss: 0.0020 - val_accuracy: 0.8966\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0016 - accuracy: 0.9440 - val_loss: 0.0020 - val_accuracy: 0.8966\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.0016 - accuracy: 0.9702 - val_loss: 0.0017 - val_accuracy: 0.9138\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 637us/step - loss: 0.0013 - accuracy: 0.9563 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 624us/step - loss: 0.0016 - accuracy: 0.9531 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 0.0012 - accuracy: 0.9581 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0013 - accuracy: 0.9509 - val_loss: 0.0016 - val_accuracy: 0.8966\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0015 - accuracy: 0.9631 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 0.0014 - accuracy: 0.9585 - val_loss: 0.0022 - val_accuracy: 0.8793\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 633us/step - loss: 0.0013 - accuracy: 0.9582 - val_loss: 0.0013 - val_accuracy: 0.9138\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 654us/step - loss: 9.1506e-04 - accuracy: 0.9763 - val_loss: 0.0019 - val_accuracy: 0.8966\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0015 - accuracy: 0.9636 - val_loss: 0.0012 - val_accuracy: 0.8966\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0013 - accuracy: 0.9724 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 610us/step - loss: 9.0811e-04 - accuracy: 0.9827 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 0.0013 - accuracy: 0.9673 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 0.0013 - accuracy: 0.9643 - val_loss: 0.0011 - val_accuracy: 0.9138\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 650us/step - loss: 7.5761e-04 - accuracy: 0.9668 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 9.4694e-04 - accuracy: 0.9742 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 647us/step - loss: 8.8205e-04 - accuracy: 0.9721 - val_loss: 0.0011 - val_accuracy: 0.8966\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 655us/step - loss: 9.2307e-04 - accuracy: 0.9830 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 669us/step - loss: 9.8150e-04 - accuracy: 0.9650 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0011 - accuracy: 0.9723 - val_loss: 8.7550e-04 - val_accuracy: 0.9483\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 636us/step - loss: 0.0012 - accuracy: 0.9643 - val_loss: 9.3016e-04 - val_accuracy: 0.9310\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 646us/step - loss: 7.3310e-04 - accuracy: 0.9753 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 9.2809e-04 - accuracy: 0.9715 - val_loss: 9.5067e-04 - val_accuracy: 0.9655\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 6.9308e-04 - accuracy: 0.9835 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 8.1116e-04 - accuracy: 0.9583 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 9.0895e-04 - accuracy: 0.9627 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 655us/step - loss: 7.4967e-04 - accuracy: 0.9739 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0011 - accuracy: 0.9426 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 657us/step - loss: 8.4923e-04 - accuracy: 0.9581 - val_loss: 0.0010 - val_accuracy: 0.9310\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 646us/step - loss: 6.5670e-04 - accuracy: 0.9921 - val_loss: 8.6369e-04 - val_accuracy: 0.9310\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 652us/step - loss: 8.1863e-04 - accuracy: 0.9854 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 640us/step - loss: 8.4701e-04 - accuracy: 0.9859 - val_loss: 8.7695e-04 - val_accuracy: 0.9483\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 643us/step - loss: 6.1334e-04 - accuracy: 0.9865 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 689us/step - loss: 6.3336e-04 - accuracy: 0.9758 - val_loss: 7.9285e-04 - val_accuracy: 0.9483\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 649us/step - loss: 6.7691e-04 - accuracy: 0.9754 - val_loss: 9.3538e-04 - val_accuracy: 0.9483\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 783us/step - loss: 6.9514e-04 - accuracy: 0.9734 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 704us/step - loss: 8.6794e-04 - accuracy: 0.9857 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 6.1465e-04 - accuracy: 0.9756 - val_loss: 7.6244e-04 - val_accuracy: 0.9655\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 669us/step - loss: 7.5394e-04 - accuracy: 0.9761 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 658us/step - loss: 8.0490e-04 - accuracy: 0.9791 - val_loss: 8.3324e-04 - val_accuracy: 0.9483\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 5.8112e-04 - accuracy: 0.9735 - val_loss: 7.4229e-04 - val_accuracy: 0.9483\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 660us/step - loss: 5.9632e-04 - accuracy: 0.9802 - val_loss: 8.5134e-04 - val_accuracy: 0.9483\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 657us/step - loss: 8.0159e-04 - accuracy: 0.9824 - val_loss: 8.4947e-04 - val_accuracy: 0.9483\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 640us/step - loss: 8.1925e-04 - accuracy: 0.9679 - val_loss: 9.0870e-04 - val_accuracy: 0.9828\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 641us/step - loss: 5.5231e-04 - accuracy: 0.9783 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 640us/step - loss: 0.0012 - accuracy: 0.9572 - val_loss: 8.5770e-04 - val_accuracy: 0.9483\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 639us/step - loss: 6.3223e-04 - accuracy: 0.9845 - val_loss: 8.2110e-04 - val_accuracy: 0.9828\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 632us/step - loss: 6.4523e-04 - accuracy: 0.9698 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 642us/step - loss: 7.6031e-04 - accuracy: 0.9806 - val_loss: 7.5095e-04 - val_accuracy: 0.9828\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 646us/step - loss: 6.0707e-04 - accuracy: 0.9890 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 626us/step - loss: 0.0017 - accuracy: 0.9782 - val_loss: 8.4583e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 617us/step - loss: 7.2449e-04 - accuracy: 0.9687 - val_loss: 9.0842e-04 - val_accuracy: 0.9828\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 604us/step - loss: 6.9745e-04 - accuracy: 0.9790 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 605us/step - loss: 7.4753e-04 - accuracy: 0.9752 - val_loss: 7.0233e-04 - val_accuracy: 0.9655\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 604us/step - loss: 8.4303e-04 - accuracy: 0.9799 - val_loss: 7.6281e-04 - val_accuracy: 0.9828\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 589us/step - loss: 7.3712e-04 - accuracy: 0.9908 - val_loss: 7.6293e-04 - val_accuracy: 0.9483\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 592us/step - loss: 6.3386e-04 - accuracy: 0.9833 - val_loss: 9.5083e-04 - val_accuracy: 0.9483\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 606us/step - loss: 6.4977e-04 - accuracy: 0.9866 - val_loss: 7.1416e-04 - val_accuracy: 0.9828\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 740us/step - loss: 5.8916e-04 - accuracy: 0.9914 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 611us/step - loss: 6.3635e-04 - accuracy: 0.9829 - val_loss: 9.6707e-04 - val_accuracy: 0.9483\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 624us/step - loss: 5.9651e-04 - accuracy: 0.9890 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 599us/step - loss: 7.8284e-04 - accuracy: 0.9780 - val_loss: 7.2557e-04 - val_accuracy: 0.9483\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 596us/step - loss: 5.7886e-04 - accuracy: 0.9914 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 589us/step - loss: 7.0563e-04 - accuracy: 0.9814 - val_loss: 6.5534e-04 - val_accuracy: 0.9483\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 583us/step - loss: 5.3252e-04 - accuracy: 0.9801 - val_loss: 7.5664e-04 - val_accuracy: 0.9483\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 587us/step - loss: 5.6619e-04 - accuracy: 0.9853 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 605us/step - loss: 5.2953e-04 - accuracy: 0.9931 - val_loss: 6.3760e-04 - val_accuracy: 0.9655\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 635us/step - loss: 5.7050e-04 - accuracy: 0.9856 - val_loss: 7.9947e-04 - val_accuracy: 0.9828\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 615us/step - loss: 7.8113e-04 - accuracy: 0.9805 - val_loss: 7.7266e-04 - val_accuracy: 0.9655\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 987us/step - loss: 6.5184e-04 - accuracy: 0.9821 - val_loss: 8.6018e-04 - val_accuracy: 0.9828\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 7.2535e-04 - accuracy: 0.9793 - val_loss: 8.0636e-04 - val_accuracy: 0.9483\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 938us/step - loss: 5.0022e-04 - accuracy: 0.9921 - val_loss: 7.9832e-04 - val_accuracy: 0.9828\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 5.2080e-04 - accuracy: 0.9909 - val_loss: 7.4860e-04 - val_accuracy: 0.9655\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 630us/step - loss: 4.7930e-04 - accuracy: 0.9875 - val_loss: 8.2081e-04 - val_accuracy: 0.9828\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 681us/step - loss: 5.6797e-04 - accuracy: 0.9701 - val_loss: 9.3044e-04 - val_accuracy: 0.9828\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 614us/step - loss: 6.3242e-04 - accuracy: 0.9853 - val_loss: 6.7241e-04 - val_accuracy: 0.9483\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 631us/step - loss: 8.3415e-04 - accuracy: 0.9595 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 630us/step - loss: 6.6435e-04 - accuracy: 0.9882 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 603us/step - loss: 5.1491e-04 - accuracy: 0.9884 - val_loss: 6.8844e-04 - val_accuracy: 0.9828\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 639us/step - loss: 5.3425e-04 - accuracy: 0.9916 - val_loss: 7.6885e-04 - val_accuracy: 0.9655\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 699us/step - loss: 6.3254e-04 - accuracy: 0.9867 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 616us/step - loss: 4.8821e-04 - accuracy: 0.9875 - val_loss: 8.3474e-04 - val_accuracy: 0.9828\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 606us/step - loss: 5.5573e-04 - accuracy: 0.9913 - val_loss: 7.8515e-04 - val_accuracy: 0.9655\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 628us/step - loss: 4.2218e-04 - accuracy: 0.9930 - val_loss: 8.7859e-04 - val_accuracy: 0.9655\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8959e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 832us/step - loss: 5.7369e-04 - accuracy: 0.9815 - val_loss: 9.1184e-04 - val_accuracy: 0.9655\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 910us/step - loss: 4.3462e-04 - accuracy: 0.9882 - val_loss: 9.5187e-04 - val_accuracy: 0.9828\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 891us/step - loss: 8.1338e-04 - accuracy: 0.9856 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 885us/step - loss: 6.6167e-04 - accuracy: 0.9757 - val_loss: 9.4494e-04 - val_accuracy: 0.9310\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 714us/step - loss: 4.8425e-04 - accuracy: 0.9819 - val_loss: 8.0777e-04 - val_accuracy: 0.9828\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 741us/step - loss: 3.9705e-04 - accuracy: 0.9882 - val_loss: 9.8889e-04 - val_accuracy: 0.9828\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 793us/step - loss: 6.0257e-04 - accuracy: 0.9900 - val_loss: 8.1813e-04 - val_accuracy: 0.9483\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 5.0368e-04 - accuracy: 0.9773 - val_loss: 6.2724e-04 - val_accuracy: 0.9655\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 5.0632e-04 - accuracy: 0.9926 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 754us/step - loss: 5.8873e-04 - accuracy: 0.9844 - val_loss: 9.3672e-04 - val_accuracy: 0.9483\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 641us/step - loss: 6.8935e-04 - accuracy: 0.9873 - val_loss: 9.3575e-04 - val_accuracy: 0.9483\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 643us/step - loss: 6.9158e-04 - accuracy: 0.9808 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 640us/step - loss: 5.2753e-04 - accuracy: 0.9832 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 9.1025e-04 - accuracy: 0.9774 - val_loss: 8.3707e-04 - val_accuracy: 0.9655\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 807us/step - loss: 4.7696e-04 - accuracy: 0.9847 - val_loss: 7.7787e-04 - val_accuracy: 0.9828\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 880us/step - loss: 4.0821e-04 - accuracy: 0.9906 - val_loss: 9.0963e-04 - val_accuracy: 0.9655\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 620us/step - loss: 5.8161e-04 - accuracy: 0.9771 - val_loss: 6.0193e-04 - val_accuracy: 0.9828\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 646us/step - loss: 5.6036e-04 - accuracy: 0.9823 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 647us/step - loss: 6.4921e-04 - accuracy: 0.9826 - val_loss: 9.0257e-04 - val_accuracy: 0.9483\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 681us/step - loss: 5.7024e-04 - accuracy: 0.9871 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 634us/step - loss: 8.3875e-04 - accuracy: 0.9844 - val_loss: 9.4764e-04 - val_accuracy: 0.9655\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 674us/step - loss: 7.4815e-04 - accuracy: 0.9629 - val_loss: 7.5767e-04 - val_accuracy: 0.9828\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 602us/step - loss: 4.6635e-04 - accuracy: 0.9899 - val_loss: 9.2380e-04 - val_accuracy: 0.9828\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 596us/step - loss: 5.5157e-04 - accuracy: 0.9879 - val_loss: 7.0134e-04 - val_accuracy: 0.9655\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 697us/step - loss: 6.1491e-04 - accuracy: 0.9809 - val_loss: 7.3076e-04 - val_accuracy: 0.9483\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 4.7827e-04 - accuracy: 0.9960 - val_loss: 6.9602e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 5.9219e-04 - accuracy: 0.9863 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 625us/step - loss: 5.1151e-04 - accuracy: 0.9854 - val_loss: 6.6284e-04 - val_accuracy: 0.9828\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 621us/step - loss: 4.0875e-04 - accuracy: 0.9830 - val_loss: 8.3648e-04 - val_accuracy: 0.9655\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 617us/step - loss: 4.5833e-04 - accuracy: 0.9771 - val_loss: 9.5714e-04 - val_accuracy: 0.9828\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 609us/step - loss: 5.6166e-04 - accuracy: 0.9879 - val_loss: 8.7257e-04 - val_accuracy: 0.9828\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 700us/step - loss: 3.8594e-04 - accuracy: 0.9929 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 681us/step - loss: 3.6691e-04 - accuracy: 0.9898 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 621us/step - loss: 5.0613e-04 - accuracy: 0.9798 - val_loss: 7.1014e-04 - val_accuracy: 0.9483\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 624us/step - loss: 3.7312e-04 - accuracy: 0.9728 - val_loss: 6.9035e-04 - val_accuracy: 0.9828\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 647us/step - loss: 4.4197e-04 - accuracy: 0.9905 - val_loss: 8.0495e-04 - val_accuracy: 0.9828\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 625us/step - loss: 3.9311e-04 - accuracy: 0.9984 - val_loss: 8.9115e-04 - val_accuracy: 0.9828\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 618us/step - loss: 3.9612e-04 - accuracy: 0.9841 - val_loss: 6.6729e-04 - val_accuracy: 0.9828\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 618us/step - loss: 3.3693e-04 - accuracy: 0.9926 - val_loss: 5.4745e-04 - val_accuracy: 0.9655\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3.3818e-04 - accuracy: 0.9908 - val_loss: 6.7261e-04 - val_accuracy: 0.9483\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3344e-04 - accuracy: 0.9943 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9696 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.6776e-04 - accuracy: 0.9932 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1141e-04 - accuracy: 0.9906 - val_loss: 8.8119e-04 - val_accuracy: 0.9828\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 5.2176e-04 - accuracy: 0.9700 - val_loss: 7.5660e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 3.3453e-04 - accuracy: 0.9912 - val_loss: 7.7791e-04 - val_accuracy: 0.9828\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 3.9781e-04 - accuracy: 0.9870 - val_loss: 6.8543e-04 - val_accuracy: 0.9483\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 958us/step - loss: 4.2210e-04 - accuracy: 0.9818 - val_loss: 5.8158e-04 - val_accuracy: 0.9655\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 615us/step - loss: 3.8956e-04 - accuracy: 0.9932 - val_loss: 9.0795e-04 - val_accuracy: 0.9828\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 628us/step - loss: 4.9720e-04 - accuracy: 0.9885 - val_loss: 6.5229e-04 - val_accuracy: 0.9655\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 621us/step - loss: 5.7892e-04 - accuracy: 0.9886 - val_loss: 6.0123e-04 - val_accuracy: 0.9655\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 628us/step - loss: 4.8545e-04 - accuracy: 0.9894 - val_loss: 6.2236e-04 - val_accuracy: 0.9828\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 772us/step - loss: 3.4800e-04 - accuracy: 0.9914 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 5.5272e-04 - accuracy: 0.9890 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 663us/step - loss: 5.9406e-04 - accuracy: 0.9778 - val_loss: 5.9827e-04 - val_accuracy: 0.9828\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 623us/step - loss: 3.5100e-04 - accuracy: 0.9872 - val_loss: 6.6893e-04 - val_accuracy: 0.9828\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 629us/step - loss: 4.4224e-04 - accuracy: 0.9891 - val_loss: 6.2425e-04 - val_accuracy: 0.9483\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 633us/step - loss: 3.0150e-04 - accuracy: 0.9888 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 657us/step - loss: 4.3402e-04 - accuracy: 0.9923 - val_loss: 7.3356e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 633us/step - loss: 3.0863e-04 - accuracy: 0.9897 - val_loss: 6.6470e-04 - val_accuracy: 0.9828\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 649us/step - loss: 3.8029e-04 - accuracy: 0.9852 - val_loss: 8.0048e-04 - val_accuracy: 0.9655\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 4.1059e-04 - accuracy: 0.9794 - val_loss: 7.5038e-04 - val_accuracy: 0.9483\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 944us/step - loss: 4.0602e-04 - accuracy: 0.9929 - val_loss: 7.5002e-04 - val_accuracy: 0.9828\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.9975e-04 - accuracy: 0.9970 - val_loss: 7.4523e-04 - val_accuracy: 0.9828\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.9584e-04 - accuracy: 0.9860 - val_loss: 6.2398e-04 - val_accuracy: 0.9828\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.5800e-04 - accuracy: 0.9904 - val_loss: 6.1316e-04 - val_accuracy: 0.9655\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 997us/step - loss: 3.3058e-04 - accuracy: 0.9973 - val_loss: 8.3899e-04 - val_accuracy: 0.9828\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4.3236e-04 - accuracy: 0.9938 - val_loss: 6.8642e-04 - val_accuracy: 0.9655\n",
            "6/6 [==============================] - 0s 696us/step - loss: 6.8642e-04 - accuracy: 0.9655\n",
            "Loss = 0.0006864182651042938, Accuracy = 0.9655172228813171\n",
            "Loss array:  [0.0005443074041977525, 0.0010317516280338168, 0.000695127819199115, 0.0006864182651042938]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 5/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.7743 - val_loss: 0.0163 - val_accuracy: 0.9483\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0150 - accuracy: 0.8854 - val_loss: 0.0085 - val_accuracy: 0.9483\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0087 - accuracy: 0.9264 - val_loss: 0.0053 - val_accuracy: 0.9483\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0066 - accuracy: 0.9139 - val_loss: 0.0030 - val_accuracy: 0.9483\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0048 - accuracy: 0.9129 - val_loss: 0.0035 - val_accuracy: 0.8966\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0039 - accuracy: 0.9209 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 627us/step - loss: 0.0030 - accuracy: 0.9375 - val_loss: 0.0034 - val_accuracy: 0.8793\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0030 - accuracy: 0.9317 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 0.0030 - accuracy: 0.9310 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0027 - accuracy: 0.9297 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0030 - accuracy: 0.9203 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0019 - accuracy: 0.9636 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0024 - accuracy: 0.9463 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0019 - accuracy: 0.9389 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 650us/step - loss: 0.0020 - accuracy: 0.9528 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0016 - accuracy: 0.9545 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 0.0021 - accuracy: 0.9357 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 908us/step - loss: 0.0012 - accuracy: 0.9469 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9521 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 964us/step - loss: 0.0013 - accuracy: 0.9588 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 961us/step - loss: 0.0013 - accuracy: 0.9513 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0013 - accuracy: 0.9434 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 9.8434e-04 - accuracy: 0.9869 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.0012 - accuracy: 0.9561 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 869us/step - loss: 0.0014 - accuracy: 0.9686 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9537 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 972us/step - loss: 0.0011 - accuracy: 0.9210 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0012 - accuracy: 0.9430 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 624us/step - loss: 9.0923e-04 - accuracy: 0.9660 - val_loss: 9.8519e-04 - val_accuracy: 0.9483\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9667 - val_loss: 9.4308e-04 - val_accuracy: 0.9828\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 794us/step - loss: 8.3032e-04 - accuracy: 0.9735 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 0.0010 - accuracy: 0.9643 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 932us/step - loss: 0.0012 - accuracy: 0.9732 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 802us/step - loss: 8.2941e-04 - accuracy: 0.9641 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 984us/step - loss: 7.0363e-04 - accuracy: 0.9838 - val_loss: 8.8108e-04 - val_accuracy: 0.9655\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.2887e-04 - accuracy: 0.9834 - val_loss: 8.9576e-04 - val_accuracy: 0.9483\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 7.9069e-04 - accuracy: 0.9800 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 885us/step - loss: 0.0010 - accuracy: 0.9844 - val_loss: 7.7235e-04 - val_accuracy: 0.9483\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 784us/step - loss: 9.0157e-04 - accuracy: 0.9711 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 692us/step - loss: 9.1567e-04 - accuracy: 0.9808 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 893us/step - loss: 9.8359e-04 - accuracy: 0.9759 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 972us/step - loss: 6.5948e-04 - accuracy: 0.9731 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.8848e-04 - accuracy: 0.9846 - val_loss: 9.5928e-04 - val_accuracy: 0.9655\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 904us/step - loss: 7.5178e-04 - accuracy: 0.9959 - val_loss: 9.1590e-04 - val_accuracy: 0.9483\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 881us/step - loss: 6.8859e-04 - accuracy: 0.9865 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0015 - accuracy: 0.9736 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 606us/step - loss: 7.1320e-04 - accuracy: 0.9825 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 611us/step - loss: 6.3545e-04 - accuracy: 0.9795 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 581us/step - loss: 8.6715e-04 - accuracy: 0.9854 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 598us/step - loss: 8.2536e-04 - accuracy: 0.9796 - val_loss: 8.0767e-04 - val_accuracy: 0.9655\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 592us/step - loss: 7.8959e-04 - accuracy: 0.9799 - val_loss: 7.8552e-04 - val_accuracy: 0.9828\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 629us/step - loss: 9.8379e-04 - accuracy: 0.9899 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 603us/step - loss: 7.9475e-04 - accuracy: 0.9863 - val_loss: 6.5541e-04 - val_accuracy: 0.9655\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 654us/step - loss: 7.8399e-04 - accuracy: 0.9680 - val_loss: 6.9734e-04 - val_accuracy: 0.9483\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 627us/step - loss: 6.5321e-04 - accuracy: 0.9826 - val_loss: 7.9693e-04 - val_accuracy: 0.9828\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 662us/step - loss: 8.5815e-04 - accuracy: 0.9865 - val_loss: 8.6084e-04 - val_accuracy: 0.9483\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4446e-04 - accuracy: 0.9872 - val_loss: 7.6543e-04 - val_accuracy: 0.9483\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3810e-04 - accuracy: 0.9816 - val_loss: 9.0533e-04 - val_accuracy: 0.9655\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 856us/step - loss: 0.0013 - accuracy: 0.9669 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 733us/step - loss: 0.0013 - accuracy: 0.9669 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 9.9263e-04 - accuracy: 0.9728 - val_loss: 9.4671e-04 - val_accuracy: 0.9655\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 9.1575e-04 - accuracy: 0.9868 - val_loss: 8.8090e-04 - val_accuracy: 0.9655\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 6.1340e-04 - accuracy: 0.9837 - val_loss: 6.5201e-04 - val_accuracy: 0.9655\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 719us/step - loss: 6.1627e-04 - accuracy: 0.9790 - val_loss: 9.6513e-04 - val_accuracy: 0.9828\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 700us/step - loss: 6.9747e-04 - accuracy: 0.9897 - val_loss: 7.5114e-04 - val_accuracy: 0.9483\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 697us/step - loss: 6.8405e-04 - accuracy: 0.9833 - val_loss: 8.0329e-04 - val_accuracy: 0.9828\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 669us/step - loss: 6.6422e-04 - accuracy: 0.9789 - val_loss: 7.1461e-04 - val_accuracy: 0.9483\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 640us/step - loss: 5.6054e-04 - accuracy: 0.9869 - val_loss: 8.3111e-04 - val_accuracy: 0.9483\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 6.4414e-04 - accuracy: 0.9875 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.0012 - accuracy: 0.9864 - val_loss: 9.2388e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4669e-04 - accuracy: 0.9827 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0695e-04 - accuracy: 0.9926 - val_loss: 8.0879e-04 - val_accuracy: 0.9483\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 933us/step - loss: 6.7613e-04 - accuracy: 0.9838 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 918us/step - loss: 5.7013e-04 - accuracy: 0.9831 - val_loss: 8.5540e-04 - val_accuracy: 0.9828\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.7912e-04 - accuracy: 0.9851 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 693us/step - loss: 8.0816e-04 - accuracy: 0.9786 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 9.7003e-04 - accuracy: 0.9789 - val_loss: 6.3721e-04 - val_accuracy: 0.9828\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 7.5118e-04 - accuracy: 0.9736 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 692us/step - loss: 7.4253e-04 - accuracy: 0.9742 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 696us/step - loss: 7.7921e-04 - accuracy: 0.9730 - val_loss: 6.3044e-04 - val_accuracy: 0.9828\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 871us/step - loss: 5.5606e-04 - accuracy: 0.9761 - val_loss: 8.2635e-04 - val_accuracy: 0.9655\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4934e-04 - accuracy: 0.9773 - val_loss: 6.4019e-04 - val_accuracy: 0.9655\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.2773e-04 - accuracy: 0.9715 - val_loss: 9.4730e-04 - val_accuracy: 0.9483\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 887us/step - loss: 5.0962e-04 - accuracy: 0.9784 - val_loss: 7.4450e-04 - val_accuracy: 0.9828\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.5874e-04 - accuracy: 0.9735 - val_loss: 6.3874e-04 - val_accuracy: 0.9828\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 738us/step - loss: 5.9684e-04 - accuracy: 0.9781 - val_loss: 9.7567e-04 - val_accuracy: 0.9828\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 946us/step - loss: 6.1150e-04 - accuracy: 0.9934 - val_loss: 8.9338e-04 - val_accuracy: 0.9655\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6.2517e-04 - accuracy: 0.9838 - val_loss: 7.6343e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.0382e-04 - accuracy: 0.9863 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1227e-04 - accuracy: 0.9610 - val_loss: 8.0170e-04 - val_accuracy: 0.9655\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7860e-04 - accuracy: 0.9802 - val_loss: 9.1362e-04 - val_accuracy: 0.9483\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 939us/step - loss: 5.6569e-04 - accuracy: 0.9885 - val_loss: 6.5386e-04 - val_accuracy: 0.9828\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 877us/step - loss: 5.8231e-04 - accuracy: 0.9750 - val_loss: 6.9688e-04 - val_accuracy: 0.9828\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 964us/step - loss: 6.0386e-04 - accuracy: 0.9794 - val_loss: 7.1442e-04 - val_accuracy: 0.9655\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.9674e-04 - accuracy: 0.9772 - val_loss: 6.3813e-04 - val_accuracy: 0.9655\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1883e-04 - accuracy: 0.9741 - val_loss: 8.7089e-04 - val_accuracy: 0.9655\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9941e-04 - accuracy: 0.9910 - val_loss: 9.0601e-04 - val_accuracy: 0.9828\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7238e-04 - accuracy: 0.9906 - val_loss: 9.0643e-04 - val_accuracy: 0.9483\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.1691e-04 - accuracy: 0.9902 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 5.4853e-04 - accuracy: 0.9880 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 980us/step - loss: 7.2671e-04 - accuracy: 0.9872 - val_loss: 6.4504e-04 - val_accuracy: 0.9828\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 750us/step - loss: 4.9058e-04 - accuracy: 0.9810 - val_loss: 8.3394e-04 - val_accuracy: 0.9655\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7476e-04 - accuracy: 0.9798 - val_loss: 7.1292e-04 - val_accuracy: 0.9828\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 847us/step - loss: 4.7433e-04 - accuracy: 0.9785 - val_loss: 6.1679e-04 - val_accuracy: 0.9828\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 948us/step - loss: 7.2104e-04 - accuracy: 0.9810 - val_loss: 8.7994e-04 - val_accuracy: 0.9828\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7084e-04 - accuracy: 0.9801 - val_loss: 8.3526e-04 - val_accuracy: 0.9655\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 984us/step - loss: 4.7002e-04 - accuracy: 0.9886 - val_loss: 6.7039e-04 - val_accuracy: 0.9655\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 4.2497e-04 - accuracy: 0.9872 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 877us/step - loss: 6.2185e-04 - accuracy: 0.9787 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 6.3369e-04 - accuracy: 0.9815 - val_loss: 6.6480e-04 - val_accuracy: 0.9828\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 8.6402e-04 - accuracy: 0.9726 - val_loss: 6.5206e-04 - val_accuracy: 0.9655\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.9679e-04 - accuracy: 0.9816 - val_loss: 6.7256e-04 - val_accuracy: 0.9828\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5813e-04 - accuracy: 0.9868 - val_loss: 6.3132e-04 - val_accuracy: 0.9828\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.0831e-04 - accuracy: 0.9907 - val_loss: 6.6892e-04 - val_accuracy: 0.9655\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 6.0065e-04 - accuracy: 0.9871 - val_loss: 6.1671e-04 - val_accuracy: 0.9655\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 3.9220e-04 - accuracy: 0.9935 - val_loss: 6.2392e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 4.4704e-04 - accuracy: 0.9933 - val_loss: 5.4998e-04 - val_accuracy: 0.9828\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 712us/step - loss: 5.3256e-04 - accuracy: 0.9838 - val_loss: 7.7692e-04 - val_accuracy: 0.9483\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2931e-04 - accuracy: 0.9620 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 943us/step - loss: 7.7369e-04 - accuracy: 0.9704 - val_loss: 7.0271e-04 - val_accuracy: 0.9655\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 5.3262e-04 - accuracy: 0.9876 - val_loss: 7.2988e-04 - val_accuracy: 0.9655\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 851us/step - loss: 6.7839e-04 - accuracy: 0.9844 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 699us/step - loss: 7.9319e-04 - accuracy: 0.9879 - val_loss: 6.1778e-04 - val_accuracy: 0.9655\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 4.6704e-04 - accuracy: 0.9951 - val_loss: 6.3369e-04 - val_accuracy: 0.9828\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 635us/step - loss: 7.1180e-04 - accuracy: 0.9912 - val_loss: 8.2866e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 583us/step - loss: 5.9942e-04 - accuracy: 0.9839 - val_loss: 6.6730e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 643us/step - loss: 4.0275e-04 - accuracy: 0.9973 - val_loss: 5.7401e-04 - val_accuracy: 0.9828\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 601us/step - loss: 6.4320e-04 - accuracy: 0.9876 - val_loss: 5.4728e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 637us/step - loss: 4.2444e-04 - accuracy: 0.9958 - val_loss: 7.8334e-04 - val_accuracy: 0.9655\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 703us/step - loss: 5.0834e-04 - accuracy: 0.9992 - val_loss: 7.9994e-04 - val_accuracy: 0.9655\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 641us/step - loss: 4.3518e-04 - accuracy: 0.9903 - val_loss: 4.8542e-04 - val_accuracy: 0.9828\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 637us/step - loss: 4.0872e-04 - accuracy: 0.9859 - val_loss: 7.6969e-04 - val_accuracy: 0.9655\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 734us/step - loss: 4.7486e-04 - accuracy: 0.9845 - val_loss: 6.3773e-04 - val_accuracy: 0.9828\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 5.1648e-04 - accuracy: 0.9879 - val_loss: 5.1020e-04 - val_accuracy: 0.9828\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 5.6832e-04 - accuracy: 0.9883 - val_loss: 7.1020e-04 - val_accuracy: 0.9828\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 657us/step - loss: 5.7381e-04 - accuracy: 0.9662 - val_loss: 5.9099e-04 - val_accuracy: 0.9655\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 4.8407e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 5.5641e-04 - accuracy: 0.9905 - val_loss: 6.1488e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 728us/step - loss: 4.5354e-04 - accuracy: 0.9959 - val_loss: 8.4877e-04 - val_accuracy: 0.9655\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 652us/step - loss: 6.0377e-04 - accuracy: 0.9735 - val_loss: 6.4338e-04 - val_accuracy: 0.9655\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 615us/step - loss: 6.0621e-04 - accuracy: 0.9813 - val_loss: 6.2906e-04 - val_accuracy: 0.9655\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 700us/step - loss: 4.3158e-04 - accuracy: 0.9968 - val_loss: 6.7513e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 635us/step - loss: 5.3062e-04 - accuracy: 0.9869 - val_loss: 8.2309e-04 - val_accuracy: 0.9828\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 6.5342e-04 - accuracy: 0.9854 - val_loss: 6.4674e-04 - val_accuracy: 0.9828\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 8.3149e-04 - accuracy: 0.9890 - val_loss: 5.9243e-04 - val_accuracy: 0.9483\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 6.1014e-04 - accuracy: 0.9754 - val_loss: 7.7111e-04 - val_accuracy: 0.9828\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 615us/step - loss: 5.5207e-04 - accuracy: 0.9850 - val_loss: 5.6046e-04 - val_accuracy: 0.9655\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 643us/step - loss: 6.8484e-04 - accuracy: 0.9761 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 623us/step - loss: 7.3050e-04 - accuracy: 0.9697 - val_loss: 7.8442e-04 - val_accuracy: 0.9655\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 621us/step - loss: 4.2956e-04 - accuracy: 0.9779 - val_loss: 5.5787e-04 - val_accuracy: 0.9828\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 677us/step - loss: 4.6561e-04 - accuracy: 0.9844 - val_loss: 5.9515e-04 - val_accuracy: 0.9655\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 627us/step - loss: 4.4121e-04 - accuracy: 0.9859 - val_loss: 5.4617e-04 - val_accuracy: 0.9828\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 632us/step - loss: 4.5520e-04 - accuracy: 0.9829 - val_loss: 4.3658e-04 - val_accuracy: 0.9828\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 675us/step - loss: 3.1312e-04 - accuracy: 0.9957 - val_loss: 4.9683e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 612us/step - loss: 3.1691e-04 - accuracy: 0.9955 - val_loss: 4.6372e-04 - val_accuracy: 0.9828\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 3.7680e-04 - accuracy: 0.9979 - val_loss: 6.8409e-04 - val_accuracy: 0.9828\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 614us/step - loss: 3.6011e-04 - accuracy: 0.9984 - val_loss: 4.5728e-04 - val_accuracy: 0.9828\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 646us/step - loss: 4.2924e-04 - accuracy: 0.9915 - val_loss: 7.0186e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 665us/step - loss: 4.5264e-04 - accuracy: 0.9915 - val_loss: 6.2730e-04 - val_accuracy: 0.9655\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 600us/step - loss: 4.7193e-04 - accuracy: 0.9950 - val_loss: 4.9089e-04 - val_accuracy: 0.9828\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 607us/step - loss: 4.2823e-04 - accuracy: 0.9942 - val_loss: 4.1946e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 630us/step - loss: 3.5453e-04 - accuracy: 0.9994 - val_loss: 4.9948e-04 - val_accuracy: 0.9828\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 638us/step - loss: 3.8730e-04 - accuracy: 0.9927 - val_loss: 4.2264e-04 - val_accuracy: 0.9655\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 652us/step - loss: 3.1574e-04 - accuracy: 0.9929 - val_loss: 5.1478e-04 - val_accuracy: 0.9828\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 672us/step - loss: 4.3383e-04 - accuracy: 0.9971 - val_loss: 5.6247e-04 - val_accuracy: 0.9828\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 4.8290e-04 - accuracy: 0.9895 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 666us/step - loss: 5.7488e-04 - accuracy: 0.9780 - val_loss: 5.5541e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 648us/step - loss: 3.7887e-04 - accuracy: 0.9983 - val_loss: 5.5824e-04 - val_accuracy: 0.9828\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 632us/step - loss: 3.8425e-04 - accuracy: 0.9969 - val_loss: 6.7750e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 5.1669e-04 - accuracy: 0.9930 - val_loss: 5.6248e-04 - val_accuracy: 0.9828\n",
            "6/6 [==============================] - 0s 421us/step - loss: 5.6248e-04 - accuracy: 0.9828\n",
            "Loss = 0.0005624757613986731, Accuracy = 0.982758641242981\n",
            "Loss array:  [0.0005443074041977525, 0.0010317516280338168, 0.000695127819199115, 0.0006864182651042938, 0.0005624757613986731]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 6/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.8541 - val_loss: 0.0177 - val_accuracy: 0.8966\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 776us/step - loss: 0.0162 - accuracy: 0.9078 - val_loss: 0.0096 - val_accuracy: 0.9138\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 631us/step - loss: 0.0086 - accuracy: 0.9262 - val_loss: 0.0058 - val_accuracy: 0.9138\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 632us/step - loss: 0.0059 - accuracy: 0.9293 - val_loss: 0.0046 - val_accuracy: 0.9310\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 608us/step - loss: 0.0046 - accuracy: 0.9423 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 603us/step - loss: 0.0039 - accuracy: 0.9354 - val_loss: 0.0041 - val_accuracy: 0.9310\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 589us/step - loss: 0.0038 - accuracy: 0.9261 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0031 - accuracy: 0.9479 - val_loss: 0.0033 - val_accuracy: 0.9138\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0031 - accuracy: 0.9421 - val_loss: 0.0029 - val_accuracy: 0.8621\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 647us/step - loss: 0.0028 - accuracy: 0.9420 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 634us/step - loss: 0.0022 - accuracy: 0.9440 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 635us/step - loss: 0.0022 - accuracy: 0.9423 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 0.0021 - accuracy: 0.9506 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0023 - accuracy: 0.9500 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.0018 - accuracy: 0.9541 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.0017 - accuracy: 0.9294 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 653us/step - loss: 0.0020 - accuracy: 0.9572 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0016 - accuracy: 0.9469 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 652us/step - loss: 0.0016 - accuracy: 0.9492 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 643us/step - loss: 0.0017 - accuracy: 0.9567 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 0.0016 - accuracy: 0.9477 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 648us/step - loss: 0.0016 - accuracy: 0.9509 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0014 - accuracy: 0.9752 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 9.9877e-04 - accuracy: 0.9788 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 590us/step - loss: 0.0012 - accuracy: 0.9756 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 632us/step - loss: 0.0012 - accuracy: 0.9521 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0011 - accuracy: 0.9696 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0012 - accuracy: 0.9710 - val_loss: 9.6077e-04 - val_accuracy: 0.9483\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 623us/step - loss: 0.0015 - accuracy: 0.9633 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 596us/step - loss: 0.0011 - accuracy: 0.9707 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 594us/step - loss: 0.0021 - accuracy: 0.9483 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 590us/step - loss: 0.0010 - accuracy: 0.9681 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 592us/step - loss: 0.0010 - accuracy: 0.9716 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 599us/step - loss: 0.0013 - accuracy: 0.9695 - val_loss: 0.0038 - val_accuracy: 0.9655\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 607us/step - loss: 0.0019 - accuracy: 0.9674 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 620us/step - loss: 9.9280e-04 - accuracy: 0.9921 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.9120e-04 - accuracy: 0.9741 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 693us/step - loss: 8.4060e-04 - accuracy: 0.9770 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 7.9500e-04 - accuracy: 0.9916 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.0011 - accuracy: 0.9619 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 8.0235e-04 - accuracy: 0.9812 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 9.7186e-04 - accuracy: 0.9741 - val_loss: 8.1064e-04 - val_accuracy: 0.9655\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 641us/step - loss: 7.6590e-04 - accuracy: 0.9795 - val_loss: 7.6284e-04 - val_accuracy: 0.9655\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 603us/step - loss: 9.6987e-04 - accuracy: 0.9649 - val_loss: 7.2593e-04 - val_accuracy: 0.9655\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 631us/step - loss: 6.8149e-04 - accuracy: 0.9756 - val_loss: 8.5686e-04 - val_accuracy: 0.9655\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 7.3715e-04 - accuracy: 0.9764 - val_loss: 7.6643e-04 - val_accuracy: 0.9655\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 626us/step - loss: 8.5122e-04 - accuracy: 0.9744 - val_loss: 8.0347e-04 - val_accuracy: 0.9828\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 7.7018e-04 - accuracy: 0.9869 - val_loss: 6.1357e-04 - val_accuracy: 0.9828\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 643us/step - loss: 5.7407e-04 - accuracy: 0.9819 - val_loss: 7.8930e-04 - val_accuracy: 0.9655\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 621us/step - loss: 6.7549e-04 - accuracy: 0.9861 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 6.9968e-04 - accuracy: 0.9841 - val_loss: 8.1803e-04 - val_accuracy: 0.9655\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 656us/step - loss: 7.6150e-04 - accuracy: 0.9845 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 617us/step - loss: 8.1647e-04 - accuracy: 0.9754 - val_loss: 8.6455e-04 - val_accuracy: 0.9655\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 628us/step - loss: 8.2419e-04 - accuracy: 0.9851 - val_loss: 8.0555e-04 - val_accuracy: 0.9828\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 569us/step - loss: 7.0751e-04 - accuracy: 0.9851 - val_loss: 7.4386e-04 - val_accuracy: 0.9655\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 653us/step - loss: 6.5231e-04 - accuracy: 0.9824 - val_loss: 7.8711e-04 - val_accuracy: 0.9655\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 623us/step - loss: 6.6632e-04 - accuracy: 0.9701 - val_loss: 8.1055e-04 - val_accuracy: 0.9655\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 612us/step - loss: 7.0051e-04 - accuracy: 0.9820 - val_loss: 9.1149e-04 - val_accuracy: 0.9483\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 594us/step - loss: 7.5758e-04 - accuracy: 0.9802 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 628us/step - loss: 8.4295e-04 - accuracy: 0.9744 - val_loss: 8.2842e-04 - val_accuracy: 0.9828\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 601us/step - loss: 6.5232e-04 - accuracy: 0.9854 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9807 - val_loss: 7.4822e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 652us/step - loss: 5.5904e-04 - accuracy: 0.9847 - val_loss: 6.1160e-04 - val_accuracy: 0.9655\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 616us/step - loss: 5.6878e-04 - accuracy: 0.9866 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 637us/step - loss: 6.1258e-04 - accuracy: 0.9891 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 906us/step - loss: 6.4269e-04 - accuracy: 0.9771 - val_loss: 6.1289e-04 - val_accuracy: 0.9483\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 930us/step - loss: 6.8580e-04 - accuracy: 0.9873 - val_loss: 9.2488e-04 - val_accuracy: 0.9828\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 626us/step - loss: 8.2227e-04 - accuracy: 0.9905 - val_loss: 6.9944e-04 - val_accuracy: 0.9828\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 613us/step - loss: 5.6825e-04 - accuracy: 0.9825 - val_loss: 8.0084e-04 - val_accuracy: 0.9655\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 612us/step - loss: 7.3280e-04 - accuracy: 0.9841 - val_loss: 6.8927e-04 - val_accuracy: 0.9828\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 595us/step - loss: 7.1383e-04 - accuracy: 0.9840 - val_loss: 8.2430e-04 - val_accuracy: 0.9483\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 599us/step - loss: 7.7386e-04 - accuracy: 0.9751 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 609us/step - loss: 8.6425e-04 - accuracy: 0.9729 - val_loss: 7.8734e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 608us/step - loss: 7.1985e-04 - accuracy: 0.9930 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 619us/step - loss: 5.8787e-04 - accuracy: 0.9948 - val_loss: 8.4687e-04 - val_accuracy: 0.9828\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 642us/step - loss: 5.4337e-04 - accuracy: 0.9959 - val_loss: 5.6931e-04 - val_accuracy: 0.9828\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 603us/step - loss: 7.0150e-04 - accuracy: 0.9830 - val_loss: 7.0426e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 610us/step - loss: 6.9064e-04 - accuracy: 0.9843 - val_loss: 5.2997e-04 - val_accuracy: 0.9655\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 602us/step - loss: 7.2753e-04 - accuracy: 0.9823 - val_loss: 6.3973e-04 - val_accuracy: 0.9828\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 7.1219e-04 - accuracy: 0.9778 - val_loss: 6.8722e-04 - val_accuracy: 0.9655\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 648us/step - loss: 5.4231e-04 - accuracy: 0.9965 - val_loss: 5.7196e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 607us/step - loss: 4.8635e-04 - accuracy: 0.9919 - val_loss: 7.6499e-04 - val_accuracy: 0.9828\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 612us/step - loss: 5.2776e-04 - accuracy: 0.9845 - val_loss: 9.8006e-04 - val_accuracy: 0.9655\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.9794e-04 - accuracy: 0.9763 - val_loss: 7.0809e-04 - val_accuracy: 0.9828\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 881us/step - loss: 6.0803e-04 - accuracy: 0.9800 - val_loss: 8.5352e-04 - val_accuracy: 0.9655\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 892us/step - loss: 7.4853e-04 - accuracy: 0.9843 - val_loss: 9.1940e-04 - val_accuracy: 0.9483\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 880us/step - loss: 8.1114e-04 - accuracy: 0.9518 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 9.1132e-04 - accuracy: 0.9727 - val_loss: 7.2687e-04 - val_accuracy: 0.9828\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 5.8268e-04 - accuracy: 0.9817 - val_loss: 8.9763e-04 - val_accuracy: 0.9655\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 687us/step - loss: 4.8574e-04 - accuracy: 0.9800 - val_loss: 5.1067e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 4.7270e-04 - accuracy: 0.9934 - val_loss: 7.7517e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 8.5574e-04 - accuracy: 0.9859 - val_loss: 8.4430e-04 - val_accuracy: 0.9483\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 907us/step - loss: 6.5177e-04 - accuracy: 0.9860 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 0.0017 - accuracy: 0.9740 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 9.3446e-04 - accuracy: 0.9744 - val_loss: 6.0969e-04 - val_accuracy: 0.9655\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 4.4074e-04 - accuracy: 0.9901 - val_loss: 7.5033e-04 - val_accuracy: 0.9483\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 6.0438e-04 - accuracy: 0.9936 - val_loss: 5.4529e-04 - val_accuracy: 0.9655\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 5.3320e-04 - accuracy: 0.9936 - val_loss: 5.4236e-04 - val_accuracy: 0.9655\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 722us/step - loss: 4.6689e-04 - accuracy: 0.9921 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 693us/step - loss: 6.4126e-04 - accuracy: 0.9887 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0011 - accuracy: 0.9724 - val_loss: 6.3457e-04 - val_accuracy: 0.9828\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 5.6559e-04 - accuracy: 0.9850 - val_loss: 5.4942e-04 - val_accuracy: 0.9828\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 3.3124e-04 - accuracy: 0.9901 - val_loss: 5.4595e-04 - val_accuracy: 0.9655\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 693us/step - loss: 6.3066e-04 - accuracy: 0.9808 - val_loss: 9.6245e-04 - val_accuracy: 0.9310\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 643us/step - loss: 5.4497e-04 - accuracy: 0.9921 - val_loss: 5.3257e-04 - val_accuracy: 0.9828\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 634us/step - loss: 4.9485e-04 - accuracy: 0.9863 - val_loss: 0.0012 - val_accuracy: 0.9138\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 6.3953e-04 - accuracy: 0.9711 - val_loss: 5.5995e-04 - val_accuracy: 0.9655\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 5.1680e-04 - accuracy: 0.9909 - val_loss: 6.9003e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.8032e-04 - accuracy: 0.9783 - val_loss: 5.7433e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 4.7518e-04 - accuracy: 0.9885 - val_loss: 5.9026e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 800us/step - loss: 6.5453e-04 - accuracy: 0.9745 - val_loss: 7.3264e-04 - val_accuracy: 0.9655\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 5.4891e-04 - accuracy: 0.9745 - val_loss: 6.3452e-04 - val_accuracy: 0.9655\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 4.0293e-04 - accuracy: 0.9874 - val_loss: 6.6578e-04 - val_accuracy: 0.9655\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 5.6021e-04 - accuracy: 0.9968 - val_loss: 5.0014e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 4.4674e-04 - accuracy: 0.9874 - val_loss: 6.4222e-04 - val_accuracy: 0.9655\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 763us/step - loss: 5.2376e-04 - accuracy: 0.9771 - val_loss: 8.7512e-04 - val_accuracy: 0.9655\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 7.2638e-04 - accuracy: 0.9887 - val_loss: 7.5274e-04 - val_accuracy: 0.9483\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 6.0733e-04 - accuracy: 0.9729 - val_loss: 5.4089e-04 - val_accuracy: 0.9828\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 4.6099e-04 - accuracy: 0.9929 - val_loss: 6.3554e-04 - val_accuracy: 0.9655\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 841us/step - loss: 5.1018e-04 - accuracy: 0.9934 - val_loss: 4.4713e-04 - val_accuracy: 0.9655\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 797us/step - loss: 3.4414e-04 - accuracy: 0.9952 - val_loss: 5.4016e-04 - val_accuracy: 0.9828\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 3.8769e-04 - accuracy: 0.9857 - val_loss: 4.6804e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 4.5240e-04 - accuracy: 0.9946 - val_loss: 5.9349e-04 - val_accuracy: 0.9655\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 5.1179e-04 - accuracy: 0.9893 - val_loss: 6.9182e-04 - val_accuracy: 0.9483\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 3.9307e-04 - accuracy: 0.9901 - val_loss: 5.6395e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 689us/step - loss: 3.5356e-04 - accuracy: 0.9962 - val_loss: 4.7955e-04 - val_accuracy: 0.9828\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 700us/step - loss: 4.5234e-04 - accuracy: 0.9847 - val_loss: 5.2090e-04 - val_accuracy: 0.9483\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 4.8192e-04 - accuracy: 0.9927 - val_loss: 5.8877e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 741us/step - loss: 4.8128e-04 - accuracy: 0.9876 - val_loss: 6.4611e-04 - val_accuracy: 0.9828\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 4.2762e-04 - accuracy: 0.9847 - val_loss: 7.7911e-04 - val_accuracy: 0.9483\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 824us/step - loss: 4.6160e-04 - accuracy: 0.9930 - val_loss: 6.0030e-04 - val_accuracy: 0.9828\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 824us/step - loss: 4.1343e-04 - accuracy: 0.9881 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 5.4817e-04 - accuracy: 0.9915 - val_loss: 6.9057e-04 - val_accuracy: 0.9655\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 4.9749e-04 - accuracy: 0.9893 - val_loss: 6.2615e-04 - val_accuracy: 0.9655\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 4.3837e-04 - accuracy: 0.9859 - val_loss: 6.8911e-04 - val_accuracy: 0.9483\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 750us/step - loss: 5.3510e-04 - accuracy: 0.9894 - val_loss: 6.1328e-04 - val_accuracy: 0.9828\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 784us/step - loss: 6.2355e-04 - accuracy: 0.9628 - val_loss: 4.5440e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 4.7955e-04 - accuracy: 0.9806 - val_loss: 6.6597e-04 - val_accuracy: 0.9828\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 750us/step - loss: 4.8712e-04 - accuracy: 0.9956 - val_loss: 6.2278e-04 - val_accuracy: 0.9655\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2412e-04 - accuracy: 0.9734 - val_loss: 7.1626e-04 - val_accuracy: 0.9655\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 876us/step - loss: 4.1926e-04 - accuracy: 0.9942 - val_loss: 6.0954e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 942us/step - loss: 3.3492e-04 - accuracy: 0.9926 - val_loss: 7.1685e-04 - val_accuracy: 0.9655\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 869us/step - loss: 4.6009e-04 - accuracy: 0.9841 - val_loss: 4.7360e-04 - val_accuracy: 0.9655\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 4.2994e-04 - accuracy: 0.9904 - val_loss: 3.7328e-04 - val_accuracy: 0.9828\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 704us/step - loss: 4.6141e-04 - accuracy: 0.9797 - val_loss: 4.7111e-04 - val_accuracy: 0.9828\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 4.5028e-04 - accuracy: 0.9888 - val_loss: 5.1809e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 4.4014e-04 - accuracy: 1.0000 - val_loss: 3.4866e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 665us/step - loss: 3.5551e-04 - accuracy: 0.9769 - val_loss: 4.7014e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 696us/step - loss: 3.4904e-04 - accuracy: 0.9975 - val_loss: 4.7854e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 779us/step - loss: 4.1658e-04 - accuracy: 0.9967 - val_loss: 4.4559e-04 - val_accuracy: 0.9655\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 660us/step - loss: 4.9881e-04 - accuracy: 0.9884 - val_loss: 7.2682e-04 - val_accuracy: 0.9828\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 701us/step - loss: 3.8469e-04 - accuracy: 0.9985 - val_loss: 4.3539e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 692us/step - loss: 3.6055e-04 - accuracy: 0.9945 - val_loss: 5.7357e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 3.8342e-04 - accuracy: 0.9917 - val_loss: 5.6525e-04 - val_accuracy: 0.9828\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 733us/step - loss: 3.7852e-04 - accuracy: 0.9975 - val_loss: 5.1011e-04 - val_accuracy: 0.9828\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 704us/step - loss: 4.3425e-04 - accuracy: 0.9798 - val_loss: 3.7199e-04 - val_accuracy: 0.9655\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 3.3286e-04 - accuracy: 0.9982 - val_loss: 5.8232e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 4.2218e-04 - accuracy: 0.9988 - val_loss: 7.2429e-04 - val_accuracy: 0.9828\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 764us/step - loss: 3.9104e-04 - accuracy: 0.9952 - val_loss: 5.9960e-04 - val_accuracy: 0.9655\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 740us/step - loss: 5.3316e-04 - accuracy: 0.9946 - val_loss: 5.6858e-04 - val_accuracy: 0.9828\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7217e-04 - accuracy: 0.9813 - val_loss: 5.0310e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 841us/step - loss: 4.6422e-04 - accuracy: 0.9866 - val_loss: 7.2781e-04 - val_accuracy: 0.9483\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 848us/step - loss: 3.1617e-04 - accuracy: 0.9997 - val_loss: 4.1695e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 735us/step - loss: 3.7929e-04 - accuracy: 0.9872 - val_loss: 7.9712e-04 - val_accuracy: 0.9828\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 5.3548e-04 - accuracy: 0.9781 - val_loss: 4.8713e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 3.9036e-04 - accuracy: 0.9927 - val_loss: 3.1963e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 810us/step - loss: 3.9408e-04 - accuracy: 0.9974 - val_loss: 7.0980e-04 - val_accuracy: 0.9655\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 3.3378e-04 - accuracy: 0.9888 - val_loss: 4.5565e-04 - val_accuracy: 0.9655\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 779us/step - loss: 3.2017e-04 - accuracy: 0.9859 - val_loss: 3.4908e-04 - val_accuracy: 0.9828\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 3.1201e-04 - accuracy: 0.9881 - val_loss: 4.5525e-04 - val_accuracy: 0.9828\n",
            "6/6 [==============================] - 0s 452us/step - loss: 4.5525e-04 - accuracy: 0.9828\n",
            "Loss = 0.0004552459577098489, Accuracy = 0.982758641242981\n",
            "Loss array:  [0.0005443074041977525, 0.0010317516280338168, 0.000695127819199115, 0.0006864182651042938, 0.0005624757613986731, 0.0004552459577098489]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 7/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.8049 - val_loss: 0.0192 - val_accuracy: 0.8103\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 799us/step - loss: 0.0143 - accuracy: 0.8822 - val_loss: 0.0149 - val_accuracy: 0.8966\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 778us/step - loss: 0.0099 - accuracy: 0.9276 - val_loss: 0.0103 - val_accuracy: 0.8966\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 0.0069 - accuracy: 0.9135 - val_loss: 0.0081 - val_accuracy: 0.9138\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 820us/step - loss: 0.0067 - accuracy: 0.9036 - val_loss: 0.0084 - val_accuracy: 0.8793\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 872us/step - loss: 0.0051 - accuracy: 0.9288 - val_loss: 0.0056 - val_accuracy: 0.9138\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 833us/step - loss: 0.0043 - accuracy: 0.9166 - val_loss: 0.0058 - val_accuracy: 0.9138\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 0.0035 - accuracy: 0.9072 - val_loss: 0.0051 - val_accuracy: 0.9310\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 0.0036 - accuracy: 0.9257 - val_loss: 0.0040 - val_accuracy: 0.9310\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 800us/step - loss: 0.0028 - accuracy: 0.9358 - val_loss: 0.0051 - val_accuracy: 0.9310\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 0.0031 - accuracy: 0.9331 - val_loss: 0.0036 - val_accuracy: 0.9310\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0026 - accuracy: 0.9391 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 0.0032 - accuracy: 0.9481 - val_loss: 0.0035 - val_accuracy: 0.9310\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0026 - accuracy: 0.9379 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.0019 - accuracy: 0.9493 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 834us/step - loss: 0.0018 - accuracy: 0.9487 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 784us/step - loss: 0.0018 - accuracy: 0.9508 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 982us/step - loss: 0.0016 - accuracy: 0.9656 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 992us/step - loss: 0.0018 - accuracy: 0.9520 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 956us/step - loss: 0.0015 - accuracy: 0.9663 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9702 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 845us/step - loss: 0.0011 - accuracy: 0.9678 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 820us/step - loss: 0.0012 - accuracy: 0.9607 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9506 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9520 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 975us/step - loss: 0.0014 - accuracy: 0.9823 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 972us/step - loss: 9.9787e-04 - accuracy: 0.9612 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0011 - accuracy: 0.9629 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.0010 - accuracy: 0.9825 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 785us/step - loss: 8.8874e-04 - accuracy: 0.9719 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0438e-04 - accuracy: 0.9831 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 8.4963e-04 - accuracy: 0.9739 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 675us/step - loss: 8.8278e-04 - accuracy: 0.9830 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 893us/step - loss: 8.0490e-04 - accuracy: 0.9784 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 834us/step - loss: 0.0010 - accuracy: 0.9636 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 721us/step - loss: 7.4635e-04 - accuracy: 0.9749 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 9.4912e-04 - accuracy: 0.9799 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 685us/step - loss: 7.4836e-04 - accuracy: 0.9706 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0011 - accuracy: 0.9635 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 809us/step - loss: 8.2652e-04 - accuracy: 0.9906 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 7.8250e-04 - accuracy: 0.9753 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 643us/step - loss: 0.0014 - accuracy: 0.9700 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 650us/step - loss: 0.0010 - accuracy: 0.9557 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 7.4038e-04 - accuracy: 0.9795 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 980us/step - loss: 6.0000e-04 - accuracy: 0.9888 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.4849e-04 - accuracy: 0.9875 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.4117e-04 - accuracy: 0.9874 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 971us/step - loss: 6.9391e-04 - accuracy: 0.9746 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 950us/step - loss: 5.7738e-04 - accuracy: 0.9928 - val_loss: 9.9938e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 708us/step - loss: 7.8616e-04 - accuracy: 0.9673 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 7.5520e-04 - accuracy: 0.9757 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.0433e-04 - accuracy: 0.9718 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 872us/step - loss: 0.0011 - accuracy: 0.9824 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 887us/step - loss: 7.2071e-04 - accuracy: 0.9797 - val_loss: 9.6359e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 838us/step - loss: 6.3616e-04 - accuracy: 0.9837 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 787us/step - loss: 8.4391e-04 - accuracy: 0.9853 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 6.2627e-04 - accuracy: 0.9883 - val_loss: 9.4066e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 5.8023e-04 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 793us/step - loss: 7.7104e-04 - accuracy: 0.9865 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 797us/step - loss: 6.8771e-04 - accuracy: 0.9838 - val_loss: 8.8868e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 5.6987e-04 - accuracy: 0.9972 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 725us/step - loss: 7.1652e-04 - accuracy: 0.9777 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 742us/step - loss: 7.7298e-04 - accuracy: 0.9801 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 720us/step - loss: 8.5879e-04 - accuracy: 0.9831 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.0012 - accuracy: 0.9670 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 709us/step - loss: 6.9848e-04 - accuracy: 0.9825 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 8.5393e-04 - accuracy: 0.9820 - val_loss: 7.7785e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 723us/step - loss: 5.5134e-04 - accuracy: 0.9931 - val_loss: 9.0937e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 720us/step - loss: 7.7479e-04 - accuracy: 0.9861 - val_loss: 9.0707e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 862us/step - loss: 5.2634e-04 - accuracy: 0.9729 - val_loss: 8.4770e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 5.3302e-04 - accuracy: 0.9910 - val_loss: 9.9168e-04 - val_accuracy: 1.0000\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 709us/step - loss: 6.9352e-04 - accuracy: 0.9911 - val_loss: 9.1937e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 674us/step - loss: 5.6631e-04 - accuracy: 0.9857 - val_loss: 8.6747e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 685us/step - loss: 5.2053e-04 - accuracy: 0.9924 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5212e-04 - accuracy: 0.9764 - val_loss: 8.7433e-04 - val_accuracy: 1.0000\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 6.5214e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 7.0533e-04 - accuracy: 0.9861 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 5.1830e-04 - accuracy: 0.9880 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 721us/step - loss: 7.1537e-04 - accuracy: 0.9902 - val_loss: 9.0603e-04 - val_accuracy: 1.0000\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 5.3985e-04 - accuracy: 0.9947 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 4.5893e-04 - accuracy: 0.9934 - val_loss: 8.6665e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 719us/step - loss: 6.1961e-04 - accuracy: 0.9804 - val_loss: 9.2667e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 4.7164e-04 - accuracy: 0.9896 - val_loss: 9.2895e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 5.7404e-04 - accuracy: 0.9807 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 754us/step - loss: 4.2050e-04 - accuracy: 0.9919 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 5.4279e-04 - accuracy: 0.9937 - val_loss: 8.3372e-04 - val_accuracy: 1.0000\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 5.3329e-04 - accuracy: 0.9853 - val_loss: 8.6107e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 780us/step - loss: 4.9795e-04 - accuracy: 0.9947 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 5.3301e-04 - accuracy: 0.9972 - val_loss: 8.5722e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 721us/step - loss: 4.3141e-04 - accuracy: 0.9874 - val_loss: 8.3069e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 7.8334e-04 - accuracy: 0.9920 - val_loss: 9.1761e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 833us/step - loss: 3.7743e-04 - accuracy: 0.9912 - val_loss: 8.2745e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 817us/step - loss: 7.4118e-04 - accuracy: 0.9699 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 854us/step - loss: 6.2333e-04 - accuracy: 0.9842 - val_loss: 8.5656e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 874us/step - loss: 5.3543e-04 - accuracy: 0.9848 - val_loss: 9.2533e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 688us/step - loss: 6.1803e-04 - accuracy: 0.9764 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 685us/step - loss: 6.7557e-04 - accuracy: 0.9701 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 709us/step - loss: 4.9589e-04 - accuracy: 0.9816 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 6.2005e-04 - accuracy: 0.9926 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0014 - accuracy: 0.9786 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 9.2466e-04 - accuracy: 0.9823 - val_loss: 7.7049e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.6812e-04 - accuracy: 0.9945 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 895us/step - loss: 4.5160e-04 - accuracy: 0.9856 - val_loss: 6.8238e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 862us/step - loss: 4.5515e-04 - accuracy: 0.9887 - val_loss: 8.0708e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 902us/step - loss: 6.1604e-04 - accuracy: 0.9846 - val_loss: 9.7225e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 869us/step - loss: 7.3296e-04 - accuracy: 0.9853 - val_loss: 7.0472e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 4.0979e-04 - accuracy: 0.9879 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 7.4728e-04 - accuracy: 0.9798 - val_loss: 9.5558e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 4.5061e-04 - accuracy: 0.9943 - val_loss: 8.2052e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 5.5886e-04 - accuracy: 0.9875 - val_loss: 7.8875e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 4.3759e-04 - accuracy: 0.9867 - val_loss: 8.5589e-04 - val_accuracy: 1.0000\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 5.0055e-04 - accuracy: 0.9874 - val_loss: 8.6575e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 786us/step - loss: 6.4803e-04 - accuracy: 0.9861 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 4.1021e-04 - accuracy: 0.9865 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 843us/step - loss: 3.5018e-04 - accuracy: 0.9884 - val_loss: 7.5643e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 749us/step - loss: 3.9117e-04 - accuracy: 0.9845 - val_loss: 8.3174e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 673us/step - loss: 3.3396e-04 - accuracy: 0.9965 - val_loss: 7.7731e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 709us/step - loss: 7.8150e-04 - accuracy: 0.9866 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 735us/step - loss: 3.9318e-04 - accuracy: 0.9852 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 762us/step - loss: 5.6468e-04 - accuracy: 0.9841 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 701us/step - loss: 5.1518e-04 - accuracy: 0.9859 - val_loss: 8.9172e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 5.2631e-04 - accuracy: 0.9875 - val_loss: 9.5066e-04 - val_accuracy: 0.9828\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 701us/step - loss: 3.8915e-04 - accuracy: 0.9897 - val_loss: 7.7211e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 687us/step - loss: 7.3911e-04 - accuracy: 0.9870 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8392e-04 - accuracy: 0.9857 - val_loss: 9.0839e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 846us/step - loss: 4.3615e-04 - accuracy: 0.9926 - val_loss: 6.9341e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 965us/step - loss: 4.9347e-04 - accuracy: 0.9854 - val_loss: 8.0888e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 784us/step - loss: 4.3293e-04 - accuracy: 0.9930 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 737us/step - loss: 6.0978e-04 - accuracy: 0.9849 - val_loss: 8.6023e-04 - val_accuracy: 0.9828\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 3.5229e-04 - accuracy: 0.9938 - val_loss: 8.8759e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 4.4053e-04 - accuracy: 0.9967 - val_loss: 7.9661e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 723us/step - loss: 5.3536e-04 - accuracy: 0.9877 - val_loss: 8.8712e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 5.1034e-04 - accuracy: 0.9838 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 3.7790e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 4.9976e-04 - accuracy: 0.9790 - val_loss: 9.1659e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 780us/step - loss: 6.5099e-04 - accuracy: 0.9804 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 760us/step - loss: 3.0469e-04 - accuracy: 0.9930 - val_loss: 8.8237e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 3.3742e-04 - accuracy: 0.9810 - val_loss: 8.0253e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 3.5756e-04 - accuracy: 0.9833 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 3.5944e-04 - accuracy: 0.9852 - val_loss: 7.1555e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 717us/step - loss: 3.7553e-04 - accuracy: 0.9966 - val_loss: 7.9212e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 699us/step - loss: 4.0184e-04 - accuracy: 0.9966 - val_loss: 7.0089e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 658us/step - loss: 4.4918e-04 - accuracy: 0.9888 - val_loss: 9.6506e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4477e-04 - accuracy: 0.9845 - val_loss: 8.8827e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 831us/step - loss: 2.9703e-04 - accuracy: 0.9955 - val_loss: 8.6998e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 936us/step - loss: 2.6071e-04 - accuracy: 0.9973 - val_loss: 9.2969e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 808us/step - loss: 3.4186e-04 - accuracy: 0.9922 - val_loss: 8.8514e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 5.1637e-04 - accuracy: 0.9899 - val_loss: 7.3610e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 3.3011e-04 - accuracy: 0.9874 - val_loss: 8.4431e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 742us/step - loss: 3.5854e-04 - accuracy: 0.9932 - val_loss: 7.0663e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 744us/step - loss: 9.2673e-04 - accuracy: 0.9657 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 738us/step - loss: 6.4275e-04 - accuracy: 0.9721 - val_loss: 7.9442e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 4.4777e-04 - accuracy: 0.9854 - val_loss: 9.0391e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 622us/step - loss: 3.0510e-04 - accuracy: 0.9924 - val_loss: 9.0783e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 2.9652e-04 - accuracy: 0.9797 - val_loss: 6.4916e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 700us/step - loss: 3.2462e-04 - accuracy: 0.9884 - val_loss: 7.6102e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 3.2046e-04 - accuracy: 0.9939 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 630us/step - loss: 3.7482e-04 - accuracy: 0.9915 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 655us/step - loss: 4.8906e-04 - accuracy: 0.9955 - val_loss: 9.6552e-04 - val_accuracy: 0.9828\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 635us/step - loss: 4.6543e-04 - accuracy: 0.9716 - val_loss: 6.8051e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 653us/step - loss: 3.3720e-04 - accuracy: 0.9944 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 698us/step - loss: 5.4601e-04 - accuracy: 0.9879 - val_loss: 9.6928e-04 - val_accuracy: 0.9828\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 633us/step - loss: 3.3834e-04 - accuracy: 0.9910 - val_loss: 6.9893e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 641us/step - loss: 3.2330e-04 - accuracy: 0.9851 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 632us/step - loss: 4.5831e-04 - accuracy: 0.9877 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 623us/step - loss: 6.1206e-04 - accuracy: 0.9707 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 740us/step - loss: 5.0180e-04 - accuracy: 0.9857 - val_loss: 9.0178e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 4.1259e-04 - accuracy: 0.9955 - val_loss: 7.2353e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 3.8014e-04 - accuracy: 0.9919 - val_loss: 8.8885e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.2293e-04 - accuracy: 0.9901 - val_loss: 8.0710e-04 - val_accuracy: 1.0000\n",
            "6/6 [==============================] - 0s 443us/step - loss: 8.0710e-04 - accuracy: 1.0000\n",
            "Loss = 0.0008070990443229675, Accuracy = 1.0\n",
            "Loss array:  [0.0005443074041977525, 0.0010317516280338168, 0.000695127819199115, 0.0006864182651042938, 0.0005624757613986731, 0.0004552459577098489, 0.0008070990443229675]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 8/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.5994 - val_loss: 0.0169 - val_accuracy: 0.8448\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0165 - accuracy: 0.8675 - val_loss: 0.0122 - val_accuracy: 0.8966\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 623us/step - loss: 0.0106 - accuracy: 0.9086 - val_loss: 0.0068 - val_accuracy: 0.9483\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0062 - accuracy: 0.9273 - val_loss: 0.0049 - val_accuracy: 0.9655\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.0045 - accuracy: 0.9312 - val_loss: 0.0057 - val_accuracy: 0.8966\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 0.0038 - accuracy: 0.9402 - val_loss: 0.0059 - val_accuracy: 0.8966\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.0033 - accuracy: 0.9163 - val_loss: 0.0081 - val_accuracy: 0.8621\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0043 - accuracy: 0.9222 - val_loss: 0.0041 - val_accuracy: 0.9138\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0029 - accuracy: 0.9375 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0027 - accuracy: 0.9332 - val_loss: 0.0050 - val_accuracy: 0.9138\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0025 - accuracy: 0.9387 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0024 - accuracy: 0.9412 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0022 - accuracy: 0.9578 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 628us/step - loss: 0.0019 - accuracy: 0.9404 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 734us/step - loss: 0.0020 - accuracy: 0.9407 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0023 - accuracy: 0.9470 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0018 - accuracy: 0.9475 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0019 - accuracy: 0.9454 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0015 - accuracy: 0.9259 - val_loss: 0.0026 - val_accuracy: 0.9310\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0016 - accuracy: 0.9665 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0015 - accuracy: 0.9379 - val_loss: 0.0037 - val_accuracy: 0.8966\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0015 - accuracy: 0.9745 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0012 - accuracy: 0.9572 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0015 - accuracy: 0.9568 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9645 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 821us/step - loss: 0.0010 - accuracy: 0.9662 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 987us/step - loss: 0.0011 - accuracy: 0.9682 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0011 - accuracy: 0.9602 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0013 - accuracy: 0.9718 - val_loss: 9.9139e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.0014 - accuracy: 0.9607 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0013 - accuracy: 0.9724 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 756us/step - loss: 9.7859e-04 - accuracy: 0.9757 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 697us/step - loss: 8.7670e-04 - accuracy: 0.9728 - val_loss: 0.0018 - val_accuracy: 0.8966\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.0010 - accuracy: 0.9672 - val_loss: 9.7869e-04 - val_accuracy: 0.9828\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.0015 - accuracy: 0.9701 - val_loss: 8.4547e-04 - val_accuracy: 0.9828\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 669us/step - loss: 8.8514e-04 - accuracy: 0.9795 - val_loss: 9.7783e-04 - val_accuracy: 0.9828\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 735us/step - loss: 7.8505e-04 - accuracy: 0.9706 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 7.7940e-04 - accuracy: 0.9792 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 668us/step - loss: 7.1898e-04 - accuracy: 0.9703 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 656us/step - loss: 7.1199e-04 - accuracy: 0.9747 - val_loss: 9.2701e-04 - val_accuracy: 0.9655\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 0.0010 - accuracy: 0.9775 - val_loss: 9.8978e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 675us/step - loss: 9.0693e-04 - accuracy: 0.9677 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 644us/step - loss: 7.2571e-04 - accuracy: 0.9758 - val_loss: 8.4965e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 626us/step - loss: 8.6443e-04 - accuracy: 0.9804 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 649us/step - loss: 7.3254e-04 - accuracy: 0.9893 - val_loss: 8.9569e-04 - val_accuracy: 0.9828\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 650us/step - loss: 7.9920e-04 - accuracy: 0.9821 - val_loss: 8.0475e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.6340e-04 - accuracy: 0.9767 - val_loss: 8.7444e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 8.3320e-04 - accuracy: 0.9782 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0012 - accuracy: 0.9801 - val_loss: 0.0034 - val_accuracy: 0.8966\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0011 - accuracy: 0.9773 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 663us/step - loss: 6.2248e-04 - accuracy: 0.9751 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 658us/step - loss: 9.6685e-04 - accuracy: 0.9829 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 675us/step - loss: 8.4903e-04 - accuracy: 0.9671 - val_loss: 8.9154e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 670us/step - loss: 6.5349e-04 - accuracy: 0.9840 - val_loss: 7.6771e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 5.4115e-04 - accuracy: 0.9856 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 679us/step - loss: 5.2295e-04 - accuracy: 0.9975 - val_loss: 9.3353e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 696us/step - loss: 6.1869e-04 - accuracy: 0.9883 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 722us/step - loss: 6.4756e-04 - accuracy: 0.9819 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 655us/step - loss: 6.9009e-04 - accuracy: 0.9882 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 6.5021e-04 - accuracy: 0.9900 - val_loss: 8.7935e-04 - val_accuracy: 0.9828\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 621us/step - loss: 6.2411e-04 - accuracy: 0.9945 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 669us/step - loss: 6.4577e-04 - accuracy: 0.9806 - val_loss: 7.2497e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 653us/step - loss: 6.3572e-04 - accuracy: 0.9855 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0010 - accuracy: 0.9699 - val_loss: 7.5498e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 651us/step - loss: 4.5487e-04 - accuracy: 0.9929 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 631us/step - loss: 7.2599e-04 - accuracy: 0.9815 - val_loss: 7.8412e-04 - val_accuracy: 0.9828\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 611us/step - loss: 5.3924e-04 - accuracy: 0.9876 - val_loss: 7.3419e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 700us/step - loss: 5.2458e-04 - accuracy: 0.9803 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 653us/step - loss: 7.6300e-04 - accuracy: 0.9721 - val_loss: 7.8457e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 696us/step - loss: 6.6725e-04 - accuracy: 0.9899 - val_loss: 7.4118e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3397e-04 - accuracy: 0.9871 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 785us/step - loss: 7.3406e-04 - accuracy: 0.9883 - val_loss: 9.8995e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 708us/step - loss: 6.5137e-04 - accuracy: 0.9791 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 963us/step - loss: 5.7712e-04 - accuracy: 0.9855 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 864us/step - loss: 5.4237e-04 - accuracy: 0.9926 - val_loss: 5.6280e-04 - val_accuracy: 1.0000\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 711us/step - loss: 6.6953e-04 - accuracy: 0.9967 - val_loss: 6.0851e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 4.8151e-04 - accuracy: 0.9833 - val_loss: 6.5482e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 6.9604e-04 - accuracy: 0.9757 - val_loss: 9.6540e-04 - val_accuracy: 0.9828\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 4.6688e-04 - accuracy: 0.9964 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 863us/step - loss: 8.8695e-04 - accuracy: 0.9939 - val_loss: 9.9805e-04 - val_accuracy: 0.9655\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 6.2392e-04 - accuracy: 0.9865 - val_loss: 9.3097e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 749us/step - loss: 9.2805e-04 - accuracy: 0.9906 - val_loss: 7.1977e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 4.3642e-04 - accuracy: 0.9899 - val_loss: 5.7345e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 794us/step - loss: 4.2256e-04 - accuracy: 0.9925 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 802us/step - loss: 5.7730e-04 - accuracy: 0.9969 - val_loss: 7.6372e-04 - val_accuracy: 1.0000\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 7.0985e-04 - accuracy: 0.9889 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 6.2670e-04 - accuracy: 0.9789 - val_loss: 8.7432e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 4.4251e-04 - accuracy: 0.9933 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 790us/step - loss: 6.1810e-04 - accuracy: 0.9874 - val_loss: 6.5513e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 7.7312e-04 - accuracy: 0.9770 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 834us/step - loss: 5.0924e-04 - accuracy: 0.9886 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 5.0277e-04 - accuracy: 0.9861 - val_loss: 5.7766e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 6.4850e-04 - accuracy: 0.9760 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 4.1178e-04 - accuracy: 0.9873 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3850e-04 - accuracy: 0.9894 - val_loss: 6.7557e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 5.0693e-04 - accuracy: 0.9875 - val_loss: 8.8633e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 4.1339e-04 - accuracy: 0.9981 - val_loss: 7.9193e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 764us/step - loss: 5.9098e-04 - accuracy: 0.9884 - val_loss: 6.3526e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 718us/step - loss: 5.7217e-04 - accuracy: 0.9914 - val_loss: 8.9843e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 5.6888e-04 - accuracy: 0.9842 - val_loss: 7.9686e-04 - val_accuracy: 1.0000\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 4.4526e-04 - accuracy: 0.9902 - val_loss: 8.2240e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 808us/step - loss: 5.3652e-04 - accuracy: 0.9852 - val_loss: 5.8490e-04 - val_accuracy: 1.0000\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 4.1153e-04 - accuracy: 0.9940 - val_loss: 7.5933e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 698us/step - loss: 3.6519e-04 - accuracy: 0.9929 - val_loss: 6.1213e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 703us/step - loss: 5.3823e-04 - accuracy: 0.9779 - val_loss: 6.9124e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 9.1260e-04 - accuracy: 0.9868 - val_loss: 7.2078e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.9545e-04 - accuracy: 0.9844 - val_loss: 5.8454e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.6995e-04 - accuracy: 0.9891 - val_loss: 6.3859e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.2123e-04 - accuracy: 0.9953 - val_loss: 6.8977e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.4799e-04 - accuracy: 0.9961 - val_loss: 8.4227e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 4.6688e-04 - accuracy: 0.9916 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 7.9739e-04 - accuracy: 0.9933 - val_loss: 9.4274e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.1695e-04 - accuracy: 0.9998 - val_loss: 5.6319e-04 - val_accuracy: 1.0000\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 762us/step - loss: 4.5134e-04 - accuracy: 0.9910 - val_loss: 7.7579e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 750us/step - loss: 6.9075e-04 - accuracy: 0.9829 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 768us/step - loss: 7.0139e-04 - accuracy: 0.9947 - val_loss: 9.0214e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 5.4316e-04 - accuracy: 0.9839 - val_loss: 7.4642e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 6.4936e-04 - accuracy: 0.9877 - val_loss: 6.3840e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 760us/step - loss: 4.9285e-04 - accuracy: 0.9897 - val_loss: 6.7691e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 3.9704e-04 - accuracy: 0.9793 - val_loss: 6.7864e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 3.6345e-04 - accuracy: 0.9930 - val_loss: 7.4489e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 762us/step - loss: 4.9833e-04 - accuracy: 0.9894 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 4.6067e-04 - accuracy: 0.9952 - val_loss: 9.0703e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 733us/step - loss: 3.9158e-04 - accuracy: 0.9923 - val_loss: 5.9360e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 793us/step - loss: 4.0418e-04 - accuracy: 0.9896 - val_loss: 6.8445e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 783us/step - loss: 3.9754e-04 - accuracy: 0.9836 - val_loss: 9.8852e-04 - val_accuracy: 0.9828\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 742us/step - loss: 5.2009e-04 - accuracy: 0.9926 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 6.7486e-04 - accuracy: 0.9728 - val_loss: 5.9081e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 833us/step - loss: 3.0175e-04 - accuracy: 0.9970 - val_loss: 5.7960e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.0825e-04 - accuracy: 0.9943 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 779us/step - loss: 4.3371e-04 - accuracy: 0.9869 - val_loss: 5.1876e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 4.2115e-04 - accuracy: 0.9942 - val_loss: 6.5497e-04 - val_accuracy: 0.9828\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 680us/step - loss: 2.5596e-04 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 662us/step - loss: 7.0527e-04 - accuracy: 0.9717 - val_loss: 5.9848e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 670us/step - loss: 4.0492e-04 - accuracy: 0.9972 - val_loss: 5.6550e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 628us/step - loss: 3.5858e-04 - accuracy: 0.9963 - val_loss: 8.9901e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 602us/step - loss: 5.8081e-04 - accuracy: 0.9908 - val_loss: 8.7724e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 607us/step - loss: 4.5108e-04 - accuracy: 0.9858 - val_loss: 6.3773e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 608us/step - loss: 5.1531e-04 - accuracy: 0.9861 - val_loss: 7.6306e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 656us/step - loss: 4.6624e-04 - accuracy: 0.9955 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 4.3325e-04 - accuracy: 0.9934 - val_loss: 7.4980e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 3.3636e-04 - accuracy: 0.9955 - val_loss: 9.7172e-04 - val_accuracy: 0.9655\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 681us/step - loss: 4.3482e-04 - accuracy: 0.9849 - val_loss: 8.2078e-04 - val_accuracy: 0.9828\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 677us/step - loss: 4.0948e-04 - accuracy: 0.9917 - val_loss: 5.3364e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 657us/step - loss: 2.9515e-04 - accuracy: 0.9963 - val_loss: 6.3866e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 686us/step - loss: 3.8932e-04 - accuracy: 0.9934 - val_loss: 6.9376e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 687us/step - loss: 6.0167e-04 - accuracy: 0.9926 - val_loss: 6.2593e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 3.1084e-04 - accuracy: 0.9949 - val_loss: 5.8660e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.7473e-04 - accuracy: 0.9887 - val_loss: 6.9400e-04 - val_accuracy: 0.9828\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 877us/step - loss: 3.1838e-04 - accuracy: 0.9911 - val_loss: 6.5269e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 998us/step - loss: 3.8283e-04 - accuracy: 0.9961 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 799us/step - loss: 5.2208e-04 - accuracy: 0.9811 - val_loss: 4.6992e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 826us/step - loss: 3.2268e-04 - accuracy: 0.9869 - val_loss: 6.9839e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 3.2062e-04 - accuracy: 0.9893 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 6.7470e-04 - accuracy: 0.9808 - val_loss: 6.4474e-04 - val_accuracy: 0.9828\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 784us/step - loss: 3.2865e-04 - accuracy: 0.9992 - val_loss: 7.6965e-04 - val_accuracy: 0.9828\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 754us/step - loss: 4.1374e-04 - accuracy: 0.9920 - val_loss: 4.5731e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 3.8388e-04 - accuracy: 0.9955 - val_loss: 6.4036e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 776us/step - loss: 3.0122e-04 - accuracy: 0.9956 - val_loss: 5.8891e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 811us/step - loss: 2.4868e-04 - accuracy: 0.9924 - val_loss: 6.4432e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 827us/step - loss: 3.1921e-04 - accuracy: 0.9947 - val_loss: 7.2606e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 762us/step - loss: 3.5580e-04 - accuracy: 0.9905 - val_loss: 9.0364e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 2.8270e-04 - accuracy: 0.9980 - val_loss: 7.3035e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 729us/step - loss: 3.2545e-04 - accuracy: 0.9949 - val_loss: 5.4187e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 4.3728e-04 - accuracy: 0.9862 - val_loss: 5.9627e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 764us/step - loss: 5.0071e-04 - accuracy: 0.9836 - val_loss: 5.5948e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 5.2063e-04 - accuracy: 0.9951 - val_loss: 5.9624e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 4.1823e-04 - accuracy: 0.9860 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 4.4450e-04 - accuracy: 0.9820 - val_loss: 7.9057e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 2.9511e-04 - accuracy: 0.9946 - val_loss: 9.8892e-04 - val_accuracy: 0.9655\n",
            "6/6 [==============================] - 0s 419us/step - loss: 9.8892e-04 - accuracy: 0.9655\n",
            "Loss = 0.000988918705843389, Accuracy = 0.9655172228813171\n",
            "Loss array:  [0.0005443074041977525, 0.0010317516280338168, 0.000695127819199115, 0.0006864182651042938, 0.0005624757613986731, 0.0004552459577098489, 0.0008070990443229675, 0.000988918705843389]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 9/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.7605 - val_loss: 0.0183 - val_accuracy: 0.8276\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 0.0140 - accuracy: 0.8744 - val_loss: 0.0095 - val_accuracy: 0.9138\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0081 - accuracy: 0.9534 - val_loss: 0.0063 - val_accuracy: 0.9138\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0058 - accuracy: 0.9451 - val_loss: 0.0048 - val_accuracy: 0.9138\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0047 - accuracy: 0.9286 - val_loss: 0.0047 - val_accuracy: 0.9310\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.0046 - accuracy: 0.9095 - val_loss: 0.0057 - val_accuracy: 0.9310\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0047 - accuracy: 0.9038 - val_loss: 0.0048 - val_accuracy: 0.9310\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0042 - accuracy: 0.9345 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.0034 - accuracy: 0.9096 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 769us/step - loss: 0.0029 - accuracy: 0.9301 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 0.0025 - accuracy: 0.9472 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 0.0022 - accuracy: 0.9418 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.0023 - accuracy: 0.9461 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0019 - accuracy: 0.9360 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0026 - accuracy: 0.9455 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0018 - accuracy: 0.9452 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0029 - accuracy: 0.9227 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9353 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0016 - accuracy: 0.9613 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9432 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 823us/step - loss: 0.0013 - accuracy: 0.9705 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 866us/step - loss: 0.0013 - accuracy: 0.9619 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 826us/step - loss: 0.0015 - accuracy: 0.9484 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 789us/step - loss: 0.0015 - accuracy: 0.9598 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 0.0020 - accuracy: 0.9359 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 802us/step - loss: 0.0012 - accuracy: 0.9639 - val_loss: 9.5691e-04 - val_accuracy: 0.9655\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 795us/step - loss: 0.0010 - accuracy: 0.9447 - val_loss: 8.6342e-04 - val_accuracy: 0.9828\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 837us/step - loss: 8.7798e-04 - accuracy: 0.9600 - val_loss: 8.8985e-04 - val_accuracy: 0.9828\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 706us/step - loss: 9.7413e-04 - accuracy: 0.9718 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0015 - accuracy: 0.9329 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 698us/step - loss: 9.9778e-04 - accuracy: 0.9534 - val_loss: 7.5373e-04 - val_accuracy: 0.9828\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 708us/step - loss: 8.9144e-04 - accuracy: 0.9646 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0012 - accuracy: 0.9570 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 969us/step - loss: 0.0010 - accuracy: 0.9578 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.9411e-04 - accuracy: 0.9732 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 8.5371e-04 - accuracy: 0.9676 - val_loss: 8.3675e-04 - val_accuracy: 0.9828\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 889us/step - loss: 9.9100e-04 - accuracy: 0.9635 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 972us/step - loss: 8.8111e-04 - accuracy: 0.9839 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 915us/step - loss: 8.0594e-04 - accuracy: 0.9768 - val_loss: 7.2586e-04 - val_accuracy: 0.9828\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 831us/step - loss: 6.2755e-04 - accuracy: 0.9622 - val_loss: 8.4555e-04 - val_accuracy: 0.9828\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 9.0017e-04 - accuracy: 0.9586 - val_loss: 8.0180e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 9.4690e-04 - accuracy: 0.9726 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 9.7623e-04 - accuracy: 0.9840 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 682us/step - loss: 8.5229e-04 - accuracy: 0.9700 - val_loss: 8.3299e-04 - val_accuracy: 0.9828\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 696us/step - loss: 7.5365e-04 - accuracy: 0.9563 - val_loss: 7.8768e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 741us/step - loss: 6.3720e-04 - accuracy: 0.9836 - val_loss: 7.4690e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 7.7371e-04 - accuracy: 0.9766 - val_loss: 9.0554e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 779us/step - loss: 9.8147e-04 - accuracy: 0.9629 - val_loss: 6.4761e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 647us/step - loss: 0.0010 - accuracy: 0.9650 - val_loss: 8.0005e-04 - val_accuracy: 0.9828\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 957us/step - loss: 6.1968e-04 - accuracy: 0.9871 - val_loss: 5.8471e-04 - val_accuracy: 0.9828\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 774us/step - loss: 6.4385e-04 - accuracy: 0.9755 - val_loss: 7.3153e-04 - val_accuracy: 0.9655\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 780us/step - loss: 6.5541e-04 - accuracy: 0.9807 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 639us/step - loss: 8.7703e-04 - accuracy: 0.9780 - val_loss: 5.9807e-04 - val_accuracy: 0.9828\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 606us/step - loss: 6.9701e-04 - accuracy: 0.9854 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 608us/step - loss: 8.1783e-04 - accuracy: 0.9699 - val_loss: 5.8526e-04 - val_accuracy: 0.9828\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 601us/step - loss: 6.6350e-04 - accuracy: 0.9801 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 620us/step - loss: 0.0011 - accuracy: 0.9498 - val_loss: 6.4852e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 618us/step - loss: 0.0012 - accuracy: 0.9503 - val_loss: 9.2688e-04 - val_accuracy: 0.9828\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 696us/step - loss: 7.1387e-04 - accuracy: 0.9768 - val_loss: 5.9089e-04 - val_accuracy: 0.9828\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 776us/step - loss: 7.8647e-04 - accuracy: 0.9745 - val_loss: 6.8718e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 731us/step - loss: 5.8726e-04 - accuracy: 0.9810 - val_loss: 9.5375e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 683us/step - loss: 6.6185e-04 - accuracy: 0.9665 - val_loss: 5.6587e-04 - val_accuracy: 0.9828\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 678us/step - loss: 6.5543e-04 - accuracy: 0.9874 - val_loss: 6.4156e-04 - val_accuracy: 0.9828\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 653us/step - loss: 7.4742e-04 - accuracy: 0.9725 - val_loss: 6.3242e-04 - val_accuracy: 0.9828\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 674us/step - loss: 5.9431e-04 - accuracy: 0.9778 - val_loss: 7.0107e-04 - val_accuracy: 0.9828\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 668us/step - loss: 8.1790e-04 - accuracy: 0.9606 - val_loss: 6.7018e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 666us/step - loss: 5.2384e-04 - accuracy: 0.9820 - val_loss: 8.4180e-04 - val_accuracy: 0.9828\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 653us/step - loss: 8.1945e-04 - accuracy: 0.9671 - val_loss: 7.5573e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3396e-04 - accuracy: 0.9908 - val_loss: 5.6682e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 944us/step - loss: 6.4347e-04 - accuracy: 0.9704 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 0.0012 - accuracy: 0.9653 - val_loss: 9.0246e-04 - val_accuracy: 0.9828\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 825us/step - loss: 7.6784e-04 - accuracy: 0.9660 - val_loss: 5.8999e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 5.9280e-04 - accuracy: 0.9834 - val_loss: 5.1288e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 6.6434e-04 - accuracy: 0.9819 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 724us/step - loss: 8.5591e-04 - accuracy: 0.9794 - val_loss: 9.0884e-04 - val_accuracy: 0.9828\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 688us/step - loss: 6.8735e-04 - accuracy: 0.9838 - val_loss: 6.1074e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 739us/step - loss: 5.3595e-04 - accuracy: 0.9762 - val_loss: 8.5082e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 714us/step - loss: 6.3109e-04 - accuracy: 0.9865 - val_loss: 5.4941e-04 - val_accuracy: 0.9828\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 759us/step - loss: 4.4939e-04 - accuracy: 0.9912 - val_loss: 6.6936e-04 - val_accuracy: 1.0000\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 799us/step - loss: 5.6268e-04 - accuracy: 0.9869 - val_loss: 9.4610e-04 - val_accuracy: 0.9828\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 841us/step - loss: 7.6206e-04 - accuracy: 0.9610 - val_loss: 6.0339e-04 - val_accuracy: 0.9828\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 5.4317e-04 - accuracy: 0.9918 - val_loss: 5.7892e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 817us/step - loss: 5.1483e-04 - accuracy: 0.9795 - val_loss: 6.5886e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.3211e-04 - accuracy: 0.9835 - val_loss: 6.1436e-04 - val_accuracy: 0.9828\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 716us/step - loss: 5.7261e-04 - accuracy: 0.9888 - val_loss: 9.5135e-04 - val_accuracy: 0.9655\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 682us/step - loss: 7.4354e-04 - accuracy: 0.9700 - val_loss: 5.1049e-04 - val_accuracy: 1.0000\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 619us/step - loss: 4.2473e-04 - accuracy: 0.9867 - val_loss: 4.3523e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 606us/step - loss: 4.4433e-04 - accuracy: 0.9751 - val_loss: 5.9714e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 6.5895e-04 - accuracy: 0.9796 - val_loss: 8.8033e-04 - val_accuracy: 0.9828\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 674us/step - loss: 6.9866e-04 - accuracy: 0.9872 - val_loss: 5.6117e-04 - val_accuracy: 0.9828\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 6.5732e-04 - accuracy: 0.9682 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 703us/step - loss: 5.5195e-04 - accuracy: 0.9860 - val_loss: 5.2603e-04 - val_accuracy: 0.9828\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 692us/step - loss: 4.9254e-04 - accuracy: 0.9895 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 672us/step - loss: 9.9390e-04 - accuracy: 0.9492 - val_loss: 5.4698e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 5.9067e-04 - accuracy: 0.9769 - val_loss: 7.2417e-04 - val_accuracy: 0.9828\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 681us/step - loss: 6.8368e-04 - accuracy: 0.9760 - val_loss: 8.8110e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 648us/step - loss: 5.6344e-04 - accuracy: 0.9897 - val_loss: 5.5884e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 674us/step - loss: 5.2169e-04 - accuracy: 0.9678 - val_loss: 9.6108e-04 - val_accuracy: 0.9828\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 676us/step - loss: 9.3379e-04 - accuracy: 0.9694 - val_loss: 7.6398e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 7.5724e-04 - accuracy: 0.9858 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 717us/step - loss: 6.8825e-04 - accuracy: 0.9809 - val_loss: 5.4662e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 668us/step - loss: 5.0565e-04 - accuracy: 0.9827 - val_loss: 8.1186e-04 - val_accuracy: 0.9828\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 669us/step - loss: 6.9013e-04 - accuracy: 0.9759 - val_loss: 5.2811e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 717us/step - loss: 5.3889e-04 - accuracy: 0.9876 - val_loss: 5.1922e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.7513e-04 - accuracy: 0.9868 - val_loss: 5.1264e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 700us/step - loss: 5.8557e-04 - accuracy: 0.9785 - val_loss: 7.7723e-04 - val_accuracy: 0.9828\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 8.4010e-04 - accuracy: 0.9771 - val_loss: 6.2115e-04 - val_accuracy: 0.9828\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 700us/step - loss: 4.2258e-04 - accuracy: 0.9780 - val_loss: 7.4983e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 702us/step - loss: 5.1110e-04 - accuracy: 0.9821 - val_loss: 7.2320e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 6.7915e-04 - accuracy: 0.9885 - val_loss: 4.5925e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 792us/step - loss: 4.8870e-04 - accuracy: 0.9786 - val_loss: 7.5265e-04 - val_accuracy: 1.0000\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 0.0011 - accuracy: 0.9599 - val_loss: 5.1374e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 703us/step - loss: 4.1044e-04 - accuracy: 0.9899 - val_loss: 8.1502e-04 - val_accuracy: 0.9828\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 632us/step - loss: 6.7021e-04 - accuracy: 0.9745 - val_loss: 8.3093e-04 - val_accuracy: 0.9828\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 605us/step - loss: 5.6221e-04 - accuracy: 0.9933 - val_loss: 4.1186e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 625us/step - loss: 5.1896e-04 - accuracy: 0.9857 - val_loss: 6.2368e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 631us/step - loss: 5.0563e-04 - accuracy: 0.9496 - val_loss: 6.8444e-04 - val_accuracy: 0.9828\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 632us/step - loss: 5.9502e-04 - accuracy: 0.9879 - val_loss: 4.3691e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 635us/step - loss: 3.9993e-04 - accuracy: 0.9889 - val_loss: 5.4571e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 634us/step - loss: 4.5586e-04 - accuracy: 0.9905 - val_loss: 8.0977e-04 - val_accuracy: 0.9828\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 684us/step - loss: 6.5757e-04 - accuracy: 0.9646 - val_loss: 4.7181e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 652us/step - loss: 5.3496e-04 - accuracy: 0.9806 - val_loss: 8.6394e-04 - val_accuracy: 0.9828\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 604us/step - loss: 6.6709e-04 - accuracy: 0.9774 - val_loss: 5.6567e-04 - val_accuracy: 0.9828\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 612us/step - loss: 4.3969e-04 - accuracy: 0.9944 - val_loss: 7.5003e-04 - val_accuracy: 0.9828\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 735us/step - loss: 4.9935e-04 - accuracy: 0.9740 - val_loss: 3.9982e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.5933e-04 - accuracy: 0.9791 - val_loss: 5.0005e-04 - val_accuracy: 0.9828\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 891us/step - loss: 3.8555e-04 - accuracy: 0.9871 - val_loss: 6.0712e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 866us/step - loss: 4.0910e-04 - accuracy: 0.9854 - val_loss: 4.7650e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 818us/step - loss: 4.0766e-04 - accuracy: 0.9841 - val_loss: 5.1725e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 849us/step - loss: 5.3493e-04 - accuracy: 0.9878 - val_loss: 5.9573e-04 - val_accuracy: 0.9828\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 798us/step - loss: 8.7766e-04 - accuracy: 0.9771 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 738us/step - loss: 5.9760e-04 - accuracy: 0.9649 - val_loss: 6.8000e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 809us/step - loss: 4.6715e-04 - accuracy: 0.9934 - val_loss: 4.0701e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 761us/step - loss: 3.7335e-04 - accuracy: 0.9850 - val_loss: 3.9363e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 4.1385e-04 - accuracy: 0.9856 - val_loss: 5.2943e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 3.7941e-04 - accuracy: 0.9894 - val_loss: 4.1600e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 737us/step - loss: 4.4246e-04 - accuracy: 0.9939 - val_loss: 4.4195e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 698us/step - loss: 5.5050e-04 - accuracy: 0.9926 - val_loss: 4.7449e-04 - val_accuracy: 0.9828\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 680us/step - loss: 5.0325e-04 - accuracy: 0.9799 - val_loss: 5.6925e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 678us/step - loss: 4.2996e-04 - accuracy: 0.9893 - val_loss: 4.6115e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 699us/step - loss: 3.6316e-04 - accuracy: 0.9879 - val_loss: 5.1473e-04 - val_accuracy: 0.9828\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 790us/step - loss: 4.5717e-04 - accuracy: 0.9767 - val_loss: 5.9156e-04 - val_accuracy: 0.9655\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 797us/step - loss: 4.0085e-04 - accuracy: 0.9950 - val_loss: 3.3210e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 3.4366e-04 - accuracy: 0.9922 - val_loss: 4.1891e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 717us/step - loss: 4.5250e-04 - accuracy: 0.9877 - val_loss: 6.2261e-04 - val_accuracy: 0.9828\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.8853e-04 - accuracy: 0.9904 - val_loss: 5.7360e-04 - val_accuracy: 0.9828\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 958us/step - loss: 5.1492e-04 - accuracy: 0.9880 - val_loss: 3.3441e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 945us/step - loss: 4.6342e-04 - accuracy: 0.9785 - val_loss: 4.2736e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 3.8409e-04 - accuracy: 0.9930 - val_loss: 4.6010e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 3.8950e-04 - accuracy: 0.9946 - val_loss: 3.6337e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 877us/step - loss: 4.1084e-04 - accuracy: 0.9906 - val_loss: 4.0399e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 690us/step - loss: 3.7712e-04 - accuracy: 0.9927 - val_loss: 4.4961e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 701us/step - loss: 4.5848e-04 - accuracy: 0.9889 - val_loss: 3.2451e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 723us/step - loss: 3.7529e-04 - accuracy: 0.9951 - val_loss: 8.2815e-04 - val_accuracy: 0.9828\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 726us/step - loss: 5.7737e-04 - accuracy: 0.9703 - val_loss: 4.1671e-04 - val_accuracy: 0.9828\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 720us/step - loss: 5.4797e-04 - accuracy: 0.9627 - val_loss: 3.6037e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 681us/step - loss: 3.6820e-04 - accuracy: 0.9927 - val_loss: 4.2682e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 711us/step - loss: 5.8702e-04 - accuracy: 0.9685 - val_loss: 3.9848e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 776us/step - loss: 4.1509e-04 - accuracy: 0.9931 - val_loss: 3.6232e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 836us/step - loss: 3.1311e-04 - accuracy: 0.9891 - val_loss: 2.8240e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 809us/step - loss: 4.1164e-04 - accuracy: 0.9937 - val_loss: 5.4495e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 785us/step - loss: 4.4234e-04 - accuracy: 0.9886 - val_loss: 5.6463e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 3.8613e-04 - accuracy: 0.9872 - val_loss: 4.1420e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 727us/step - loss: 3.6098e-04 - accuracy: 0.9976 - val_loss: 4.7973e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 779us/step - loss: 5.3162e-04 - accuracy: 0.9921 - val_loss: 3.6510e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 3.8014e-04 - accuracy: 0.9942 - val_loss: 3.8659e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 917us/step - loss: 4.5910e-04 - accuracy: 0.9974 - val_loss: 4.1393e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.2116e-04 - accuracy: 0.9861 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 6.3024e-04 - accuracy: 0.9674 - val_loss: 5.3097e-04 - val_accuracy: 0.9828\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 732us/step - loss: 4.0977e-04 - accuracy: 0.9896 - val_loss: 5.5371e-04 - val_accuracy: 1.0000\n",
            "6/6 [==============================] - 0s 390us/step - loss: 5.5371e-04 - accuracy: 1.0000\n",
            "Loss = 0.0005537065444514155, Accuracy = 1.0\n",
            "Loss array:  [0.0005443074041977525, 0.0010317516280338168, 0.000695127819199115, 0.0006864182651042938, 0.0005624757613986731, 0.0004552459577098489, 0.0008070990443229675, 0.000988918705843389, 0.0005537065444514155]\n",
            "####################### Iteration   0  #######################\n",
            "Fold 10/10\n",
            "Epoch 1/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.2079 - accuracy: 0.6610 - val_loss: 0.0253 - val_accuracy: 0.8793\n",
            "Epoch 2/170\n",
            "53/53 [==============================] - 0s 805us/step - loss: 0.0213 - accuracy: 0.8351 - val_loss: 0.0151 - val_accuracy: 0.9138\n",
            "Epoch 3/170\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0146 - accuracy: 0.8762 - val_loss: 0.0109 - val_accuracy: 0.9483\n",
            "Epoch 4/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 0.0099 - accuracy: 0.9459 - val_loss: 0.0071 - val_accuracy: 0.9310\n",
            "Epoch 5/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 0.0069 - accuracy: 0.9263 - val_loss: 0.0046 - val_accuracy: 0.9483\n",
            "Epoch 6/170\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.0055 - accuracy: 0.9132 - val_loss: 0.0042 - val_accuracy: 0.9483\n",
            "Epoch 7/170\n",
            "53/53 [==============================] - 0s 753us/step - loss: 0.0038 - accuracy: 0.9337 - val_loss: 0.0039 - val_accuracy: 0.9483\n",
            "Epoch 8/170\n",
            "53/53 [==============================] - 0s 749us/step - loss: 0.0034 - accuracy: 0.9385 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 9/170\n",
            "53/53 [==============================] - 0s 644us/step - loss: 0.0031 - accuracy: 0.9065 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 10/170\n",
            "53/53 [==============================] - 0s 636us/step - loss: 0.0027 - accuracy: 0.9530 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "Epoch 11/170\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0032 - accuracy: 0.9201 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 12/170\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0025 - accuracy: 0.9246 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 13/170\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0033 - accuracy: 0.9470 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 14/170\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0023 - accuracy: 0.9439 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 15/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9623 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 16/170\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0017 - accuracy: 0.9537 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 17/170\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9387 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 18/170\n",
            "53/53 [==============================] - 0s 757us/step - loss: 0.0017 - accuracy: 0.9360 - val_loss: 0.0024 - val_accuracy: 0.9828\n",
            "Epoch 19/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 0.0018 - accuracy: 0.9547 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 20/170\n",
            "53/53 [==============================] - 0s 776us/step - loss: 0.0017 - accuracy: 0.9370 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 21/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.0015 - accuracy: 0.9654 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 22/170\n",
            "53/53 [==============================] - 0s 866us/step - loss: 0.0016 - accuracy: 0.9563 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 23/170\n",
            "53/53 [==============================] - 0s 821us/step - loss: 0.0011 - accuracy: 0.9644 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 24/170\n",
            "53/53 [==============================] - 0s 928us/step - loss: 0.0017 - accuracy: 0.9605 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 25/170\n",
            "53/53 [==============================] - 0s 855us/step - loss: 0.0018 - accuracy: 0.9507 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 26/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 0.0013 - accuracy: 0.9766 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 27/170\n",
            "53/53 [==============================] - 0s 770us/step - loss: 0.0011 - accuracy: 0.9783 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 28/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 0.0014 - accuracy: 0.9669 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 29/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 9.8972e-04 - accuracy: 0.9701 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 30/170\n",
            "53/53 [==============================] - 0s 752us/step - loss: 0.0014 - accuracy: 0.9540 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 31/170\n",
            "53/53 [==============================] - 0s 625us/step - loss: 0.0012 - accuracy: 0.9584 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 32/170\n",
            "53/53 [==============================] - 0s 782us/step - loss: 0.0011 - accuracy: 0.9790 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 33/170\n",
            "53/53 [==============================] - 0s 647us/step - loss: 0.0012 - accuracy: 0.9742 - val_loss: 9.8199e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/170\n",
            "53/53 [==============================] - 0s 609us/step - loss: 9.9420e-04 - accuracy: 0.9821 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 35/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.9445e-04 - accuracy: 0.9786 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 36/170\n",
            "53/53 [==============================] - 0s 896us/step - loss: 9.6349e-04 - accuracy: 0.9776 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 37/170\n",
            "53/53 [==============================] - 0s 871us/step - loss: 8.1917e-04 - accuracy: 0.9815 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 38/170\n",
            "53/53 [==============================] - 0s 830us/step - loss: 9.1444e-04 - accuracy: 0.9784 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 39/170\n",
            "53/53 [==============================] - 0s 846us/step - loss: 9.8180e-04 - accuracy: 0.9762 - val_loss: 9.1093e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/170\n",
            "53/53 [==============================] - 0s 810us/step - loss: 7.4493e-04 - accuracy: 0.9851 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 41/170\n",
            "53/53 [==============================] - 0s 832us/step - loss: 8.3058e-04 - accuracy: 0.9699 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 42/170\n",
            "53/53 [==============================] - 0s 832us/step - loss: 7.3509e-04 - accuracy: 0.9749 - val_loss: 9.2983e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/170\n",
            "53/53 [==============================] - 0s 765us/step - loss: 8.2753e-04 - accuracy: 0.9812 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 44/170\n",
            "53/53 [==============================] - 0s 758us/step - loss: 0.0011 - accuracy: 0.9753 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 45/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 7.5394e-04 - accuracy: 0.9762 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 46/170\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0011 - accuracy: 0.9624 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 47/170\n",
            "53/53 [==============================] - 0s 740us/step - loss: 9.6824e-04 - accuracy: 0.9769 - val_loss: 9.7369e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/170\n",
            "53/53 [==============================] - 0s 740us/step - loss: 0.0013 - accuracy: 0.9742 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 49/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 8.2539e-04 - accuracy: 0.9705 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 50/170\n",
            "53/53 [==============================] - 0s 737us/step - loss: 6.9659e-04 - accuracy: 0.9930 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 51/170\n",
            "53/53 [==============================] - 0s 857us/step - loss: 9.0189e-04 - accuracy: 0.9761 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 52/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 7.9161e-04 - accuracy: 0.9699 - val_loss: 9.0316e-04 - val_accuracy: 0.9655\n",
            "Epoch 53/170\n",
            "53/53 [==============================] - 0s 765us/step - loss: 7.1075e-04 - accuracy: 0.9940 - val_loss: 8.1995e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/170\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7.3764e-04 - accuracy: 0.9805 - val_loss: 9.3672e-04 - val_accuracy: 0.9655\n",
            "Epoch 55/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 7.1784e-04 - accuracy: 0.9738 - val_loss: 9.5935e-04 - val_accuracy: 0.9828\n",
            "Epoch 56/170\n",
            "53/53 [==============================] - 0s 749us/step - loss: 7.6650e-04 - accuracy: 0.9824 - val_loss: 8.9896e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/170\n",
            "53/53 [==============================] - 0s 756us/step - loss: 6.4310e-04 - accuracy: 0.9917 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 58/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 7.0739e-04 - accuracy: 0.9823 - val_loss: 8.6198e-04 - val_accuracy: 0.9828\n",
            "Epoch 59/170\n",
            "53/53 [==============================] - 0s 748us/step - loss: 7.1600e-04 - accuracy: 0.9882 - val_loss: 9.6517e-04 - val_accuracy: 0.9655\n",
            "Epoch 60/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 0.0010 - accuracy: 0.9802 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 61/170\n",
            "53/53 [==============================] - 0s 772us/step - loss: 0.0011 - accuracy: 0.9806 - val_loss: 9.8063e-04 - val_accuracy: 0.9828\n",
            "Epoch 62/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 8.2915e-04 - accuracy: 0.9796 - val_loss: 7.1476e-04 - val_accuracy: 0.9828\n",
            "Epoch 63/170\n",
            "53/53 [==============================] - 0s 820us/step - loss: 5.7747e-04 - accuracy: 0.9901 - val_loss: 7.3352e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/170\n",
            "53/53 [==============================] - 0s 806us/step - loss: 6.2459e-04 - accuracy: 0.9866 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 65/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 8.7722e-04 - accuracy: 0.9826 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 66/170\n",
            "53/53 [==============================] - 0s 760us/step - loss: 9.9158e-04 - accuracy: 0.9790 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 67/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 0.0011 - accuracy: 0.9659 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 68/170\n",
            "53/53 [==============================] - 0s 767us/step - loss: 0.0011 - accuracy: 0.9724 - val_loss: 8.5052e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2097e-04 - accuracy: 0.9848 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 70/170\n",
            "53/53 [==============================] - 0s 872us/step - loss: 7.1097e-04 - accuracy: 0.9813 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 71/170\n",
            "53/53 [==============================] - 0s 788us/step - loss: 6.5828e-04 - accuracy: 0.9871 - val_loss: 8.0339e-04 - val_accuracy: 1.0000\n",
            "Epoch 72/170\n",
            "53/53 [==============================] - 0s 862us/step - loss: 6.4661e-04 - accuracy: 0.9742 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 73/170\n",
            "53/53 [==============================] - 0s 835us/step - loss: 5.7715e-04 - accuracy: 0.9908 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 74/170\n",
            "53/53 [==============================] - 0s 799us/step - loss: 0.0010 - accuracy: 0.9810 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 75/170\n",
            "53/53 [==============================] - 0s 804us/step - loss: 8.1220e-04 - accuracy: 0.9673 - val_loss: 7.6860e-04 - val_accuracy: 1.0000\n",
            "Epoch 76/170\n",
            "53/53 [==============================] - 0s 777us/step - loss: 6.1101e-04 - accuracy: 0.9842 - val_loss: 7.9946e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/170\n",
            "53/53 [==============================] - 0s 765us/step - loss: 5.6796e-04 - accuracy: 0.9795 - val_loss: 0.0015 - val_accuracy: 0.9138\n",
            "Epoch 78/170\n",
            "53/53 [==============================] - 0s 751us/step - loss: 7.6657e-04 - accuracy: 0.9816 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 79/170\n",
            "53/53 [==============================] - 0s 720us/step - loss: 6.8416e-04 - accuracy: 0.9824 - val_loss: 7.0228e-04 - val_accuracy: 0.9655\n",
            "Epoch 80/170\n",
            "53/53 [==============================] - 0s 742us/step - loss: 7.8646e-04 - accuracy: 0.9749 - val_loss: 6.5156e-04 - val_accuracy: 1.0000\n",
            "Epoch 81/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 7.6008e-04 - accuracy: 0.9782 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 82/170\n",
            "53/53 [==============================] - 0s 781us/step - loss: 9.9081e-04 - accuracy: 0.9637 - val_loss: 9.0189e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/170\n",
            "53/53 [==============================] - 0s 755us/step - loss: 7.1630e-04 - accuracy: 0.9937 - val_loss: 7.8238e-04 - val_accuracy: 0.9828\n",
            "Epoch 84/170\n",
            "53/53 [==============================] - 0s 807us/step - loss: 5.8095e-04 - accuracy: 0.9905 - val_loss: 6.3697e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/170\n",
            "53/53 [==============================] - 0s 783us/step - loss: 5.7104e-04 - accuracy: 0.9889 - val_loss: 6.8367e-04 - val_accuracy: 1.0000\n",
            "Epoch 86/170\n",
            "53/53 [==============================] - 0s 766us/step - loss: 5.8160e-04 - accuracy: 0.9903 - val_loss: 7.8246e-04 - val_accuracy: 0.9828\n",
            "Epoch 87/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.5280e-04 - accuracy: 0.9770 - val_loss: 7.1138e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/170\n",
            "53/53 [==============================] - 0s 884us/step - loss: 4.6687e-04 - accuracy: 0.9833 - val_loss: 6.7073e-04 - val_accuracy: 0.9828\n",
            "Epoch 89/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 6.6051e-04 - accuracy: 0.9894 - val_loss: 7.8867e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/170\n",
            "53/53 [==============================] - 0s 745us/step - loss: 5.6474e-04 - accuracy: 0.9885 - val_loss: 6.8861e-04 - val_accuracy: 0.9828\n",
            "Epoch 91/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 5.7175e-04 - accuracy: 0.9910 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 92/170\n",
            "53/53 [==============================] - 0s 682us/step - loss: 8.5288e-04 - accuracy: 0.9854 - val_loss: 6.4911e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/170\n",
            "53/53 [==============================] - 0s 635us/step - loss: 4.7816e-04 - accuracy: 0.9928 - val_loss: 9.7127e-04 - val_accuracy: 0.9655\n",
            "Epoch 94/170\n",
            "53/53 [==============================] - 0s 676us/step - loss: 5.7044e-04 - accuracy: 0.9736 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 95/170\n",
            "53/53 [==============================] - 0s 634us/step - loss: 6.2172e-04 - accuracy: 0.9816 - val_loss: 6.4139e-04 - val_accuracy: 0.9828\n",
            "Epoch 96/170\n",
            "53/53 [==============================] - 0s 662us/step - loss: 4.4301e-04 - accuracy: 0.9892 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 97/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 8.5594e-04 - accuracy: 0.9913 - val_loss: 6.6047e-04 - val_accuracy: 0.9828\n",
            "Epoch 98/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 5.3494e-04 - accuracy: 0.9881 - val_loss: 8.6713e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/170\n",
            "53/53 [==============================] - 0s 687us/step - loss: 5.8093e-04 - accuracy: 0.9749 - val_loss: 7.8793e-04 - val_accuracy: 0.9828\n",
            "Epoch 100/170\n",
            "53/53 [==============================] - 0s 668us/step - loss: 6.0277e-04 - accuracy: 0.9912 - val_loss: 7.8529e-04 - val_accuracy: 0.9828\n",
            "Epoch 101/170\n",
            "53/53 [==============================] - 0s 657us/step - loss: 6.4620e-04 - accuracy: 0.9968 - val_loss: 8.3231e-04 - val_accuracy: 0.9828\n",
            "Epoch 102/170\n",
            "53/53 [==============================] - 0s 673us/step - loss: 5.6126e-04 - accuracy: 0.9871 - val_loss: 7.4633e-04 - val_accuracy: 0.9828\n",
            "Epoch 103/170\n",
            "53/53 [==============================] - 0s 656us/step - loss: 5.9079e-04 - accuracy: 0.9794 - val_loss: 7.3234e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/170\n",
            "53/53 [==============================] - 0s 656us/step - loss: 6.0987e-04 - accuracy: 0.9863 - val_loss: 6.5257e-04 - val_accuracy: 0.9828\n",
            "Epoch 105/170\n",
            "53/53 [==============================] - 0s 662us/step - loss: 5.9609e-04 - accuracy: 0.9936 - val_loss: 8.0724e-04 - val_accuracy: 0.9655\n",
            "Epoch 106/170\n",
            "53/53 [==============================] - 0s 775us/step - loss: 5.9054e-04 - accuracy: 0.9901 - val_loss: 7.1010e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/170\n",
            "53/53 [==============================] - 0s 786us/step - loss: 6.0432e-04 - accuracy: 0.9873 - val_loss: 7.7425e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/170\n",
            "53/53 [==============================] - 0s 796us/step - loss: 6.3436e-04 - accuracy: 0.9944 - val_loss: 6.5384e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/170\n",
            "53/53 [==============================] - 0s 666us/step - loss: 4.8898e-04 - accuracy: 0.9881 - val_loss: 6.7426e-04 - val_accuracy: 0.9828\n",
            "Epoch 110/170\n",
            "53/53 [==============================] - 0s 647us/step - loss: 5.7756e-04 - accuracy: 0.9903 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 111/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.0004e-04 - accuracy: 0.9914 - val_loss: 6.6749e-04 - val_accuracy: 0.9828\n",
            "Epoch 112/170\n",
            "53/53 [==============================] - 0s 841us/step - loss: 4.7306e-04 - accuracy: 0.9876 - val_loss: 7.7613e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/170\n",
            "53/53 [==============================] - 0s 791us/step - loss: 9.2308e-04 - accuracy: 0.9714 - val_loss: 6.1781e-04 - val_accuracy: 0.9828\n",
            "Epoch 114/170\n",
            "53/53 [==============================] - 0s 822us/step - loss: 7.6194e-04 - accuracy: 0.9716 - val_loss: 8.8040e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/170\n",
            "53/53 [==============================] - 0s 803us/step - loss: 5.0460e-04 - accuracy: 0.9726 - val_loss: 5.8472e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/170\n",
            "53/53 [==============================] - 0s 829us/step - loss: 4.2362e-04 - accuracy: 0.9900 - val_loss: 5.8658e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 5.0897e-04 - accuracy: 0.9838 - val_loss: 9.0129e-04 - val_accuracy: 0.9655\n",
            "Epoch 118/170\n",
            "53/53 [==============================] - 0s 715us/step - loss: 6.2552e-04 - accuracy: 0.9793 - val_loss: 7.2643e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/170\n",
            "53/53 [==============================] - 0s 695us/step - loss: 5.1838e-04 - accuracy: 0.9902 - val_loss: 5.9975e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/170\n",
            "53/53 [==============================] - 0s 699us/step - loss: 7.4525e-04 - accuracy: 0.9797 - val_loss: 7.4224e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/170\n",
            "53/53 [==============================] - 0s 697us/step - loss: 4.7279e-04 - accuracy: 0.9875 - val_loss: 5.7164e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/170\n",
            "53/53 [==============================] - 0s 624us/step - loss: 9.0707e-04 - accuracy: 0.9863 - val_loss: 9.0063e-04 - val_accuracy: 0.9655\n",
            "Epoch 123/170\n",
            "53/53 [==============================] - 0s 643us/step - loss: 4.7719e-04 - accuracy: 0.9939 - val_loss: 6.0626e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/170\n",
            "53/53 [==============================] - 0s 707us/step - loss: 5.7058e-04 - accuracy: 0.9922 - val_loss: 6.4932e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 5.0746e-04 - accuracy: 0.9882 - val_loss: 5.9693e-04 - val_accuracy: 0.9828\n",
            "Epoch 126/170\n",
            "53/53 [==============================] - 0s 723us/step - loss: 4.0271e-04 - accuracy: 0.9960 - val_loss: 7.1277e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/170\n",
            "53/53 [==============================] - 0s 629us/step - loss: 3.7688e-04 - accuracy: 0.9853 - val_loss: 6.0780e-04 - val_accuracy: 0.9828\n",
            "Epoch 128/170\n",
            "53/53 [==============================] - 0s 620us/step - loss: 4.6864e-04 - accuracy: 0.9915 - val_loss: 7.2667e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/170\n",
            "53/53 [==============================] - 0s 629us/step - loss: 5.3891e-04 - accuracy: 0.9972 - val_loss: 5.9842e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/170\n",
            "53/53 [==============================] - 0s 640us/step - loss: 3.3632e-04 - accuracy: 0.9959 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 131/170\n",
            "53/53 [==============================] - 0s 617us/step - loss: 6.1380e-04 - accuracy: 0.9843 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 132/170\n",
            "53/53 [==============================] - 0s 643us/step - loss: 5.4952e-04 - accuracy: 0.9785 - val_loss: 7.2598e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/170\n",
            "53/53 [==============================] - 0s 666us/step - loss: 5.4114e-04 - accuracy: 0.9798 - val_loss: 5.7138e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/170\n",
            "53/53 [==============================] - 0s 663us/step - loss: 4.8704e-04 - accuracy: 0.9908 - val_loss: 6.6483e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 5.9909e-04 - accuracy: 0.9922 - val_loss: 6.1226e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/170\n",
            "53/53 [==============================] - 0s 995us/step - loss: 4.4840e-04 - accuracy: 0.9975 - val_loss: 5.6346e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/170\n",
            "53/53 [==============================] - 0s 859us/step - loss: 4.4884e-04 - accuracy: 0.9955 - val_loss: 5.0358e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/170\n",
            "53/53 [==============================] - 0s 810us/step - loss: 3.9100e-04 - accuracy: 0.9885 - val_loss: 7.9085e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/170\n",
            "53/53 [==============================] - 0s 833us/step - loss: 7.8739e-04 - accuracy: 0.9677 - val_loss: 7.1887e-04 - val_accuracy: 0.9828\n",
            "Epoch 140/170\n",
            "53/53 [==============================] - 0s 697us/step - loss: 5.7036e-04 - accuracy: 0.9853 - val_loss: 6.0447e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/170\n",
            "53/53 [==============================] - 0s 672us/step - loss: 7.7213e-04 - accuracy: 0.9901 - val_loss: 7.4034e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/170\n",
            "53/53 [==============================] - 0s 652us/step - loss: 4.0168e-04 - accuracy: 0.9971 - val_loss: 8.8513e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/170\n",
            "53/53 [==============================] - 0s 664us/step - loss: 4.4924e-04 - accuracy: 0.9855 - val_loss: 6.6106e-04 - val_accuracy: 0.9828\n",
            "Epoch 144/170\n",
            "53/53 [==============================] - 0s 852us/step - loss: 4.3558e-04 - accuracy: 0.9874 - val_loss: 6.9517e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/170\n",
            "53/53 [==============================] - 0s 743us/step - loss: 4.3374e-04 - accuracy: 0.9997 - val_loss: 5.0708e-04 - val_accuracy: 0.9828\n",
            "Epoch 146/170\n",
            "53/53 [==============================] - 0s 661us/step - loss: 3.3467e-04 - accuracy: 0.9973 - val_loss: 5.5649e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/170\n",
            "53/53 [==============================] - 0s 678us/step - loss: 3.7727e-04 - accuracy: 0.9902 - val_loss: 4.9850e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/170\n",
            "53/53 [==============================] - 0s 638us/step - loss: 3.7736e-04 - accuracy: 0.9991 - val_loss: 8.1120e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/170\n",
            "53/53 [==============================] - 0s 666us/step - loss: 4.4742e-04 - accuracy: 0.9863 - val_loss: 6.2156e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/170\n",
            "53/53 [==============================] - 0s 649us/step - loss: 5.7594e-04 - accuracy: 0.9952 - val_loss: 7.2302e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/170\n",
            "53/53 [==============================] - 0s 635us/step - loss: 4.6680e-04 - accuracy: 0.9916 - val_loss: 5.0379e-04 - val_accuracy: 0.9828\n",
            "Epoch 152/170\n",
            "53/53 [==============================] - 0s 955us/step - loss: 3.9413e-04 - accuracy: 0.9906 - val_loss: 7.3373e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.5955e-04 - accuracy: 0.9953 - val_loss: 7.4582e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/170\n",
            "53/53 [==============================] - 0s 866us/step - loss: 5.1675e-04 - accuracy: 0.9873 - val_loss: 5.5028e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/170\n",
            "53/53 [==============================] - 0s 828us/step - loss: 4.8862e-04 - accuracy: 0.9864 - val_loss: 6.6877e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/170\n",
            "53/53 [==============================] - 0s 832us/step - loss: 5.1818e-04 - accuracy: 0.9958 - val_loss: 6.4079e-04 - val_accuracy: 0.9828\n",
            "Epoch 157/170\n",
            "53/53 [==============================] - 0s 773us/step - loss: 3.7050e-04 - accuracy: 0.9989 - val_loss: 6.9002e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/170\n",
            "53/53 [==============================] - 0s 716us/step - loss: 8.5257e-04 - accuracy: 0.9776 - val_loss: 5.8583e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/170\n",
            "53/53 [==============================] - 0s 747us/step - loss: 4.9997e-04 - accuracy: 0.9960 - val_loss: 7.1207e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/170\n",
            "53/53 [==============================] - 0s 730us/step - loss: 5.9633e-04 - accuracy: 0.9924 - val_loss: 6.1181e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/170\n",
            "53/53 [==============================] - 0s 746us/step - loss: 6.2032e-04 - accuracy: 0.9835 - val_loss: 8.7767e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/170\n",
            "53/53 [==============================] - 0s 686us/step - loss: 6.5874e-04 - accuracy: 0.9907 - val_loss: 5.2719e-04 - val_accuracy: 0.9655\n",
            "Epoch 163/170\n",
            "53/53 [==============================] - 0s 682us/step - loss: 4.6650e-04 - accuracy: 0.9885 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 164/170\n",
            "53/53 [==============================] - 0s 723us/step - loss: 6.0681e-04 - accuracy: 0.9958 - val_loss: 5.6220e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/170\n",
            "53/53 [==============================] - 0s 714us/step - loss: 2.9387e-04 - accuracy: 0.9915 - val_loss: 4.5287e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/170\n",
            "53/53 [==============================] - 0s 736us/step - loss: 3.8486e-04 - accuracy: 0.9985 - val_loss: 8.8153e-04 - val_accuracy: 0.9483\n",
            "Epoch 167/170\n",
            "53/53 [==============================] - 0s 706us/step - loss: 4.7356e-04 - accuracy: 0.9770 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 168/170\n",
            "53/53 [==============================] - 0s 709us/step - loss: 5.7892e-04 - accuracy: 0.9743 - val_loss: 6.5606e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/170\n",
            "53/53 [==============================] - 0s 717us/step - loss: 4.4557e-04 - accuracy: 0.9917 - val_loss: 4.9364e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/170\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 4.3578e-04 - accuracy: 0.9929 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "6/6 [==============================] - 0s 406us/step - loss: 0.0011 - accuracy: 0.9828\n",
            "Loss = 0.0011370107531547546, Accuracy = 0.982758641242981\n",
            "Loss array:  [0.0005443074041977525, 0.0010317516280338168, 0.000695127819199115, 0.0006864182651042938, 0.0005624757613986731, 0.0004552459577098489, 0.0008070990443229675, 0.000988918705843389, 0.0005537065444514155, 0.0011370107531547546]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "NUM_EPOCHS = 170# 180\n",
        "BATCH_SIZE = 8\n",
        "K_FOLD_SPLITS = 10\n",
        "\n",
        "\n",
        "# Define the cross-validation process to be used inside cross_val_Score evaluation\n",
        "cv = KFold(n_splits=K_FOLD_SPLITS)\n",
        "\n",
        "# Handling for accommodating multiple targets\n",
        "Y1 = y_train_norm[:,0]\n",
        "Y2 = y_train_norm[:,1]\n",
        "targets = (Y1, Y2)\n",
        "\n",
        "X = X_train_norm\n",
        "\n",
        "i = 0\n",
        "arr_loss = list()\n",
        "arr_rmse = list()\n",
        "min_loss = 1000000\n",
        "best_model = None\n",
        "history = None\n",
        "history_best_model = None\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_indices, val_indices) in enumerate(cv.split(X_train_norm)):\n",
        "  print('####################### Iteration  ', i, ' #######################')\n",
        "  print(f'Fold {fold+1}/{K_FOLD_SPLITS}')\n",
        "  X_train_fold, y_train_fold = X_train_norm[train_indices], y_train_norm[train_indices]\n",
        "  X_val_fold, y_val_fold = X_train_norm[val_indices], y_train_norm[val_indices]\n",
        "\n",
        "  # Convert the folds into tf.data.Dataset\n",
        "  train_dataset_fold = make_dataset(X_train_fold, y_train_fold, batch_size=batch_size, shuffle=True)\n",
        "  val_dataset_fold = make_dataset(X_val_fold, y_val_fold, batch_size=batch_size)\n",
        "\n",
        "\n",
        "  model = my_model()\n",
        "  history = model.fit(train_dataset_fold, epochs=NUM_EPOCHS, validation_data=val_dataset_fold)\n",
        "\n",
        "  #testing on validation set process\n",
        "  loss, accuracy = model.evaluate(val_dataset_fold, verbose=1)\n",
        "  print(f\"Loss = {loss}, Accuracy = {accuracy}\")\n",
        "\n",
        "  # Check if this is the best model based on validation loss\n",
        "  if loss < min_loss:\n",
        "      best_model = model\n",
        "      history_best_model = history.history\n",
        "      min_loss = loss\n",
        "\n",
        "  # Append the current fold's loss and accuracy to the tracking lists\n",
        "  arr_loss.append(loss)\n",
        "  arr_rmse.append(accuracy)  # Assuming you want to track accuracy; change if needed\n",
        "  print('Loss array: ', arr_loss)\n",
        "\n",
        "# Saving the best model within the k folds\n",
        "best_model.save(FILENAME_BEST_MODEL)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results\n",
        "- Plot of k-cross validation performance\n",
        "- Scatter Plot of prediction results against true values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "xKSkPnO4ETWD",
        "outputId": "564ee694-d414-4d21-bbd9-f838e7249dd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loss across k folds\n",
        "plot_line(arr_loss, \"Loss across k-folds\", \"Value of k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training and Validation Loss\n",
        "#plot_loss_curve(history_best_model, NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the test dataset\n",
        "X_test_norm = scaler_input.transform(X_test)\n",
        "y_test_norm = scaler_output.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-erJ0l_Yu4P",
        "outputId": "9cff94b2-e4ca-491b-8459-aeaa1eff7606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time: 0.0238 seconds\n",
            "Maxval here is:  25.192127\n",
            "Maxval here is:  0.9278\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "Y_pred_normalized = best_model.predict(X_test_norm)\n",
        "end_time = time.time()\n",
        "Y_pred_normalized_entire = best_model.predict(dataset_x_norm)\n",
        "# Calculate elapsed time in seconds\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Elapsed time:\", round(elapsed_time, 3), \"seconds\")\n",
        "\n",
        "\n",
        "Y_pred = scaler_output.inverse_transform(Y_pred_normalized)\n",
        "Y_pred_entire = scaler_output.inverse_transform(Y_pred_normalized_entire)\n",
        "Y_actual = np.array(y_test)\n",
        "Y_actual_entire = np.array(df_targets)\n",
        "# Moisture Content\n",
        "scatter_plot(trueValues=Y_actual[:,0], \n",
        "             predictions=Y_pred[:,0], \n",
        "             title=\"Moisture Content\")\n",
        "a, b = np.polyfit(Y_pred[:, 0], Y_actual[:, 0], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,0]), max(Y_actual[:,0])), 1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_MC.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)\n",
        "\n",
        "# Bulk Density\n",
        "scatter_plot(trueValues=Y_actual[:,1], \n",
        "             predictions=Y_pred[:,1], \n",
        "             title=\"Bulk Density\")\n",
        "plt.xlim([min(min(Y_pred[:,1]), min(Y_actual[:,1]))-0.1, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1])\n",
        "a, b = np.polyfit(Y_pred[:, 1], Y_actual[:, 1], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1, 0.1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_BD.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Error analysis\n",
        "- R squared calculation\n",
        "- Mean accuracy error"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### R squared calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9951\n",
            "0.9435\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# MOISTURE CONTENT\n",
        "#   - R-squared\n",
        "# mc_r2_score = r2_score(Y_actual[:, 0], Y_pred[:, 0])\n",
        "mc_r2_score = calculate_r_squared(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"{:#.4g}\".format(mc_r2_score))\n",
        "\n",
        "# BULK DENSITY\n",
        "#   - R-squared\n",
        "# bd_r2_score = r2_score(Y_actual[:, 1], Y_pred[:, 1])\n",
        "bd_r2_score = calculate_r_squared(y_true=Y_actual[:, 1], y_pred=Y_pred[:, 1])\n",
        "print(\"{:#.4g}\".format(bd_r2_score))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE_MC:  0.2576\n",
            "RMSE_BD:  0.02913\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sigfig import round\n",
        "\n",
        "#MC\n",
        "rmse_mc = np.sqrt(mean_squared_error(Y_actual[:, 0], Y_pred[:, 0]))\n",
        "print('RMSE_MC: ', \"{0:.4g}\".format(rmse_mc))\n",
        "\n",
        "#BD\n",
        "rmse_bd = np.sqrt(mean_squared_error(Y_actual[:, 1], Y_pred[:, 1]))\n",
        "print('RMSE_BD: ', \"{0:.4g}\".format(rmse_bd))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will compare with the results from Trabelsi's paper. This is single moisture prediction \n",
        "\n",
        "R^2 : 0.993\\\n",
        "Mean Squared Error: 0.028\\\n",
        "Mean absolute Error: 0.135\\\n",
        "Min. Absolute Error: 0.004\\\n",
        "Max Absolute Error: 0.441"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9949\n",
            "Mean Squared Error:  0.06634\n",
            "Mean Absolute Error:  0.1895\n",
            "Min Absolute Error:  0.0016549682617181816\n",
            "Max Absolute Error:  0.8069008636474617\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,max_error, r2_score\n",
        "from sigfig import round\n",
        "\n",
        "mc_r2_score = r2_score(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual[:, 0], Y_pred[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual[:, 0], Y_pred[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual[:,0])):\n",
        "    sum = Y_actual[:,0][i] - Y_pred[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9966\n",
            "Mean Squared Error:  0.04889\n",
            "Mean Absolute Error:  0.1678\n",
            "Min Absolute Error:  0.00019775390624943157\n",
            "Max Absolute Error:  0.9824071502685534\n"
          ]
        }
      ],
      "source": [
        "mc_r2_score = r2_score(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual_entire[:,0])):\n",
        "    sum = Y_actual_entire[:,0][i] - Y_pred_entire[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
