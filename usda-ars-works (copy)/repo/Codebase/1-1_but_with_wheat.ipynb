{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {},
      "outputs": [],
      "source": [
        "#GRAIN_TYPE = 'Wheat'\n",
        "#GRAIN_TYPE = 'newWheatData'\n",
        "#GRAIN_TYPE = 'CornAdded_Type'\n",
        "GRAIN_TYPE = 'WheatAdded_Type'\n",
        "# GRAIN_TYPE = 'Oats'\n",
        "\n",
        "# GRAIN_TYPE = 'Barley'\n",
        "# GRAIN_TYPE = 'Sorghum'\n",
        "# GRAIN_TYPE = 'Soybeans'\n",
        "# GRAIN_TYPE = 'Corn'\n",
        "\n",
        "FILENAME_BEST_MODEL = 'Best models/target_2/hybrid_models/' + GRAIN_TYPE + '_t2_kcv_dnn_mc.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNGoIGbc0kw_",
        "outputId": "279cc9c8-32fd-4f89-e56b-83a0a31081dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ]
        }
      ],
      "source": [
        "#Import libraries\n",
        "import requests\n",
        "import pydot\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Data visualization\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "#Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Machine Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Activation, BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "np.random.seed(39)\n",
        "random.seed(39)\n",
        "tf.random.set_seed(39)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "# print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {
        "id": "nxHO_qH0Zi5J"
      },
      "outputs": [],
      "source": [
        "def calculate_r_squared(y_true, y_pred):\n",
        "   corr_matrix = np.corrcoef(y_true, y_pred)\n",
        "   corr = corr_matrix[0,1]\n",
        "   R_sq = corr**2\n",
        "   return R_sq\n",
        "\n",
        "def plot_loss_curve(history, epoch_size):\n",
        "    loss_train = history.history['loss']\n",
        "    loss_val = history.history['val_loss']\n",
        "    epochs = range(0,epoch_size)\n",
        "    \n",
        "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "    \n",
        "    plt.title('Training and Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_line(metric, title, xlabel):\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.title(title, fontsize = 16)\n",
        "    plt.plot(metric)\n",
        "    plt.xlabel(xlabel, fontsize = 14)\n",
        "    plt.grid()\n",
        "    plt.legend(loc= \"best\")\n",
        "    plt.show()\n",
        "\n",
        "def scatter_plot(trueValues, predictions, title):\n",
        "  plt.figure(figsize=(8,3))\n",
        "  ax = plt.axes()\n",
        "  maxVal = max( max(trueValues), max(predictions) )\n",
        "\n",
        "  ax.scatter(x=predictions, y=trueValues)\n",
        "  ax.plot([0, 1, maxVal], [0, 1, maxVal], label=\"Ideal fit\")\n",
        "  print('Maxval here is: ', maxVal)\n",
        "  plt.title(title, fontsize = 16)\n",
        "  plt.xlabel(\"Predictions\", fontsize = 14)\n",
        "  plt.ylabel(\"Real\", fontsize = 14)\n",
        "  plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "s3pvA5g-zdgv",
        "outputId": "7a7208f1-6b68-4eba-ad1d-9108d0df66ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From USDA:  ../Datasets/processed/WheatAdded_Type.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Variety</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>8.8258</td>\n",
              "      <td>-55.973</td>\n",
              "      <td>-415.973</td>\n",
              "      <td>2.416</td>\n",
              "      <td>0.243</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-6.341975</td>\n",
              "      <td>62.3</td>\n",
              "      <td>61.7806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>10.2572</td>\n",
              "      <td>-114.289</td>\n",
              "      <td>-474.289</td>\n",
              "      <td>2.412</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-11.142320</td>\n",
              "      <td>71.2</td>\n",
              "      <td>82.0576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>11.5679</td>\n",
              "      <td>-168.171</td>\n",
              "      <td>-528.171</td>\n",
              "      <td>2.395</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-14.537729</td>\n",
              "      <td>80.1</td>\n",
              "      <td>104.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>12.8795</td>\n",
              "      <td>134.849</td>\n",
              "      <td>-585.151</td>\n",
              "      <td>2.390</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>10.470049</td>\n",
              "      <td>89.0</td>\n",
              "      <td>128.7950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>13.7649</td>\n",
              "      <td>83.502</td>\n",
              "      <td>-636.498</td>\n",
              "      <td>2.371</td>\n",
              "      <td>0.238</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>6.066299</td>\n",
              "      <td>97.9</td>\n",
              "      <td>151.4139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 Variety  Freq  d(cm)    M%  Density     Attn    Phase  \\\n",
              "0           0  KANSAS   7.0    8.9  11.3   0.7356   8.8258  -55.973   \n",
              "1           1  KANSAS   8.0    8.9  11.3   0.7356  10.2572 -114.289   \n",
              "2           2  KANSAS   9.0    8.9  11.3   0.7356  11.5679 -168.171   \n",
              "3           3  KANSAS  10.0    8.9  11.3   0.7356  12.8795  134.849   \n",
              "4           4  KANSAS  11.0    8.9  11.3   0.7356  13.7649   83.502   \n",
              "\n",
              "   Phase_Corr  Permittivity_real  Permittivity_imaginary       Type  \\\n",
              "0    -415.973              2.416                   0.243  15.855506   \n",
              "1    -474.289              2.412                   0.246  15.855506   \n",
              "2    -528.171              2.395                   0.246  15.855506   \n",
              "3    -585.151              2.390                   0.246  15.855506   \n",
              "4    -636.498              2.371                   0.238  15.855506   \n",
              "\n",
              "   Phase/Attn  Freq*d(cm)  Freq*Attn  \n",
              "0   -6.341975        62.3    61.7806  \n",
              "1  -11.142320        71.2    82.0576  \n",
              "2  -14.537729        80.1   104.1111  \n",
              "3   10.470049        89.0   128.7950  \n",
              "4    6.066299        97.9   151.4139  "
            ]
          },
          "execution_count": 381,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#url dataset\n",
        "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
        "\n",
        "#read in excel format\n",
        "df = pd.read_csv(URL)\n",
        "#df = df[df['Variety'] == 'SOUTH DAKOTA']\n",
        "#df = df[(df['Density'] >= 0.72) & (df['Density'] <= 0.88)]\n",
        "\n",
        "print(\"From USDA: \", URL)\n",
        "\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUzjHHV2stm"
      },
      "source": [
        "# 2. Overview of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Xohz7dGh2sXH",
        "outputId": "7d018cd8-018a-45d3-b1b7-ba9fc14aa5e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>402.500000</td>\n",
              "      <td>10.811414</td>\n",
              "      <td>7.088834</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>0.796298</td>\n",
              "      <td>18.410033</td>\n",
              "      <td>-4.604663</td>\n",
              "      <td>-633.488065</td>\n",
              "      <td>2.912112</td>\n",
              "      <td>0.499187</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>-0.377074</td>\n",
              "      <td>77.159677</td>\n",
              "      <td>215.799030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>232.816451</td>\n",
              "      <td>3.530055</td>\n",
              "      <td>1.554604</td>\n",
              "      <td>3.794772</td>\n",
              "      <td>0.067384</td>\n",
              "      <td>5.946835</td>\n",
              "      <td>101.951444</td>\n",
              "      <td>219.510760</td>\n",
              "      <td>0.305758</td>\n",
              "      <td>0.186739</td>\n",
              "      <td>0.629743</td>\n",
              "      <td>6.071761</td>\n",
              "      <td>32.552200</td>\n",
              "      <td>124.108325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>10.260000</td>\n",
              "      <td>0.625400</td>\n",
              "      <td>8.002300</td>\n",
              "      <td>-179.335000</td>\n",
              "      <td>-1274.435000</td>\n",
              "      <td>2.340000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>15.352809</td>\n",
              "      <td>-17.418676</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>40.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>201.250000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>13.680000</td>\n",
              "      <td>0.745400</td>\n",
              "      <td>13.524700</td>\n",
              "      <td>-88.842000</td>\n",
              "      <td>-793.405750</td>\n",
              "      <td>2.688500</td>\n",
              "      <td>0.337000</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-5.077754</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>107.817375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>402.500000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>16.225000</td>\n",
              "      <td>0.801300</td>\n",
              "      <td>18.131600</td>\n",
              "      <td>-9.838500</td>\n",
              "      <td>-602.380500</td>\n",
              "      <td>2.861500</td>\n",
              "      <td>0.470500</td>\n",
              "      <td>16.400366</td>\n",
              "      <td>-0.589378</td>\n",
              "      <td>71.200000</td>\n",
              "      <td>195.600450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>603.750000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>18.810000</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>23.098000</td>\n",
              "      <td>80.957250</td>\n",
              "      <td>-456.055750</td>\n",
              "      <td>3.109750</td>\n",
              "      <td>0.639000</td>\n",
              "      <td>16.401988</td>\n",
              "      <td>4.300734</td>\n",
              "      <td>100.100000</td>\n",
              "      <td>310.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>805.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>24.410000</td>\n",
              "      <td>0.927800</td>\n",
              "      <td>29.897000</td>\n",
              "      <td>179.048000</td>\n",
              "      <td>-235.044000</td>\n",
              "      <td>4.038000</td>\n",
              "      <td>0.987000</td>\n",
              "      <td>17.344167</td>\n",
              "      <td>14.827701</td>\n",
              "      <td>160.200000</td>\n",
              "      <td>538.146000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0        Freq       d(cm)          M%     Density        Attn  \\\n",
              "count  806.000000  806.000000  806.000000  806.000000  806.000000  806.000000   \n",
              "mean   402.500000   10.811414    7.088834   16.189541    0.796298   18.410033   \n",
              "std    232.816451    3.530055    1.554604    3.794772    0.067384    5.946835   \n",
              "min      0.000000    5.000000    4.400000   10.260000    0.625400    8.002300   \n",
              "25%    201.250000    8.000000    6.500000   13.680000    0.745400   13.524700   \n",
              "50%    402.500000   11.000000    7.700000   16.225000    0.801300   18.131600   \n",
              "75%    603.750000   13.000000    7.700000   18.810000    0.842000   23.098000   \n",
              "max    805.000000   18.000000    8.900000   24.410000    0.927800   29.897000   \n",
              "\n",
              "            Phase   Phase_Corr  Permittivity_real  Permittivity_imaginary  \\\n",
              "count  806.000000   806.000000         806.000000              806.000000   \n",
              "mean    -4.604663  -633.488065           2.912112                0.499187   \n",
              "std    101.951444   219.510760           0.305758                0.186739   \n",
              "min   -179.335000 -1274.435000           2.340000                0.220000   \n",
              "25%    -88.842000  -793.405750           2.688500                0.337000   \n",
              "50%     -9.838500  -602.380500           2.861500                0.470500   \n",
              "75%     80.957250  -456.055750           3.109750                0.639000   \n",
              "max    179.048000  -235.044000           4.038000                0.987000   \n",
              "\n",
              "             Type  Phase/Attn  Freq*d(cm)   Freq*Attn  \n",
              "count  806.000000  806.000000  806.000000  806.000000  \n",
              "mean    16.189541   -0.377074   77.159677  215.799030  \n",
              "std      0.629743    6.071761   32.552200  124.108325  \n",
              "min     15.352809  -17.418676   22.000000   40.011500  \n",
              "25%     15.855506   -5.077754   52.800000  107.817375  \n",
              "50%     16.400366   -0.589378   71.200000  195.600450  \n",
              "75%     16.401988    4.300734  100.100000  310.863000  \n",
              "max     17.344167   14.827701  160.200000  538.146000  "
            ]
          },
          "execution_count": 382,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data summary\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmFqsYQyGnM",
        "outputId": "54445a7f-a2c8-452a-9651-42dbbe682d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(806, 15)"
            ]
          },
          "execution_count": 383,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimension of the dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fep-GIv4yUuf",
        "outputId": "c46072fa-aa7f-4549-9a1d-4c5b05d11112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unnamed: 0                0\n",
              "Variety                   0\n",
              "Freq                      0\n",
              "d(cm)                     0\n",
              "M%                        0\n",
              "Density                   0\n",
              "Attn                      0\n",
              "Phase                     0\n",
              "Phase_Corr                0\n",
              "Permittivity_real         0\n",
              "Permittivity_imaginary    0\n",
              "Type                      0\n",
              "Phase/Attn                0\n",
              "Freq*d(cm)                0\n",
              "Freq*Attn                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 384,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check info about missing values in dataframe\n",
        "df.isnull().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_TKP9VymuK"
      },
      "source": [
        "# Exploratory Data Analysis\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz1g9T3FzhF0"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "\n",
        "1.   Convert dataframe to numpy array for flexibility.\n",
        "2. Split our data into training and testing datasets and store the target values in different variables.\n",
        "3.   Normalize the features by applying some operations in the data sets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 385,
      "metadata": {
        "id": "T0juhagf1M2I"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy array\n",
        "df_features = df[['Freq', \n",
        "                    'd(cm)', \n",
        "                    'Attn', \n",
        "                    'Phase_Corr', \n",
        "                    'Permittivity_real', \n",
        "                    'Permittivity_imaginary',\n",
        "                    'Type',\n",
        "                    ]]\n",
        "\n",
        "df_targets = df[['M%', 'Density']]\n",
        "# df_targets = df[['Density', 'M%']]\n",
        "\n",
        "dataset_x = df_features.to_numpy()\n",
        "dataset_y = df_targets.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting dataset to test and train+validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 386,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform train-test split on RAW DATA\n",
        "X_trainVal, X_test, y_trainVal, y_test = train_test_split(dataset_x, dataset_y, \n",
        "                                                    test_size=0.15\n",
        "                                                    ,random_state=42\n",
        "                                                    )\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainVal, y_trainVal, \n",
        "                                                    test_size=0.15 #validation split\n",
        "                                                    ,random_state=42\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Normalizing the data set\n",
        "scaler_input = MinMaxScaler()\n",
        "scaler_output = MinMaxScaler()\n",
        "\n",
        "# Normalize Train set\n",
        "X_train_norm = scaler_input.fit_transform(X_train)\n",
        "y_train_norm = scaler_output.fit_transform(y_train)\n",
        "\n",
        "# Normalize Validation set\n",
        "X_val_norm = scaler_input.fit_transform(X_val)\n",
        "y_val_norm = scaler_output.fit_transform(y_val)\n",
        "\n",
        "# Normalize the entire dataset (input features)\n",
        "dataset_x_norm = scaler_input.transform(dataset_x)  # Use transform, NOT fit_transform\n",
        "\n",
        "# Normalize the entire dataset (output targets)\n",
        "dataset_y_norm = scaler_output.transform(dataset_y)  # Use transform, NOT fit_transform\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKfjwMP0Tzn"
      },
      "source": [
        "# K-cross Validation\n",
        "* Input features: 7\n",
        "* Output targets: 2\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 388,
      "metadata": {
        "id": "l31WJZ7Z0ONb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_162\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_648 (Dense)            (None, 49)                392       \n",
            "_________________________________________________________________\n",
            "dense_649 (Dense)            (None, 49)                2450      \n",
            "_________________________________________________________________\n",
            "dense_650 (Dense)            (None, 49)                2450      \n",
            "_________________________________________________________________\n",
            "dense_651 (Dense)            (None, 2)                 100       \n",
            "=================================================================\n",
            "Total params: 5,392\n",
            "Trainable params: 5,392\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import layers, Sequential, regularizers\n",
        "\n",
        "# Define the model-building function\n",
        "def my_model():\n",
        "  my_model = Sequential([\n",
        "    \n",
        "    layers.Dense(49, input_shape=(7,), activation='relu', \n",
        "                #  kernel_regularizer=regularizers.l2(0.01)\n",
        "                 ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.1),\n",
        "\n",
        "\n",
        "    layers.Dense(49, activation='relu', \n",
        "                # kernel_regularizer=regularizers.l2(0.01)\n",
        "                ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.1),````\n",
        "\n",
        "    layers.Dense(49, activation='relu', \n",
        "                # kernel_regularizer=regularizers.l2(0.01)\n",
        "                ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.2),\n",
        "    \n",
        "    layers.Dense(2, activation='sigmoid')  # Output layer with 2 neurons for the two regression targets\n",
        "  ])\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.0006105) # 0.0006 \n",
        "  my_model.compile(\n",
        "      optimizer = opt,\n",
        "      loss = 'mse',\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "\n",
        "  return my_model\n",
        "\n",
        "plot_model(my_model(), show_shapes=True, show_layer_names=True)\n",
        "my_model().summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running model with KCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khCKKB74hFVT",
        "outputId": "37e79cdf-4183-4559-f560-fceb2fc0c630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/190\n",
            "Epoch 1/190\n",
            "Epoch 1/190\n",
            "Epoch 1/190\n",
            "Epoch 1/190\n",
            "Epoch 1/190\n",
            "Epoch 1/190\n",
            "Epoch 1/190\n",
            "Epoch 1/190\n",
            "Epoch 1/190\n",
            " 1/53 [..............................] - ETA: 1:17 - loss: 0.0711 - accuracy: 0.4000WARNING:tensorflow:5 out of the last 100600 calls to <function Model.make_train_function.<locals>.train_function at 0x7f42f453e7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "53/53 [==============================] - 2s 12ms/step - loss: 0.0633 - accuracy: 0.6552 - val_loss: 0.0341 - val_accuracy: 0.8103\n",
            "Epoch 2/190\n",
            "53/53 [==============================] - 2s 12ms/step - loss: 0.0519 - accuracy: 0.7445 - val_loss: 0.0291 - val_accuracy: 0.8621\n",
            "53/53 [==============================] - 2s 12ms/step - loss: 0.0624 - accuracy: 0.6516 - val_loss: 0.0395 - val_accuracy: 0.8136\n",
            "Epoch 2/190\n",
            "Epoch 2/190\n",
            "53/53 [==============================] - 2s 11ms/step - loss: 0.0626 - accuracy: 0.6181 - val_loss: 0.0463 - val_accuracy: 0.8966\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0373 - accuracy: 0.8000Epoch 2/190\n",
            "53/53 [==============================] - 2s 12ms/step - loss: 0.0594 - accuracy: 0.7345 - val_loss: 0.0488 - val_accuracy: 0.8276\n",
            "53/53 [==============================] - 2s 12ms/step - loss: 0.0578 - accuracy: 0.5800 - val_loss: 0.0406 - val_accuracy: 0.8621\n",
            "Epoch 2/190\n",
            "Epoch 2/190\n",
            "53/53 [==============================] - 2s 11ms/step - loss: 0.0517 - accuracy: 0.6437 - val_loss: 0.0304 - val_accuracy: 0.9310\n",
            "Epoch 2/190\n",
            "53/53 [==============================] - 2s 12ms/step - loss: 0.0584 - accuracy: 0.6551 - val_loss: 0.0426 - val_accuracy: 0.7586\n",
            "53/53 [==============================] - 2s 12ms/step - loss: 0.0623 - accuracy: 0.6400 - val_loss: 0.0336 - val_accuracy: 0.8621\n",
            "Epoch 2/190\n",
            "Epoch 2/190\n",
            "53/53 [==============================] - 2s 12ms/step - loss: 0.0576 - accuracy: 0.8094 - val_loss: 0.0332 - val_accuracy: 0.8475\n",
            "20/53 [==========>...................] - ETA: 0s - loss: 0.0433 - accuracy: 0.8972Epoch 2/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.8058 - val_loss: 0.0221 - val_accuracy: 0.8966\n",
            "Epoch 3/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.8805 - val_loss: 0.0194 - val_accuracy: 0.8276\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0351 - accuracy: 0.8768Epoch 3/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.8486 - val_loss: 0.0215 - val_accuracy: 0.8448\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.8371 - val_loss: 0.0247 - val_accuracy: 0.8475\n",
            "Epoch 3/190\n",
            "Epoch 3/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.8174 - val_loss: 0.0253 - val_accuracy: 0.7931\n",
            "Epoch 3/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.8552 - val_loss: 0.0239 - val_accuracy: 0.8966\n",
            "Epoch 3/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.8400 - val_loss: 0.0173 - val_accuracy: 0.8793\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0239 - accuracy: 0.8657Epoch 3/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.8676 - val_loss: 0.0192 - val_accuracy: 0.8276\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.8399 - val_loss: 0.0269 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 3/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.8587 - val_loss: 0.0219 - val_accuracy: 0.8136\n",
            "Epoch 3/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.8296 - val_loss: 0.0155 - val_accuracy: 0.9138\n",
            "Epoch 4/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.8562 - val_loss: 0.0157 - val_accuracy: 0.8276\n",
            "Epoch 4/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.8488 - val_loss: 0.0161 - val_accuracy: 0.8448\n",
            "49/53 [==========================>...] - ETA: 0s - loss: 0.0183 - accuracy: 0.8720Epoch 4/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.8179 - val_loss: 0.0200 - val_accuracy: 0.8305\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0318 - accuracy: 0.9000Epoch 4/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.8222 - val_loss: 0.0223 - val_accuracy: 0.8103\n",
            "Epoch 4/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.8713 - val_loss: 0.0131 - val_accuracy: 0.8448\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.8488 - val_loss: 0.0171 - val_accuracy: 0.8793\n",
            "Epoch 4/190\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0209 - accuracy: 0.8817\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.8455 - val_loss: 0.0149 - val_accuracy: 0.8276\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0244 - accuracy: 0.8468Epoch 4/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.8609 - val_loss: 0.0212 - val_accuracy: 0.8103\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0412 - accuracy: 0.9000Epoch 4/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.8090 - val_loss: 0.0192 - val_accuracy: 0.8136\n",
            "Epoch 4/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.8616 - val_loss: 0.0122 - val_accuracy: 0.9138\n",
            "Epoch 5/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.8633 - val_loss: 0.0138 - val_accuracy: 0.9138\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0247 - accuracy: 0.80Epoch 5/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.8610 - val_loss: 0.0116 - val_accuracy: 0.8966\n",
            "Epoch 5/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0217 - accuracy: 0.8307 - val_loss: 0.0196 - val_accuracy: 0.8475\n",
            "50/53 [===========================>..] - ETA: 0s - loss: 0.0201 - accuracy: 0.8611Epoch 5/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.8532 - val_loss: 0.0181 - val_accuracy: 0.8966\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0137 - accuracy: 0.7971Epoch 5/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.8860 - val_loss: 0.0097 - val_accuracy: 0.9310\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0146 - accuracy: 0.8225Epoch 5/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.8609 - val_loss: 0.0216 - val_accuracy: 0.8448\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.8542 - val_loss: 0.0133 - val_accuracy: 0.9310\n",
            "\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0189 - accuracy: 0.8224Epoch 5/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.8623 - val_loss: 0.0101 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0117 - accuracy: 0.8000Epoch 5/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.8450 - val_loss: 0.0145 - val_accuracy: 0.8475\n",
            "Epoch 5/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.8620 - val_loss: 0.0111 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.8563 - val_loss: 0.0137 - val_accuracy: 0.9138\n",
            "Epoch 6/190Epoch 6/190\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 0.0158 - accuracy: 0.8510\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.8707 - val_loss: 0.0111 - val_accuracy: 0.8276\n",
            "Epoch 6/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.8446 - val_loss: 0.0168 - val_accuracy: 0.8475\n",
            "Epoch 6/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.8553 - val_loss: 0.0146 - val_accuracy: 0.9310\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0165 - accuracy: 0.8562Epoch 6/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.8716 - val_loss: 0.0098 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0090 - accuracy: 1.00Epoch 6/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.8745 - val_loss: 0.0110 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.8383 - val_loss: 0.0187 - val_accuracy: 0.8621\n",
            "Epoch 6/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000Epoch 6/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.8703 - val_loss: 0.0079 - val_accuracy: 0.9483\n",
            "Epoch 6/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.8958 - val_loss: 0.0115 - val_accuracy: 0.8644\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0105 - accuracy: 0.90Epoch 6/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9057 - val_loss: 0.0071 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9050 - val_loss: 0.0095 - val_accuracy: 0.9310\n",
            "Epoch 7/190\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0127 - accuracy: 0.8787Epoch 7/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9033 - val_loss: 0.0081 - val_accuracy: 0.9138\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000Epoch 7/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.8774 - val_loss: 0.0139 - val_accuracy: 0.8814\n",
            "47/53 [=========================>....] - ETA: 0s - loss: 0.0104 - accuracy: 0.8930Epoch 7\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.8823 - val_loss: 0.0104 - val_accuracy: 0.9138\n",
            "Epoch 7/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9031 - val_loss: 0.0069 - val_accuracy: 0.9655\n",
            "Epoch 7/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.8952 - val_loss: 0.0079 - val_accuracy: 0.9483\n",
            "Epoch 7/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.8946 - val_loss: 0.0126 - val_accuracy: 0.8966\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9092 - val_loss: 0.0051 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000Epoch 7/190Epoch 7/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9238 - val_loss: 0.0095 - val_accuracy: 0.8644\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 0.0085 - accuracy: 0.9206Epoch 7/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9220 - val_loss: 0.0076 - val_accuracy: 0.8621\n",
            "Epoch 8/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9409 - val_loss: 0.0060 - val_accuracy: 0.9483\n",
            "48/53 [==========================>...] - ETA: 0s - loss: 0.0094 - accuracy: 0.9359Epoch 8/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9243 - val_loss: 0.0087 - val_accuracy: 0.9310\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0092 - accuracy: 0.9000Epoch 8/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.8838 - val_loss: 0.0100 - val_accuracy: 0.9492\n",
            "49/53 [==========================>...] - ETA: 0s - loss: 0.0068 - accuracy: 0.9297Epoch 8/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9347 - val_loss: 0.0083 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9288 - val_loss: 0.0062 - val_accuracy: 0.9655\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0074 - accuracy: 0.9306\n",
            "Epoch 8/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9243 - val_loss: 0.0064 - val_accuracy: 0.9310\n",
            "Epoch 8/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9272 - val_loss: 0.0108 - val_accuracy: 0.8966\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0071 - accuracy: 0.8000Epoch 8/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9258 - val_loss: 0.0042 - val_accuracy: 0.9655\n",
            "Epoch 8/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9363 - val_loss: 0.0102 - val_accuracy: 0.8814\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0073 - accuracy: 0.9161Epoch 8/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9346 - val_loss: 0.0054 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9335 - val_loss: 0.0063 - val_accuracy: 0.8793\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0065 - accuracy: 0.92Epoch 9/190\n",
            "Epoch 9/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9352 - val_loss: 0.0078 - val_accuracy: 0.9310\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000Epoch 9/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.8937 - val_loss: 0.0090 - val_accuracy: 0.9322\n",
            "Epoch 9/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9283 - val_loss: 0.0067 - val_accuracy: 0.9310\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0059 - accuracy: 0.9736Epoch 9/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9261 - val_loss: 0.0061 - val_accuracy: 0.9483\n",
            "Epoch 9/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9253 - val_loss: 0.0056 - val_accuracy: 0.9483\n",
            "Epoch 9/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9202 - val_loss: 0.0090 - val_accuracy: 0.8966\n",
            "Epoch 9/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9229 - val_loss: 0.0085 - val_accuracy: 0.8644\n",
            "Epoch 9/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9379 - val_loss: 0.0039 - val_accuracy: 0.9655\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 0.0058 - accuracy: 0.9435Epoch 9/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9340 - val_loss: 0.0100 - val_accuracy: 0.8621\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9455 - val_loss: 0.0047 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9334 - val_loss: 0.0087 - val_accuracy: 0.9310\n",
            "Epoch 10/190Epoch 10/190\n",
            "\n",
            "Epoch 10/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9313 - val_loss: 0.0088 - val_accuracy: 0.9153\n",
            "Epoch 10/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9390 - val_loss: 0.0061 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9275 - val_loss: 0.0055 - val_accuracy: 0.9483\n",
            "Epoch 10/190\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0075 - accuracy: 0.9015Epoch 10/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9387 - val_loss: 0.0060 - val_accuracy: 0.9483\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0088 - accuracy: 0.8707Epoch 10/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9490 - val_loss: 0.0071 - val_accuracy: 0.8644\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9306 - val_loss: 0.0110 - val_accuracy: 0.9138\n",
            "Epoch 10/190Epoch 10/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9369 - val_loss: 0.0059 - val_accuracy: 0.9483\n",
            "Epoch 10/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9065 - val_loss: 0.0063 - val_accuracy: 0.8966\n",
            "47/53 [=========================>....] - ETA: 0s - loss: 0.0057 - accuracy: 0.9070Epoch 11/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9413 - val_loss: 0.0045 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.8987 - val_loss: 0.0055 - val_accuracy: 0.9138\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0034 - accuracy: 0.7000Epoch 11/190\n",
            "Epoch 11/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9061 - val_loss: 0.0067 - val_accuracy: 0.9492\n",
            "49/53 [==========================>...] - ETA: 0s - loss: 0.0067 - accuracy: 0.9174Epoch 11/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9021 - val_loss: 0.0059 - val_accuracy: 0.9483\n",
            "Epoch 11/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9096 - val_loss: 0.0053 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0043 - accuracy: 0.70Epoch 11/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9189 - val_loss: 0.0045 - val_accuracy: 0.9483\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0052 - accuracy: 0.9149Epoch 11/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9302 - val_loss: 0.0083 - val_accuracy: 0.8644\n",
            "Epoch 11/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9087 - val_loss: 0.0076 - val_accuracy: 0.9483\n",
            "Epoch 11/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9108 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 11/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9144 - val_loss: 0.0069 - val_accuracy: 0.8793\n",
            "Epoch 12/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9201 - val_loss: 0.0040 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9092 - val_loss: 0.0068 - val_accuracy: 0.9310\n",
            "Epoch 12/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000Epoch 12/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9251 - val_loss: 0.0088 - val_accuracy: 0.8983\n",
            "Epoch 12/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9132 - val_loss: 0.0051 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9075 - val_loss: 0.0047 - val_accuracy: 0.9483\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0079 - accuracy: 0.9237Epoch 12/190\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0048 - accuracy: 0.9538Epoch 12/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9185 - val_loss: 0.0048 - val_accuracy: 0.9310\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0075 - accuracy: 0.9205Epoch 12/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9244 - val_loss: 0.0069 - val_accuracy: 0.8644\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0105 - accuracy: 0.9000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9262 - val_loss: 0.0071 - val_accuracy: 0.9310\n",
            "Epoch 12/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9402 - val_loss: 0.0041 - val_accuracy: 0.9483\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 0.0045 - accuracy: 0.9496Epoch 12/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9255 - val_loss: 0.0050 - val_accuracy: 0.9138\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 0.0052 - accuracy: 0.9367Epoch 13/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9153 - val_loss: 0.0057 - val_accuracy: 0.8793\n",
            "Epoch 13/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.9398 - val_loss: 0.0038 - val_accuracy: 0.9483\n",
            "Epoch 13/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 0.9210 - val_loss: 0.0078 - val_accuracy: 0.8983\n",
            "Epoch 13/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9358 - val_loss: 0.0043 - val_accuracy: 0.9310\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0056 - accuracy: 0.8940Epoch 13/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9241 - val_loss: 0.0052 - val_accuracy: 0.9655\n",
            "Epoch 13/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9318 - val_loss: 0.0063 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.9378 - val_loss: 0.0067 - val_accuracy: 0.8983\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0044 - accuracy: 0.9503\n",
            "Epoch 13/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9308 - val_loss: 0.0040 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000Epoch 13/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9455 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 13/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9082 - val_loss: 0.0046 - val_accuracy: 0.9138\n",
            "Epoch 14/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9135 - val_loss: 0.0061 - val_accuracy: 0.8966\n",
            "Epoch 14/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9300 - val_loss: 0.0035 - val_accuracy: 0.9483\n",
            "47/53 [=========================>....] - ETA: 0s - loss: 0.0049 - accuracy: 0.9508Epoch 14/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9349 - val_loss: 0.0055 - val_accuracy: 0.9492\n",
            "Epoch 14/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9239 - val_loss: 0.0039 - val_accuracy: 0.9483\n",
            "Epoch 14/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9169 - val_loss: 0.0057 - val_accuracy: 0.9310\n",
            "Epoch 14/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9269 - val_loss: 0.0057 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9494 - val_loss: 0.0067 - val_accuracy: 0.8644\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0040 - accuracy: 0.9029\n",
            "Epoch 14/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9196 - val_loss: 0.0047 - val_accuracy: 0.8793\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0047 - accuracy: 0.9318Epoch 14/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9393 - val_loss: 0.0032 - val_accuracy: 0.9655\n",
            "Epoch 14/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9034 - val_loss: 0.0045 - val_accuracy: 0.8966\n",
            "Epoch 15/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9163 - val_loss: 0.0054 - val_accuracy: 0.8793\n",
            "50/53 [===========================>..] - ETA: 0s - loss: 0.0046 - accuracy: 0.9398Epoch 15/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9323 - val_loss: 0.0039 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0038 - accuracy: 1.00Epoch 15/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9193 - val_loss: 0.0051 - val_accuracy: 0.9492\n",
            "Epoch 15/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9389 - val_loss: 0.0041 - val_accuracy: 0.9655\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0041 - accuracy: 0.9148Epoch 15/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9395 - val_loss: 0.0069 - val_accuracy: 0.8814\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9232 - val_loss: 0.0050 - val_accuracy: 0.9655\n",
            "Epoch 15/190\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0037 - accuracy: 0.9652Epoch 15/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9282 - val_loss: 0.0050 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9219 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0053 - accuracy: 0.9048Epoch 15/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9180 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0045 - accuracy: 0.9341Epoch 15/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9334 - val_loss: 0.0042 - val_accuracy: 0.8966\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0043 - accuracy: 0.9416Epoch 16/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.9458 - val_loss: 0.0062 - val_accuracy: 0.8966\n",
            "Epoch 16/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.9343 - val_loss: 0.0034 - val_accuracy: 0.9483\n",
            "Epoch 16/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9229 - val_loss: 0.0047 - val_accuracy: 0.9661\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9540Epoch 16/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.9351 - val_loss: 0.0035 - val_accuracy: 0.9655\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9411Epoch 16/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9399 - val_loss: 0.0053 - val_accuracy: 0.9655\n",
            "Epoch 16/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9537 - val_loss: 0.0059 - val_accuracy: 0.8644\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0036 - accuracy: 0.9628Epoch 16/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9410 - val_loss: 0.0047 - val_accuracy: 0.9483\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0050 - accuracy: 0.9345Epoch 16/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9376 - val_loss: 0.0041 - val_accuracy: 0.8966\n",
            "Epoch 16/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9507 - val_loss: 0.0040 - val_accuracy: 0.8966\n",
            "Epoch 16/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9336 - val_loss: 0.0050 - val_accuracy: 0.8966\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9340 - val_loss: 0.0041 - val_accuracy: 0.9138\n",
            "Epoch 17/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0020 - accuracy: 0.9000Epoch 17/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9455 - val_loss: 0.0039 - val_accuracy: 0.9138\n",
            "Epoch 17/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9289 - val_loss: 0.0056 - val_accuracy: 0.8983\n",
            "Epoch 17/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9552 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 17/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9472 - val_loss: 0.0057 - val_accuracy: 0.8793\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0040 - accuracy: 0.9059Epoch 17/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9508 - val_loss: 0.0050 - val_accuracy: 0.8983\n",
            "Epoch 17/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9374 - val_loss: 0.0045 - val_accuracy: 0.9483\n",
            "Epoch 17/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9515 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 17/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9333 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 17/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9140 - val_loss: 0.0049 - val_accuracy: 0.9138\n",
            "Epoch 18/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9293 - val_loss: 0.0047 - val_accuracy: 0.8793\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 0.0039 - accuracy: 0.9490Epoch 18/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9279 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 18/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9352 - val_loss: 0.0050 - val_accuracy: 0.9153\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0034 - accuracy: 0.9203Epoch 18/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9395 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0039 - accuracy: 0.9390Epoch 18/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9416 - val_loss: 0.0056 - val_accuracy: 0.9310\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0044 - accuracy: 0.8949\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9477 - val_loss: 0.0049 - val_accuracy: 0.8814\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0042 - accuracy: 0.9308Epoch 18/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9212 - val_loss: 0.0053 - val_accuracy: 0.9483\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 0.0039 - accuracy: 0.9257Epoch 18/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9422 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 18/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9385 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0025 - accuracy: 0.8000Epoch 18/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9198 - val_loss: 0.0048 - val_accuracy: 0.9138\n",
            "Epoch 19/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9379 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 19/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.9332 - val_loss: 0.0045 - val_accuracy: 0.8793\n",
            "Epoch 19/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9284 - val_loss: 0.0048 - val_accuracy: 0.9322\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000Epoch 19/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9369 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 19/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9191 - val_loss: 0.0060 - val_accuracy: 0.8793\n",
            "Epoch 19/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9482 - val_loss: 0.0048 - val_accuracy: 0.8814\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0033 - accuracy: 0.9554Epoch 19/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9287 - val_loss: 0.0044 - val_accuracy: 0.9483\n",
            "Epoch 19/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9292 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 19/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9298 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 0.0035 - accuracy: 0.9584Epoch 19/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9436 - val_loss: 0.0050 - val_accuracy: 0.8966\n",
            "Epoch 20/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9458 - val_loss: 0.0032 - val_accuracy: 0.9483\n",
            "Epoch 20/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9329 - val_loss: 0.0048 - val_accuracy: 0.9322\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9407 - val_loss: 0.0040 - val_accuracy: 0.9138\n",
            "\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Epoch 20/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9500 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 0.0039 - accuracy: 0.9650Epoch 20/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9519 - val_loss: 0.0049 - val_accuracy: 0.8793\n",
            "Epoch 20/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9343 - val_loss: 0.0051 - val_accuracy: 0.8814\n",
            "Epoch 20/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9450 - val_loss: 0.0040 - val_accuracy: 0.9483\n",
            "Epoch 20/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9552 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 20/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9622 - val_loss: 0.0036 - val_accuracy: 0.8966\n",
            "Epoch 20/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9269 - val_loss: 0.0046 - val_accuracy: 0.9138\n",
            "Epoch 21/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9195 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0038 - accuracy: 0.9459\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9200 - val_loss: 0.0038 - val_accuracy: 0.8793\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9321 - val_loss: 0.0041 - val_accuracy: 0.9153\n",
            "Epoch 21/190\n",
            "43/53 [=======================>......] - ETA: 0s - loss: 0.0038 - accuracy: 0.9436Epoch 21/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 0.9328 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9274 - val_loss: 0.0051 - val_accuracy: 0.9138\n",
            "23/53 [============>.................] - ETA: 0s - loss: 0.0039 - accuracy: 0.9345Epoch 21/190Epoch 21/190\n",
            "\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9216 - val_loss: 0.0046 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9418 - val_loss: 0.0048 - val_accuracy: 0.8814\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9417 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 21/190\n",
            "Epoch 21/190\n",
            "Epoch 21/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.9430 - val_loss: 0.0034 - val_accuracy: 0.9483\n",
            "Epoch 21/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9235 - val_loss: 0.0045 - val_accuracy: 0.9138\n",
            "Epoch 22/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9313 - val_loss: 0.0031 - val_accuracy: 0.9483\n",
            "Epoch 22/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9251 - val_loss: 0.0037 - val_accuracy: 0.8966\n",
            "Epoch 22/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9235 - val_loss: 0.0048 - val_accuracy: 0.8983\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0027 - accuracy: 0.9139\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9279 - val_loss: 0.0041 - val_accuracy: 0.9655\n",
            "Epoch 22/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9398 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 22/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9221 - val_loss: 0.0044 - val_accuracy: 0.8814\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9451 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 22/190\n",
            "Epoch 22/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9318 - val_loss: 0.0052 - val_accuracy: 0.9655\n",
            "Epoch 22/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9297 - val_loss: 0.0033 - val_accuracy: 0.9138\n",
            "Epoch 22/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9346 - val_loss: 0.0047 - val_accuracy: 0.8966\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 0.0044 - accuracy: 0.9061Epoch 23/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9231 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 23/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9431 - val_loss: 0.0035 - val_accuracy: 0.9138\n",
            "Epoch 23/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9120 - val_loss: 0.0038 - val_accuracy: 0.9492\n",
            "Epoch 23/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 0.9284 - val_loss: 0.0040 - val_accuracy: 0.9655\n",
            "Epoch 23/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9425 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9527 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "11/53 [=====>........................] - ETA: 0s - loss: 0.0027 - accuracy: 0.9371Epoch 23/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.4057e-04 - accuracy: 0.9000Epoch 23/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.9049 - val_loss: 0.0051 - val_accuracy: 0.8644\n",
            "Epoch 23/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9324 - val_loss: 0.0048 - val_accuracy: 0.9310\n",
            "Epoch 23/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9358 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0029 - accuracy: 0.9186Epoch 23/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9246 - val_loss: 0.0043 - val_accuracy: 0.9138\n",
            "Epoch 24/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9414 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0031 - accuracy: 0.9481Epoch 24/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9287 - val_loss: 0.0036 - val_accuracy: 0.9138\n",
            "Epoch 24/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9330 - val_loss: 0.0035 - val_accuracy: 0.9492\n",
            "Epoch 24/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9271 - val_loss: 0.0042 - val_accuracy: 0.9310\n",
            "Epoch 24/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9508 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9486 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9446 - val_loss: 0.0047 - val_accuracy: 0.8644\n",
            "\n",
            "Epoch 24/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0024 - accuracy: 0.9000Epoch 24/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9223 - val_loss: 0.0039 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000Epoch 24/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9434 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 24/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9166 - val_loss: 0.0057 - val_accuracy: 0.8966\n",
            "Epoch 25/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9469 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 25/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9400 - val_loss: 0.0049 - val_accuracy: 0.9483\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0029 - accuracy: 0.8872Epoch 25/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9437 - val_loss: 0.0035 - val_accuracy: 0.9492\n",
            "Epoch 25/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9349 - val_loss: 0.0066 - val_accuracy: 0.8793\n",
            "10/53 [====>.........................] - ETA: 0s - loss: 0.0056 - accuracy: 0.9197Epoch 25/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9502 - val_loss: 0.0026 - val_accuracy: 0.9138\n",
            "Epoch 25/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9466 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9253 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "\n",
            "38/53 [====================>.........] - ETA: 0s - loss: 0.0029 - accuracy: 0.9097Epoch 25/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9522 - val_loss: 0.0056 - val_accuracy: 0.8814\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0045 - accuracy: 0.9000Epoch 25/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9469 - val_loss: 0.0051 - val_accuracy: 0.8966\n",
            "Epoch 25/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9176 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "38/53 [====================>.........] - ETA: 0s - loss: 0.0030 - accuracy: 0.9413Epoch 26/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.9268 - val_loss: 0.0045 - val_accuracy: 0.9138\n",
            "Epoch 26/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9162 - val_loss: 0.0036 - val_accuracy: 0.8793\n",
            "Epoch 26/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9414 - val_loss: 0.0035 - val_accuracy: 0.9492\n",
            "Epoch 26/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9181 - val_loss: 0.0037 - val_accuracy: 0.9655\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0033 - accuracy: 0.9320Epoch 26/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9436 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 26/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9159 - val_loss: 0.0041 - val_accuracy: 0.9483\n",
            "Epoch 26/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9439 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 26/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9291 - val_loss: 0.0032 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9366 - val_loss: 0.0045 - val_accuracy: 0.8814\n",
            "Epoch 26/190\n",
            "Epoch 26/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9480 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 27/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9303 - val_loss: 0.0041 - val_accuracy: 0.9138\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0032 - accuracy: 0.9587Epoch 27/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9311 - val_loss: 0.0035 - val_accuracy: 0.9138\n",
            "Epoch 27/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9166 - val_loss: 0.0033 - val_accuracy: 0.9492\n",
            "Epoch 27/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9518 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 27/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9321 - val_loss: 0.0039 - val_accuracy: 0.9655\n",
            "Epoch 27/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9383 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "37/53 [===================>..........] - ETA: 0s - loss: 0.0035 - accuracy: 0.95Epoch 27/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9513 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 27/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9441 - val_loss: 0.0041 - val_accuracy: 0.8814\n",
            "Epoch 27/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9451 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 27/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9247 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 28/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 0.9457 - val_loss: 0.0042 - val_accuracy: 0.9138\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0031 - accuracy: 0.9630Epoch 28/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9385 - val_loss: 0.0033 - val_accuracy: 0.9138\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0032 - accuracy: 0.9551Epoch 28/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9234 - val_loss: 0.0032 - val_accuracy: 0.9492\n",
            "47/53 [=========================>....] - ETA: 0s - loss: 0.0026 - accuracy: 0.9394\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9470 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 28/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9394 - val_loss: 0.0040 - val_accuracy: 0.9138\n",
            "Epoch 28/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9394 - val_loss: 0.0041 - val_accuracy: 0.9483\n",
            "Epoch 28/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9453 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9370 - val_loss: 0.0049 - val_accuracy: 0.8814\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0021 - accuracy: 0.9745Epoch 28/190\n",
            "Epoch 28/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9477 - val_loss: 0.0033 - val_accuracy: 0.9310\n",
            "Epoch 28/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9591 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 29/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9129 - val_loss: 0.0042 - val_accuracy: 0.9138\n",
            "Epoch 29/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9192 - val_loss: 0.0034 - val_accuracy: 0.93100s - loss: 0.0024 - accuracy: \n",
            "Epoch 29/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9511 - val_loss: 0.0032 - val_accuracy: 0.9322\n",
            "Epoch 29/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9666 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 29/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9335 - val_loss: 0.0050 - val_accuracy: 0.8793\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0037 - accuracy: 0.9440Epoch 29/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9495 - val_loss: 0.0034 - val_accuracy: 0.9483\n",
            "39/53 [=====================>........] - ETA: 0s - loss: 0.0035 - accuracy: 0.9474Epoch 29/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9369 - val_loss: 0.0031 - val_accuracy: 0.9138\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 0.0036 - accuracy: 0.9500Epoch 29/1\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9487 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 0.9598 - val_loss: 0.0035 - val_accuracy: 0.8983\n",
            "Epoch 29/190\n",
            "Epoch 29/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9419 - val_loss: 0.0031 - val_accuracy: 0.9138\n",
            "Epoch 30/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9437 - val_loss: 0.0042 - val_accuracy: 0.9138\n",
            "Epoch 30/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9471 - val_loss: 0.0032 - val_accuracy: 0.9138\n",
            "Epoch 30/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9350 - val_loss: 0.0030 - val_accuracy: 0.9492\n",
            "Epoch 30/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9803 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 30/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9275 - val_loss: 0.0041 - val_accuracy: 0.9483\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 0.0036 - accuracy: 0.9453Epoch 30/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9384 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "18/53 [=========>....................] - ETA: 0s - loss: 0.0038 - accuracy: 0.9768Epoch 30/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9469 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 30/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9550 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0037 - accuracy: 0.9443Epoch 30/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9353 - val_loss: 0.0037 - val_accuracy: 0.8814\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0035 - accuracy: 0.9592Epoch 30/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9500 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 31/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9480 - val_loss: 0.0040 - val_accuracy: 0.9138\n",
            "Epoch 31/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9406 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "Epoch 31/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9474 - val_loss: 0.0032 - val_accuracy: 0.9322\n",
            "Epoch 31/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9680 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 0.0024 - accuracy: 0.9317Epoch 31/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.9492 - val_loss: 0.0035 - val_accuracy: 0.9483\n",
            "Epoch 31/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9617 - val_loss: 0.0031 - val_accuracy: 0.9483\n",
            "Epoch 31/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 0.9461 - val_loss: 0.0031 - val_accuracy: 0.9138\n",
            "Epoch 31/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9644 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0045 - accuracy: 0.7000Epoch 31/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9492 - val_loss: 0.0036 - val_accuracy: 0.8814\n",
            "Epoch 31/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9143 - val_loss: 0.0039 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9339 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 32/190\n",
            "Epoch 32/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9130 - val_loss: 0.0032 - val_accuracy: 0.8966\n",
            "Epoch 32/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9435 - val_loss: 0.0030 - val_accuracy: 0.9492\n",
            "47/53 [=========================>....] - ETA: 0s - loss: 0.0023 - accuracy: 0.9478Epoch 32/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9353 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0035 - accuracy: 0.9000Epoch 32/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9359 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0020 - accuracy: 0.9462Epoch 32/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9468 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 32/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9456 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 32/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9169 - val_loss: 0.0030 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9000Epoch 32/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9490 - val_loss: 0.0034 - val_accuracy: 0.8814\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9000Epoch 32/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9364 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0026 - accuracy: 0.9271Epoch 33/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9175 - val_loss: 0.0041 - val_accuracy: 0.8966\n",
            "Epoch 33/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9462 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 33/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9674 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9322 - val_loss: 0.0034 - val_accuracy: 0.9492\n",
            "Epoch 33/190\n",
            "Epoch 33/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9332 - val_loss: 0.0041 - val_accuracy: 0.8793\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0020 - accuracy: 0.9436Epoch 33/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9367 - val_loss: 0.0030 - val_accuracy: 0.9483\n",
            "Epoch 33/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9598 - val_loss: 0.0051 - val_accuracy: 0.8644\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9457 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 33/190Epoch 33/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9399 - val_loss: 0.0033 - val_accuracy: 0.8966\n",
            "Epoch 33/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9470 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 34/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9189 - val_loss: 0.0038 - val_accuracy: 0.9138\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0024 - accuracy: 0.8894Epoch 34/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9359 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 0.0026 - accuracy: 0.9305Epoch 34/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9548 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 34/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9323 - val_loss: 0.0029 - val_accuracy: 0.9492\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0039 - accuracy: 0.9359Epoch 34/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9334 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0030 - accuracy: 0.9534Epoch 34/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9364 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "Epoch 34/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9330 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 34/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9271 - val_loss: 0.0033 - val_accuracy: 0.9153\n",
            "Epoch 34/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9495 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 34/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9507 - val_loss: 0.0037 - val_accuracy: 0.9138\n",
            "Epoch 35/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9366 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000Epoch 35/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9316 - val_loss: 0.0029 - val_accuracy: 0.9138\n",
            "48/53 [==========================>...] - ETA: 0s - loss: 0.0019 - accuracy: 0.9435\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9448 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 35/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9413 - val_loss: 0.0026 - val_accuracy: 0.9492\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000Epoch 35/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9417 - val_loss: 0.0032 - val_accuracy: 0.9138\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0022 - accuracy: 0.9601Epoch 35/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9554 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 35/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9617 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0020 - accuracy: 0.9603Epoch 35/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9577 - val_loss: 0.0043 - val_accuracy: 0.8814\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9549 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 35/190\n",
            "Epoch 35/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9321 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 36/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9462 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 36/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9278 - val_loss: 0.0029 - val_accuracy: 0.9138\n",
            "Epoch 36/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9398 - val_loss: 0.0032 - val_accuracy: 0.9492\n",
            "Epoch 36/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9553 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 36/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9454 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 36/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9588 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 36/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9546 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9490 - val_loss: 0.0034 - val_accuracy: 0.8983\n",
            "Epoch 36/190\n",
            "Epoch 36/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9409 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 36/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9333 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 37/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9316 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0025 - accuracy: 0.9000Epoch 37/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9317 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 37/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9495 - val_loss: 0.0025 - val_accuracy: 0.9661\n",
            "Epoch 37/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9529 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 37/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9340 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0019 - accuracy: 0.9528Epoch 37/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9426 - val_loss: 0.0031 - val_accuracy: 0.9483\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0029 - accuracy: 0.9452Epoch 37/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9538 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9567 - val_loss: 0.0038 - val_accuracy: 0.8983\n",
            "Epoch 37/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000Epoch 37/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9445 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0034 - accuracy: 0.9396Epoch 37/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9427 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 38/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9170 - val_loss: 0.0038 - val_accuracy: 0.9138\n",
            "Epoch 38/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9391 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0028 - accuracy: 0.9320Epoch 38/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9496 - val_loss: 0.0028 - val_accuracy: 0.9661\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0047 - accuracy: 0.9084Epoch 38/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9721 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 38/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9430 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 38/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9524 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0029 - accuracy: 0.9326Epoch 38/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9570 - val_loss: 0.0049 - val_accuracy: 0.8644\n",
            "Epoch 38/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9569 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000Epoch 38/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9344 - val_loss: 0.0034 - val_accuracy: 0.8966\n",
            "Epoch 38/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9453 - val_loss: 0.0020 - val_accuracy: 0.9138\n",
            "Epoch 39/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9275 - val_loss: 0.0035 - val_accuracy: 0.9138\n",
            "Epoch 39/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.9238 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 39/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9446 - val_loss: 0.0033 - val_accuracy: 0.9492\n",
            "Epoch 39/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9591 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 39/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9426 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "43/53 [=======================>......] - ETA: 0s - loss: 0.0019 - accuracy: 0.9645Epoch 39/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9472 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 39/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9633 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "26/53 [=============>................] - ETA: 0s - loss: 0.0026 - accuracy: 0.9533Epoch 39/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9448 - val_loss: 0.0030 - val_accuracy: 0.9153\n",
            "Epoch 39/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9428 - val_loss: 0.0032 - val_accuracy: 0.9138\n",
            "Epoch 39/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9393 - val_loss: 0.0044 - val_accuracy: 0.8793\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9409 - val_loss: 0.0022 - val_accuracy: 0.8966\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0017 - accuracy: 0.9832Epoch 40/190\n",
            "Epoch 40/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9528 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 40/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9487 - val_loss: 0.0024 - val_accuracy: 0.9492\n",
            "Epoch 40/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9611 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 40/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9386 - val_loss: 0.0040 - val_accuracy: 0.8793\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0032 - accuracy: 0.9395Epoch 40/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9522 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 40/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9646 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 40/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9677 - val_loss: 0.0030 - val_accuracy: 0.8983\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 0.0031 - accuracy: 0.9497Epoch 40/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9462 - val_loss: 0.0035 - val_accuracy: 0.8793\n",
            "Epoch 40/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9418 - val_loss: 0.0036 - val_accuracy: 0.8966\n",
            "Epoch 41/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9473 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0034 - accuracy: 0.9000Epoch 41/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9484 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 41/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9336 - val_loss: 0.0025 - val_accuracy: 0.9661\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0033 - accuracy: 0.9642Epoch 41/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9787 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 41/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9518 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 41/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9617 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "49/53 [==========================>...] - ETA: 0s - loss: 0.0019 - accuracy: 0.9566Epoch 41/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9566 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 41/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9388 - val_loss: 0.0028 - val_accuracy: 0.8983\n",
            "Epoch 41/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9595 - val_loss: 0.0031 - val_accuracy: 0.9138\n",
            "25/53 [=============>................] - ETA: 0s - loss: 0.0019 - accuracy: 0.9700Epoch 41/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9610 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9427 - val_loss: 0.0034 - val_accuracy: 0.9310\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0027 - accuracy: 0.9654\n",
            "Epoch 42/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9507 - val_loss: 0.0026 - val_accuracy: 0.9310\n",
            "Epoch 42/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9621 - val_loss: 0.0024 - val_accuracy: 0.9322\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9679 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 42/190Epoch 42/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9616 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 42/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9622 - val_loss: 0.0030 - val_accuracy: 0.9483\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0016 - accuracy: 0.9626Epoch 42/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9669 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 42/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9580 - val_loss: 0.0034 - val_accuracy: 0.9153\n",
            "Epoch 42/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9592 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 0.0017 - accuracy: 0.9577Epoch 42/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9577 - val_loss: 0.0019 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9435 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 43/190\n",
            "Epoch 43/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9533 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 43/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9593 - val_loss: 0.0027 - val_accuracy: 0.9492\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0022 - accuracy: 0.9477Epoch 43/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9607 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0039 - accuracy: 0.7000Epoch 43/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9532 - val_loss: 0.0026 - val_accuracy: 0.9310\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 0.0016 - accuracy: 0.9634Epoch 43/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9603 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 0.0021 - accuracy: 0.9498Epoch 43/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9629 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "25/53 [=============>................] - ETA: 0s - loss: 0.0023 - accuracy: 0.9425\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9500 - val_loss: 0.0027 - val_accuracy: 0.9153\n",
            "Epoch 43/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9541 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 43/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9314 - val_loss: 0.0034 - val_accuracy: 0.8966\n",
            "Epoch 44/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9488 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 44/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9344 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 44/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9479 - val_loss: 0.0022 - val_accuracy: 0.9492\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0021 - accuracy: 0.9781\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9576 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 44/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9451 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 44/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9454 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 0.0020 - accuracy: 0.9721Epoch 44/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9607 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 44/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9696 - val_loss: 0.0026 - val_accuracy: 0.9153\n",
            "Epoch 44/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9582 - val_loss: 0.0038 - val_accuracy: 0.8793\n",
            "Epoch 44/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9403 - val_loss: 0.0038 - val_accuracy: 0.9483\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 0.0022 - accuracy: 0.9538Epoch 45/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9389 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 45/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9422 - val_loss: 0.0030 - val_accuracy: 0.8966\n",
            "Epoch 45/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9530 - val_loss: 0.0022 - val_accuracy: 0.9153\n",
            "Epoch 45/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9635 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 45/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9506 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 45/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9438 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 45/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9535 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 45/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9623 - val_loss: 0.0029 - val_accuracy: 0.9153\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0018 - accuracy: 0.9481Epoch 45/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9309 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0014 - accuracy: 0.9770Epoch 45/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9418 - val_loss: 0.0035 - val_accuracy: 0.9310\n",
            "Epoch 46/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9469 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 46/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9475 - val_loss: 0.0037 - val_accuracy: 0.8793\n",
            "Epoch 46/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9586 - val_loss: 0.0023 - val_accuracy: 0.9492\n",
            "Epoch 46/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9729 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0024 - accuracy: 0.9552Epoch 46/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9492 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 46/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9660 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 0.0038 - accuracy: 0.9480Epoch 46/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9616 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 46/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9446 - val_loss: 0.0027 - val_accuracy: 0.9322\n",
            "Epoch 46/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9533 - val_loss: 0.0035 - val_accuracy: 0.9483\n",
            "Epoch 46/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9445 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 47/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9439 - val_loss: 0.0033 - val_accuracy: 0.9138\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000Epoch 47/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9625 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0019 - accuracy: 0.9000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9546 - val_loss: 0.0021 - val_accuracy: 0.9322\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9558Epoch 47/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9601 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 47/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9546 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "26/53 [=============>................] - ETA: 0s - loss: 0.0032 - accuracy: 0.9342Epoch 47/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9549 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0031 - accuracy: 0.9528\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9733 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 47/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9682 - val_loss: 0.0028 - val_accuracy: 0.9322\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0018 - accuracy: 0.9408Epoch 47/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9517 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "Epoch 47/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9354 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 48/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9392 - val_loss: 0.0035 - val_accuracy: 0.8793\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9531 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 48/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000Epoch 48/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9457 - val_loss: 0.0022 - val_accuracy: 0.9492\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0018 - accuracy: 0.9533Epoch 48/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9552 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "33/53 [=================>............] - ETA: 0s - loss: 0.0026 - accuracy: 0.9348Epoch 48/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9434 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 48/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9492 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 48/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9553 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "18/53 [=========>....................] - ETA: 0s - loss: 0.0024 - accuracy: 0.9405Epoch 48/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9546 - val_loss: 0.0037 - val_accuracy: 0.9153\n",
            "Epoch 48/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9394 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 0.0030 - accuracy: 0.9481Epoch 48/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9473 - val_loss: 0.0027 - val_accuracy: 0.8966\n",
            "Epoch 49/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9519 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0039 - accuracy: 0.8000Epoch 49/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9469 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000Epoch 49/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9460 - val_loss: 0.0021 - val_accuracy: 0.9492\n",
            "Epoch 49/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9722 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 49/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9521 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0021 - accuracy: 0.9080Epoch 49/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9655 - val_loss: 0.0025 - val_accuracy: 0.9828\n",
            "Epoch 49/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9725 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0036 - accuracy: 0.90Epoch 49/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9491 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0018 - accuracy: 0.9536\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9388 - val_loss: 0.0026 - val_accuracy: 0.9661\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 0.0016 - accuracy: 0.9648Epoch 49/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9386 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 50/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9637 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 50/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9580 - val_loss: 0.0029 - val_accuracy: 0.9138\n",
            "Epoch 50/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9372 - val_loss: 0.0019 - val_accuracy: 0.9831\n",
            "Epoch 50/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9576 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 50/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9571 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 50/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9641 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9684 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 50/190\n",
            "33/53 [=================>............] - ETA: 0s - loss: 0.0027 - accuracy: 0.9308Epoch 50/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9508 - val_loss: 0.0029 - val_accuracy: 0.9138\n",
            "Epoch 50/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9481 - val_loss: 0.0028 - val_accuracy: 0.9492\n",
            "Epoch 50/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9349 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0017 - accuracy: 0.9646Epoch 51/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9327 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9431 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 51/190Epoch 51/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9527 - val_loss: 0.0025 - val_accuracy: 0.9492\n",
            "Epoch 51/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9617 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "11/53 [=====>........................] - ETA: 0s - loss: 0.0024 - accuracy: 0.9721Epoch 51/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9264 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9515 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 51/190Epoch 51/190\n",
            "\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9418 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 0.0016 - accuracy: 0.9371Epoch 51/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9418 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "Epoch 51/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9548 - val_loss: 0.0025 - val_accuracy: 0.9322\n",
            "Epoch 51/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9557 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 52/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9447 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 52/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9548 - val_loss: 0.0029 - val_accuracy: 0.9138\n",
            "Epoch 52/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9597 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 52/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9663 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 52/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9504 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 52/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9533 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 52/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9632 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 52/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9499 - val_loss: 0.0031 - val_accuracy: 0.8966\n",
            "Epoch 52/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9646 - val_loss: 0.0029 - val_accuracy: 0.9322\n",
            "Epoch 52/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9569 - val_loss: 0.0028 - val_accuracy: 0.8966\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9396 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 53/190\n",
            "Epoch 53/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9460 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "48/53 [==========================>...] - ETA: 0s - loss: 0.0013 - accuracy: 0.9609Epoch 53/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9336 - val_loss: 0.0026 - val_accuracy: 0.9322\n",
            "Epoch 53/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9613 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0019 - accuracy: 0.9376Epoch 53/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9456 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 53/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9522 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9512 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9265    h 53/1\n",
            "Epoch 53/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9552 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 53/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9452 - val_loss: 0.0024 - val_accuracy: 0.9322\n",
            "19/53 [=========>....................] - ETA: 0s - loss: 0.0014 - accuracy: 0.9752\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9371 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "Epoch 54/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9472 - val_loss: 0.0027 - val_accuracy: 0.9138\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 0.0018 - accuracy: 0.9489Epoch 54/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9681 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000Epoch 54/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9732 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 54/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9406 - val_loss: 0.0019 - val_accuracy: 0.9492\n",
            "Epoch 54/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9668 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Epoch 54/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9850 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9711 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000Epoch 54/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9437 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "18/53 [=========>....................] - ETA: 0s - loss: 0.0018 - accuracy: 0.9410Epoch 54/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9489 - val_loss: 0.0022 - val_accuracy: 0.9661\n",
            "Epoch 54/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9495 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 55/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9474 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 55/190======================>..] - ETA: 0s - loss: 0.0016 - accuracy: 0.9572\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9654 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 55/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9575 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 55/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9649 - val_loss: 0.0022 - val_accuracy: 0.9661\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0014 - accuracy: 0.9548Epoch 55/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9674 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "22/53 [===========>..................] - ETA: 0s - loss: 0.0021 - accuracy: 0.9346Epoch 55/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9504 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9757 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 55/190\n",
            "Epoch 55/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9427 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 55/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9700 - val_loss: 0.0024 - val_accuracy: 0.9322\n",
            "25/53 [=============>................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9612Epoch 55/1\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9461 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "38/53 [====================>.........] - ETA: 0s - loss: 0.0019 - accuracy: 0.9709Epoch 56/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9577 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 56/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9422 - val_loss: 0.0029 - val_accuracy: 0.8793\n",
            "Epoch 56/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9636 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 56/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9673 - val_loss: 0.0018 - val_accuracy: 0.9322\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0018 - accuracy: 0.9612Epoch 56/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9426 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0030 - accuracy: 0.9538Epoch 56/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9594 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 56/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9630 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0016 - accuracy: 0.9350Epoch 56/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9403 - val_loss: 0.0036 - val_accuracy: 0.8793\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9589 - val_loss: 0.0022 - val_accuracy: 0.9492\n",
            "Epoch 56/190\n",
            "Epoch 56/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9552 - val_loss: 0.0027 - val_accuracy: 0.8966\n",
            "39/53 [=====================>........] - ETA: 0s - loss: 0.0019 - accuracy: 0.9658Epoch 57/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9459 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 57/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9407 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 57/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9890 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 57/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9632 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 57/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9477 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0010 - accuracy: 0.9269Epoch 57/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9549 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 57/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9659 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 0.0022 - accuracy: 0.9378Epoch 57/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.9597 - val_loss: 0.0024 - val_accuracy: 0.9661\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0011 - accuracy: 0.9462Epoch 57/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9530 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 57/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9529 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 58/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9483 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 58/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9454 - val_loss: 0.0025 - val_accuracy: 0.8966\n",
            "Epoch 58/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9547 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 58/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9639 - val_loss: 0.0020 - val_accuracy: 0.9322\n",
            "Epoch 58/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9507 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 58/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9533 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 0.0015 - accuracy: 0.9678Epoch 58/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9691 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 58/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9642 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0029 - accuracy: 0.9268Epoch 58/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9638 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "Epoch 58/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9297 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0025 - accuracy: 0.9621\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9563 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000Epoch 59/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9596 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 59/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9574 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 59/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9549 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 59/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9542 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 59/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9639 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 59/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9685 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9701 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "18/53 [=========>....................] - ETA: 0s - loss: 0.0015 - accuracy: 0.9526Epoch 59/190Epoch 59/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9602 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "48/53 [==========================>...] - ETA: 0s - loss: 0.0025 - accuracy: 0.9600Epoch 59/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9597 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 0.0020 - accuracy: 0.9503Epoch 60/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9486 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 60/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9452 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "Epoch 60/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9652 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 60/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9507 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 60/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9568 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "18/53 [=========>....................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9384Epoch 60/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9590 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0019 - accuracy: 0.9604Epoch 60/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9540 - val_loss: 0.0023 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9692 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 60/190\n",
            "Epoch 60/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9432 - val_loss: 0.0030 - val_accuracy: 0.8966\n",
            " 1/53 [..............................] - ETA: 0s - loss: 8.8233e-04 - accuracy: 1.0000h 60/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9572 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0017 - accuracy: 0.9588Epoch 61/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9435 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0018 - accuracy: 0.9515Epoch 61/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9565 - val_loss: 0.0027 - val_accuracy: 0.9138\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0015 - accuracy: 0.9506Epoch 61/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9780 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 61/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9460 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9526 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 61/190Epoch 61/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9529 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0022 - accuracy: 0.9523\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9518 - val_loss: 0.0023 - val_accuracy: 0.9661\n",
            "Epoch 61/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9583 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9586 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 61/190\n",
            "Epoch 61/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9355 - val_loss: 0.0030 - val_accuracy: 0.8966\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0015 - accuracy: 0.9634Epoch 62/1\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9749 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "23/53 [============>.................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9642Epoch 62/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9528 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9743 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "26/53 [=============>................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9783Epoch 62/190\n",
            "Epoch 62/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9600 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 0.0025 - accuracy: 0.9620Epoch 62/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9624 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 62/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9752 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0015 - accuracy: 0.95Epoch 62/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9602 - val_loss: 0.0021 - val_accuracy: 0.9831\n",
            "Epoch 62/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9462 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9780 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 62/190\n",
            "Epoch 62/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9506 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 63/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9713 - val_loss: 0.0017 - val_accuracy: 0.9138\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0014 - accuracy: 0.9686Epoch 63/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9667 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9729 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 0.0022 - accuracy: 0.9633Epoch 63/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000Epoch 63/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9535 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9455 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "12/53 [=====>........................] - ETA: 0s - loss: 0.0017 - accuracy: 0.9442Epoch 63/190Epoch 63/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9648 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 63/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.9430 - val_loss: 0.0022 - val_accuracy: 0.9492\n",
            "Epoch 63/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9555 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9645 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 63/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9502 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "47/53 [=========================>....] - ETA: 0s - loss: 0.0016 - accuracy: 0.9540Epoch 64/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9659 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 64/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9586 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9638 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 64/190\n",
            "Epoch 64/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9537 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0014 - accuracy: 0.9596Epoch 64/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9637 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 64/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9608 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 64/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9603 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0025 - accuracy: 0.9570Epoch 64/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9650 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 64/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9497 - val_loss: 0.0033 - val_accuracy: 0.8966\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9000Epoch 64/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9579 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "25/53 [=============>................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9564Epoch 65/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9545 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 65/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9602 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 65/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9626 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 65/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.9603 - val_loss: 0.0024 - val_accuracy: 0.9322\n",
            "Epoch 65/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9503 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "37/53 [===================>..........] - ETA: 0s - loss: 0.0012 - accuracy: 0.95479000Epoch 65/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9590 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "49/53 [==========================>...] - ETA: 0s - loss: 0.0026 - accuracy: 0.95Epoch 65/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.9624 - val_loss: 0.0019 - val_accuracy: 0.9831\n",
            "Epoch 65/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9584 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9590 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 65/190\n",
            "Epoch 65/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9492 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "Epoch 66/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9634 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 66/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9626 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 66/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9775 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 66/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9639 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 66/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9546 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 66/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9710 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0012 - accuracy: 0.9622Epoch 66/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9523 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 66/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9600 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 66/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9683 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 66/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9534 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0013 - accuracy: 0.9747\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9620 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 67/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9456 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0027 - accuracy: 0.95Epoch 67/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9743 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 67/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9526 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 67/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9462 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 0.0014 - accuracy: 0.9591Epoch 67/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9487 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0015 - accuracy: 0.9394\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9329 - val_loss: 0.0022 - val_accuracy: 0.9661\n",
            "Epoch 67/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9607 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 67/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9528 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "Epoch 67/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9545 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 68/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9630 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 68/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9581 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 68/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9784 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 68/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9485 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "48/53 [==========================>...] - ETA: 0s - loss: 0.0014 - accuracy: 0.9492Epoch 68/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9394 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 68/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9503 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0012 - accuracy: 0.9819Epoch 68/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9474 - val_loss: 0.0020 - val_accuracy: 0.9831\n",
            "Epoch 68/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9617 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 68/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9525 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0013 - accuracy: 0.97Epoch 68/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9430 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0012 - accuracy: 0.97Epoch 69/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9788 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 69/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9610 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0012 - accuracy: 0.9712Epoch 69/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9695 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 69/190\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0014 - accuracy: 0.962953/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9739 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9669 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 69/190\n",
            "Epoch 69/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9701 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 69/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9629 - val_loss: 0.0022 - val_accuracy: 0.9492\n",
            "Epoch 69/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9748 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 69/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9476 - val_loss: 0.0029 - val_accuracy: 0.8966\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0013 - accuracy: 0.9786Epoch 69/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9547 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 70/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9714 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 70/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9671 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 0.0023 - accuracy: 0.9627Epoch 70/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9698 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9561 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 70/190\n",
            "Epoch 70/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9707 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 70/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9682 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0027 - accuracy: 0.9311Epoch 70/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9677 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "Epoch 70/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9687 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0010 - accuracy: 0.9694Epoch 70/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9597 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0013 - accuracy: 0.9780Epoch 70/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9409 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 71/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9715 - val_loss: 0.0019 - val_accuracy: 0.9138\n",
            "Epoch 71/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9538 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9641 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0011 - accuracy: 0.9769Epoch 71/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000Epoch 71/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9636 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0013 - accuracy: 0.9697och 71/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9705 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9416Epoch 71/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9664 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0027 - accuracy: 0.9550Epoch 71/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9686 - val_loss: 0.0033 - val_accuracy: 0.8983\n",
            "Epoch 71/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9724 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 71/190=========>...............] - ETA: 0s - loss: 0.0016 - accuracy: 0.94\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9564 - val_loss: 0.0029 - val_accuracy: 0.8966\n",
            "Epoch 71/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9550 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 72/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9541 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 72/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9634 - val_loss: 0.0015 - val_accuracy: 0.9322\n",
            "Epoch 72/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9780 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 72/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9521 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 72/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9671 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9649    Epoch 72/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9644 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 72/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9681 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 72/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9363 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 72/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9546 - val_loss: 0.0027 - val_accuracy: 0.9138\n",
            "Epoch 72/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9518 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 73/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9660 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 73/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9542 - val_loss: 0.0015 - val_accuracy: 0.9322\n",
            "Epoch 73/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.8385e-04 - accuracy: 0.9783 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9475 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 73/190\n",
            "Epoch 73/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9478 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            " 1/53 [..............................] - ETA: 0s - loss: 8.0550e-04 - accuracy: 0.9000Epoch 73/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9540 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9754    Epoch 73/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9596 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0010 - accuracy: 0.9000Epoch 73/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9546 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 73/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9419 - val_loss: 0.0029 - val_accuracy: 0.9138\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 0.0012 - accuracy: 0.9598Epoch 73/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9365 - val_loss: 0.0024 - val_accuracy: 0.8966\n",
            "Epoch 74/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9555 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0022 - accuracy: 0.9351Epoch 74/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9695 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 74/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9581 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 74/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9569 - val_loss: 0.0018 - val_accuracy: 0.94830s - loss: 0.0011 - accuracy: 1.00\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.4161e-04 - accuracy: 0.9622 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 74/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000Epoch 74/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9646 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 74/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9735 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 74/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9587 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0022 - accuracy: 0.94Epoch 74/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9458 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 74/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9471 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0013 - accuracy: 0.9729Epoch 75/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9688 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 75/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9642 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0019 - accuracy: 0.9779Epoch 75/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9713 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 75/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9706 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 75/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9581 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9000Epoch 75/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9632 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 75/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9588 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 75/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9683 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "43/53 [=======================>......] - ETA: 0s - loss: 0.0022 - accuracy: 0.9682Epoch 75/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9672 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "39/53 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 0.9743\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9664 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 76/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6416e-04 - accuracy: 0.9606 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9544Epoch 76/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9723 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 76/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9627 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 76/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6255e-04 - accuracy: 0.9835 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9527 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 76/190\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9255Epoch 76/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9511 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 76/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9596 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000Epoch 76/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9679 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 76/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9547 - val_loss: 0.0029 - val_accuracy: 0.8966\n",
            "Epoch 76/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9350 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 77/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9554 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 77/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9600 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9672 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 77/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Epoch 77/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9591 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.9412 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0010 - accuracy: 0.9932    Epoch 77/190Epoch 77/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9607 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 77/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9638 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 77/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9702 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0013 - accuracy: 0.9763\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9542 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 78/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9439 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 77/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9860 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "47/53 [=========================>....] - ETA: 0s - loss: 0.0020 - accuracy: 0.9545Epoch 78/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9705 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 78/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9616 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0014 - accuracy: 0.9000Epoch 78/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9620 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0030 - accuracy: 0.95920000Epoch 78/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9536 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9556 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "\n",
            " 1/53 [..............................] - ETA: 0s - loss: 4.3987e-04 - accuracy: 1.0000Epoch 78/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9602 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "12/53 [=====>........................] - ETA: 0s - loss: 0.0010 - accuracy: 0.9968    Epoch 78/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9789 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0013 - accuracy: 0.9000Epoch 78/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9585 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 78/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9640 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 79/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9798 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0018 - accuracy: 0.9902Epoch 79/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9471 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "47/53 [=========================>....] - ETA: 0s - loss: 0.0012 - accuracy: 0.9581Epoch 79/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9827 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 0.0020 - accuracy: 0.9698Epoch 79/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9334e-04 - accuracy: 0.9785 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 0.0018 - accuracy: 0.9795Epoch 79/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9966e-04 - accuracy: 0.9798 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9790 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 79/190\n",
            "Epoch 79/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9772 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9587 - val_loss: 0.0024 - val_accuracy: 0.9661\n",
            "Epoch 79/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 8.3731e-04 - accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9624 - val_loss: 0.0029 - val_accuracy: 0.8966\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9721 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 79/190\n",
            "Epoch 80/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9572 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "Epoch 80/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9693 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 80/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9704 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 0.0022 - accuracy: 0.9600Epoch 80/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9677 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9641Epoch 80/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9714 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9788 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 80/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0010 - accuracy: 0.8000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9640 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "26/53 [=============>................] - ETA: 0s - loss: 0.0014 - accuracy: 0.9268Epoch 80/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9742 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0012 - accuracy: 0.8000Epoch 80/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9695 - val_loss: 0.0030 - val_accuracy: 0.8966\n",
            "Epoch 80/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9624 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0030 - accuracy: 0.8000Epoch 81/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9432 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0021 - accuracy: 0.9314Epoch 81/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9662 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 81/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9330e-04 - accuracy: 0.9664 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 81/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9646 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 81/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9352e-04 - accuracy: 0.9561 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000Epoch 81/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9599 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 81/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9661 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000Epoch 81/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9716 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0021 - accuracy: 0.9482Epoch 81/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9503 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 81/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9668 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 82/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9586 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0022 - accuracy: 0.9725\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9546 - val_loss: 0.0015 - val_accuracy: 0.9322\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 0.9567Epoch 82/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9635 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 82/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.4576e-04 - accuracy: 0.9828 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0020 - accuracy: 0.9689Epoch 82/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9598 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 82/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9645 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 82/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9677 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000Epoch 82/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9571 - val_loss: 0.0028 - val_accuracy: 0.9322\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9000Epoch 82/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9699 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9657 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 83/190Epoch 82/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.8234e-04 - accuracy: 0.9605 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 83/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9685 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0015 - accuracy: 0.9720Epoch 83/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9670 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 0.0020 - accuracy: 0.9575Epoch 83/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9790 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000Epoch 83/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9685 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 83/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9701 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0011 - accuracy: 0.9608Epoch 83/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9566 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "43/53 [=======================>......] - ETA: 0s - loss: 0.0020 - accuracy: 0.9559Epoch 83/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9667 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 83/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9539 - val_loss: 0.0026 - val_accuracy: 0.9138\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9841Epoch 83/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9699 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 84/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9656 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 84/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9665 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0026 - accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9663 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0019 - accuracy: 0.9670Epoch 84/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.5095e-04 - accuracy: 0.9860 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 84/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9706 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0013 - accuracy: 0.9526\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9681 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9454Epoch 84/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9662 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0020 - accuracy: 0.9000Epoch 84/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9789 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 84/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9615 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0015 - accuracy: 0.9211Epoch 84/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9670 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 85/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9629 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 85/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9711 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 85/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9616 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 85/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.8821e-04 - accuracy: 0.9807 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 85/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9581 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9659 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 85/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 2.3633e-04 - accuracy: 1.0000Epoch 85/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9565 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 85/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9766 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 85/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9454 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 85/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9799 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 86/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9669e-04 - accuracy: 0.9692 - val_loss: 9.8820e-04 - val_accuracy: 0.9828\n",
            "Epoch 86/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9626 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 86/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9616 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 86/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0606e-04 - accuracy: 0.9741 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 86/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9616 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 86/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9672 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 86/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9658 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 86/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9702 - val_loss: 0.0027 - val_accuracy: 0.9322\n",
            "12/53 [=====>........................] - ETA: 0s - loss: 0.0010 - accuracy: 0.9576    Epoch 86/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9688 - val_loss: 0.0026 - val_accuracy: 0.9138\n",
            "Epoch 86/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9550 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 87/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9856 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 87/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9581 - val_loss: 0.0015 - val_accuracy: 0.9322\n",
            "Epoch 87/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9762 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 0.0019 - accuracy: 0.9628Epoch 87/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.1005e-04 - accuracy: 0.9781 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 87/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9637 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 87/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.9702 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9879Epoch 87/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9762 - val_loss: 0.0025 - val_accuracy: 0.9322\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9769 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 87/190\n",
            "Epoch 87/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9640 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 87/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9656 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9874 - val_loss: 9.4296e-04 - val_accuracy: 0.9828\n",
            "Epoch 88/190\n",
            "Epoch 88/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9640 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 88/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9646 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 88/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9825 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 88/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9724 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 88/1\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9765 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 88/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9640 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 88/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9668 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0028 - accuracy: 0.8000Epoch 88/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9532 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9502Epoch 88/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3016e-04 - accuracy: 0.9808 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 0.0010 - accuracy: 0.9800Epoch 89/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9646 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 9.3126e-04 - accuracy: 0.9700Epoch 89/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9676 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 0.0025 - accuracy: 0.9441Epoch 89/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9773 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0017 - accuracy: 0.9819Epoch 89/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3713e-04 - accuracy: 0.9739 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 89/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.7972e-04 - accuracy: 0.9570 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 89/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9536 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 9.3624e-04 - accuracy: 0.9949Epoch 89/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9727 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 89/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9584 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 89/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9499 - val_loss: 0.0026 - val_accuracy: 0.9138\n",
            "Epoch 89/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.4317e-04 - accuracy: 0.9929 - val_loss: 9.9059e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9725 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 90/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9632 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0019 - accuracy: 0.9828Epoch 90/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9821 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 90/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.7067e-04 - accuracy: 0.9793 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 90/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.7295e-04 - accuracy: 0.9777 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 90/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9828 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 90/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9775 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 90/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9620 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 90/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9627 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9677Epoch 90/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9377e-04 - accuracy: 0.9791 - val_loss: 9.8643e-04 - val_accuracy: 0.9828\n",
            "Epoch 91/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9676 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 91/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9685 - val_loss: 0.0025 - val_accuracy: 0.8983\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 0.0011 - accuracy: 0.9565    Epoch 91/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9867e-04 - accuracy: 0.9744 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 9.3547e-04 - accuracy: 0.9667Epoch 91/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.5909e-04 - accuracy: 0.9753 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 91/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.4356e-04 - accuracy: 0.9667 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 91/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9692 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 91/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9670 - val_loss: 9.9041e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9617 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 8.2664e-04 - accuracy: 0.9795Epoch 91/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9564 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9969    Epoch 91/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.7957e-04 - accuracy: 0.9914 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 92/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9761 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 92/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9774 - val_loss: 9.9048e-04 - val_accuracy: 0.9661\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 9.5576e-04 - accuracy: 0.9862Epoch 92/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9791e-04 - accuracy: 0.9775 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 92/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.4391e-04 - accuracy: 0.9784 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0011 - accuracy: 0.9894Epoch 92/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6832e-04 - accuracy: 0.9841 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 92/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9805 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 9.3656e-04 - accuracy: 0.9834Epoch 92/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9864 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 92/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9737 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 92/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9740 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 92/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3696e-04 - accuracy: 0.9812 - val_loss: 9.6821e-04 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000Epoch 93/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9657 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 93/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9787 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 93/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.2198e-04 - accuracy: 0.9860 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6302e-04 - accuracy: 0.9792 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 93/190\n",
            "Epoch 93/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9750 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 0.9723Epoch 93/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9788 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 93/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9778 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 93/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9710 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 93/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7425e-04 - accuracy: 0.9822 - val_loss: 9.7249e-04 - val_accuracy: 0.9828\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 9.8432e-04 - accuracy: 0.9699Epoch 94/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9650 - val_loss: 0.0025 - val_accuracy: 0.8966\n",
            "Epoch 93/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9639 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 8.8028e-04 - accuracy: 0.9829Epoch 94/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9715 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 0.0010 - accuracy: 0.9687Epoch 94/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.8858e-04 - accuracy: 0.9805 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 94/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.8398e-04 - accuracy: 0.9859 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 94/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9767 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0015 - accuracy: 0.9562Epoch 94/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9685 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 94/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9681 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.8221e-04 - accuracy: 0.9757 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 94/190\n",
            "Epoch 94/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7551e-04 - accuracy: 0.9781 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 95/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9592 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9635 - val_loss: 0.0019 - val_accuracy: 0.9138\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 9.9793e-04 - accuracy: 0.9589Epoch 94/190\n",
            "Epoch 95/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9619 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 95/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0441e-04 - accuracy: 0.9753 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 95/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.2298e-04 - accuracy: 0.9685 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "26/53 [=============>................] - ETA: 0s - loss: 0.0017 - accuracy: 0.9609Epoch 95/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.8622e-04 - accuracy: 0.9793 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9705 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 95/190\n",
            "Epoch 95/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9782 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9643 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 95/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 5.4784e-04 - accuracy: 1.0000Epoch 95/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.4697e-04 - accuracy: 0.9813 - val_loss: 9.0459e-04 - val_accuracy: 0.9828\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 9.2822e-04 - accuracy: 0.9855Epoch 96/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.9616 - val_loss: 0.0027 - val_accuracy: 0.9138\n",
            " 1/53 [..............................] - ETA: 0s - loss: 4.4053e-04 - accuracy: 1.0000Epoch 95/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9759 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000Epoch 96/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9517 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 96/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.4450e-04 - accuracy: 0.9830 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 96/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9674e-04 - accuracy: 0.9832 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 96/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9849 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 0.0017 - accuracy: 0.9549Epoch 96/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9775 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 96/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9618 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 8.6974e-04 - accuracy: 0.9722Epoch 96/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9802 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 9.3275e-04 - accuracy: 0.9570Epoch 96/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1607e-04 - accuracy: 0.9794 - val_loss: 0.0010 - val_accuracy: 0.9310\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 0.0010 - accuracy: 0.9711    \n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9611 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 97/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9705 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "Epoch 96/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9591 - val_loss: 9.0779e-04 - val_accuracy: 0.9661\n",
            "Epoch 97/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.2635e-04 - accuracy: 0.9648 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 0.0011 - accuracy: 0.9604    Epoch 97/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.4659e-04 - accuracy: 0.9758 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 97/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9753 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 97/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9743 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 97/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6404e-04 - accuracy: 0.9716 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0017 - accuracy: 0.9610Epoch 97/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9674 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0012 - accuracy: 0.9806\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.8046e-04 - accuracy: 0.9624 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 98/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.9620 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0015 - accuracy: 0.95349846Epoch 98/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.9632 - val_loss: 0.0026 - val_accuracy: 0.9138\n",
            "Epoch 97/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9781 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9651Epoch 98/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9652 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 9.3611e-04 - accuracy: 0.9839Epoch 98/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0851e-04 - accuracy: 0.9840 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 98/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9640 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 98/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3236e-04 - accuracy: 0.9827 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000Epoch 98/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9798 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9738Epoch 98/1\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9651 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 98/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.5710e-04 - accuracy: 0.9875 - val_loss: 9.9122e-04 - val_accuracy: 0.9483\n",
            "Epoch 99/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9409 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 99/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9647 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "39/53 [=====================>........] - ETA: 0s - loss: 8.9977e-04 - accuracy: 0.9739Epoch 98/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9720 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0010 - accuracy: 0.9774Epoch 99/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9885 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 99/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9865e-04 - accuracy: 0.9753 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9677 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 99/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000Epoch 99/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9781 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 0.0022 - accuracy: 0.9555Epoch 99/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.9843e-04 - accuracy: 0.9828 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 99/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9793 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 99/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9707 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 100/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.5273e-04 - accuracy: 0.9821 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0014 - accuracy: 0.98Epoch 100/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9604 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9649 - val_loss: 9.1114e-04 - val_accuracy: 0.9661\n",
            "\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0117e-04 - accuracy: 0.9755 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9707Epoch 100/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9839 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 8.4378e-04 - accuracy: 0.9818Epoch 100/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9750 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 100/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1751e-04 - accuracy: 0.9765 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 0.0016 - accuracy: 0.965427/53 [==============>...............] - ETA: 0s - loss: 0.0011 - accuracy: 0.9584Epoch 100/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9662 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 100/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.2829e-04 - accuracy: 0.9864 - val_loss: 9.8955e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9647 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 101/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.6140e-04 - accuracy: 0.9819 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 101/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9688 - val_loss: 0.0032 - val_accuracy: 0.9483\n",
            "Epoch 100/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9593 - val_loss: 9.5947e-04 - val_accuracy: 0.9661\n",
            "Epoch 101/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1423e-04 - accuracy: 0.9714 - val_loss: 0.0032 - val_accuracy: 0.9138\n",
            "Epoch 101/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9760 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 0.0020 - accuracy: 0.9708Epoch 101/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9564e-04 - accuracy: 0.9774 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 0.0010 - accuracy: 0.9801    Epoch 101/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0178e-04 - accuracy: 0.9654 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 101/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9603 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 101/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.9056e-04 - accuracy: 0.9691 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 101/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9713 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9916Epoch 102/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.2629e-04 - accuracy: 0.9830 - val_loss: 8.8456e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9583 - val_loss: 0.0039 - val_accuracy: 0.9138\n",
            "Epoch 101/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9618 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0011 - accuracy: 0.9622Epoch 102/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9750 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 102/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9798 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 102/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.4586e-04 - accuracy: 0.9866 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 7.4601e-04 - accuracy: 0.9879\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9672 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 102/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9629 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0012 - accuracy: 0.9564Epoch 102/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9802 - val_loss: 9.7181e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9861 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 103/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7791e-04 - accuracy: 0.9819 - val_loss: 8.7961e-04 - val_accuracy: 0.9828\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 8.6937e-04 - accuracy: 0.9553Epoch 103/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9569 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "31/53 [================>.............] - ETA: 0s - loss: 7.4340e-04 - accuracy: 0.9800Epoch 102/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.2271e-04 - accuracy: 0.9816 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 103/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9582 - val_loss: 8.9879e-04 - val_accuracy: 0.9492\n",
            "Epoch 103/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9923 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 0.0014 - accuracy: 0.980898Epoch 103/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8907e-04 - accuracy: 0.9878 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 103/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8946e-04 - accuracy: 0.9800 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "38/53 [====================>.........] - ETA: 0s - loss: 9.0354e-04 - accuracy: 0.9731Epoch 103/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0213e-04 - accuracy: 0.9676 - val_loss: 9.3253e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9533 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 103/190Epoch 103/190\n",
            "\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9798 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 9.8764e-04 - accuracy: 0.9834Epoch 104/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.2823e-04 - accuracy: 0.9741 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 104/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9671 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.3780e-04 - accuracy: 0.9866 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 103/190\n",
            "Epoch 104/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9658 - val_loss: 8.5495e-04 - val_accuracy: 0.9661\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 8.8387e-04 - accuracy: 0.9537Epoch 104/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9838 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 104/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.5083e-04 - accuracy: 0.9861 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0016 - accuracy: 0.9573Epoch 104/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.2828e-04 - accuracy: 0.9813 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0016 - accuracy: 0.9628Epoch 104/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.2340e-04 - accuracy: 0.9785 - val_loss: 8.7178e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9209e-04 - accuracy: 0.9783 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 104/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9646 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0015 - accuracy: 0.9784Epoch 105/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.8806e-04 - accuracy: 0.9714 - val_loss: 9.2891e-04 - val_accuracy: 1.0000\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0012 - accuracy: 0.9697Epoch 105/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9753 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "Epoch 104/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.8619e-04 - accuracy: 0.9684 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 105/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9846 - val_loss: 9.7230e-04 - val_accuracy: 0.9661\n",
            "25/53 [=============>................] - ETA: 0s - loss: 0.0016 - accuracy: 0.98249446Epoch 105/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9711 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 105/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9743 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 105/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.8904e-04 - accuracy: 0.9492 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 105/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.5975e-04 - accuracy: 0.9602 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 8.1222e-04 - accuracy: 0.9986Epoch 105/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9750 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 105/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9785 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0016 - accuracy: 0.9523Epoch 106/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.4317e-04 - accuracy: 0.9860 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 106/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9536 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "34/53 [==================>...........] - ETA: 0s - loss: 9.5895e-04 - accuracy: 0.9785Epoch 105/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3874e-04 - accuracy: 0.9913 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 106/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9574 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 106/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9397e-04 - accuracy: 0.9890 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 0.0016 - accuracy: 0.9667Epoch 106/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9723 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 0.0017 - accuracy: 0.9518\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1041e-04 - accuracy: 0.9848 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 7.7946e-04 - accuracy: 0.9502\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.2688e-04 - accuracy: 0.9777 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 106/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.7998e-04 - accuracy: 0.9621 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 106/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9709 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 107/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1268e-04 - accuracy: 0.9687 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 107/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9569 - val_loss: 0.0022 - val_accuracy: 0.8966\n",
            "Epoch 106/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.5891e-04 - accuracy: 0.9712 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 107/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9739 - val_loss: 8.0496e-04 - val_accuracy: 0.9492\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 0.0010 - accuracy: 0.9537Epoch 107/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9768 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 107/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.3821e-04 - accuracy: 0.9666 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 8.1941e-04 - accuracy: 0.9649Epoch 107/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9563 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9641 - val_loss: 9.3902e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/190\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 0.0017 - accuracy: 0.94Epoch 107/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9808 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "50/53 [===========================>..] - ETA: 0s - loss: 7.2748e-04 - accuracy: 0.9778Epoch 107/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9675 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 108/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.3685e-04 - accuracy: 0.9779 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 108/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9574 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0016 - accuracy: 0.9352Epoch 107/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9274e-04 - accuracy: 0.9617 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "39/53 [=====================>........] - ETA: 0s - loss: 8.1521e-04 - accuracy: 0.9695Epoch 108/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.8329e-04 - accuracy: 0.9689 - val_loss: 8.5055e-04 - val_accuracy: 0.9661\n",
            "Epoch 108/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9676 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 108/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.4489e-04 - accuracy: 0.9676 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - ETA: 0s - loss: 8.4549e-04 - accuracy: 0.9710\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9662e-04 - accuracy: 0.9783 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 108/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.4720e-04 - accuracy: 0.9711 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 108/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9739 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 8.3082e-04 - accuracy: 0.9904Epoch 108/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9518 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 109/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.8587e-04 - accuracy: 0.9777 - val_loss: 9.0216e-04 - val_accuracy: 0.9828\n",
            "Epoch 109/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9469 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0012 - accuracy: 0.9777Epoch 108/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3295e-04 - accuracy: 0.9694 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 109/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.4646e-04 - accuracy: 0.9831 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 109/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9744 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 0.9742Epoch 109/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1569e-04 - accuracy: 0.9868 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 109/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3951e-04 - accuracy: 0.9825 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 109/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9735 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0022 - accuracy: 0.9276\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9811 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 109/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9657 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 9.0835e-04 - accuracy: 0.9405Epoch 110/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.4426e-04 - accuracy: 0.9692 - val_loss: 9.7472e-04 - val_accuracy: 0.9828\n",
            "25/53 [=============>................] - ETA: 0s - loss: 8.3637e-04 - accuracy: 0.9822Epoch 110/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9380 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 109/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.4638e-04 - accuracy: 0.9625 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 110/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9584 - val_loss: 8.1203e-04 - val_accuracy: 0.9492\n",
            "Epoch 110/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9780 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 110/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2999e-04 - accuracy: 0.9890 - val_loss: 9.8487e-04 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Epoch 110/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.6307e-04 - accuracy: 0.9784 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 9.6368e-04 - accuracy: 0.9931Epoch 110/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6472e-04 - accuracy: 0.9603 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0014 - accuracy: 0.9899Epoch 110/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9682 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 110/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9671 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 111/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9053e-04 - accuracy: 0.9866 - val_loss: 9.2899e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9686 - val_loss: 0.0024 - val_accuracy: 0.8966\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0013 - accuracy: 0.9530Epoch 110/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.3929e-04 - accuracy: 0.9849 - val_loss: 9.9376e-04 - val_accuracy: 1.0000\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 8.7992e-04 - accuracy: 0.9876Epoch 111/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.8765e-04 - accuracy: 0.9825 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0014 - accuracy: 0.9558Epoch 111/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9846 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 7.2387e-04 - accuracy: 0.9900Epoch 111/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.1898e-04 - accuracy: 0.9711 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 7.0915e-04 - accuracy: 0.9903Epoch 111/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.7820e-04 - accuracy: 0.9851 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 111/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1359e-04 - accuracy: 0.9727 - val_loss: 9.4184e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.5303e-04 - accuracy: 0.9714 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 111/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9594 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 112/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9708 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.5006e-04 - accuracy: 0.9882 - val_loss: 8.0864e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0023 - accuracy: 0.9000Epoch 112/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7704e-04 - accuracy: 0.9788 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 112/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9463 - val_loss: 8.1580e-04 - val_accuracy: 0.9661\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 9.7498e-04 - accuracy: 0.9732Epoch 112/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9725 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 112/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0327e-04 - accuracy: 0.9831 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 112/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.5831e-04 - accuracy: 0.9742 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 112/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9245e-04 - accuracy: 0.9731 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 8.5275e-04 - accuracy: 1.0000Epoch 112/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0417e-04 - accuracy: 0.9577 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "31/53 [================>.............] - ETA: 0s - loss: 9.1496e-04 - accuracy: 0.9566Epoch 112/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9775 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 113/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.3973e-04 - accuracy: 0.9812 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9582 - val_loss: 0.0022 - val_accuracy: 0.8966\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 8.1099e-04 - accuracy: 0.9771Epoch 112/190\n",
            "Epoch 113/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3299e-04 - accuracy: 0.9616 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.6325e-04 - accuracy: 0.9741 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 113/190\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0010 - accuracy: 0.97749016Epoch 113/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9868 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 0.0014 - accuracy: 0.95Epoch 113/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.4089e-04 - accuracy: 0.9910 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0014 - accuracy: 0.9803Epoch 113/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9861e-04 - accuracy: 0.9772 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 113/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.3416e-04 - accuracy: 0.9727 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "25/53 [=============>................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9566Epoch 113/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.6654e-04 - accuracy: 0.9705 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 9.6704e-04 - accuracy: 0.9773\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9550 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 7.0880e-04 - accuracy: 0.9687Epoch 114/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9737 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.4426e-04 - accuracy: 0.9779 - val_loss: 9.7787e-04 - val_accuracy: 0.9828\n",
            "Epoch 113/190Epoch 114/190\n",
            "\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.4991e-04 - accuracy: 0.9705 - val_loss: 8.2564e-04 - val_accuracy: 0.9661\n",
            "12/53 [=====>........................] - ETA: 0s - loss: 8.6798e-04 - accuracy: 1.0000Epoch 114/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9650 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.7250e-04 - accuracy: 1.0000Epoch 114/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9672 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 114/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.7971e-04 - accuracy: 0.9691 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9916    Epoch 114/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.6162e-04 - accuracy: 0.9754 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.96119674Epoch 114/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.9680 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 115/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9613 - val_loss: 8.6795e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.7551e-04 - accuracy: 0.9675 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000Epoch 114/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 4.4614e-04 - accuracy: 1.0000Epoch 114/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.3356e-04 - accuracy: 0.9896 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 9.2212e-04 - accuracy: 0.9765Epoch 115/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9580 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.5937e-04 - accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9853 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0015 - accuracy: 0.9889Epoch 115/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9776 - val_loss: 0.0015 - val_accuracy: 0.9153\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 9.1505e-04 - accuracy: 0.9657Epoch 115/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9725e-04 - accuracy: 0.9895 - val_loss: 9.7189e-04 - val_accuracy: 0.9828\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0014 - accuracy: 0.9858Epoch 115/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9833 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.3386e-04 - accuracy: 1.0000Epoch 115/190================>.......] - ETA: 0s - loss: 9.8863e-04 - accuracy: 0.9864\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.2870e-04 - accuracy: 0.9754 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "31/53 [================>.............] - ETA: 0s - loss: 8.3247e-04 - accuracy: 0.9917Epoch 115/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9848 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 116/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.1313e-04 - accuracy: 0.9670 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 115/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.7371e-04 - accuracy: 0.9847 - val_loss: 7.6462e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9511 - val_loss: 0.0022 - val_accuracy: 0.8966\n",
            "Epoch 115/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.2000e-04 - accuracy: 0.9903 - val_loss: 8.5353e-04 - val_accuracy: 0.9483\n",
            "52/53 [============================>.] - ETA: 0s - loss: 8.3862e-04 - accuracy: 0.9871Epoch 116/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.5705e-04 - accuracy: 0.9697 - val_loss: 8.1037e-04 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.3771e-04 - accuracy: 0.9871 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 0.0016 - accuracy: 0.9862Epoch 116/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.1814e-04 - accuracy: 0.9875 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 8.0507e-04 - accuracy: 0.9779h 116/1\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9794 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 116/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.4826e-04 - accuracy: 0.9897 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "31/53 [================>.............] - ETA: 0s - loss: 6.9278e-04 - accuracy: 0.9686\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9836 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.5188e-04 - accuracy: 0.9725 - val_loss: 0.0019 - val_accuracy: 0.9831\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 6.6789e-04 - accuracy: 0.9737Epoch 117/190\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 7.3978e-04 - accuracy: 0.9699Epoch 116/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9366e-04 - accuracy: 0.9821 - val_loss: 8.3659e-04 - val_accuracy: 1.0000\n",
            "43/53 [=======================>......] - ETA: 0s - loss: 7.9863e-04 - accuracy: 0.9766Epoch 116/1\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9679 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "Epoch 116/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.6016e-04 - accuracy: 0.9701 - val_loss: 9.3680e-04 - val_accuracy: 0.9483\n",
            "Epoch 117/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.8377e-04 - accuracy: 0.9747 - val_loss: 9.5167e-04 - val_accuracy: 0.9661\n",
            "Epoch 117/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.1165e-04 - accuracy: 0.9756 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 117/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.9155e-04 - accuracy: 0.9834 - val_loss: 9.6876e-04 - val_accuracy: 0.9828\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 0.0019 - accuracy: 0.979396Epoch 117/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9816 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 117/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.4576e-04 - accuracy: 0.9720 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 117/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.6362e-04 - accuracy: 0.9733 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 117/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9692 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "37/53 [===================>..........] - ETA: 0s - loss: 8.1977e-04 - accuracy: 0.9752Epoch 118\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.3123e-04 - accuracy: 0.9813 - val_loss: 8.8118e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9740 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 117/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9034e-04 - accuracy: 0.9618 - val_loss: 7.9712e-04 - val_accuracy: 1.0000\n",
            "25/53 [=============>................] - ETA: 0s - loss: 9.2344e-04 - accuracy: 0.9728Epoch 118/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.1551e-04 - accuracy: 0.9750 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "39/53 [=====================>........] - ETA: 0s - loss: 8.9823e-04 - accuracy: 0.9573Epoch 118/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.6519e-04 - accuracy: 0.9737 - val_loss: 7.4834e-04 - val_accuracy: 0.9661\n",
            "Epoch 118/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.6388e-04 - accuracy: 0.9822 - val_loss: 9.5094e-04 - val_accuracy: 0.9655\n",
            "Epoch 118/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9782 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 118/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.8352e-04 - accuracy: 0.9610 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 6.7979e-04 - accuracy: 0.9698Epoch 118/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.3751e-04 - accuracy: 0.9711 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 8.5231e-04 - accuracy: 0.9565Epoch 118/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9705 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3244e-04 - accuracy: 0.9623 - val_loss: 7.6691e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/190\n",
            "31/53 [================>.............] - ETA: 0s - loss: 6.3406e-04 - accuracy: 0.9816\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9601 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "Epoch 118/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2389e-04 - accuracy: 0.9753 - val_loss: 8.6464e-04 - val_accuracy: 1.0000\n",
            "32/53 [=================>............] - ETA: 0s - loss: 0.0010 - accuracy: 0.9667Epoch 119/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3595e-04 - accuracy: 0.9593 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 119/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9851e-04 - accuracy: 0.9728 - val_loss: 8.4311e-04 - val_accuracy: 0.9661\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000Epoch 119/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1787e-04 - accuracy: 0.9627 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "48/53 [==========================>...] - ETA: 0s - loss: 9.8374e-04 - accuracy: 0.9663Epoch 119/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.7757e-04 - accuracy: 0.9814 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0010 - accuracy: 1.00009756Epoch 119/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7579e-04 - accuracy: 0.9691 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 119/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.7665e-04 - accuracy: 0.9662 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 119/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9891 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8735e-04 - accuracy: 0.9612 - val_loss: 8.9300e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/190Epoch 120/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9555 - val_loss: 0.0020 - val_accuracy: 0.9138\n",
            "Epoch 119/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.5774e-04 - accuracy: 0.9799 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 120/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8708e-04 - accuracy: 0.9796 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 5.4500e-04 - accuracy: 1.0000Epoch 120/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.4891e-04 - accuracy: 0.9801 - val_loss: 8.3982e-04 - val_accuracy: 0.9492\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 8.2999e-04 - accuracy: 0.9909Epoch 120/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9838 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 120/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9604e-04 - accuracy: 0.9907 - val_loss: 9.9964e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.3564e-04 - accuracy: 0.9895 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 9.4080e-04 - accuracy: 0.9757Epoch 120/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.6398e-04 - accuracy: 0.9764 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 120/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9695 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3274e-04 - accuracy: 0.9752 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 7.7585e-04 - accuracy: 0.9833Epoch 121/190\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 7.9174e-04 - accuracy: 0.9966Epoch 120/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9676 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 0.0010 - accuracy: 0.9572Epoch 120/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.9256e-04 - accuracy: 0.9950 - val_loss: 9.4314e-04 - val_accuracy: 0.9828\n",
            "Epoch 121/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.8365e-04 - accuracy: 0.9828 - val_loss: 9.6958e-04 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 5.2437e-04 - accuracy: 1.0000Epoch 121/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9891e-04 - accuracy: 0.9845 - val_loss: 8.9713e-04 - val_accuracy: 0.9661\n",
            "Epoch 121/1\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.4898e-04 - accuracy: 0.9788 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.2435e-04 - accuracy: 1.0000Epoch 121/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.9589e-04 - accuracy: 0.9832 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 121/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.5364e-04 - accuracy: 0.9637 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 121/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.5628e-04 - accuracy: 0.9863 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 121/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9803 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 122/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.4723e-04 - accuracy: 0.9768 - val_loss: 9.3553e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9695 - val_loss: 0.0020 - val_accuracy: 0.9138\n",
            "Epoch 121/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7715e-04 - accuracy: 0.9770 - val_loss: 9.2994e-04 - val_accuracy: 0.9828\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9545    Epoch 122/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1532e-04 - accuracy: 0.9886 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000Epoch 122/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1087e-04 - accuracy: 0.9772 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 122/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.5300e-04 - accuracy: 0.9792 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            " 1/53 [..............................] - ETA: 0s - loss: 8.1374e-04 - accuracy: 1.0000Epoch 122/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.3597e-04 - accuracy: 0.9816 - val_loss: 9.7534e-04 - val_accuracy: 0.9828\n",
            "Epoch 122/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6514e-04 - accuracy: 0.9806 - val_loss: 0.0014 - val_accuracy: 0.98310s - loss: 0.0012 - accuracy: \n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.0890e-04 - accuracy: 0.9803 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 122/190\n",
            "Epoch 122/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9849 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 9.5303e-04 - accuracy: 0.9980h 123\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.6630e-04 - accuracy: 0.9716 - val_loss: 8.1868e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9586 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 122/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0951e-04 - accuracy: 0.9888 - val_loss: 9.1437e-04 - val_accuracy: 0.9655\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9965    Epoch 123/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.5641e-04 - accuracy: 0.9875 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 123/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9861 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 123/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9760 - val_loss: 7.3845e-04 - val_accuracy: 0.9661\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.3451e-04 - accuracy: 1.0000Epoch 123/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.6944e-04 - accuracy: 0.9834 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 4.8164e-04 - accuracy: 1.0000Epoch 123/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9757 - val_loss: 0.0020 - val_accuracy: 0.9831\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7653e-04 - accuracy: 0.9924 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.9362e-04 - accuracy: 1.0000Epoch 123/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9795 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 9.7161e-04 - accuracy: 0.9676Epoch 124/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.4960e-04 - accuracy: 0.9838 - val_loss: 7.3051e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9730 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 123/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8734e-04 - accuracy: 0.9864 - val_loss: 9.0394e-04 - val_accuracy: 0.9483\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 7.1730e-04 - accuracy: 0.9846Epoch 124/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.2311e-04 - accuracy: 0.9751 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 8.1186e-04 - accuracy: 0.9750Epoch 124/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1339e-04 - accuracy: 0.9764 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.5896e-04 - accuracy: 0.9846 - val_loss: 7.3774e-04 - val_accuracy: 0.9661\n",
            "Epoch 124/190Epoch 124/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6224e-04 - accuracy: 0.9668 - val_loss: 9.5501e-04 - val_accuracy: 0.9828\n",
            "Epoch 124/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1993e-04 - accuracy: 0.9783 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 124/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.4008e-04 - accuracy: 0.9749 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 124/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9867 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 125/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.6972e-04 - accuracy: 0.9832 - val_loss: 9.3697e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9676 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0011 - accuracy: 0.974397Epoch 124/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.8476e-04 - accuracy: 0.9759 - val_loss: 8.1611e-04 - val_accuracy: 0.9828\n",
            "Epoch 125/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.3849e-04 - accuracy: 0.9771 - val_loss: 9.5455e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.1782e-04 - accuracy: 0.9787 - val_loss: 7.8524e-04 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9765 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 125/1\n",
            "Epoch 125/190\n",
            "Epoch 125/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.5644e-04 - accuracy: 0.9770 - val_loss: 9.4104e-04 - val_accuracy: 0.9828\n",
            "Epoch 125/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3977e-04 - accuracy: 0.9681 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 8.9458e-04 - accuracy: 0.9641\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.7241e-04 - accuracy: 0.9663 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 125/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9853 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "31/53 [================>.............] - ETA: 0s - loss: 8.8677e-04 - accuracy: 0.9917Epoch 126/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7623e-04 - accuracy: 0.9658 - val_loss: 8.0974e-04 - val_accuracy: 1.0000\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 8.1127e-04 - accuracy: 0.9767Epoch 125/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9705 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 125/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3691e-04 - accuracy: 0.9835 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 126/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.5955e-04 - accuracy: 0.9723 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 126/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9785e-04 - accuracy: 0.9891 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 8.9207e-04 - accuracy: 0.9337Epoch 126/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9007e-04 - accuracy: 0.9865 - val_loss: 8.6945e-04 - val_accuracy: 0.9831\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.8374e-04 - accuracy: 0.9000Epoch 126/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.4356e-04 - accuracy: 0.9941 - val_loss: 9.2752e-04 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - ETA: 0s - loss: 7.7095e-04 - accuracy: 0.9809Epoch 126/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.7078e-04 - accuracy: 0.9809 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 8.9116e-04 - accuracy: 0.9503Epoch 126/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.7242e-04 - accuracy: 0.9720 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "18/53 [=========>....................] - ETA: 0s - loss: 0.0010 - accuracy: 0.9801  Epoch 126/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9622 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "43/53 [=======================>......] - ETA: 0s - loss: 8.8294e-04 - accuracy: 0.9555Epoch 127/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.3715e-04 - accuracy: 0.9693 - val_loss: 9.7571e-04 - val_accuracy: 1.0000\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 6.2384e-04 - accuracy: 0.9771Epoch 126/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9659 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 126/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.8046e-04 - accuracy: 0.9585 - val_loss: 9.1903e-04 - val_accuracy: 0.9828\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0012 - accuracy: 0.99779651Epoch 127/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7077e-04 - accuracy: 0.9762 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "38/53 [====================>.........] - ETA: 0s - loss: 8.8823e-04 - accuracy: 0.9838Epoch 127/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9768 - val_loss: 8.1568e-04 - val_accuracy: 0.9661\n",
            "Epoch 127/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.1338e-04 - accuracy: 0.9666 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 127/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.5601e-04 - accuracy: 0.9816 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 127/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.2387e-04 - accuracy: 0.9721 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 5.9300e-04 - accuracy: 1.0000Epoch 127/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.0840e-04 - accuracy: 0.9807 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 127/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9901 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 128/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.2834e-04 - accuracy: 0.9687 - val_loss: 8.2092e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9707 - val_loss: 0.0020 - val_accuracy: 0.9138\n",
            "Epoch 127/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.5322e-04 - accuracy: 0.9924 - val_loss: 8.3781e-04 - val_accuracy: 0.9828\n",
            "Epoch 128/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.0275e-04 - accuracy: 0.9902 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 128/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.2944e-04 - accuracy: 0.9839 - val_loss: 7.8952e-04 - val_accuracy: 0.9661\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 7.3770e-04 - accuracy: 0.9947Epoch 128/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.8116e-04 - accuracy: 0.9891 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "11/53 [=====>........................] - ETA: 0s - loss: 6.3256e-04 - accuracy: 0.9964Epoch 128/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.7665e-04 - accuracy: 0.9846 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 128/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.1573e-04 - accuracy: 0.9839 - val_loss: 9.9359e-04 - val_accuracy: 0.9655\n",
            "Epoch 128/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.4756e-04 - accuracy: 0.9721 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "26/53 [=============>................] - ETA: 0s - loss: 7.0974e-04 - accuracy: 0.9909Epoch 128/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9861 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 129/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.2920e-04 - accuracy: 0.9895 - val_loss: 7.3569e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9814 - val_loss: 0.0019 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.7829e-04 - accuracy: 0.9882 - val_loss: 8.7086e-04 - val_accuracy: 0.9828\n",
            "Epoch 128/190\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 8.8487e-04 - accuracy: 0.9615Epoch 129/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4386e-04 - accuracy: 0.9871 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 6.8866e-04 - accuracy: 0.9678Epoch 129/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.8087e-04 - accuracy: 0.9773 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 129/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.4123e-04 - accuracy: 0.9869 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 129/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1540e-04 - accuracy: 0.9843 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 129/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8662e-04 - accuracy: 0.9827 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 7.3259e-04 - accuracy: 0.9999Epoch 129/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7696e-04 - accuracy: 0.9656 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 129/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9757 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 130/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.5808e-04 - accuracy: 0.9704 - val_loss: 7.7100e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9757 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 129/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.8654e-04 - accuracy: 0.9961 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 130/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.9953e-04 - accuracy: 0.9888 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - ETA: 0s - loss: 9.9563e-04 - accuracy: 0.9659Epoch 130/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.8846e-04 - accuracy: 0.9750 - val_loss: 9.4660e-04 - val_accuracy: 0.9831\n",
            "Epoch 130/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.9474e-04 - accuracy: 0.9662 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 130/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7949e-04 - accuracy: 0.9680 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000Epoch 130/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.6999e-04 - accuracy: 0.9819 - val_loss: 9.1338e-04 - val_accuracy: 0.9828\n",
            "Epoch 130/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7267e-04 - accuracy: 0.9545 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 130/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9549 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "31/53 [================>.............] - ETA: 0s - loss: 6.6974e-04 - accuracy: 0.9885Epoch 131/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.6169e-04 - accuracy: 0.9808 - val_loss: 9.0389e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1712e-04 - accuracy: 0.9718 - val_loss: 8.7363e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9491 - val_loss: 0.0020 - val_accuracy: 0.9138\n",
            "Epoch 130/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.6192e-04 - accuracy: 1.0000Epoch 130/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8693e-04 - accuracy: 0.9860 - val_loss: 9.3431e-04 - val_accuracy: 1.0000\n",
            "11/53 [=====>........................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9876Epoch 131/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.4035e-04 - accuracy: 0.9763 - val_loss: 7.4911e-04 - val_accuracy: 0.9661\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 9.0857e-04 - accuracy: 0.9808Epoch 131/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0738e-04 - accuracy: 0.9939 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 131/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1383e-04 - accuracy: 0.9750 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.2251e-04 - accuracy: 1.0000h 131/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.5739e-04 - accuracy: 0.9798 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 131/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.0004e-04 - accuracy: 0.9798 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 7.2989e-04 - accuracy: 0.9933Epoch 131/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9751 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 132/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9704 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.3594e-04 - accuracy: 0.9914 - val_loss: 8.5561e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/190\n",
            "Epoch 132/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.6266e-04 - accuracy: 0.9757 - val_loss: 8.5032e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.5011e-04 - accuracy: 0.9896 - val_loss: 9.5185e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6490e-04 - accuracy: 0.9845 - val_loss: 8.0315e-04 - val_accuracy: 0.9492\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9840  Epoch 132/190\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 5.8343e-04 - accuracy: 0.9980Epoch 132/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.6631e-04 - accuracy: 0.9888 - val_loss: 9.7388e-04 - val_accuracy: 0.9655\n",
            "Epoch 132/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4688e-04 - accuracy: 0.9850 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "24/53 [============>.................] - ETA: 0s - loss: 0.0012 - accuracy: 0.98Epoch 132/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2473e-04 - accuracy: 0.9813 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "10/53 [====>.........................] - ETA: 0s - loss: 6.3805e-04 - accuracy: 1.0000Epoch 132/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9764 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 6.3562e-04 - accuracy: 0.9977Epoch 132/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9793 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 8.0524e-04 - accuracy: 0.9000Epoch 133/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.7155e-04 - accuracy: 0.9829 - val_loss: 9.3805e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9781 - val_loss: 0.0019 - val_accuracy: 0.9138\n",
            "Epoch 132/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.0675e-04 - accuracy: 0.9752 - val_loss: 9.3051e-04 - val_accuracy: 1.0000\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 6.9708e-04 - accuracy: 0.9830Epoch 132/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.6670e-04 - accuracy: 0.9813 - val_loss: 7.6513e-04 - val_accuracy: 0.9661\n",
            "50/53 [===========================>..] - ETA: 0s - loss: 6.3341e-04 - accuracy: 0.9843Epoch 133/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4997e-04 - accuracy: 0.9854 - val_loss: 9.2950e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.5444e-04 - accuracy: 0.9942 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 9.7813e-04 - accuracy: 0.9000Epoch 133/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1095e-04 - accuracy: 0.9806 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 133/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.3578e-04 - accuracy: 0.9843 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 133/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9801 - val_loss: 0.0013 - val_accuracy: 0.9483TA: 0s - loss: 0.0013 - accuracy: 0.\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1865e-04 - accuracy: 0.9638 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 133/190\n",
            "Epoch 134/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7094e-04 - accuracy: 0.9741 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 134/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1956e-04 - accuracy: 0.9794 - val_loss: 9.8273e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9669 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 0.0012 - accuracy: 0.99Epoch 133/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1246e-04 - accuracy: 0.9793 - val_loss: 8.5751e-04 - val_accuracy: 0.9492\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7604e-04 - accuracy: 0.9760 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000Epoch 134/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.2505e-04 - accuracy: 0.9725 - val_loss: 9.6506e-04 - val_accuracy: 0.9655\n",
            "Epoch 134/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.0024e-04 - accuracy: 0.9777 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 134/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.8394e-04 - accuracy: 0.9768 - val_loss: 8.6716e-04 - val_accuracy: 0.9828\n",
            "Epoch 134/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6915e-04 - accuracy: 0.9791 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9892 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 134/190\n",
            "Epoch 135/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.5836e-04 - accuracy: 0.9725 - val_loss: 8.9846e-04 - val_accuracy: 0.9828\n",
            "Epoch 135/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.6982e-04 - accuracy: 0.9695 - val_loss: 7.1979e-04 - val_accuracy: 1.0000\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 9.0264e-04 - accuracy: 0.9802Epoch 134/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9748 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 7.9312e-04 - accuracy: 0.9819Epoch 134/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.6322e-04 - accuracy: 0.9789 - val_loss: 8.2861e-04 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.7245e-04 - accuracy: 0.9734 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "39/53 [=====================>........] - ETA: 0s - loss: 0.0011 - accuracy: 0.9768Epoch 135/190\n",
            "Epoch 135/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.0077e-04 - accuracy: 0.9817 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 135/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.9181e-04 - accuracy: 0.9793 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 135/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.6055e-04 - accuracy: 0.9892 - val_loss: 8.8433e-04 - val_accuracy: 0.9828\n",
            "Epoch 135/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.5034e-04 - accuracy: 0.9680 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 135/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9776 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 7.3425e-04 - accuracy: 0.9850Epoch 136/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2716e-04 - accuracy: 0.9858 - val_loss: 8.8234e-04 - val_accuracy: 0.9483\n",
            "32/53 [=================>............] - ETA: 0s - loss: 6.8655e-04 - accuracy: 0.9687Epoch 136/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0327e-04 - accuracy: 0.9687 - val_loss: 6.8563e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9602 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 7.6982e-04 - accuracy: 0.9491Epoch 135/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.3058e-04 - accuracy: 0.9806 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "23/53 [============>.................] - ETA: 0s - loss: 7.9331e-04 - accuracy: 0.9549Epoch 136/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.6306e-04 - accuracy: 0.9629 - val_loss: 6.4112e-04 - val_accuracy: 0.9661\n",
            "Epoch 136/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.0768e-04 - accuracy: 0.9727 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 136/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.3041e-04 - accuracy: 0.9707 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 136/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.0484e-04 - accuracy: 0.9563 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 136/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9813 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.7618e-04 - accuracy: 0.9618 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.9887e-04 - accuracy: 1.0000Epoch 136/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8194e-04 - accuracy: 0.9628 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 137/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.2943e-04 - accuracy: 0.9826 - val_loss: 7.3941e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9704 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 136/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.3328e-04 - accuracy: 0.9846 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1928e-04 - accuracy: 0.9838 - val_loss: 8.4123e-04 - val_accuracy: 0.9492\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 7.8676e-04 - accuracy: 0.9727Epoch 137/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 4.7848e-04 - accuracy: 1.0000Epoch 137/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7427e-04 - accuracy: 0.9862 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 8.2921e-04 - accuracy: 0.8000Epoch 137/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3962e-04 - accuracy: 0.9886 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 137/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.0824e-04 - accuracy: 0.9947 - val_loss: 9.4374e-04 - val_accuracy: 0.9655\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 8.0845e-04 - accuracy: 0.9419Epoch 137/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9677e-04 - accuracy: 0.9731 - val_loss: 0.0020 - val_accuracy: 0.9831\n",
            "Epoch 137/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9811 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9801    Epoch 138/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.5735e-04 - accuracy: 0.9799 - val_loss: 9.4848e-04 - val_accuracy: 1.0000\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 8.1612e-04 - accuracy: 0.9842Epoch 138/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4008e-04 - accuracy: 0.9684 - val_loss: 6.9997e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9596 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 7.8977e-04 - accuracy: 0.9658Epoch 137/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4317e-04 - accuracy: 0.9828 - val_loss: 9.1915e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9209e-04 - accuracy: 0.9683 - val_loss: 9.6136e-04 - val_accuracy: 0.9322\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 0.0010 - accuracy: 0.9861    Epoch 138/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.0823e-04 - accuracy: 0.9000Epoch 138/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9000e-04 - accuracy: 0.9832 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 138/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9844 - val_loss: 9.4508e-04 - val_accuracy: 0.9655\n",
            "Epoch 138/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.8350e-04 - accuracy: 0.9540 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 138/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9860 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 5.8550e-04 - accuracy: 0.9651Epoch 139/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.9796e-04 - accuracy: 0.9888 - val_loss: 9.1741e-04 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000Epoch 138/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.3137e-04 - accuracy: 0.9682 - val_loss: 8.1614e-04 - val_accuracy: 0.9828\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0010 - accuracy: 0.973096Epoch 139/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2242e-04 - accuracy: 0.9845 - val_loss: 7.9469e-04 - val_accuracy: 1.0000\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9683Epoch 138/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9762 - val_loss: 0.0017 - val_accuracy: 0.9138\n",
            "Epoch 138/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.4324e-04 - accuracy: 0.9778 - val_loss: 8.9002e-04 - val_accuracy: 1.0000\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 6.3742e-04 - accuracy: 0.9863Epoch 139/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.4978e-04 - accuracy: 0.9717 - val_loss: 7.1618e-04 - val_accuracy: 0.9661\n",
            " 1/53 [..............................] - ETA: 0s - loss: 4.7315e-04 - accuracy: 1.0000Epoch 139/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.6478e-04 - accuracy: 0.9767 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 139/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1011e-04 - accuracy: 0.9900 - val_loss: 9.7050e-04 - val_accuracy: 0.9828\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 6.4858e-04 - accuracy: 0.9848Epoch 139/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6964e-04 - accuracy: 0.9758 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 139/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9794 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 140/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.3890e-04 - accuracy: 0.9863 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 139/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8405e-04 - accuracy: 0.9742 - val_loss: 7.0141e-04 - val_accuracy: 1.0000\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9548    Epoch 139/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.5586e-04 - accuracy: 0.9842 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 140/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9819 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 8.0528e-04 - accuracy: 0.9971Epoch 139/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8742e-04 - accuracy: 0.9742 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 140/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4933e-04 - accuracy: 0.9881 - val_loss: 9.6285e-04 - val_accuracy: 0.9661\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 7.0610e-04 - accuracy: 0.9946Epoch 140/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.5413e-04 - accuracy: 0.9792 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 140/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9619e-04 - accuracy: 0.9738 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.2612e-04 - accuracy: 0.9955 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "18/53 [=========>....................] - ETA: 0s - loss: 8.9705e-04 - accuracy: 0.9718Epoch 140/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9726 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 141/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.0059e-04 - accuracy: 0.9932 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 140/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8863e-04 - accuracy: 0.9757 - val_loss: 7.8465e-04 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1307e-04 - accuracy: 0.9673 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "18/53 [=========>....................] - ETA: 0s - loss: 9.0836e-04 - accuracy: 0.9965Epoch 140/190\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 8.3883e-04 - accuracy: 0.9472Epoch 141/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9697 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 140/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0309e-04 - accuracy: 0.9760 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 9.3998e-04 - accuracy: 0.9621Epoch 141/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.8419e-04 - accuracy: 0.9741 - val_loss: 7.0624e-04 - val_accuracy: 0.9492\n",
            "Epoch 141/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.9994e-04 - accuracy: 0.9794 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - ETA: 0s - loss: 9.9359e-04 - accuracy: 0.9671Epoch 141/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.9913e-04 - accuracy: 0.9918 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 0.0011 - accuracy: 0.97009905Epoch 141/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9718 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Epoch 142/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.9398e-04 - accuracy: 0.9672 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 141/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.1564e-04 - accuracy: 0.9904 - val_loss: 8.7833e-04 - val_accuracy: 0.9828\n",
            "26/53 [=============>................] - ETA: 0s - loss: 8.8333e-04 - accuracy: 0.9978Epoch 141/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.6902e-04 - accuracy: 0.9667 - val_loss: 9.2078e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.5290e-04 - accuracy: 0.9835 - val_loss: 9.3692e-04 - val_accuracy: 0.9828\n",
            "Epoch 141/190\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9952Epoch 142/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9703 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 141/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1942e-04 - accuracy: 0.9890 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "47/53 [=========================>....] - ETA: 0s - loss: 0.0010 - accuracy: 0.9741Epoch 142/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1221e-04 - accuracy: 0.9833 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.5402e-04 - accuracy: 0.9855 - val_loss: 9.2378e-04 - val_accuracy: 0.9661\n",
            "Epoch 142/190\n",
            "Epoch 142/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9737 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 6.7706e-04 - accuracy: 0.9874Epoch 142/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9877 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 143/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.7271e-04 - accuracy: 0.9873 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000Epoch 142/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8121e-04 - accuracy: 0.9864 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 142/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4634e-04 - accuracy: 0.9878 - val_loss: 7.6953e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.8159e-04 - accuracy: 0.9865 - val_loss: 8.3170e-04 - val_accuracy: 0.9483\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9782Epoch 143/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9615 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 142/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8982e-04 - accuracy: 0.9889 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 143/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.4528e-04 - accuracy: 0.9651 - val_loss: 8.1578e-04 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4664e-04 - accuracy: 0.9817 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 143/190\n",
            "Epoch 143/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9853 - val_loss: 9.4169e-04 - val_accuracy: 0.9483\n",
            "Epoch 143/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.9372e-04 - accuracy: 0.9612 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 143/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9727 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 144/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.3913e-04 - accuracy: 0.9895 - val_loss: 9.6679e-04 - val_accuracy: 0.9655\n",
            "Epoch 143/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.0116e-04 - accuracy: 0.9798 - val_loss: 6.9704e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.5404e-04 - accuracy: 0.9840 - val_loss: 8.4239e-04 - val_accuracy: 0.9828\n",
            "50/53 [===========================>..] - ETA: 0s - loss: 0.0012 - accuracy: 0.9702Epoch 144/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9700 - val_loss: 0.0017 - val_accuracy: 0.9138\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 6.9938e-04 - accuracy: 0.9738Epoch 143/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.4302e-04 - accuracy: 0.9755 - val_loss: 8.1181e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.5671e-04 - accuracy: 0.9823 - val_loss: 6.7553e-04 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2393e-04 - accuracy: 0.9892 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 144/190Epoch 144/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.6995e-04 - accuracy: 0.9824 - val_loss: 9.8004e-04 - val_accuracy: 0.9655\n",
            "Epoch 144/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.7696e-04 - accuracy: 0.9865 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 144/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6699e-04 - accuracy: 0.9861 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "11/53 [=====>........................] - ETA: 0s - loss: 6.4725e-04 - accuracy: 0.9816Epoch 145/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.3798e-04 - accuracy: 0.9790 - val_loss: 9.9274e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.3254e-04 - accuracy: 0.9804 - val_loss: 7.7932e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.7181e-04 - accuracy: 0.9842 - val_loss: 8.9409e-04 - val_accuracy: 0.9828\n",
            "Epoch 144/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.2634e-04 - accuracy: 1.0000Epoch 145/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9616 - val_loss: 0.0017 - val_accuracy: 0.9138\n",
            "Epoch 144/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2837e-04 - accuracy: 0.9881 - val_loss: 9.2311e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.9558e-04 - accuracy: 0.9844 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 145/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1355e-04 - accuracy: 0.9895 - val_loss: 8.1828e-04 - val_accuracy: 0.9492\n",
            "Epoch 145/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.5576e-04 - accuracy: 0.9883 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 7.2847e-04 - accuracy: 0.9732Epoch 145/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8736e-04 - accuracy: 0.9763 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 145/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9861 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 6.0994e-04 - accuracy: 0.9900Epoch 146/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2555e-04 - accuracy: 0.9834 - val_loss: 8.8874e-04 - val_accuracy: 0.9828\n",
            "Epoch 145/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.0504e-04 - accuracy: 0.9879 - val_loss: 8.6404e-04 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000Epoch 146/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.3202e-04 - accuracy: 0.9722 - val_loss: 6.9382e-04 - val_accuracy: 1.0000\n",
            "31/53 [================>.............] - ETA: 0s - loss: 6.4634e-04 - accuracy: 0.9785Epoch 145/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9756 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 145/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2232e-04 - accuracy: 0.9916 - val_loss: 8.6318e-04 - val_accuracy: 1.0000\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 8.7620e-04 - accuracy: 0.9846Epoch 146/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.6638e-04 - accuracy: 0.9791 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 0.0012 - accuracy: 0.9719Epoch 146/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.0286e-04 - accuracy: 0.9714 - val_loss: 6.5090e-04 - val_accuracy: 0.9661\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 7.2087e-04 - accuracy: 0.9923Epoch 146/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.6338e-04 - accuracy: 0.9835 - val_loss: 9.6203e-04 - val_accuracy: 0.9655\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 6.8266e-04 - accuracy: 0.9857Epoch 146/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.6838e-04 - accuracy: 0.9714 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 146/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9742 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 8.1421e-04 - accuracy: 0.9902Epoch 147/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1540e-04 - accuracy: 0.9915 - val_loss: 8.9317e-04 - val_accuracy: 0.9655\n",
            "Epoch 146/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.9230e-04 - accuracy: 0.9853 - val_loss: 8.8838e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7092e-04 - accuracy: 0.9720 - val_loss: 8.1666e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/190\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9677Epoch 147/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9692 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 146/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9515e-04 - accuracy: 0.9881 - val_loss: 8.8071e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.7960e-04 - accuracy: 0.9871 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 147/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.4407e-04 - accuracy: 0.9815 - val_loss: 8.7623e-04 - val_accuracy: 0.9492\n",
            "Epoch 147/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.4762e-04 - accuracy: 0.9778 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 147/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8129e-04 - accuracy: 0.9878 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.6568e-04 - accuracy: 1.0000Epoch 147/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9679 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 148/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.7677e-04 - accuracy: 0.9694 - val_loss: 9.3939e-04 - val_accuracy: 0.9655\n",
            "Epoch 147/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.8877e-04 - accuracy: 0.9754 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.0942e-04 - accuracy: 0.9855 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 148/190\n",
            "Epoch 147/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9609 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 147/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.7777e-04 - accuracy: 0.9812 - val_loss: 8.5363e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8405e-04 - accuracy: 0.9715 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 148/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.3868e-04 - accuracy: 0.9763 - val_loss: 6.6001e-04 - val_accuracy: 0.9492\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.5227e-04 - accuracy: 0.9693 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.3101e-04 - accuracy: 0.9827 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 148/190\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0012 - accuracy: 0.977700Epoch 148/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.6769e-04 - accuracy: 0.9754 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 149/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.5398e-04 - accuracy: 0.9864 - val_loss: 9.6710e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2499e-04 - accuracy: 0.9833 - val_loss: 8.1300e-04 - val_accuracy: 0.9655\n",
            "Epoch 149/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.0201e-04 - accuracy: 0.9592 - val_loss: 6.9012e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9768 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 148/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.8364e-04 - accuracy: 0.9880 - val_loss: 8.6518e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.3088e-04 - accuracy: 0.9836 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "50/53 [===========================>..] - ETA: 0s - loss: 7.9981e-04 - accuracy: 0.9698Epoch 149/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4799e-04 - accuracy: 0.9925 - val_loss: 0.0015 - val_accuracy: 0.9153\n",
            "49/53 [==========================>...] - ETA: 0s - loss: 6.5269e-04 - accuracy: 0.9817Epoch 149/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0010e-04 - accuracy: 0.9830 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            " 1/53 [..............................] - ETA: 0s - loss: 9.2249e-04 - accuracy: 0.8000Epoch 149/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0134e-04 - accuracy: 0.9706 - val_loss: 9.2988e-04 - val_accuracy: 0.9483\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 0.0010 - accuracy: 0.97079800Epoch 149/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9798 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 150/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.5970e-04 - accuracy: 0.9819 - val_loss: 8.6850e-04 - val_accuracy: 0.9655\n",
            "Epoch 149/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.3138e-04 - accuracy: 0.9819 - val_loss: 8.1788e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.2404e-04 - accuracy: 0.9738 - val_loss: 8.6387e-04 - val_accuracy: 0.9655\n",
            "Epoch 150/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9712 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 149/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8224e-04 - accuracy: 0.9931 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 150/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.1559e-04 - accuracy: 0.9876 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 150/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.2739e-04 - accuracy: 0.9753 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "43/53 [=======================>......] - ETA: 0s - loss: 8.0743e-04 - accuracy: 0.9908Epoch 150/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.0482e-04 - accuracy: 0.9801 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.7170e-04 - accuracy: 0.9694 - val_loss: 6.6325e-04 - val_accuracy: 0.9492\n",
            "Epoch 150/190\n",
            "Epoch 150/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.8213e-04 - accuracy: 0.9734 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 151/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.3849e-04 - accuracy: 0.9898 - val_loss: 9.7037e-04 - val_accuracy: 0.9828\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 6.9432e-04 - accuracy: 1.0000Epoch 150/1\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.6478e-04 - accuracy: 0.9758 - val_loss: 8.8799e-04 - val_accuracy: 0.9828\n",
            "Epoch 150/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.9128e-04 - accuracy: 0.9888 - val_loss: 8.0309e-04 - val_accuracy: 0.9828\n",
            "Epoch 151/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9715 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 150/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.7254e-04 - accuracy: 0.9838 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 7.2197e-04 - accuracy: 0.9945Epoch 151/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9621e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 8.8084e-04 - accuracy: 0.9864Epoch 151/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1802e-04 - accuracy: 0.9802 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 8.2068e-04 - accuracy: 0.9775Epoch 151/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7485e-04 - accuracy: 0.9906 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 6.1147e-04 - accuracy: 0.9886Epoch 151/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.4057e-04 - accuracy: 0.9958 - val_loss: 6.5409e-04 - val_accuracy: 0.9492\n",
            "Epoch 151/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.9591e-04 - accuracy: 0.9865 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 152/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0578e-04 - accuracy: 0.9779 - val_loss: 9.7851e-04 - val_accuracy: 0.9655\n",
            "Epoch 151/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8831e-04 - accuracy: 0.9829 - val_loss: 7.1869e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.9231e-04 - accuracy: 0.9878 - val_loss: 9.0563e-04 - val_accuracy: 0.9828\n",
            "Epoch 152/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9795 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 151/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2755e-04 - accuracy: 0.9887 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 5.3659e-04 - accuracy: 0.9953Epoch 152/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.9609e-04 - accuracy: 0.9868 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 152/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.5546e-04 - accuracy: 0.9829 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 7.2406e-04 - accuracy: 0.9754Epoch 152/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.6922e-04 - accuracy: 0.9837 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4263e-04 - accuracy: 0.9886 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 152/190\n",
            "Epoch 152/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9102e-04 - accuracy: 0.9772 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 153/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.0612e-04 - accuracy: 0.9860 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 152/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.3446e-04 - accuracy: 0.9758 - val_loss: 9.0707e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.9174e-04 - accuracy: 0.9805 - val_loss: 7.6615e-04 - val_accuracy: 1.0000\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 8.4271e-04 - accuracy: 0.9984\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9679 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 152/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.8235e-04 - accuracy: 0.9678 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 153/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4198e-04 - accuracy: 0.9828 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 6.7130e-04 - accuracy: 0.9906Epoch 153/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8541e-04 - accuracy: 0.9836 - val_loss: 0.0012 - val_accuracy: 0.98310s - loss: 0.0010 - accuracy: \n",
            "Epoch 153/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0879e-04 - accuracy: 0.9902 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 153/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.4864e-04 - accuracy: 0.9896 - val_loss: 6.5922e-04 - val_accuracy: 0.9492\n",
            "Epoch 153/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9780 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 154/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.5348e-04 - accuracy: 0.9926 - val_loss: 9.8663e-04 - val_accuracy: 0.9655\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 8.4935e-04 - accuracy: 0.9841\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0220e-04 - accuracy: 0.9852 - val_loss: 8.2573e-04 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Epoch 154/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.2157e-04 - accuracy: 0.9846 - val_loss: 8.1542e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9848 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "\n",
            "Epoch 153/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.9633e-04 - accuracy: 0.9922 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9802    Epoch 154/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.0358e-04 - accuracy: 0.9804 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 154/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.4031e-04 - accuracy: 0.9765 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 154/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4215e-04 - accuracy: 0.9938 - val_loss: 8.4643e-04 - val_accuracy: 0.9655\n",
            "Epoch 154/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4317e-04 - accuracy: 0.9767 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 154/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9732 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 155/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4247e-04 - accuracy: 0.9859 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4424e-04 - accuracy: 0.9722 - val_loss: 7.9723e-04 - val_accuracy: 0.9828\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 9.1785e-04 - accuracy: 0.9931Epoch 154/190Epoch 155/190\n",
            "\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.9433e-04 - accuracy: 0.9772 - val_loss: 7.0438e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9773 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.1355e-04 - accuracy: 0.9863 - val_loss: 8.7670e-04 - val_accuracy: 1.0000\n",
            "43/53 [=======================>......] - ETA: 0s - loss: 5.9578e-04 - accuracy: 0.9871Epoch 154/190\n",
            "Epoch 155/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.0190e-04 - accuracy: 0.9855 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 155/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.5433e-04 - accuracy: 0.9652 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 155/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3954e-04 - accuracy: 0.9845 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 155/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.4449e-04 - accuracy: 0.9889 - val_loss: 9.7554e-04 - val_accuracy: 0.9483\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 0.0012 - accuracy: 0.974200Epoch 155/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9841 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 156/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.1231e-04 - accuracy: 0.9902 - val_loss: 8.7098e-04 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.1452e-04 - accuracy: 0.9742 - val_loss: 8.4899e-04 - val_accuracy: 0.9483\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 8.0262e-04 - accuracy: 0.9725Epoch 155/190\n",
            "Epoch 156/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.4755e-04 - accuracy: 0.9858 - val_loss: 6.2517e-04 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.5790e-04 - accuracy: 0.9000Epoch 155/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.7480e-04 - accuracy: 0.9799 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "45/53 [========================>.....] - ETA: 0s - loss: 6.5149e-04 - accuracy: 0.9785Epoch 156/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9741 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 155/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.5566e-04 - accuracy: 0.9790 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 156/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1313e-04 - accuracy: 0.9720 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 6.3709e-04 - accuracy: 0.9712Epoch 156/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.3233e-04 - accuracy: 0.9766 - val_loss: 7.6023e-04 - val_accuracy: 0.9661\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 6.9500e-04 - accuracy: 0.9756Epoch 156/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.2482e-04 - accuracy: 0.9877 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 156/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9806 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.5648e-04 - accuracy: 0.9784 - val_loss: 9.4369e-04 - val_accuracy: 0.9655\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 9.3695e-04 - accuracy: 0.9786\n",
            "Epoch 156/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4794e-04 - accuracy: 0.9739 - val_loss: 8.7365e-04 - val_accuracy: 0.9655\n",
            "51/53 [===========================>..] - ETA: 0s - loss: 0.0011 - accuracy: 0.9707Epoch 157/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4143e-04 - accuracy: 0.9842 - val_loss: 9.1107e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.9953e-04 - accuracy: 0.9770 - val_loss: 6.6503e-04 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.7509e-04 - accuracy: 1.0000Epoch 156/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9712 - val_loss: 0.0015 - val_accuracy: 0.9138\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 8.5661e-04 - accuracy: 0.9728\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.4663e-04 - accuracy: 0.9813 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 157/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.0502e-04 - accuracy: 0.9844 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 157/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.6636e-04 - accuracy: 0.9955 - val_loss: 7.7870e-04 - val_accuracy: 0.9661\n",
            "Epoch 157/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1861e-04 - accuracy: 0.9745 - val_loss: 9.2791e-04 - val_accuracy: 0.9655\n",
            "Epoch 157/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1064e-04 - accuracy: 0.9740 - val_loss: 8.3790e-04 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.7452e-04 - accuracy: 0.9798 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 157/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 3.6159e-04 - accuracy: 0.9000Epoch 158/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.4916e-04 - accuracy: 0.9835 - val_loss: 7.4510e-04 - val_accuracy: 0.9655\n",
            "Epoch 158/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.3240e-04 - accuracy: 0.9874 - val_loss: 7.9072e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.4229e-04 - accuracy: 0.9814 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 157/190\n",
            "Epoch 158/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9806 - val_loss: 0.0016 - val_accuracy: 0.9138\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 0.0010 - accuracy: 0.9676    Epoch 157/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.3691e-04 - accuracy: 0.9827 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 158/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1918e-04 - accuracy: 0.9873 - val_loss: 6.2951e-04 - val_accuracy: 0.9661\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 5.9103e-04 - accuracy: 0.9785Epoch 158/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.3744e-04 - accuracy: 0.9802 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.0978e-04 - accuracy: 0.9884 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 158/190Epoch 158/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.9534e-04 - accuracy: 0.9800 - val_loss: 9.7867e-04 - val_accuracy: 0.9655\n",
            "Epoch 158/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9749 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 159/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.3798e-04 - accuracy: 0.9801 - val_loss: 8.8112e-04 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 5.5919e-04 - accuracy: 1.0000Epoch 159/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.3917e-04 - accuracy: 0.9811 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.0191e-04 - accuracy: 0.9720 - val_loss: 7.5169e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 3.9944e-04 - accuracy: 1.0000Epoch 158/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9697 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 158/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.8391e-04 - accuracy: 0.9647 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 159/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.6861e-04 - accuracy: 0.9854 - val_loss: 7.1690e-04 - val_accuracy: 0.9661\n",
            "Epoch 159/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9969e-04 - accuracy: 0.9815 - val_loss: 9.8379e-04 - val_accuracy: 0.9828\n",
            "32/53 [=================>............] - ETA: 0s - loss: 6.0701e-04 - accuracy: 0.9746Epoch 159/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1381e-04 - accuracy: 0.9808 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.5032e-04 - accuracy: 0.9000Epoch 159/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9894 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7578e-04 - accuracy: 0.9827 - val_loss: 9.3931e-04 - val_accuracy: 0.9483\n",
            "Epoch 160/190\n",
            "Epoch 160/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.4425e-04 - accuracy: 0.9838 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.9241e-04 - accuracy: 0.9805 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "25/53 [=============>................] - ETA: 0s - loss: 8.7909e-04 - accuracy: 0.9589Epoch 160/190\n",
            "Epoch 159/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.1740e-04 - accuracy: 0.9774 - val_loss: 6.7649e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9633 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 159/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8668e-04 - accuracy: 0.9872 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9387    Epoch 160/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1574e-04 - accuracy: 0.9668 - val_loss: 6.1097e-04 - val_accuracy: 0.9661\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0011 - accuracy: 0.9584Epoch 160/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.8757e-04 - accuracy: 0.9804 - val_loss: 9.6109e-04 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.1044e-04 - accuracy: 0.9686 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "34/53 [==================>...........] - ETA: 0s - loss: 6.6536e-04 - accuracy: 0.9676Epoch 160/190\n",
            "Epoch 160/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.2062e-04 - accuracy: 0.9604 - val_loss: 7.5232e-04 - val_accuracy: 1.0000s: 6.8896e-04 - accuracy: \n",
            "Epoch 161/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9646 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4063e-04 - accuracy: 0.9912 - val_loss: 8.2983e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/190Epoch 161/190\n",
            "\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.4533e-04 - accuracy: 0.9673 - val_loss: 8.4375e-04 - val_accuracy: 1.0000\n",
            "37/53 [===================>..........] - ETA: 0s - loss: 7.4043e-04 - accuracy: 0.9731Epoch 161/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.0106e-04 - accuracy: 0.9707 - val_loss: 8.7115e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9784 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "35/53 [==================>...........] - ETA: 0s - loss: 8.4839e-04 - accuracy: 0.9695\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.8831e-04 - accuracy: 0.9767 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 4.2486e-04 - accuracy: 1.0000Epoch 161/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.4039e-04 - accuracy: 0.9751 - val_loss: 7.5060e-04 - val_accuracy: 0.9492\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 7.1988e-04 - accuracy: 0.9789Epoch 161/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.2832e-04 - accuracy: 0.9731 - val_loss: 9.1659e-04 - val_accuracy: 0.9483\n",
            "Epoch 161/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.2231e-04 - accuracy: 0.9682 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 161/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.2119e-04 - accuracy: 0.9786 - val_loss: 8.6942e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9672 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.9306e-04 - accuracy: 0.9874 - val_loss: 8.9116e-04 - val_accuracy: 0.9828\n",
            "\n",
            "Epoch 161/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.0809e-04 - accuracy: 0.9876 - val_loss: 9.2522e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9731Epoch 162/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.6892e-04 - accuracy: 0.9587 - val_loss: 7.0766e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9732 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 161/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.1073e-04 - accuracy: 0.9865 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 5.7014e-04 - accuracy: 0.9000Epoch 162/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.4266e-04 - accuracy: 0.9770 - val_loss: 7.1431e-04 - val_accuracy: 0.9661\n",
            "49/53 [==========================>...] - ETA: 0s - loss: 7.0684e-04 - accuracy: 0.9889Epoch 162/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.7448e-04 - accuracy: 0.9937 - val_loss: 9.0419e-04 - val_accuracy: 0.9655\n",
            "Epoch 162/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.0794e-04 - accuracy: 0.9887 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 162/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.9634e-04 - accuracy: 0.9854 - val_loss: 8.8865e-04 - val_accuracy: 0.9828\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 5.5855e-04 - accuracy: 0.9930Epoch 163/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.1170e-04 - accuracy: 0.9859 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 163/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.4208e-04 - accuracy: 0.9960 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 163/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.3007e-04 - accuracy: 0.9725 - val_loss: 6.7192e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.7635e-04 - accuracy: 0.9796 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "36/53 [===================>..........] - ETA: 0s - loss: 6.7630e-04 - accuracy: 0.9697Epoch 162/190\n",
            "26/53 [=============>................] - ETA: 0s - loss: 6.7691e-04 - accuracy: 0.9564Epoch 162/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.6826e-04 - accuracy: 0.9915 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 163/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9671 - val_loss: 0.0015 - val_accuracy: 0.9138\n",
            "34/53 [==================>...........] - ETA: 0s - loss: 6.6016e-04 - accuracy: 0.9829Epoch 162/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.9375e-04 - accuracy: 0.9720 - val_loss: 6.1019e-04 - val_accuracy: 0.9661\n",
            "Epoch 163/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.9686e-04 - accuracy: 0.9833 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 163/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.9159e-04 - accuracy: 0.9635 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 163/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8780e-04 - accuracy: 0.9800 - val_loss: 8.1692e-04 - val_accuracy: 0.9655\n",
            "Epoch 164/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.2193e-04 - accuracy: 0.9768 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 7.6652e-04 - accuracy: 0.9807Epoch 164/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.0003e-04 - accuracy: 0.9905 - val_loss: 9.3931e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.8508e-04 - accuracy: 0.9828 - val_loss: 6.9145e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.5153e-04 - accuracy: 0.9748 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.8439e-04 - accuracy: 0.9791 - val_loss: 8.5874e-04 - val_accuracy: 1.0000\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9453    Epoch 163/1\n",
            "Epoch 163/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4208e-04 - accuracy: 0.9794 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 2.7187e-04 - accuracy: 1.0000Epoch 164/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7071e-04 - accuracy: 0.9835 - val_loss: 8.2989e-04 - val_accuracy: 0.9492\n",
            "Epoch 164/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.9161e-04 - accuracy: 0.9687 - val_loss: 9.2855e-04 - val_accuracy: 0.9483\n",
            "Epoch 164/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1335e-04 - accuracy: 0.9787 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 164/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4755e-04 - accuracy: 0.9854 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9620 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 165/190\n",
            "Epoch 165/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.4533e-04 - accuracy: 0.9866 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 165/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.5141e-04 - accuracy: 0.9871 - val_loss: 7.9062e-04 - val_accuracy: 1.0000\n",
            "38/53 [====================>.........] - ETA: 0s - loss: 8.9275e-04 - accuracy: 0.9733Epoch 164/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9687 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4251e-04 - accuracy: 0.9898 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 164/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.3571e-04 - accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.7085e-04 - accuracy: 0.9848 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 164/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7579e-04 - accuracy: 0.9732 - val_loss: 7.4825e-04 - val_accuracy: 0.9661\n",
            "Epoch 165/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.5332e-04 - accuracy: 0.9892 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 7.0506e-04 - accuracy: 0.9852Epoch 165/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0309e-04 - accuracy: 0.9784 - val_loss: 9.9917e-04 - val_accuracy: 0.9831\n",
            "Epoch 165/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.0789e-04 - accuracy: 0.9849 - val_loss: 8.5179e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.9483e-04 - accuracy: 0.9747 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 6.4292e-04 - accuracy: 0.9704Epoch 166/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 8.9736e-04 - accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.6859e-04 - accuracy: 0.9855 - val_loss: 8.7710e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.4666e-04 - accuracy: 0.9800 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 165/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.4199e-04 - accuracy: 0.9869 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 166/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.7661e-04 - accuracy: 0.9867 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0011 - accuracy: 0.9000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.5016e-04 - accuracy: 0.9726 - val_loss: 9.8639e-04 - val_accuracy: 0.9655\n",
            "41/53 [======================>.......] - ETA: 0s - loss: 7.2135e-04 - accuracy: 0.98\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.8033e-04 - accuracy: 0.9827 - val_loss: 6.8847e-04 - val_accuracy: 0.9661\n",
            "Epoch 166/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2542e-04 - accuracy: 0.9867 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 166/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0296e-04 - accuracy: 0.9892 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 166/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7166e-04 - accuracy: 0.9833 - val_loss: 7.9423e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9660 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 167/190\n",
            "Epoch 167/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8505e-04 - accuracy: 0.9855 - val_loss: 8.1905e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.5353e-04 - accuracy: 0.9867 - val_loss: 6.9847e-04 - val_accuracy: 1.0000\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 8.4149e-04 - accuracy: 0.9901Epoch 166/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.2765e-04 - accuracy: 0.9749 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "11/53 [=====>........................] - ETA: 0s - loss: 5.2653e-04 - accuracy: 0.9973Epoch 167/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9661 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 2.0161e-04 - accuracy: 1.0000Epoch 166/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.7865e-04 - accuracy: 0.9786 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 8.2944e-04 - accuracy: 0.9866Epoch 166/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.0824e-04 - accuracy: 0.9906 - val_loss: 6.8546e-04 - val_accuracy: 0.9661\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 5.4303e-04 - accuracy: 0.9888Epoch 167/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9768 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 6.9828e-04 - accuracy: 0.9996Epoch 167/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.1428e-04 - accuracy: 0.9847 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 167/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.6350e-04 - accuracy: 0.9852 - val_loss: 9.7211e-04 - val_accuracy: 1.0000\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 6.0801e-04 - accuracy: 0.9916Epoch 168/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9715 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 168/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.9951e-04 - accuracy: 0.9865 - val_loss: 7.8122e-04 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 9.7271e-04 - accuracy: 1.0000Epoch 168/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.3249e-04 - accuracy: 0.9786 - val_loss: 6.9843e-04 - val_accuracy: 1.0000\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 7.7423e-04 - accuracy: 0.9957\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9736 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.0695e-04 - accuracy: 0.9796 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 167/190\n",
            "Epoch 168/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.4785e-04 - accuracy: 0.9926 - val_loss: 8.0698e-04 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 5.9830e-04 - accuracy: 1.0000Epoch 167/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.5030e-04 - accuracy: 0.9848 - val_loss: 7.0018e-04 - val_accuracy: 0.9661\n",
            "Epoch 168/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.5708e-04 - accuracy: 0.9940 - val_loss: 8.7592e-04 - val_accuracy: 0.9655\n",
            "19/53 [=========>....................] - ETA: 0s - loss: 6.4796e-04 - accuracy: 0.9899Epoch 168/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.6803e-04 - accuracy: 0.9865 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 168/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.6775e-04 - accuracy: 0.9606 - val_loss: 7.5897e-04 - val_accuracy: 1.0000\n",
            "32/53 [=================>............] - ETA: 0s - loss: 7.9643e-04 - accuracy: 0.9685Epoch 169/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1110e-04 - accuracy: 0.9805 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "15/53 [=======>......................] - ETA: 0s - loss: 9.0725e-04 - accuracy: 0.9703Epoch 169/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.1377e-04 - accuracy: 0.9680 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 169/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.5370e-04 - accuracy: 0.9832 - val_loss: 6.7810e-04 - val_accuracy: 1.0000\n",
            "31/53 [================>.............] - ETA: 0s - loss: 7.3543e-04 - accuracy: 0.9890Epoch 168/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9826 - val_loss: 0.0016 - val_accuracy: 0.9483TA: 0s - loss: 6.0704e-04 - accura\n",
            "21/53 [==========>...................] - ETA: 0s - loss: 5.4551e-04 - accuracy: 0.9953/53 [==============================] - 0s 5ms/step - loss: 6.7452e-04 - accuracy: 0.9835 - val_loss: 8.7927e-04 - val_accuracy: 0.9828\n",
            "12/53 [=====>........................] - ETA: 0s - loss: 5.3682e-04 - accuracy: 0.9883Epoch 168/190\n",
            "Epoch 168/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.1086e-04 - accuracy: 0.9635 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.1668e-04 - accuracy: 1.0000Epoch 169/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.3338e-04 - accuracy: 0.9701 - val_loss: 9.8955e-04 - val_accuracy: 0.9492\n",
            "Epoch 169/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.3811e-04 - accuracy: 0.9885 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 169/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9927e-04 - accuracy: 0.9710 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 169/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.9356e-04 - accuracy: 0.9903 - val_loss: 8.2089e-04 - val_accuracy: 0.9483\n",
            "Epoch 170/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.9388e-04 - accuracy: 0.9757 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 170/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2761e-04 - accuracy: 0.9819 - val_loss: 6.2926e-04 - val_accuracy: 1.0000\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 7.8204e-04 - accuracy: 0.98Epoch 169/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.7087e-04 - accuracy: 0.9829 - val_loss: 8.5584e-04 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 4.8425e-04 - accuracy: 1.0000Epoch 170/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.8222e-04 - accuracy: 0.9795 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9706 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 169/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 5.2251e-04 - accuracy: 0.9000Epoch 169/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.0582e-04 - accuracy: 0.9781 - val_loss: 9.7459e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8360e-04 - accuracy: 0.9821 - val_loss: 6.7349e-04 - val_accuracy: 0.9492\n",
            "Epoch 170/190\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 9.9227e-04 - accuracy: 0.9749\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.6214e-04 - accuracy: 0.9867 - val_loss: 7.5532e-04 - val_accuracy: 1.0000\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 5.8251e-04 - accuracy: 0.9848Epoch 170/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.7329e-04 - accuracy: 0.9730 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 170/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.5223e-04 - accuracy: 0.9773 - val_loss: 8.1043e-04 - val_accuracy: 1.0000\n",
            "Epoch 171/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.1292e-04 - accuracy: 0.9860 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 171/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.2400e-04 - accuracy: 0.9851 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 171/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.2671e-04 - accuracy: 0.9787 - val_loss: 6.6777e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9742 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.6650e-04 - accuracy: 0.9730 - val_loss: 8.8644e-04 - val_accuracy: 0.9828\n",
            "14/53 [======>.......................] - ETA: 0s - loss: 4.6656e-04 - accuracy: 0.9938Epoch 170/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 3.5930e-04 - accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.0307e-04 - accuracy: 0.9840 - val_loss: 9.7663e-04 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.8803e-04 - accuracy: 1.0000Epoch 171/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.8716e-04 - accuracy: 0.9857 - val_loss: 8.1388e-04 - val_accuracy: 0.9661\n",
            "Epoch 171/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.6077e-04 - accuracy: 0.9804 - val_loss: 8.4214e-04 - val_accuracy: 0.9655\n",
            "Epoch 171/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0159e-04 - accuracy: 0.9800 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 171/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.3906e-04 - accuracy: 0.9846 - val_loss: 9.7654e-04 - val_accuracy: 1.0000\n",
            "Epoch 172/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.8577e-04 - accuracy: 0.9817 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 0.0010 - accuracy: 0.9858    Epoch 172/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.5892e-04 - accuracy: 0.9862 - val_loss: 9.2188e-04 - val_accuracy: 1.0000\n",
            "Epoch 172/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.2679e-04 - accuracy: 0.9841 - val_loss: 7.3127e-04 - val_accuracy: 1.0000\n",
            "Epoch 171/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9844 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "Epoch 171/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.3117e-04 - accuracy: 0.9899 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "13/53 [======>.......................] - ETA: 0s - loss: 4.7254e-04 - accuracy: 0.9961Epoch 171/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.9968e-04 - accuracy: 0.9925 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.6562e-04 - accuracy: 0.9778 - val_loss: 7.2298e-04 - val_accuracy: 0.9831\n",
            "Epoch 172/190\n",
            "Epoch 172/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.6480e-04 - accuracy: 0.9909 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 172/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.5766e-04 - accuracy: 0.9722 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 172/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2411e-04 - accuracy: 0.9776 - val_loss: 7.8677e-04 - val_accuracy: 0.9655\n",
            "Epoch 173/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.6151e-04 - accuracy: 0.9837 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.9240e-04 - accuracy: 0.9775 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 173/190\n",
            "26/53 [=============>................] - ETA: 0s - loss: 9.6115e-04 - accuracy: 0.9748Epoch 173/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.9601e-04 - accuracy: 0.9859 - val_loss: 7.6120e-04 - val_accuracy: 1.0000\n",
            "Epoch 172/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.7469e-04 - accuracy: 0.9874 - val_loss: 8.5110e-04 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.1040e-04 - accuracy: 0.9751 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "Epoch 172/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.8096e-04 - accuracy: 1.0000Epoch 172/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.8292e-04 - accuracy: 0.9760 - val_loss: 6.7886e-04 - val_accuracy: 0.9492\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.3806e-04 - accuracy: 0.9728 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 173/190\n",
            "Epoch 173/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7040e-04 - accuracy: 0.9806 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 5.7642e-04 - accuracy: 0.9622Epoch 173/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9518e-04 - accuracy: 0.9821 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 173/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.5047e-04 - accuracy: 0.9715 - val_loss: 8.0141e-04 - val_accuracy: 0.9655\n",
            "Epoch 174/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9513 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.7305e-04 - accuracy: 0.9744 - val_loss: 9.0822e-04 - val_accuracy: 1.0000\n",
            "Epoch 174/190\n",
            "Epoch 174/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.5588e-04 - accuracy: 0.9722 - val_loss: 7.9246e-04 - val_accuracy: 0.9828\n",
            "Epoch 173/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2979e-04 - accuracy: 0.9961 - val_loss: 8.6455e-04 - val_accuracy: 0.9655\n",
            "Epoch 173/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8782e-04 - accuracy: 0.9674 - val_loss: 9.3051e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.4568e-04 - accuracy: 0.9786 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 174/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.5881e-04 - accuracy: 0.9748 - val_loss: 9.5251e-04 - val_accuracy: 0.9492\n",
            "Epoch 173/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 9.1984e-04 - accuracy: 1.0000Epoch 174/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7491e-04 - accuracy: 0.9550 - val_loss: 7.8284e-04 - val_accuracy: 0.9655\n",
            "31/53 [================>.............] - ETA: 0s - loss: 0.0010 - accuracy: 0.9903Epoch 174/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1502e-04 - accuracy: 0.9803 - val_loss: 9.5504e-04 - val_accuracy: 0.9661\n",
            "Epoch 174/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2346e-04 - accuracy: 0.9961 - val_loss: 9.8996e-04 - val_accuracy: 0.9828\n",
            "Epoch 175/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.6670e-04 - accuracy: 0.9963 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 175/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3213e-04 - accuracy: 0.9911 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 175/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.7586e-04 - accuracy: 0.9753 - val_loss: 9.4680e-04 - val_accuracy: 0.9828\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 8.1356e-04 - accuracy: 0.9717\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9891e-04 - accuracy: 0.9722 - val_loss: 9.5497e-04 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1040e-04 - accuracy: 0.9657 - val_loss: 0.0015 - val_accuracy: 0.9138\n",
            "\n",
            " 1/53 [..............................] - ETA: 0s - loss: 7.0753e-04 - accuracy: 1.0000Epoch 174/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.2250e-04 - accuracy: 0.9837 - val_loss: 8.5923e-04 - val_accuracy: 0.9492\n",
            "Epoch 175/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.9211e-04 - accuracy: 0.9834 - val_loss: 9.8080e-04 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.1543e-04 - accuracy: 0.9913 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "25/53 [=============>................] - ETA: 0s - loss: 7.1027e-04 - accuracy: 0.9830Epoch 175/190Epoch 175/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0953e-04 - accuracy: 0.9678 - val_loss: 9.9219e-04 - val_accuracy: 0.9661\n",
            "Epoch 175/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2822e-04 - accuracy: 0.9870 - val_loss: 7.3529e-04 - val_accuracy: 0.9828\n",
            "Epoch 176/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.4619e-04 - accuracy: 0.9819 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 6.0169e-04 - accuracy: 0.9941Epoch 176/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.4520e-04 - accuracy: 0.9811 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 176/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.8434e-04 - accuracy: 0.9841 - val_loss: 6.5052e-04 - val_accuracy: 1.0000\n",
            "43/53 [=======================>......] - ETA: 0s - loss: 6.4142e-04 - accuracy: 0.9956Epoch 175/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9749 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.7340e-04 - accuracy: 0.9845 - val_loss: 8.8275e-04 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4633e-04 - accuracy: 0.9944 - val_loss: 7.7188e-04 - val_accuracy: 0.9661\n",
            "Epoch 175/190\n",
            "Epoch 176/190\n",
            "Epoch 175/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4477e-04 - accuracy: 0.9876 - val_loss: 9.1093e-04 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0010 - accuracy: 0.9000Epoch 176/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.7705e-04 - accuracy: 0.9857 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.7285e-04 - accuracy: 1.0000Epoch 176/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.7728e-04 - accuracy: 0.9839 - val_loss: 0.0019 - val_accuracy: 0.9831\n",
            "Epoch 176/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1197e-04 - accuracy: 0.9772 - val_loss: 8.7619e-04 - val_accuracy: 1.0000\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 6.0325e-04 - accuracy: 0.9959Epoch 177/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.3435e-04 - accuracy: 0.9935 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 177/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.4687e-04 - accuracy: 0.9840 - val_loss: 8.3944e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.2045e-04 - accuracy: 0.9834 - val_loss: 5.8945e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.7147e-04 - accuracy: 0.9804 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.4493e-04 - accuracy: 0.9698 - val_loss: 6.0205e-04 - val_accuracy: 0.9661\n",
            "Epoch 177/190\n",
            "Epoch 176/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4439e-04 - accuracy: 0.9745 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.8271e-04 - accuracy: 0.9896 - val_loss: 9.6014e-04 - val_accuracy: 0.9655\n",
            "Epoch 177/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9363e-04 - accuracy: 0.9692 - val_loss: 9.8664e-04 - val_accuracy: 0.9655\n",
            " 1/53 [..............................] - ETA: 0s - loss: 6.8311e-04 - accuracy: 1.0000Epoch 177/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9622 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 177/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8200e-04 - accuracy: 0.9914 - val_loss: 9.2173e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9652 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 9.5453e-04 - accuracy: 0.9797Epoch 178/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.6859e-04 - accuracy: 0.9831 - val_loss: 8.4602e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.2834e-04 - accuracy: 0.9851 - val_loss: 7.7594e-04 - val_accuracy: 1.0000\n",
            "31/53 [================>.............] - ETA: 0s - loss: 5.6663e-04 - accuracy: 0.9976Epoch 177/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.3578e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.5872e-04 - accuracy: 0.9815 - val_loss: 9.4202e-04 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2340e-04 - accuracy: 0.9710 - val_loss: 6.0019e-04 - val_accuracy: 0.9492\n",
            "Epoch 177/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000Epoch 178/190/190\n",
            "\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.6795e-04 - accuracy: 0.9803 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "32/53 [=================>............] - ETA: 0s - loss: 4.4009e-04 - accuracy: 0.9963\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.4221e-04 - accuracy: 0.9798 - val_loss: 8.7604e-04 - val_accuracy: 0.9655\n",
            "Epoch 177/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9011e-04 - accuracy: 0.9819 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 178/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.7123e-04 - accuracy: 0.9951 - val_loss: 8.4962e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.7118e-04 - accuracy: 0.9905 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 179/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 4.7610e-04 - accuracy: 0.9947 - val_loss: 7.7541e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.5813e-04 - accuracy: 0.9867 - val_loss: 7.0628e-04 - val_accuracy: 1.0000\n",
            "44/53 [=======================>......] - ETA: 0s - loss: 6.7924e-04 - accuracy: 0.9849Epoch 178/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.5518e-04 - accuracy: 0.9753 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2590e-04 - accuracy: 0.9861 - val_loss: 7.9144e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 179/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.9449e-04 - accuracy: 0.9846 - val_loss: 6.3306e-04 - val_accuracy: 0.9661\n",
            "Epoch 179/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.2681e-04 - accuracy: 0.9884 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 179/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.3265e-04 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 179/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.6296e-04 - accuracy: 0.9790 - val_loss: 8.8355e-04 - val_accuracy: 0.9828\n",
            "Epoch 178/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.0480e-04 - accuracy: 0.9863 - val_loss: 8.3098e-04 - val_accuracy: 0.9655\n",
            "Epoch 180/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.9515e-04 - accuracy: 0.9868 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 180/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 4.7615e-04 - accuracy: 0.9883 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 6.0393e-04 - accuracy: 0.9905Epoch 180/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.3234e-04 - accuracy: 0.9930 - val_loss: 8.6546e-04 - val_accuracy: 1.0000\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 5.9807e-04 - accuracy: 0.9843Epoch 179/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1578e-04 - accuracy: 0.9914 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.3266e-04 - accuracy: 0.9797 - val_loss: 9.0733e-04 - val_accuracy: 0.9655\n",
            "Epoch 179/190\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 4.3233e-04 - accuracy: 0.9831Epoch 180/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.8423e-04 - accuracy: 0.9759 - val_loss: 6.2589e-04 - val_accuracy: 0.9492\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 6.3100e-04 - accuracy: 0.9857Epoch 180/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.4806e-04 - accuracy: 0.9743 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 180/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.2592e-04 - accuracy: 0.9878 - val_loss: 9.3412e-04 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 3.1912e-04 - accuracy: 1.0000Epoch 180/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.6479e-04 - accuracy: 0.9939 - val_loss: 8.6924e-04 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.9569e-04 - accuracy: 0.9814 - val_loss: 7.7690e-04 - val_accuracy: 0.9828\n",
            "\n",
            "Epoch 181/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.0475e-04 - accuracy: 0.9820 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 4.8356e-04 - accuracy: 0.9935Epoch 181/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 4.6679e-04 - accuracy: 0.9820 - val_loss: 8.2928e-04 - val_accuracy: 1.0000\n",
            "26/53 [=============>................] - ETA: 0s - loss: 6.6773e-04 - accuracy: 0.9956Epoch 181/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.7155e-04 - accuracy: 0.9833 - val_loss: 6.4182e-04 - val_accuracy: 1.0000\n",
            "Epoch 180/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.3914e-04 - accuracy: 0.9835 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.4820e-04 - accuracy: 0.9908 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 181/190\n",
            "Epoch 180/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.4487e-04 - accuracy: 0.9828 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 5.9464e-04 - accuracy: 0.9560Epoch 181/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.5740e-04 - accuracy: 0.9713 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 181/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.9155e-04 - accuracy: 0.9939 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.7211e-04 - accuracy: 0.9696 - val_loss: 8.1183e-04 - val_accuracy: 1.0000\n",
            "Epoch 182/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 9.8007e-04 - accuracy: 1.0000Epoch 181/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.4445e-04 - accuracy: 0.9854 - val_loss: 8.4359e-04 - val_accuracy: 0.9655\n",
            "Epoch 180/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.7778e-04 - accuracy: 0.9772 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 182/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.1087e-04 - accuracy: 0.9819 - val_loss: 8.6620e-04 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0012 - accuracy: 0.9000Epoch 182/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.9106e-04 - accuracy: 0.9623 - val_loss: 6.1333e-04 - val_accuracy: 1.0000\n",
            "Epoch 181/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.0096e-04 - accuracy: 0.9780 - val_loss: 8.5728e-04 - val_accuracy: 1.0000\n",
            "Epoch 182/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.1064e-04 - accuracy: 0.9730 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "32/53 [=================>............] - ETA: 0s - loss: 5.0590e-04 - accuracy: 0.9853\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.8239e-04 - accuracy: 0.9764 - val_loss: 7.3003e-04 - val_accuracy: 0.9831\n",
            "Epoch 182/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.7010e-04 - accuracy: 0.9760 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 9.7780e-04 - accuracy: 1.0000Epoch 182/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.4097e-04 - accuracy: 0.9732 - val_loss: 8.5612e-04 - val_accuracy: 1.0000\n",
            "Epoch 183/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.5986e-04 - accuracy: 0.9827 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 182/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 4.9334e-04 - accuracy: 0.9806 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 181/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0414e-04 - accuracy: 0.9765 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "31/53 [================>.............] - ETA: 0s - loss: 9.2202e-04 - accuracy: 0.9597Epoch 183/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.2727e-04 - accuracy: 0.9861 - val_loss: 8.5314e-04 - val_accuracy: 1.0000\n",
            "Epoch 183/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.1887e-04 - accuracy: 0.9716 - val_loss: 6.3762e-04 - val_accuracy: 1.0000\n",
            "Epoch 182/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7373e-04 - accuracy: 0.9702 - val_loss: 9.1547e-04 - val_accuracy: 0.9828\n",
            "Epoch 183/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.5369e-04 - accuracy: 0.9654 - val_loss: 0.0013 - val_accuracy: 0.9138\n",
            "Epoch 182/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2299e-04 - accuracy: 0.9806 - val_loss: 6.9081e-04 - val_accuracy: 0.9492\n",
            "Epoch 183/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.4902e-04 - accuracy: 0.9703 - val_loss: 9.3977e-04 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 2.9992e-04 - accuracy: 1.0000Epoch 183/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2963e-04 - accuracy: 0.9759 - val_loss: 7.9203e-04 - val_accuracy: 0.9655\n",
            "Epoch 184/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.4069e-04 - accuracy: 0.9731 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 183/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.0702e-04 - accuracy: 0.9814 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 182/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.6142e-04 - accuracy: 0.9914 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 184/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.1466e-04 - accuracy: 0.9726 - val_loss: 8.7698e-04 - val_accuracy: 1.0000\n",
            "26/53 [=============>................] - ETA: 0s - loss: 5.4309e-04 - accuracy: 0.9772Epoch 184/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.2378e-04 - accuracy: 0.9862 - val_loss: 6.4290e-04 - val_accuracy: 1.0000\n",
            "Epoch 183/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2890e-04 - accuracy: 0.9881 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "46/53 [=========================>....] - ETA: 0s - loss: 7.2913e-04 - accuracy: 0.9770\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1778e-04 - accuracy: 0.9676 - val_loss: 0.0013 - val_accuracy: 0.93100s - loss: 7.4781e-04 - accuracy: 1.00\n",
            "Epoch 183/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.3603e-04 - accuracy: 0.9920 - val_loss: 5.5001e-04 - val_accuracy: 0.9661\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 4.9966e-04 - accuracy: 0.9912Epoch 184/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.5803e-04 - accuracy: 0.9782 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 184/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.2320e-04 - accuracy: 0.9773 - val_loss: 7.9397e-04 - val_accuracy: 1.0000\n",
            "Epoch 185/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8100e-04 - accuracy: 0.9807 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 184/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.5233e-04 - accuracy: 0.9755 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 183/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.1650e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "11/53 [=====>........................] - ETA: 0s - loss: 6.3830e-04 - accuracy: 0.97Epoch 185/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.2533e-04 - accuracy: 0.9809 - val_loss: 7.7441e-04 - val_accuracy: 1.0000\n",
            "Epoch 185/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.3960e-04 - accuracy: 0.9868 - val_loss: 6.8072e-04 - val_accuracy: 1.0000\n",
            "Epoch 184/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.7043e-04 - accuracy: 0.9914 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 185/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.1433e-04 - accuracy: 0.9809 - val_loss: 0.0013 - val_accuracy: 0.9138\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 5.8430e-04 - accuracy: 0.9867Epoch 184/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.0363e-04 - accuracy: 0.9818 - val_loss: 6.2123e-04 - val_accuracy: 0.9661\n",
            "29/53 [===============>..............] - ETA: 0s - loss: 8.3737e-04 - accuracy: 0.9812Epoch 185/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.5984e-04 - accuracy: 0.9975 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            " 1/53 [..............................] - ETA: 0s - loss: 4.2387e-04 - accuracy: 1.0000Epoch 185/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.5977e-04 - accuracy: 0.9843 - val_loss: 9.0673e-04 - val_accuracy: 1.0000\n",
            "Epoch 186/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8702e-04 - accuracy: 0.9826 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 185/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.8572e-04 - accuracy: 0.9882 - val_loss: 8.8259e-04 - val_accuracy: 0.9655\n",
            "42/53 [======================>.......] - ETA: 0s - loss: 8.2772e-04 - accuracy: 0.9830Epoch 184/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.9325e-04 - accuracy: 0.9860 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "26/53 [=============>................] - ETA: 0s - loss: 6.6654e-04 - accuracy: 0.98Epoch 186/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.9742e-04 - accuracy: 0.9828 - val_loss: 8.9130e-04 - val_accuracy: 1.0000\n",
            "26/53 [=============>................] - ETA: 0s - loss: 7.6460e-04 - accuracy: 0.9843Epoch 186/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.2079e-04 - accuracy: 0.9828 - val_loss: 7.1161e-04 - val_accuracy: 1.0000\n",
            "Epoch 185/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.4391e-04 - accuracy: 0.9860 - val_loss: 6.9998e-04 - val_accuracy: 1.0000\n",
            "Epoch 186/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.2397e-04 - accuracy: 0.9686 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "43/53 [=======================>......] - ETA: 0s - loss: 8.0792e-04 - accuracy: 0.9818Epoch 185/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.5591e-04 - accuracy: 0.9878 - val_loss: 9.2350e-04 - val_accuracy: 0.9661\n",
            "27/53 [==============>...............] - ETA: 0s - loss: 6.9139e-04 - accuracy: 0.9788\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.3870e-04 - accuracy: 0.9837 - val_loss: 9.8807e-04 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.9976e-04 - accuracy: 0.9865 - val_loss: 7.0178e-04 - val_accuracy: 0.9828\n",
            "Epoch 186/190\n",
            " 1/53 [..............................] - ETA: 0s - loss: 1.8331e-04 - accuracy: 1.0000Epoch 187/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.8660e-04 - accuracy: 0.9823 - val_loss: 9.0689e-04 - val_accuracy: 0.9661\n",
            "36/53 [===================>..........] - ETA: 0s - loss: 7.1738e-04 - accuracy: 0.9788Epoch 186/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.2865e-04 - accuracy: 0.9803 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 185/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.5783e-04 - accuracy: 0.9791 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.1798e-04 - accuracy: 0.9921 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 187/190Epoch 187/190\n",
            "\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.2716e-04 - accuracy: 0.9791 - val_loss: 7.0624e-04 - val_accuracy: 1.0000\n",
            "17/53 [========>.....................] - ETA: 0s - loss: 6.6643e-04 - accuracy: 0.9836Epoch 186/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1414e-04 - accuracy: 0.9856 - val_loss: 7.6726e-04 - val_accuracy: 0.9828\n",
            "Epoch 187/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.8868e-04 - accuracy: 0.9843 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 186/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.5684e-04 - accuracy: 0.9905 - val_loss: 7.3163e-04 - val_accuracy: 0.9661\n",
            "25/53 [=============>................] - ETA: 0s - loss: 5.4496e-04 - accuracy: 0.9849Epoch 187/1\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.1858e-04 - accuracy: 0.9833 - val_loss: 9.3290e-04 - val_accuracy: 0.9828\n",
            "Epoch 187/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.1137e-04 - accuracy: 0.9949 - val_loss: 7.6252e-04 - val_accuracy: 1.0000\n",
            "Epoch 188/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.3298e-04 - accuracy: 0.9881 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 7.5559e-04 - accuracy: 0.9893Epoch 187/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.6735e-04 - accuracy: 0.9863 - val_loss: 9.0169e-04 - val_accuracy: 0.9655\n",
            "Epoch 186/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.2369e-04 - accuracy: 0.9887 - val_loss: 8.1658e-04 - val_accuracy: 1.0000\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 6.0562e-04 - accuracy: 0.9828Epoch 188/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 7.9184e-04 - accuracy: 0.9876 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 188/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.5516e-04 - accuracy: 0.9857 - val_loss: 5.6008e-04 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Epoch 187/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.4486e-04 - accuracy: 0.9808 - val_loss: 9.0910e-04 - val_accuracy: 0.9828\n",
            "Epoch 188/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.2864e-04 - accuracy: 0.9804 - val_loss: 0.0014 - val_accuracy: 0.9138\n",
            "Epoch 187/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.6364e-04 - accuracy: 0.9826 - val_loss: 6.8895e-04 - val_accuracy: 0.9661\n",
            "28/53 [==============>...............] - ETA: 0s - loss: 5.4846e-04 - accuracy: 0.9931Epoch 188/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.7946e-04 - accuracy: 0.9907 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 188/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.4150e-04 - accuracy: 0.9846 - val_loss: 8.3023e-04 - val_accuracy: 1.0000\n",
            "Epoch 189/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.2389e-04 - accuracy: 0.9761 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            " 1/53 [..............................] - ETA: 0s - loss: 3.5307e-04 - accuracy: 1.0000Epoch 188/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.5166e-04 - accuracy: 0.9891 - val_loss: 9.1041e-04 - val_accuracy: 0.9655\n",
            "Epoch 187/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 4.4125e-04 - accuracy: 0.9889 - val_loss: 7.5081e-04 - val_accuracy: 1.0000\n",
            "31/53 [================>.............] - ETA: 0s - loss: 5.4556e-04 - accuracy: 0.9892Epoch 189/1\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.5726e-04 - accuracy: 0.9857 - val_loss: 6.1254e-04 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.8228e-04 - accuracy: 0.9765 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "16/53 [========>.....................] - ETA: 0s - loss: 5.4133e-04 - accuracy: 0.9789Epoch 188/1\n",
            "Epoch 189/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.7656e-04 - accuracy: 0.9777 - val_loss: 7.4701e-04 - val_accuracy: 0.9828\n",
            "Epoch 189/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 8.6641e-04 - accuracy: 0.9793 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 188/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.8730e-04 - accuracy: 0.9884 - val_loss: 6.2843e-04 - val_accuracy: 0.9492\n",
            "11/53 [=====>........................] - ETA: 0s - loss: 8.1844e-04 - accuracy: 0.9961\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.9187e-04 - accuracy: 0.9888 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.6762e-04 - accuracy: 0.9798 - val_loss: 7.5603e-04 - val_accuracy: 0.9655\n",
            "Epoch 189/190\n",
            "Epoch 190/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.2952e-04 - accuracy: 0.9816 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "25/53 [=============>................] - ETA: 0s - loss: 6.8840e-04 - accuracy: 0.9811Epoch 189/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.8006e-04 - accuracy: 0.9834 - val_loss: 9.1010e-04 - val_accuracy: 0.9828\n",
            "Epoch 188/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.2509e-04 - accuracy: 0.9894 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "30/53 [===============>..............] - ETA: 0s - loss: 6.5915e-04 - accuracy: 0.98Epoch 190/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.0350e-04 - accuracy: 0.9849 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 190/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5.1761e-04 - accuracy: 0.9851 - val_loss: 6.4095e-04 - val_accuracy: 1.0000\n",
            "Epoch 189/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.5293e-04 - accuracy: 0.9818 - val_loss: 7.0835e-04 - val_accuracy: 1.0000\n",
            "Epoch 190/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.5730e-04 - accuracy: 0.9839 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 189/190\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.7754e-04 - accuracy: 0.9870 - val_loss: 7.6691e-04 - val_accuracy: 0.9661\n",
            "Epoch 190/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.8898e-04 - accuracy: 0.9739 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 190/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.2070e-04 - accuracy: 0.9851 - val_loss: 7.4836e-04 - val_accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.8528e-04 - accuracy: 0.9799 - val_loss: 9.3393e-04 - val_accuracy: 0.9661\n",
            "40/53 [=====================>........] - ETA: 0s - loss: 5.2720e-04 - accuracy: 0.9687Epoch 190/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.0110e-04 - accuracy: 0.9775 - val_loss: 9.5021e-04 - val_accuracy: 0.9828\n",
            "Epoch 189/190\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.4836e-04 - accuracy: 0.9828\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 5.6422e-04 - accuracy: 0.9858 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 8.1805e-04 - accuracy: 0.9831 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.0721e-04 - accuracy: 0.9690 - val_loss: 6.1912e-04 - val_accuracy: 1.0000\n",
            "Epoch 190/190\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 6.6732e-04 - accuracy: 0.9791 - val_loss: 8.6692e-04 - val_accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 9.3921e-04 - accuracy: 0.9883 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 190/190\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9655\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 9.2268e-04 - accuracy: 0.9718 - val_loss: 7.6324e-04 - val_accuracy: 0.9492\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.6417e-04 - accuracy: 0.9849 - val_loss: 8.9070e-04 - val_accuracy: 0.9828\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.6692e-04 - accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9731 - val_loss: 9.5651e-04 - val_accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7.1297e-04 - accuracy: 0.9799 - val_loss: 8.8721e-04 - val_accuracy: 0.9655\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.9070e-04 - accuracy: 0.9828\n",
            "Epoch 190/190\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 7.6324e-04 - accuracy: 0.9492\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 9.5651e-04 - accuracy: 0.9661\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 6.8267e-04 - accuracy: 0.9857 - val_loss: 9.5232e-04 - val_accuracy: 0.9655\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 9.5232e-04 - accuracy: 0.9655\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 8.6170e-04 - accuracy: 0.9758 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "2/2 [==============================] - 0s 822us/step - loss: 0.0013 - accuracy: 0.9310\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 6.2992e-04 - accuracy: 0.9901 - val_loss: 8.7765e-04 - val_accuracy: 0.9655\n",
            "2/2 [==============================] - 0s 695us/step - loss: 8.7765e-04 - accuracy: 0.9655\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "NUM_EPOCHS = 190 # 180\n",
        "BATCH_SIZE = 10\n",
        "K_FOLD_SPLITS = 10\n",
        "\n",
        "\n",
        "# Define the cross-validation process to be used inside cross_val_Score evaluation\n",
        "cv = KFold(n_splits=K_FOLD_SPLITS)\n",
        "\n",
        "# Handling for accommodating multiple targets\n",
        "Y1 = y_train_norm[:,0]\n",
        "Y2 = y_train_norm[:,1]\n",
        "targets = (Y1, Y2)\n",
        "\n",
        "X = X_train_norm\n",
        "\n",
        "i = 0\n",
        "arr_loss = list()\n",
        "arr_rmse = list()\n",
        "min_loss = 1000000\n",
        "best_model = None\n",
        "history = None\n",
        "history_best_model = None\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_indices, test_indices in cv.split(X_train):\n",
        "  print('####################### Iteration  ', i, ' #######################')\n",
        "  trainX, valX = np.array(X[train_indices]), np.array(X[test_indices])\n",
        "  trainY = np.vstack((Y1[train_indices], Y2[train_indices])).T\n",
        "  valY = np.vstack((Y1[test_indices], Y2[test_indices])).T\n",
        "\n",
        "  model = my_model()\n",
        "  history = model.fit(trainX, trainY,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            validation_data = (valX, valY)\n",
        "  )\n",
        "\n",
        "\n",
        "  #testing on validation set process\n",
        "  loss, rmse = model.evaluate(x = valX, y = valY, verbose=1)\n",
        "  print(f\"Loss = {loss}, rmse = {rmse}\" )\n",
        "\n",
        "  if loss < min_loss:\n",
        "    best_model = model\n",
        "    history_best_model = history\n",
        "    min_loss = loss\n",
        "\n",
        "  arr_loss.append(loss)\n",
        "  arr_rmse.append(rmse)\n",
        "  print('Loss array: ', arr_loss)\n",
        "  i+=1\n",
        "\n",
        "# Saving the best model within the k folds\n",
        "best_model.save(FILENAME_BEST_MODEL)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results\n",
        "- Plot of k-cross validation performance\n",
        "- Scatter Plot of prediction results against true values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 390,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "xKSkPnO4ETWD",
        "outputId": "564ee694-d414-4d21-bbd9-f838e7249dd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loss across k folds\n",
        "plot_line(arr_loss, \"Loss across k-folds\", \"Value of k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training and Validation Loss\n",
        "plot_loss_curve(history_best_model, NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 392,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the test dataset\n",
        "X_test_norm = scaler_input.transform(X_test)\n",
        "y_test_norm = scaler_output.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 393,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-erJ0l_Yu4P",
        "outputId": "9cff94b2-e4ca-491b-8459-aeaa1eff7606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time: 0.0251 seconds\n",
            "Maxval here is:  24.41\n",
            "Maxval here is:  0.9278\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "Y_pred_normalized = best_model.predict(X_test_norm)\n",
        "end_time = time.time()\n",
        "Y_pred_normalized_entire = best_model.predict(dataset_x_norm)\n",
        "# Calculate elapsed time in seconds\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Elapsed time:\", round(elapsed_time, 3), \"seconds\")\n",
        "\n",
        "\n",
        "Y_pred = scaler_output.inverse_transform(Y_pred_normalized)\n",
        "Y_pred_entire = scaler_output.inverse_transform(Y_pred_normalized_entire)\n",
        "Y_actual = np.array(y_test)\n",
        "Y_actual_entire = np.array(df_targets)\n",
        "# Moisture Content\n",
        "scatter_plot(trueValues=Y_actual[:,0], \n",
        "             predictions=Y_pred[:,0], \n",
        "             title=\"Moisture Content\")\n",
        "a, b = np.polyfit(Y_pred[:, 0], Y_actual[:, 0], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,0]), max(Y_actual[:,0])), 1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_MC.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)\n",
        "\n",
        "# Bulk Density\n",
        "scatter_plot(trueValues=Y_actual[:,1], \n",
        "             predictions=Y_pred[:,1], \n",
        "             title=\"Bulk Density\")\n",
        "plt.xlim([min(min(Y_pred[:,1]), min(Y_actual[:,1]))-0.1, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1])\n",
        "a, b = np.polyfit(Y_pred[:, 1], Y_actual[:, 1], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1, 0.1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_BD.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Error analysis\n",
        "- R squared calculation\n",
        "- Mean accuracy error"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### R squared calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 394,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9909\n",
            "0.9218\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# MOISTURE CONTENT\n",
        "#   - R-squared\n",
        "# mc_r2_score = r2_score(Y_actual[:, 0], Y_pred[:, 0])\n",
        "mc_r2_score = calculate_r_squared(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"{:#.4g}\".format(mc_r2_score))\n",
        "\n",
        "# BULK DENSITY\n",
        "#   - R-squared\n",
        "# bd_r2_score = r2_score(Y_actual[:, 1], Y_pred[:, 1])\n",
        "bd_r2_score = calculate_r_squared(y_true=Y_actual[:, 1], y_pred=Y_pred[:, 1])\n",
        "print(\"{:#.4g}\".format(bd_r2_score))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 395,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE_MC:  0.3688\n",
            "RMSE_BD:  0.03097\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sigfig import round\n",
        "\n",
        "#MC\n",
        "rmse_mc = np.sqrt(mean_squared_error(Y_actual[:, 0], Y_pred[:, 0]))\n",
        "print('RMSE_MC: ', \"{0:.4g}\".format(rmse_mc))\n",
        "\n",
        "#BD\n",
        "rmse_bd = np.sqrt(mean_squared_error(Y_actual[:, 1], Y_pred[:, 1]))\n",
        "print('RMSE_BD: ', \"{0:.4g}\".format(rmse_bd))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will compare with the results from Trabelsi's paper. This is single moisture prediction \n",
        "\n",
        "R^2 : 0.993\\\n",
        "Mean Squared Error: 0.028\\\n",
        "Mean absolute Error: 0.135\\\n",
        "Min. Absolute Error: 0.004\\\n",
        "Max Absolute Error: 0.441"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 396,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9896\n",
            "Mean Squared Error:  0.136\n",
            "Mean Absolute Error:  0.2762\n",
            "Min Absolute Error:  0.004505805969237997\n",
            "Max Absolute Error:  1.3082466125488281\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,max_error, r2_score\n",
        "from sigfig import round\n",
        "\n",
        "mc_r2_score = r2_score(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual[:, 0], Y_pred[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual[:, 0], Y_pred[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual[:,0])):\n",
        "    sum = Y_actual[:,0][i] - Y_pred[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9933\n",
            "Mean Squared Error:  0.09637\n",
            "Mean Absolute Error:  0.2343\n",
            "Min Absolute Error:  0.00015007019042911907\n",
            "Max Absolute Error:  1.3082466125488281\n"
          ]
        }
      ],
      "source": [
        "mc_r2_score = r2_score(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual_entire[:,0])):\n",
        "    sum = Y_actual_entire[:,0][i] - Y_pred_entire[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
