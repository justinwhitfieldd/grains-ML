{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [],
      "source": [
        "#GRAIN_TYPE = 'Wheat'\n",
        "#GRAIN_TYPE = 'newWheatData'\n",
        "#GRAIN_TYPE = 'CornAdded_Type'\n",
        "GRAIN_TYPE = 'cleaned_data'\n",
        "# GRAIN_TYPE = 'Oats'\n",
        "\n",
        "# GRAIN_TYPE = 'Barley'\n",
        "# GRAIN_TYPE = 'Sorghum'\n",
        "# GRAIN_TYPE = 'Soybeans'\n",
        "# GRAIN_TYPE = 'Corn'\n",
        "\n",
        "FILENAME_BEST_MODEL = 'Best models/target_2/hybrid_models/' + GRAIN_TYPE + '_t2_kcv_dnn_mc.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNGoIGbc0kw_",
        "outputId": "279cc9c8-32fd-4f89-e56b-83a0a31081dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ]
        }
      ],
      "source": [
        "#Import libraries\n",
        "import requests\n",
        "import pydot\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Data visualization\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "#Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Machine Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Activation, BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "np.random.seed(39)\n",
        "random.seed(39)\n",
        "tf.random.set_seed(39)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "# print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "nxHO_qH0Zi5J"
      },
      "outputs": [],
      "source": [
        "def calculate_r_squared(y_true, y_pred):\n",
        "   corr_matrix = np.corrcoef(y_true, y_pred)\n",
        "   corr = corr_matrix[0,1]\n",
        "   R_sq = corr**2\n",
        "   return R_sq\n",
        "\n",
        "def plot_loss_curve(history, epoch_size):\n",
        "    loss_train = history.history['loss']\n",
        "    loss_val = history.history['val_loss']\n",
        "    epochs = range(0,epoch_size)\n",
        "    \n",
        "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "    \n",
        "    plt.title('Training and Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_line(metric, title, xlabel):\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.title(title, fontsize = 16)\n",
        "    plt.plot(metric)\n",
        "    plt.xlabel(xlabel, fontsize = 14)\n",
        "    plt.grid()\n",
        "    plt.legend(loc= \"best\")\n",
        "    plt.show()\n",
        "\n",
        "def scatter_plot(trueValues, predictions, title):\n",
        "  plt.figure(figsize=(8,3))\n",
        "  ax = plt.axes()\n",
        "  maxVal = max( max(trueValues), max(predictions) )\n",
        "\n",
        "  ax.scatter(x=predictions, y=trueValues)\n",
        "  ax.plot([0, 1, maxVal], [0, 1, maxVal], label=\"Ideal fit\")\n",
        "  print('Maxval here is: ', maxVal)\n",
        "  plt.title(title, fontsize = 16)\n",
        "  plt.xlabel(\"Predictions\", fontsize = 14)\n",
        "  plt.ylabel(\"Real\", fontsize = 14)\n",
        "  plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "s3pvA5g-zdgv",
        "outputId": "7a7208f1-6b68-4eba-ad1d-9108d0df66ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From USDA:  ../Datasets/processed/cleaned_data.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variety</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>8.8258</td>\n",
              "      <td>-55.973</td>\n",
              "      <td>-415.973</td>\n",
              "      <td>2.416</td>\n",
              "      <td>0.243</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-6.341975</td>\n",
              "      <td>62.3</td>\n",
              "      <td>61.7806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>10.2572</td>\n",
              "      <td>-114.289</td>\n",
              "      <td>-474.289</td>\n",
              "      <td>2.412</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-11.142320</td>\n",
              "      <td>71.2</td>\n",
              "      <td>82.0576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>11.5679</td>\n",
              "      <td>-168.171</td>\n",
              "      <td>-528.171</td>\n",
              "      <td>2.395</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-14.537729</td>\n",
              "      <td>80.1</td>\n",
              "      <td>104.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>12.8795</td>\n",
              "      <td>134.849</td>\n",
              "      <td>-585.151</td>\n",
              "      <td>2.390</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>10.470049</td>\n",
              "      <td>89.0</td>\n",
              "      <td>128.7950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KANSAS</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>13.7649</td>\n",
              "      <td>83.502</td>\n",
              "      <td>-636.498</td>\n",
              "      <td>2.371</td>\n",
              "      <td>0.238</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>6.066299</td>\n",
              "      <td>97.9</td>\n",
              "      <td>151.4139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Variety  Freq  d(cm)    M%  Density     Attn    Phase  Phase_Corr  \\\n",
              "0  KANSAS   7.0    8.9  11.3   0.7356   8.8258  -55.973    -415.973   \n",
              "1  KANSAS   8.0    8.9  11.3   0.7356  10.2572 -114.289    -474.289   \n",
              "2  KANSAS   9.0    8.9  11.3   0.7356  11.5679 -168.171    -528.171   \n",
              "3  KANSAS  10.0    8.9  11.3   0.7356  12.8795  134.849    -585.151   \n",
              "4  KANSAS  11.0    8.9  11.3   0.7356  13.7649   83.502    -636.498   \n",
              "\n",
              "   Permittivity_real  Permittivity_imaginary       Type  Phase/Attn  \\\n",
              "0              2.416                   0.243  15.855506   -6.341975   \n",
              "1              2.412                   0.246  15.855506  -11.142320   \n",
              "2              2.395                   0.246  15.855506  -14.537729   \n",
              "3              2.390                   0.246  15.855506   10.470049   \n",
              "4              2.371                   0.238  15.855506    6.066299   \n",
              "\n",
              "   Freq*d(cm)  Freq*Attn  \n",
              "0        62.3    61.7806  \n",
              "1        71.2    82.0576  \n",
              "2        80.1   104.1111  \n",
              "3        89.0   128.7950  \n",
              "4        97.9   151.4139  "
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#url dataset\n",
        "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
        "\n",
        "#read in excel format\n",
        "df = pd.read_csv(URL)\n",
        "#df = df[df['Variety'] == 'SOUTH DAKOTA']\n",
        "#df = df[(df['Density'] >= 0.72) & (df['Density'] <= 0.88)]\n",
        "\n",
        "print(\"From USDA: \", URL)\n",
        "\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUzjHHV2stm"
      },
      "source": [
        "# 2. Overview of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Xohz7dGh2sXH",
        "outputId": "7d018cd8-018a-45d3-b1b7-ba9fc14aa5e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10.811414</td>\n",
              "      <td>7.088834</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>0.796298</td>\n",
              "      <td>18.410033</td>\n",
              "      <td>-4.604663</td>\n",
              "      <td>-633.488065</td>\n",
              "      <td>2.912112</td>\n",
              "      <td>0.499187</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>-0.377074</td>\n",
              "      <td>77.159677</td>\n",
              "      <td>215.799030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.530055</td>\n",
              "      <td>1.554604</td>\n",
              "      <td>3.794772</td>\n",
              "      <td>0.067384</td>\n",
              "      <td>5.946835</td>\n",
              "      <td>101.951444</td>\n",
              "      <td>219.510760</td>\n",
              "      <td>0.305758</td>\n",
              "      <td>0.186739</td>\n",
              "      <td>0.629743</td>\n",
              "      <td>6.071761</td>\n",
              "      <td>32.552200</td>\n",
              "      <td>124.108325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>10.260000</td>\n",
              "      <td>0.625400</td>\n",
              "      <td>8.002300</td>\n",
              "      <td>-179.335000</td>\n",
              "      <td>-1274.435000</td>\n",
              "      <td>2.340000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>15.352809</td>\n",
              "      <td>-17.418676</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>40.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>13.680000</td>\n",
              "      <td>0.745400</td>\n",
              "      <td>13.524700</td>\n",
              "      <td>-88.842000</td>\n",
              "      <td>-793.405750</td>\n",
              "      <td>2.688500</td>\n",
              "      <td>0.337000</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-5.077754</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>107.817375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>16.225000</td>\n",
              "      <td>0.801300</td>\n",
              "      <td>18.131600</td>\n",
              "      <td>-9.838500</td>\n",
              "      <td>-602.380500</td>\n",
              "      <td>2.861500</td>\n",
              "      <td>0.470500</td>\n",
              "      <td>16.400366</td>\n",
              "      <td>-0.589378</td>\n",
              "      <td>71.200000</td>\n",
              "      <td>195.600450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>18.810000</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>23.098000</td>\n",
              "      <td>80.957250</td>\n",
              "      <td>-456.055750</td>\n",
              "      <td>3.109750</td>\n",
              "      <td>0.639000</td>\n",
              "      <td>16.401988</td>\n",
              "      <td>4.300734</td>\n",
              "      <td>100.100000</td>\n",
              "      <td>310.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>24.410000</td>\n",
              "      <td>0.927800</td>\n",
              "      <td>29.897000</td>\n",
              "      <td>179.048000</td>\n",
              "      <td>-235.044000</td>\n",
              "      <td>4.038000</td>\n",
              "      <td>0.987000</td>\n",
              "      <td>17.344167</td>\n",
              "      <td>14.827701</td>\n",
              "      <td>160.200000</td>\n",
              "      <td>538.146000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Freq       d(cm)          M%     Density        Attn       Phase  \\\n",
              "count  806.000000  806.000000  806.000000  806.000000  806.000000  806.000000   \n",
              "mean    10.811414    7.088834   16.189541    0.796298   18.410033   -4.604663   \n",
              "std      3.530055    1.554604    3.794772    0.067384    5.946835  101.951444   \n",
              "min      5.000000    4.400000   10.260000    0.625400    8.002300 -179.335000   \n",
              "25%      8.000000    6.500000   13.680000    0.745400   13.524700  -88.842000   \n",
              "50%     11.000000    7.700000   16.225000    0.801300   18.131600   -9.838500   \n",
              "75%     13.000000    7.700000   18.810000    0.842000   23.098000   80.957250   \n",
              "max     18.000000    8.900000   24.410000    0.927800   29.897000  179.048000   \n",
              "\n",
              "        Phase_Corr  Permittivity_real  Permittivity_imaginary        Type  \\\n",
              "count   806.000000         806.000000              806.000000  806.000000   \n",
              "mean   -633.488065           2.912112                0.499187   16.189541   \n",
              "std     219.510760           0.305758                0.186739    0.629743   \n",
              "min   -1274.435000           2.340000                0.220000   15.352809   \n",
              "25%    -793.405750           2.688500                0.337000   15.855506   \n",
              "50%    -602.380500           2.861500                0.470500   16.400366   \n",
              "75%    -456.055750           3.109750                0.639000   16.401988   \n",
              "max    -235.044000           4.038000                0.987000   17.344167   \n",
              "\n",
              "       Phase/Attn  Freq*d(cm)   Freq*Attn  \n",
              "count  806.000000  806.000000  806.000000  \n",
              "mean    -0.377074   77.159677  215.799030  \n",
              "std      6.071761   32.552200  124.108325  \n",
              "min    -17.418676   22.000000   40.011500  \n",
              "25%     -5.077754   52.800000  107.817375  \n",
              "50%     -0.589378   71.200000  195.600450  \n",
              "75%      4.300734  100.100000  310.863000  \n",
              "max     14.827701  160.200000  538.146000  "
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data summary\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmFqsYQyGnM",
        "outputId": "54445a7f-a2c8-452a-9651-42dbbe682d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(806, 14)"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimension of the dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fep-GIv4yUuf",
        "outputId": "c46072fa-aa7f-4549-9a1d-4c5b05d11112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Variety                   0\n",
              "Freq                      0\n",
              "d(cm)                     0\n",
              "M%                        0\n",
              "Density                   0\n",
              "Attn                      0\n",
              "Phase                     0\n",
              "Phase_Corr                0\n",
              "Permittivity_real         0\n",
              "Permittivity_imaginary    0\n",
              "Type                      0\n",
              "Phase/Attn                0\n",
              "Freq*d(cm)                0\n",
              "Freq*Attn                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 207,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check info about missing values in dataframe\n",
        "df.isnull().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_TKP9VymuK"
      },
      "source": [
        "# Exploratory Data Analysis\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz1g9T3FzhF0"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "\n",
        "1.   Convert dataframe to numpy array for flexibility.\n",
        "2. Split our data into training and testing datasets and store the target values in different variables.\n",
        "3.   Normalize the features by applying some operations in the data sets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "T0juhagf1M2I"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy array\n",
        "df_features = df[['Freq', \n",
        "                    'd(cm)', \n",
        "                   # 'Attn', \n",
        "                    'Phase_Corr', \n",
        "                    'Permittivity_real', \n",
        "                    'Permittivity_imaginary',\n",
        "                    'Type',\n",
        "                    ]]\n",
        "\n",
        "df_targets = df[['M%', 'Density']]\n",
        "# df_targets = df[['Density', 'M%']]\n",
        "\n",
        "dataset_x = df_features.to_numpy()\n",
        "dataset_y = df_targets.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting dataset to test and train+validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform train-test split on RAW DATA\n",
        "X_trainVal, X_test, y_trainVal, y_test = train_test_split(dataset_x, dataset_y, \n",
        "                                                    test_size=0.15\n",
        "                                                    ,random_state=42\n",
        "                                                    )\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainVal, y_trainVal, \n",
        "                                                    test_size=0.15 #validation split\n",
        "                                                    ,random_state=42\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Normalizing the data set\n",
        "scaler_input = MinMaxScaler()\n",
        "scaler_output = MinMaxScaler()\n",
        "\n",
        "# Normalize Train set\n",
        "X_train_norm = scaler_input.fit_transform(X_train)\n",
        "y_train_norm = scaler_output.fit_transform(y_train)\n",
        "\n",
        "# Normalize Validation set\n",
        "X_val_norm = scaler_input.fit_transform(X_val)\n",
        "y_val_norm = scaler_output.fit_transform(y_val)\n",
        "\n",
        "# Normalize the entire dataset (input features)\n",
        "dataset_x_norm = scaler_input.transform(dataset_x)  # Use transform, NOT fit_transform\n",
        "\n",
        "# Normalize the entire dataset (output targets)\n",
        "dataset_y_norm = scaler_output.transform(dataset_y)  # Use transform, NOT fit_transform\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKfjwMP0Tzn"
      },
      "source": [
        "# K-cross Validation\n",
        "* Input features: 7\n",
        "* Output targets: 2\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "l31WJZ7Z0ONb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_103\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_412 (Dense)            (None, 36)                252       \n",
            "_________________________________________________________________\n",
            "dense_413 (Dense)            (None, 36)                1332      \n",
            "_________________________________________________________________\n",
            "dense_414 (Dense)            (None, 36)                1332      \n",
            "_________________________________________________________________\n",
            "dense_415 (Dense)            (None, 2)                 74        \n",
            "=================================================================\n",
            "Total params: 2,990\n",
            "Trainable params: 2,990\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import layers, Sequential, regularizers\n",
        "\n",
        "# Define the model-building function\n",
        "def my_model():\n",
        "  my_model = Sequential([\n",
        "    \n",
        "    layers.Dense(36, input_shape=(6,), activation='relu', \n",
        "                #  kernel_regularizer=regularizers.l2(0.01)\n",
        "                 ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.1),\n",
        "\n",
        "\n",
        "    layers.Dense(36, activation='relu', \n",
        "                # kernel_regularizer=regularizers.l2(0.01)\n",
        "                ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.1),````\n",
        "\n",
        "    layers.Dense(36, activation='relu', \n",
        "                # kernel_regularizer=regularizers.l2(0.01)\n",
        "                ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.2),\n",
        "    \n",
        "    layers.Dense(2, activation='sigmoid')  # Output layer with 2 neurons for the two regression targets\n",
        "  ])\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.0006105) # 0.0006 \n",
        "  my_model.compile(\n",
        "      optimizer = opt,\n",
        "      loss = 'mse',\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "\n",
        "  return my_model\n",
        "\n",
        "plot_model(my_model(), show_shapes=True, show_layer_names=True)\n",
        "my_model().summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running model with KCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khCKKB74hFVT",
        "outputId": "37e79cdf-4183-4559-f560-fceb2fc0c630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "####################### Iteration   0  #######################\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.6579 - val_loss: 0.0489 - val_accuracy: 0.6949\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.6866 - val_loss: 0.0307 - val_accuracy: 0.9322\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.8671 - val_loss: 0.0184 - val_accuracy: 0.8814\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 0.8766 - val_loss: 0.0158 - val_accuracy: 0.8475\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 0.8603 - val_loss: 0.0130 - val_accuracy: 0.8814\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.8985 - val_loss: 0.0102 - val_accuracy: 0.9153\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 0.8926 - val_loss: 0.0084 - val_accuracy: 0.9492\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 0.9180 - val_loss: 0.0080 - val_accuracy: 0.9492\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.9284 - val_loss: 0.0090 - val_accuracy: 0.8983\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 0.8936 - val_loss: 0.0067 - val_accuracy: 0.9492\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 0.9340 - val_loss: 0.0084 - val_accuracy: 0.9153\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 0.9222 - val_loss: 0.0073 - val_accuracy: 0.9322\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 0.9413 - val_loss: 0.0060 - val_accuracy: 0.9661\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.9302 - val_loss: 0.0052 - val_accuracy: 0.9492\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.9394 - val_loss: 0.0051 - val_accuracy: 0.9492\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.9277 - val_loss: 0.0047 - val_accuracy: 0.9661\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9401 - val_loss: 0.0049 - val_accuracy: 0.9492\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9442 - val_loss: 0.0047 - val_accuracy: 0.9492\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9331 - val_loss: 0.0045 - val_accuracy: 0.9322\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.9272 - val_loss: 0.0044 - val_accuracy: 0.9322\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9179 - val_loss: 0.0038 - val_accuracy: 0.9492\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.9145 - val_loss: 0.0040 - val_accuracy: 0.9322\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.9300 - val_loss: 0.0035 - val_accuracy: 0.9661\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 0.9421 - val_loss: 0.0035 - val_accuracy: 0.9322\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.9275 - val_loss: 0.0036 - val_accuracy: 0.9322\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 0.9268 - val_loss: 0.0033 - val_accuracy: 0.9322\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.9178 - val_loss: 0.0032 - val_accuracy: 0.9322\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9468 - val_loss: 0.0032 - val_accuracy: 0.9322\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9407 - val_loss: 0.0031 - val_accuracy: 0.9322\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9477 - val_loss: 0.0031 - val_accuracy: 0.9322\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9410 - val_loss: 0.0031 - val_accuracy: 0.9322\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9383 - val_loss: 0.0032 - val_accuracy: 0.9661\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9366 - val_loss: 0.0027 - val_accuracy: 0.9492\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9543 - val_loss: 0.0026 - val_accuracy: 0.9661\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9420 - val_loss: 0.0026 - val_accuracy: 0.9322\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9437 - val_loss: 0.0025 - val_accuracy: 0.9661\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9437 - val_loss: 0.0026 - val_accuracy: 0.9661\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9448 - val_loss: 0.0028 - val_accuracy: 0.9153\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9544 - val_loss: 0.0022 - val_accuracy: 0.9492\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9396 - val_loss: 0.0022 - val_accuracy: 0.9492\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9600 - val_loss: 0.0024 - val_accuracy: 0.9153\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9550 - val_loss: 0.0024 - val_accuracy: 0.9153\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9479 - val_loss: 0.0021 - val_accuracy: 0.9492\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9623 - val_loss: 0.0024 - val_accuracy: 0.9153\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9517 - val_loss: 0.0021 - val_accuracy: 0.9322\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9468 - val_loss: 0.0019 - val_accuracy: 0.9492\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9679 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9456 - val_loss: 0.0020 - val_accuracy: 0.9322\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9549 - val_loss: 0.0021 - val_accuracy: 0.9322\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9512 - val_loss: 0.0019 - val_accuracy: 0.9322\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9682 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9319 - val_loss: 0.0027 - val_accuracy: 0.9322\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9425 - val_loss: 0.0019 - val_accuracy: 0.9322\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9625 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9654 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9642 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9666 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9677 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9556 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9564 - val_loss: 0.0020 - val_accuracy: 0.9492\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9703 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9519 - val_loss: 0.0019 - val_accuracy: 0.9322\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9602 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9678 - val_loss: 0.0023 - val_accuracy: 0.9153\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9585 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9606 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.9502 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9619 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9762 - val_loss: 0.0018 - val_accuracy: 0.9322\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9760 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9697 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9695 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9778 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9613 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9625 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9676 - val_loss: 0.0019 - val_accuracy: 0.9322\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9697 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9540 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9744 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9681 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9579 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9685 - val_loss: 0.0022 - val_accuracy: 0.9492\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9575 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9728 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9708 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9702 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9649 - val_loss: 0.0018 - val_accuracy: 0.9322\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9682 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9696 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9717 - val_loss: 0.0020 - val_accuracy: 0.9492\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9735 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9815 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9686 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9485 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9752 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9753 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9696 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9641 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9698 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9748 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9655 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9691 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9883 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9660 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9660 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9691 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9780 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9636 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9702 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9464 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9607 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9692 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9574 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9652 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9751 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9779 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9629 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9823 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9812 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9762 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9651 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9812 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9732 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9851 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9703 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9745 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9648 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9599 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9713 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9813 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 904us/step - loss: 0.0011 - accuracy: 0.9825 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 770us/step - loss: 0.0013 - accuracy: 0.9712 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 845us/step - loss: 0.0012 - accuracy: 0.9682 - val_loss: 0.0014 - val_accuracy: 0.9322\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0012 - accuracy: 0.9519 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0010 - accuracy: 0.9794 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0012 - accuracy: 0.9569 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 815us/step - loss: 0.0012 - accuracy: 0.9718 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 792us/step - loss: 0.0011 - accuracy: 0.9623 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.0011 - accuracy: 0.9620 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 798us/step - loss: 0.0011 - accuracy: 0.9763 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 822us/step - loss: 0.0012 - accuracy: 0.9670 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 862us/step - loss: 0.0011 - accuracy: 0.9726 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 830us/step - loss: 0.0011 - accuracy: 0.9707 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 793us/step - loss: 0.0011 - accuracy: 0.9686 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 876us/step - loss: 0.0011 - accuracy: 0.9823 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.0010 - accuracy: 0.9686 - val_loss: 9.4756e-04 - val_accuracy: 0.9492\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 792us/step - loss: 0.0011 - accuracy: 0.9824 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 744us/step - loss: 0.0011 - accuracy: 0.9595 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 885us/step - loss: 0.0010 - accuracy: 0.9825 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 807us/step - loss: 0.0010 - accuracy: 0.9738 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 813us/step - loss: 9.2692e-04 - accuracy: 0.9687 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 837us/step - loss: 0.0011 - accuracy: 0.9711 - val_loss: 0.0017 - val_accuracy: 0.9153\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.0012 - accuracy: 0.9556 - val_loss: 9.8552e-04 - val_accuracy: 0.9661\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 842us/step - loss: 0.0010 - accuracy: 0.9760 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0010 - accuracy: 0.9723 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0012 - accuracy: 0.9836 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0011 - accuracy: 0.9781 - val_loss: 9.6872e-04 - val_accuracy: 0.9492\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 849us/step - loss: 0.0011 - accuracy: 0.9700 - val_loss: 9.5427e-04 - val_accuracy: 0.9661\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 822us/step - loss: 0.0011 - accuracy: 0.9732 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 839us/step - loss: 0.0011 - accuracy: 0.9837 - val_loss: 9.4488e-04 - val_accuracy: 0.9661\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.0012 - accuracy: 0.9538 - val_loss: 9.4606e-04 - val_accuracy: 0.9661\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 810us/step - loss: 0.0011 - accuracy: 0.9743 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 792us/step - loss: 0.0011 - accuracy: 0.9713 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0012 - accuracy: 0.9738 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0011 - accuracy: 0.9787 - val_loss: 0.0010 - val_accuracy: 0.9661\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 776us/step - loss: 0.0011 - accuracy: 0.9752 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0012 - accuracy: 0.9686 - val_loss: 0.0013 - val_accuracy: 0.9322\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 868us/step - loss: 0.0011 - accuracy: 0.9704 - val_loss: 9.6163e-04 - val_accuracy: 0.9661\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 855us/step - loss: 9.8054e-04 - accuracy: 0.9690 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0011 - accuracy: 0.9756 - val_loss: 9.0295e-04 - val_accuracy: 0.9661\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 793us/step - loss: 0.0011 - accuracy: 0.9808 - val_loss: 9.3007e-04 - val_accuracy: 0.9661\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 856us/step - loss: 0.0010 - accuracy: 0.9784 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0010 - accuracy: 0.9844 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 860us/step - loss: 9.1733e-04 - accuracy: 0.9856 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 783us/step - loss: 0.0015 - accuracy: 0.9588 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 852us/step - loss: 0.0010 - accuracy: 0.9735 - val_loss: 9.1604e-04 - val_accuracy: 0.9661\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 996us/step - loss: 0.0011 - accuracy: 0.9684 - val_loss: 9.2771e-04 - val_accuracy: 0.9492\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9731 - val_loss: 9.0185e-04 - val_accuracy: 0.9492\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 804us/step - loss: 9.9109e-04 - accuracy: 0.9860 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0011 - accuracy: 0.9842 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 0.0011 - accuracy: 0.9702 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0010 - accuracy: 0.9806 - val_loss: 8.6035e-04 - val_accuracy: 0.9661\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 850us/step - loss: 9.6265e-04 - accuracy: 0.9767 - val_loss: 0.0013 - val_accuracy: 0.9322\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 804us/step - loss: 0.0011 - accuracy: 0.9741 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9492\n",
            "Loss = 0.0010347323259338737, rmse = 0.9491525292396545\n",
            "Loss array:  [0.0010347323259338737]\n",
            "####################### Iteration   1  #######################\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.4808 - val_loss: 0.0411 - val_accuracy: 0.8305\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0387 - accuracy: 0.8617 - val_loss: 0.0269 - val_accuracy: 0.8305\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 857us/step - loss: 0.0252 - accuracy: 0.8100 - val_loss: 0.0242 - val_accuracy: 0.8136\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 856us/step - loss: 0.0211 - accuracy: 0.8546 - val_loss: 0.0207 - val_accuracy: 0.8136\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 777us/step - loss: 0.0169 - accuracy: 0.8688 - val_loss: 0.0170 - val_accuracy: 0.8475\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 902us/step - loss: 0.0129 - accuracy: 0.9176 - val_loss: 0.0132 - val_accuracy: 0.8475\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.0099 - accuracy: 0.9132 - val_loss: 0.0111 - val_accuracy: 0.8644\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0085 - accuracy: 0.9300 - val_loss: 0.0102 - val_accuracy: 0.8983\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 848us/step - loss: 0.0069 - accuracy: 0.9507 - val_loss: 0.0079 - val_accuracy: 0.8644\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 835us/step - loss: 0.0065 - accuracy: 0.9249 - val_loss: 0.0096 - val_accuracy: 0.8644\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 842us/step - loss: 0.0059 - accuracy: 0.9346 - val_loss: 0.0070 - val_accuracy: 0.8644\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 866us/step - loss: 0.0055 - accuracy: 0.9313 - val_loss: 0.0067 - val_accuracy: 0.8475\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 916us/step - loss: 0.0050 - accuracy: 0.9467 - val_loss: 0.0065 - val_accuracy: 0.8644\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 784us/step - loss: 0.0047 - accuracy: 0.9477 - val_loss: 0.0070 - val_accuracy: 0.8983\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 865us/step - loss: 0.0051 - accuracy: 0.9541 - val_loss: 0.0060 - val_accuracy: 0.8983\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 788us/step - loss: 0.0047 - accuracy: 0.9465 - val_loss: 0.0059 - val_accuracy: 0.8983\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0039 - accuracy: 0.9550 - val_loss: 0.0054 - val_accuracy: 0.8814\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 768us/step - loss: 0.0040 - accuracy: 0.9605 - val_loss: 0.0054 - val_accuracy: 0.8814\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 752us/step - loss: 0.0039 - accuracy: 0.9394 - val_loss: 0.0057 - val_accuracy: 0.8644\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 853us/step - loss: 0.0040 - accuracy: 0.9471 - val_loss: 0.0052 - val_accuracy: 0.8814\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0040 - accuracy: 0.9370 - val_loss: 0.0050 - val_accuracy: 0.9153\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 852us/step - loss: 0.0042 - accuracy: 0.9309 - val_loss: 0.0051 - val_accuracy: 0.8983\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0035 - accuracy: 0.9560 - val_loss: 0.0050 - val_accuracy: 0.9153\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 861us/step - loss: 0.0036 - accuracy: 0.9410 - val_loss: 0.0052 - val_accuracy: 0.8983\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 790us/step - loss: 0.0031 - accuracy: 0.9438 - val_loss: 0.0046 - val_accuracy: 0.8814\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 814us/step - loss: 0.0035 - accuracy: 0.9625 - val_loss: 0.0045 - val_accuracy: 0.8983\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 815us/step - loss: 0.0034 - accuracy: 0.9324 - val_loss: 0.0045 - val_accuracy: 0.9153\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0034 - accuracy: 0.9599 - val_loss: 0.0043 - val_accuracy: 0.9153\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 832us/step - loss: 0.0034 - accuracy: 0.9505 - val_loss: 0.0044 - val_accuracy: 0.9153\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 799us/step - loss: 0.0031 - accuracy: 0.9477 - val_loss: 0.0043 - val_accuracy: 0.9153\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 809us/step - loss: 0.0031 - accuracy: 0.9293 - val_loss: 0.0042 - val_accuracy: 0.9153\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 802us/step - loss: 0.0029 - accuracy: 0.9631 - val_loss: 0.0058 - val_accuracy: 0.8475\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 798us/step - loss: 0.0031 - accuracy: 0.9189 - val_loss: 0.0037 - val_accuracy: 0.8814\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.0027 - accuracy: 0.9528 - val_loss: 0.0039 - val_accuracy: 0.8814\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 764us/step - loss: 0.0028 - accuracy: 0.9480 - val_loss: 0.0041 - val_accuracy: 0.8814\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 891us/step - loss: 0.0028 - accuracy: 0.9469 - val_loss: 0.0044 - val_accuracy: 0.8983\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0026 - accuracy: 0.9478 - val_loss: 0.0052 - val_accuracy: 0.8305\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 841us/step - loss: 0.0029 - accuracy: 0.9521 - val_loss: 0.0038 - val_accuracy: 0.9153\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0026 - accuracy: 0.9534 - val_loss: 0.0038 - val_accuracy: 0.8983\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0024 - accuracy: 0.9447 - val_loss: 0.0039 - val_accuracy: 0.8983\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 856us/step - loss: 0.0027 - accuracy: 0.9521 - val_loss: 0.0033 - val_accuracy: 0.9492\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0027 - accuracy: 0.9665 - val_loss: 0.0036 - val_accuracy: 0.8983\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 884us/step - loss: 0.0023 - accuracy: 0.9703 - val_loss: 0.0032 - val_accuracy: 0.9153\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0023 - accuracy: 0.9547 - val_loss: 0.0032 - val_accuracy: 0.9322\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 874us/step - loss: 0.0022 - accuracy: 0.9563 - val_loss: 0.0030 - val_accuracy: 0.9153\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 736us/step - loss: 0.0021 - accuracy: 0.9634 - val_loss: 0.0038 - val_accuracy: 0.8983\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0021 - accuracy: 0.9605 - val_loss: 0.0033 - val_accuracy: 0.8983\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 785us/step - loss: 0.0023 - accuracy: 0.9579 - val_loss: 0.0031 - val_accuracy: 0.9492\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 814us/step - loss: 0.0020 - accuracy: 0.9464 - val_loss: 0.0033 - val_accuracy: 0.8814\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 870us/step - loss: 0.0020 - accuracy: 0.9493 - val_loss: 0.0032 - val_accuracy: 0.8814\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 833us/step - loss: 0.0021 - accuracy: 0.9717 - val_loss: 0.0032 - val_accuracy: 0.9153\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 936us/step - loss: 0.0019 - accuracy: 0.9386 - val_loss: 0.0032 - val_accuracy: 0.9322\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 812us/step - loss: 0.0022 - accuracy: 0.9525 - val_loss: 0.0033 - val_accuracy: 0.9153\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 832us/step - loss: 0.0019 - accuracy: 0.9798 - val_loss: 0.0030 - val_accuracy: 0.9492\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 812us/step - loss: 0.0020 - accuracy: 0.9700 - val_loss: 0.0026 - val_accuracy: 0.9492\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 785us/step - loss: 0.0018 - accuracy: 0.9664 - val_loss: 0.0030 - val_accuracy: 0.8983\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9691 - val_loss: 0.0027 - val_accuracy: 0.9153\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 975us/step - loss: 0.0019 - accuracy: 0.9629 - val_loss: 0.0027 - val_accuracy: 0.9153\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0017 - accuracy: 0.9535 - val_loss: 0.0027 - val_accuracy: 0.8983\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 899us/step - loss: 0.0018 - accuracy: 0.9560 - val_loss: 0.0027 - val_accuracy: 0.9322\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9688 - val_loss: 0.0027 - val_accuracy: 0.9322\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0018 - accuracy: 0.9686 - val_loss: 0.0027 - val_accuracy: 0.9661\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 967us/step - loss: 0.0015 - accuracy: 0.9587 - val_loss: 0.0024 - val_accuracy: 0.9153\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 0.0018 - accuracy: 0.9680 - val_loss: 0.0023 - val_accuracy: 0.9492\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 953us/step - loss: 0.0016 - accuracy: 0.9651 - val_loss: 0.0024 - val_accuracy: 0.9661\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0016 - accuracy: 0.9512 - val_loss: 0.0025 - val_accuracy: 0.9661\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9482 - val_loss: 0.0024 - val_accuracy: 0.9322\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9645 - val_loss: 0.0026 - val_accuracy: 0.9661\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 932us/step - loss: 0.0015 - accuracy: 0.9681 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0013 - accuracy: 0.9756 - val_loss: 0.0027 - val_accuracy: 0.9153\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9695 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 977us/step - loss: 0.0014 - accuracy: 0.9661 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 911us/step - loss: 0.0014 - accuracy: 0.9827 - val_loss: 0.0023 - val_accuracy: 0.9661\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 902us/step - loss: 0.0015 - accuracy: 0.9631 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 892us/step - loss: 0.0014 - accuracy: 0.9686 - val_loss: 0.0023 - val_accuracy: 0.9322\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 989us/step - loss: 0.0014 - accuracy: 0.9641 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0014 - accuracy: 0.9594 - val_loss: 0.0020 - val_accuracy: 0.9831\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9609 - val_loss: 0.0026 - val_accuracy: 0.9153\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9794 - val_loss: 0.0021 - val_accuracy: 0.9492\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 963us/step - loss: 0.0014 - accuracy: 0.9620 - val_loss: 0.0019 - val_accuracy: 0.9831\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 966us/step - loss: 0.0013 - accuracy: 0.9712 - val_loss: 0.0025 - val_accuracy: 0.9322\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 947us/step - loss: 0.0014 - accuracy: 0.9776 - val_loss: 0.0019 - val_accuracy: 0.9322\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0013 - accuracy: 0.9823 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9827 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 882us/step - loss: 0.0013 - accuracy: 0.9763 - val_loss: 0.0028 - val_accuracy: 0.8983\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0015 - accuracy: 0.9752 - val_loss: 0.0025 - val_accuracy: 0.9492\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 841us/step - loss: 0.0014 - accuracy: 0.9715 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 992us/step - loss: 0.0014 - accuracy: 0.9600 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0013 - accuracy: 0.9612 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0012 - accuracy: 0.9726 - val_loss: 0.0019 - val_accuracy: 0.9492\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0012 - accuracy: 0.9739 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 0.0013 - accuracy: 0.9746 - val_loss: 0.0022 - val_accuracy: 0.9322\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 927us/step - loss: 0.0013 - accuracy: 0.9741 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 876us/step - loss: 0.0012 - accuracy: 0.9741 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 909us/step - loss: 0.0013 - accuracy: 0.9531 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0012 - accuracy: 0.9749 - val_loss: 0.0020 - val_accuracy: 0.9831\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 873us/step - loss: 0.0013 - accuracy: 0.9888 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 918us/step - loss: 0.0011 - accuracy: 0.9732 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0013 - accuracy: 0.9752 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0012 - accuracy: 0.9672 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9725 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9700 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9740 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9880 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 868us/step - loss: 0.0011 - accuracy: 0.9843 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9842 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9728 - val_loss: 0.0018 - val_accuracy: 0.9322\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9828 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.0013 - accuracy: 0.9770 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9763 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 950us/step - loss: 0.0010 - accuracy: 0.9630 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0011 - accuracy: 0.9747 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 0.0010 - accuracy: 0.9792 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 925us/step - loss: 0.0011 - accuracy: 0.9795 - val_loss: 0.0018 - val_accuracy: 0.9322\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9767 - val_loss: 0.0020 - val_accuracy: 0.9322\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0010 - accuracy: 0.9809 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 960us/step - loss: 0.0012 - accuracy: 0.9768 - val_loss: 0.0019 - val_accuracy: 0.9831\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 905us/step - loss: 0.0012 - accuracy: 0.9711 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 869us/step - loss: 0.0011 - accuracy: 0.9862 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 978us/step - loss: 0.0011 - accuracy: 0.9789 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9782 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 842us/step - loss: 0.0013 - accuracy: 0.9728 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0011 - accuracy: 0.9864 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 928us/step - loss: 0.0011 - accuracy: 0.9657 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9749 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 935us/step - loss: 0.0010 - accuracy: 0.9885 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 0.0012 - accuracy: 0.9848 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9740 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 963us/step - loss: 0.0011 - accuracy: 0.9666 - val_loss: 0.0025 - val_accuracy: 0.9322\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 921us/step - loss: 0.0012 - accuracy: 0.9753 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 990us/step - loss: 0.0012 - accuracy: 0.9796 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 945us/step - loss: 9.6192e-04 - accuracy: 0.9741 - val_loss: 0.0021 - val_accuracy: 0.9492\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9832 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 868us/step - loss: 0.0012 - accuracy: 0.9741 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9716 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 990us/step - loss: 9.5939e-04 - accuracy: 0.9795 - val_loss: 0.0028 - val_accuracy: 0.9153\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9632 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 9.9068e-04 - accuracy: 0.9812 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9643 - val_loss: 0.0016 - val_accuracy: 0.9153\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0014 - accuracy: 0.9615 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9737 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0011 - accuracy: 0.9798 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9856 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 9.5666e-04 - accuracy: 0.9820 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0666e-04 - accuracy: 0.9851 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 977us/step - loss: 9.8231e-04 - accuracy: 0.9899 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 956us/step - loss: 9.7631e-04 - accuracy: 0.9806 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0010 - accuracy: 0.9788 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 984us/step - loss: 0.0011 - accuracy: 0.9637 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1129e-04 - accuracy: 0.9954 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.8153e-04 - accuracy: 0.9819 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6755e-04 - accuracy: 0.9784 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 795us/step - loss: 9.4383e-04 - accuracy: 0.9934 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 904us/step - loss: 0.0010 - accuracy: 0.9579 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 882us/step - loss: 9.5102e-04 - accuracy: 0.9923 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 9.4153e-04 - accuracy: 0.9899 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0012 - accuracy: 0.9829 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0011 - accuracy: 0.9629 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.9584e-04 - accuracy: 0.9722 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 860us/step - loss: 9.6098e-04 - accuracy: 0.9834 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 9.6490e-04 - accuracy: 0.9855 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 9.2660e-04 - accuracy: 0.9684 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 915us/step - loss: 0.0010 - accuracy: 0.9763 - val_loss: 0.0014 - val_accuracy: 0.9322\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 873us/step - loss: 0.0012 - accuracy: 0.9658 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 927us/step - loss: 0.0011 - accuracy: 0.9794 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 962us/step - loss: 9.9340e-04 - accuracy: 0.9863 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 910us/step - loss: 8.7969e-04 - accuracy: 0.9818 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 890us/step - loss: 0.0010 - accuracy: 0.9774 - val_loss: 0.0014 - val_accuracy: 0.9322\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0010 - accuracy: 0.9839 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 9.2888e-04 - accuracy: 0.9833 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 981us/step - loss: 8.6678e-04 - accuracy: 0.9885 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 877us/step - loss: 9.5674e-04 - accuracy: 0.9753 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 8.4111e-04 - accuracy: 0.9729 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 852us/step - loss: 9.7929e-04 - accuracy: 0.9784 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5703e-04 - accuracy: 0.9861 - val_loss: 0.0020 - val_accuracy: 0.9492\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 926us/step - loss: 0.0012 - accuracy: 0.9659 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 916us/step - loss: 9.6154e-04 - accuracy: 0.9630 - val_loss: 0.0025 - val_accuracy: 0.9322\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 816us/step - loss: 0.0011 - accuracy: 0.9762 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9755 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 8.4410e-04 - accuracy: 0.9924 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 908us/step - loss: 0.0011 - accuracy: 0.9802 - val_loss: 0.0023 - val_accuracy: 0.9492\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 796us/step - loss: 0.0011 - accuracy: 0.9731 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 959us/step - loss: 8.6407e-04 - accuracy: 0.9880 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 810us/step - loss: 8.6178e-04 - accuracy: 0.9738 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9771 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 637us/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Loss = 0.0011190316872671247, rmse = 1.0\n",
            "Loss array:  [0.0010347323259338737, 0.0011190316872671247]\n",
            "####################### Iteration   2  #######################\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.6762 - val_loss: 0.0378 - val_accuracy: 0.8621\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.8932 - val_loss: 0.0215 - val_accuracy: 0.8793\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0230 - accuracy: 0.8677 - val_loss: 0.0173 - val_accuracy: 0.8793\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 0.8706 - val_loss: 0.0141 - val_accuracy: 0.9310\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 966us/step - loss: 0.0157 - accuracy: 0.8824 - val_loss: 0.0124 - val_accuracy: 0.8966\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 882us/step - loss: 0.0130 - accuracy: 0.9036 - val_loss: 0.0080 - val_accuracy: 0.9655\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 874us/step - loss: 0.0101 - accuracy: 0.9230 - val_loss: 0.0063 - val_accuracy: 0.9828\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 903us/step - loss: 0.0090 - accuracy: 0.9237 - val_loss: 0.0050 - val_accuracy: 0.9655\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.0075 - accuracy: 0.9260 - val_loss: 0.0070 - val_accuracy: 0.9483\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 999us/step - loss: 0.0086 - accuracy: 0.8933 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 790us/step - loss: 0.0061 - accuracy: 0.9183 - val_loss: 0.0038 - val_accuracy: 0.9655\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 0.0066 - accuracy: 0.9135 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 824us/step - loss: 0.0058 - accuracy: 0.8925 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 884us/step - loss: 0.0055 - accuracy: 0.8981 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 748us/step - loss: 0.0051 - accuracy: 0.9248 - val_loss: 0.0035 - val_accuracy: 0.8793\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 778us/step - loss: 0.0048 - accuracy: 0.9250 - val_loss: 0.0031 - val_accuracy: 0.8621\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 787us/step - loss: 0.0047 - accuracy: 0.8920 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0045 - accuracy: 0.9120 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 858us/step - loss: 0.0048 - accuracy: 0.9209 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 754us/step - loss: 0.0049 - accuracy: 0.9039 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.9008 - val_loss: 0.0025 - val_accuracy: 0.8966\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0044 - accuracy: 0.9147 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 887us/step - loss: 0.0046 - accuracy: 0.9146 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 733us/step - loss: 0.0041 - accuracy: 0.9312 - val_loss: 0.0033 - val_accuracy: 0.8966\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 764us/step - loss: 0.0047 - accuracy: 0.9047 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0039 - accuracy: 0.9181 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 822us/step - loss: 0.0042 - accuracy: 0.9151 - val_loss: 0.0025 - val_accuracy: 0.8793\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 858us/step - loss: 0.0044 - accuracy: 0.9085 - val_loss: 0.0032 - val_accuracy: 0.8793\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 763us/step - loss: 0.0039 - accuracy: 0.9378 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0040 - accuracy: 0.9309 - val_loss: 0.0025 - val_accuracy: 0.8793\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 825us/step - loss: 0.0042 - accuracy: 0.8934 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.9201 - val_loss: 0.0028 - val_accuracy: 0.8793\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 812us/step - loss: 0.0041 - accuracy: 0.9171 - val_loss: 0.0023 - val_accuracy: 0.8966\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 860us/step - loss: 0.0039 - accuracy: 0.9148 - val_loss: 0.0023 - val_accuracy: 0.8966\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 793us/step - loss: 0.0043 - accuracy: 0.9152 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0039 - accuracy: 0.9232 - val_loss: 0.0025 - val_accuracy: 0.8793\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 849us/step - loss: 0.0040 - accuracy: 0.9335 - val_loss: 0.0022 - val_accuracy: 0.8966\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 912us/step - loss: 0.0041 - accuracy: 0.9010 - val_loss: 0.0029 - val_accuracy: 0.8966\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 909us/step - loss: 0.0039 - accuracy: 0.9048 - val_loss: 0.0022 - val_accuracy: 0.8966\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 0.9359 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 943us/step - loss: 0.0035 - accuracy: 0.9456 - val_loss: 0.0023 - val_accuracy: 0.8793\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 980us/step - loss: 0.0039 - accuracy: 0.9152 - val_loss: 0.0022 - val_accuracy: 0.8966\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 789us/step - loss: 0.0039 - accuracy: 0.9080 - val_loss: 0.0024 - val_accuracy: 0.8793\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0038 - accuracy: 0.9351 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 924us/step - loss: 0.0034 - accuracy: 0.9271 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 807us/step - loss: 0.0042 - accuracy: 0.9338 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 0.0035 - accuracy: 0.9271 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0035 - accuracy: 0.9329 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 921us/step - loss: 0.0037 - accuracy: 0.9113 - val_loss: 0.0020 - val_accuracy: 0.9138\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0032 - accuracy: 0.9319 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 930us/step - loss: 0.0033 - accuracy: 0.9391 - val_loss: 0.0024 - val_accuracy: 0.8966\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 969us/step - loss: 0.0031 - accuracy: 0.9245 - val_loss: 0.0023 - val_accuracy: 0.8966\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9295 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 847us/step - loss: 0.0033 - accuracy: 0.9198 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9214 - val_loss: 0.0034 - val_accuracy: 0.8966\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 905us/step - loss: 0.0035 - accuracy: 0.9255 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 938us/step - loss: 0.0033 - accuracy: 0.9282 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0034 - accuracy: 0.9143 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9361 - val_loss: 0.0028 - val_accuracy: 0.8966\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0030 - accuracy: 0.9482 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9232 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 932us/step - loss: 0.0029 - accuracy: 0.9424 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 932us/step - loss: 0.0029 - accuracy: 0.9359 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 915us/step - loss: 0.0028 - accuracy: 0.9253 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 905us/step - loss: 0.0032 - accuracy: 0.9310 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 855us/step - loss: 0.0029 - accuracy: 0.9498 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 954us/step - loss: 0.0032 - accuracy: 0.9381 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 850us/step - loss: 0.0026 - accuracy: 0.9278 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 948us/step - loss: 0.0027 - accuracy: 0.9504 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 857us/step - loss: 0.0028 - accuracy: 0.9358 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.9440 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 950us/step - loss: 0.0025 - accuracy: 0.9464 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 908us/step - loss: 0.0025 - accuracy: 0.9401 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9469 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 902us/step - loss: 0.0024 - accuracy: 0.9554 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9164 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 902us/step - loss: 0.0026 - accuracy: 0.9567 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 917us/step - loss: 0.0025 - accuracy: 0.9576 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 887us/step - loss: 0.0022 - accuracy: 0.9611 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 973us/step - loss: 0.0024 - accuracy: 0.9537 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 838us/step - loss: 0.0025 - accuracy: 0.9631 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9618 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 870us/step - loss: 0.0021 - accuracy: 0.9693 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 881us/step - loss: 0.0022 - accuracy: 0.9423 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 857us/step - loss: 0.0021 - accuracy: 0.9717 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0021 - accuracy: 0.9609 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 916us/step - loss: 0.0021 - accuracy: 0.9610 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 872us/step - loss: 0.0022 - accuracy: 0.9688 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 935us/step - loss: 0.0019 - accuracy: 0.9767 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 790us/step - loss: 0.0020 - accuracy: 0.9732 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0019 - accuracy: 0.9623 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0020 - accuracy: 0.9620 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 959us/step - loss: 0.0018 - accuracy: 0.9693 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 886us/step - loss: 0.0018 - accuracy: 0.9573 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 975us/step - loss: 0.0018 - accuracy: 0.9727 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0018 - accuracy: 0.9539 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 944us/step - loss: 0.0017 - accuracy: 0.9651 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 812us/step - loss: 0.0020 - accuracy: 0.9617 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 960us/step - loss: 0.0022 - accuracy: 0.9672 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 0.0020 - accuracy: 0.9600 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 955us/step - loss: 0.0017 - accuracy: 0.9758 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 891us/step - loss: 0.0017 - accuracy: 0.9707 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9791 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 968us/step - loss: 0.0018 - accuracy: 0.9586 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 927us/step - loss: 0.0017 - accuracy: 0.9694 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 833us/step - loss: 0.0017 - accuracy: 0.9597 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 950us/step - loss: 0.0017 - accuracy: 0.9591 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 783us/step - loss: 0.0017 - accuracy: 0.9604 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 931us/step - loss: 0.0017 - accuracy: 0.9688 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 850us/step - loss: 0.0016 - accuracy: 0.9819 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 993us/step - loss: 0.0016 - accuracy: 0.9731 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 833us/step - loss: 0.0016 - accuracy: 0.9877 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9758 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 890us/step - loss: 0.0015 - accuracy: 0.9750 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0016 - accuracy: 0.9748 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 841us/step - loss: 0.0016 - accuracy: 0.9755 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9699 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 761us/step - loss: 0.0014 - accuracy: 0.9700 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 827us/step - loss: 0.0016 - accuracy: 0.9842 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 976us/step - loss: 0.0014 - accuracy: 0.9766 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 947us/step - loss: 0.0015 - accuracy: 0.9694 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 912us/step - loss: 0.0015 - accuracy: 0.9851 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9706 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 901us/step - loss: 0.0015 - accuracy: 0.9598 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9778 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 874us/step - loss: 0.0012 - accuracy: 0.9727 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9843 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 866us/step - loss: 0.0013 - accuracy: 0.9877 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9663 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9797 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9727 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 891us/step - loss: 0.0013 - accuracy: 0.9725 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 852us/step - loss: 0.0016 - accuracy: 0.9713 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0014 - accuracy: 0.9856 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 950us/step - loss: 0.0014 - accuracy: 0.9699 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9613 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 818us/step - loss: 0.0013 - accuracy: 0.9720 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 884us/step - loss: 0.0013 - accuracy: 0.9764 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0013 - accuracy: 0.9736 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0013 - accuracy: 0.9640 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9865 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0014 - accuracy: 0.9834 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 917us/step - loss: 0.0013 - accuracy: 0.9662 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 909us/step - loss: 0.0012 - accuracy: 0.9695 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 976us/step - loss: 0.0012 - accuracy: 0.9883 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 959us/step - loss: 0.0015 - accuracy: 0.9677 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 0.0012 - accuracy: 0.9852 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0012 - accuracy: 0.9746 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 950us/step - loss: 0.0011 - accuracy: 0.9853 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 882us/step - loss: 0.0012 - accuracy: 0.9867 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 928us/step - loss: 0.0011 - accuracy: 0.9801 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0012 - accuracy: 0.9892 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 938us/step - loss: 0.0013 - accuracy: 0.9767 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 869us/step - loss: 0.0012 - accuracy: 0.9793 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9918 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9895 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9749 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 990us/step - loss: 0.0012 - accuracy: 0.9627 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 826us/step - loss: 0.0012 - accuracy: 0.9689 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0011 - accuracy: 0.9846 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0012 - accuracy: 0.9634 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9794 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 830us/step - loss: 0.0011 - accuracy: 0.9793 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 913us/step - loss: 0.0011 - accuracy: 0.9858 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 908us/step - loss: 0.0012 - accuracy: 0.9558 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 0.0011 - accuracy: 0.9759 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 978us/step - loss: 0.0011 - accuracy: 0.9824 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0011 - accuracy: 0.9569 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 873us/step - loss: 0.0011 - accuracy: 0.9776 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 905us/step - loss: 0.0011 - accuracy: 0.9900 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 9.3659e-04 - accuracy: 0.9785 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.7226e-04 - accuracy: 0.9904 - val_loss: 9.9605e-04 - val_accuracy: 0.9828\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 945us/step - loss: 0.0011 - accuracy: 0.9666 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 935us/step - loss: 0.0011 - accuracy: 0.9895 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 894us/step - loss: 0.0010 - accuracy: 0.9832 - val_loss: 9.6707e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 9.6926e-04 - accuracy: 0.9878 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 978us/step - loss: 0.0011 - accuracy: 0.9657 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 946us/step - loss: 9.0044e-04 - accuracy: 0.9871 - val_loss: 9.5218e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 887us/step - loss: 8.4004e-04 - accuracy: 0.9891 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 912us/step - loss: 9.5086e-04 - accuracy: 0.9782 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0536e-04 - accuracy: 0.9802 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9727 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 915us/step - loss: 9.7809e-04 - accuracy: 0.9805 - val_loss: 9.2885e-04 - val_accuracy: 1.0000\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 886us/step - loss: 9.0571e-04 - accuracy: 0.9886 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 901us/step - loss: 9.2179e-04 - accuracy: 0.9924 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9828\n",
            "Loss = 0.0010019029723480344, rmse = 0.982758641242981\n",
            "Loss array:  [0.0010347323259338737, 0.0011190316872671247, 0.0010019029723480344]\n",
            "####################### Iteration   3  #######################\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.5752 - val_loss: 0.0434 - val_accuracy: 0.7586\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 920us/step - loss: 0.0506 - accuracy: 0.8417 - val_loss: 0.0254 - val_accuracy: 0.7759\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 887us/step - loss: 0.0271 - accuracy: 0.8497 - val_loss: 0.0172 - val_accuracy: 0.7586\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 984us/step - loss: 0.0214 - accuracy: 0.8614 - val_loss: 0.0136 - val_accuracy: 0.8276\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 852us/step - loss: 0.0155 - accuracy: 0.8726 - val_loss: 0.0121 - val_accuracy: 0.8103\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 938us/step - loss: 0.0126 - accuracy: 0.8954 - val_loss: 0.0093 - val_accuracy: 0.8966\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 0.9214 - val_loss: 0.0080 - val_accuracy: 0.8966\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 913us/step - loss: 0.0086 - accuracy: 0.9407 - val_loss: 0.0070 - val_accuracy: 0.9138\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 847us/step - loss: 0.0077 - accuracy: 0.9398 - val_loss: 0.0081 - val_accuracy: 0.8621\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 922us/step - loss: 0.0086 - accuracy: 0.9000 - val_loss: 0.0061 - val_accuracy: 0.9138\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 807us/step - loss: 0.0064 - accuracy: 0.9228 - val_loss: 0.0064 - val_accuracy: 0.9138\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.9160 - val_loss: 0.0055 - val_accuracy: 0.9138\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 0.9112 - val_loss: 0.0051 - val_accuracy: 0.9138\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 930us/step - loss: 0.0057 - accuracy: 0.9063 - val_loss: 0.0050 - val_accuracy: 0.9138\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 850us/step - loss: 0.0054 - accuracy: 0.9394 - val_loss: 0.0048 - val_accuracy: 0.9138\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 974us/step - loss: 0.0052 - accuracy: 0.9406 - val_loss: 0.0049 - val_accuracy: 0.9138\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 976us/step - loss: 0.0052 - accuracy: 0.9207 - val_loss: 0.0050 - val_accuracy: 0.9138\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 0.0049 - accuracy: 0.9223 - val_loss: 0.0049 - val_accuracy: 0.9138\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 876us/step - loss: 0.0052 - accuracy: 0.9443 - val_loss: 0.0044 - val_accuracy: 0.9138\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 922us/step - loss: 0.0053 - accuracy: 0.9310 - val_loss: 0.0042 - val_accuracy: 0.9138\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 0.0047 - accuracy: 0.9242 - val_loss: 0.0041 - val_accuracy: 0.9138\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.9396 - val_loss: 0.0041 - val_accuracy: 0.9138\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 0.9180 - val_loss: 0.0041 - val_accuracy: 0.9138\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 815us/step - loss: 0.0045 - accuracy: 0.9241 - val_loss: 0.0043 - val_accuracy: 0.9310\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 948us/step - loss: 0.0051 - accuracy: 0.9097 - val_loss: 0.0041 - val_accuracy: 0.9138\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 849us/step - loss: 0.0041 - accuracy: 0.9268 - val_loss: 0.0039 - val_accuracy: 0.9138\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.9370 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 848us/step - loss: 0.0045 - accuracy: 0.9269 - val_loss: 0.0041 - val_accuracy: 0.9310\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 886us/step - loss: 0.0041 - accuracy: 0.9551 - val_loss: 0.0038 - val_accuracy: 0.9138\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 886us/step - loss: 0.0041 - accuracy: 0.9353 - val_loss: 0.0036 - val_accuracy: 0.9138\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 911us/step - loss: 0.0041 - accuracy: 0.9074 - val_loss: 0.0037 - val_accuracy: 0.9138\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 870us/step - loss: 0.0040 - accuracy: 0.9297 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 969us/step - loss: 0.0040 - accuracy: 0.9243 - val_loss: 0.0034 - val_accuracy: 0.9138\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 891us/step - loss: 0.0039 - accuracy: 0.9331 - val_loss: 0.0036 - val_accuracy: 0.9138\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 997us/step - loss: 0.0040 - accuracy: 0.9268 - val_loss: 0.0035 - val_accuracy: 0.9138\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 924us/step - loss: 0.0038 - accuracy: 0.9327 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 931us/step - loss: 0.0037 - accuracy: 0.9353 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 871us/step - loss: 0.0041 - accuracy: 0.9194 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 959us/step - loss: 0.0036 - accuracy: 0.9233 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 0.0034 - accuracy: 0.9477 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0033 - accuracy: 0.9406 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0036 - accuracy: 0.9291 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 996us/step - loss: 0.0035 - accuracy: 0.9138 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 876us/step - loss: 0.0036 - accuracy: 0.9433 - val_loss: 0.0034 - val_accuracy: 0.9138\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 909us/step - loss: 0.0032 - accuracy: 0.9369 - val_loss: 0.0040 - val_accuracy: 0.8966\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9318 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 909us/step - loss: 0.0031 - accuracy: 0.9385 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 901us/step - loss: 0.0031 - accuracy: 0.9464 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 0.0032 - accuracy: 0.9373 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 0.0028 - accuracy: 0.9305 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 825us/step - loss: 0.0029 - accuracy: 0.9515 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 946us/step - loss: 0.0028 - accuracy: 0.9584 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 899us/step - loss: 0.0027 - accuracy: 0.9432 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 939us/step - loss: 0.0028 - accuracy: 0.9489 - val_loss: 0.0026 - val_accuracy: 0.9310\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.9471 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0030 - accuracy: 0.9332 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.9613 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 841us/step - loss: 0.0027 - accuracy: 0.9364 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 951us/step - loss: 0.0025 - accuracy: 0.9503 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 858us/step - loss: 0.0023 - accuracy: 0.9698 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 921us/step - loss: 0.0025 - accuracy: 0.9500 - val_loss: 0.0030 - val_accuracy: 0.8966\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 856us/step - loss: 0.0023 - accuracy: 0.9548 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9559 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 946us/step - loss: 0.0023 - accuracy: 0.9403 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 905us/step - loss: 0.0024 - accuracy: 0.9535 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 963us/step - loss: 0.0023 - accuracy: 0.9640 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.9524 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 804us/step - loss: 0.0022 - accuracy: 0.9560 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0022 - accuracy: 0.9569 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 990us/step - loss: 0.0022 - accuracy: 0.9527 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 924us/step - loss: 0.0023 - accuracy: 0.9724 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 844us/step - loss: 0.0019 - accuracy: 0.9671 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 986us/step - loss: 0.0019 - accuracy: 0.9547 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0019 - accuracy: 0.9668 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0018 - accuracy: 0.9688 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 982us/step - loss: 0.0020 - accuracy: 0.9582 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9653 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 938us/step - loss: 0.0018 - accuracy: 0.9783 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9783 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0017 - accuracy: 0.9716 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 969us/step - loss: 0.0018 - accuracy: 0.9880 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 920us/step - loss: 0.0018 - accuracy: 0.9734 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 978us/step - loss: 0.0016 - accuracy: 0.9700 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 924us/step - loss: 0.0018 - accuracy: 0.9746 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9881 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 830us/step - loss: 0.0016 - accuracy: 0.9820 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9766 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 894us/step - loss: 0.0018 - accuracy: 0.9781 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9784 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 865us/step - loss: 0.0016 - accuracy: 0.9849 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9915 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9799 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 985us/step - loss: 0.0015 - accuracy: 0.9884 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9871 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9796 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 998us/step - loss: 0.0014 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 975us/step - loss: 0.0016 - accuracy: 0.9717 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9630 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9659 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 929us/step - loss: 0.0015 - accuracy: 0.9742 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 882us/step - loss: 0.0014 - accuracy: 0.9753 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 921us/step - loss: 0.0015 - accuracy: 0.9842 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 840us/step - loss: 0.0014 - accuracy: 0.9870 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 995us/step - loss: 0.0014 - accuracy: 0.9736 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 850us/step - loss: 0.0014 - accuracy: 0.9887 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0015 - accuracy: 0.9768 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 779us/step - loss: 0.0014 - accuracy: 0.9757 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 0.0015 - accuracy: 0.9761 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0013 - accuracy: 0.9844 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 845us/step - loss: 0.0014 - accuracy: 0.9693 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0013 - accuracy: 0.9828 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 968us/step - loss: 0.0014 - accuracy: 0.9845 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 874us/step - loss: 0.0014 - accuracy: 0.9746 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 887us/step - loss: 0.0014 - accuracy: 0.9886 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 0.0014 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0013 - accuracy: 0.9868 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0012 - accuracy: 0.9883 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 855us/step - loss: 0.0013 - accuracy: 0.9772 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 956us/step - loss: 0.0016 - accuracy: 0.9779 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 905us/step - loss: 0.0012 - accuracy: 0.9826 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9795 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9862 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 950us/step - loss: 0.0012 - accuracy: 0.9771 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 974us/step - loss: 0.0014 - accuracy: 0.9736 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 931us/step - loss: 0.0012 - accuracy: 0.9845 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9715 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 927us/step - loss: 0.0012 - accuracy: 0.9903 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9820 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 874us/step - loss: 0.0013 - accuracy: 0.9685 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 959us/step - loss: 0.0013 - accuracy: 0.9694 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0012 - accuracy: 0.9881 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 982us/step - loss: 0.0011 - accuracy: 0.9751 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 934us/step - loss: 0.0012 - accuracy: 0.9839 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9803 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0012 - accuracy: 0.9799 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9855 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 943us/step - loss: 0.0012 - accuracy: 0.9874 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 967us/step - loss: 0.0012 - accuracy: 0.9867 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 840us/step - loss: 0.0012 - accuracy: 0.9789 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 926us/step - loss: 0.0012 - accuracy: 0.9875 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9864 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 980us/step - loss: 0.0011 - accuracy: 0.9913 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9763 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 961us/step - loss: 0.0010 - accuracy: 0.9931 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 872us/step - loss: 0.0012 - accuracy: 0.9813 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 780us/step - loss: 0.0015 - accuracy: 0.9601 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 820us/step - loss: 0.0014 - accuracy: 0.9738 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 919us/step - loss: 0.0011 - accuracy: 0.9870 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0011 - accuracy: 0.9796 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 807us/step - loss: 0.0011 - accuracy: 0.9864 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 855us/step - loss: 0.0010 - accuracy: 0.9677 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0011 - accuracy: 0.9778 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 800us/step - loss: 0.0011 - accuracy: 0.9915 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 0.0013 - accuracy: 0.9707 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 882us/step - loss: 0.0011 - accuracy: 0.9818 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 943us/step - loss: 0.0010 - accuracy: 0.9880 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 0.0011 - accuracy: 0.9828 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 945us/step - loss: 0.0011 - accuracy: 0.9822 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 920us/step - loss: 0.0011 - accuracy: 0.9887 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 875us/step - loss: 0.0010 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 839us/step - loss: 0.0011 - accuracy: 0.9686 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 972us/step - loss: 9.8462e-04 - accuracy: 0.9768 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 892us/step - loss: 9.8715e-04 - accuracy: 0.9771 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.6665e-04 - accuracy: 0.9694 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 998us/step - loss: 0.0012 - accuracy: 0.9758 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 870us/step - loss: 0.0012 - accuracy: 0.9868 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9787 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9769 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 868us/step - loss: 0.0012 - accuracy: 0.9773 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 0.0011 - accuracy: 0.9891 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 951us/step - loss: 9.0615e-04 - accuracy: 0.9898 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 990us/step - loss: 9.3272e-04 - accuracy: 0.9900 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 946us/step - loss: 0.0010 - accuracy: 0.9834 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0011 - accuracy: 0.9858 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 825us/step - loss: 0.0011 - accuracy: 0.9900 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 0.0011 - accuracy: 0.9886 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 950us/step - loss: 0.0012 - accuracy: 0.9876 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.7013e-04 - accuracy: 0.9833 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 882us/step - loss: 9.1220e-04 - accuracy: 0.9836 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 934us/step - loss: 8.9996e-04 - accuracy: 0.9764 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 863us/step - loss: 8.2200e-04 - accuracy: 0.9766 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0942e-04 - accuracy: 0.9809 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 919us/step - loss: 9.7327e-04 - accuracy: 0.9883 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.8404e-04 - accuracy: 0.9943 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9899 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "2/2 [==============================] - 0s 754us/step - loss: 0.0011 - accuracy: 0.9828\n",
            "Loss = 0.0011460670502856374, rmse = 0.982758641242981\n",
            "Loss array:  [0.0010347323259338737, 0.0011190316872671247, 0.0010019029723480344, 0.0011460670502856374]\n",
            "####################### Iteration   4  #######################\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.5614 - val_loss: 0.0555 - val_accuracy: 0.7069\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0454 - accuracy: 0.7304 - val_loss: 0.0336 - val_accuracy: 0.8966\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 853us/step - loss: 0.0281 - accuracy: 0.8430 - val_loss: 0.0230 - val_accuracy: 0.8621\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0234 - accuracy: 0.8308 - val_loss: 0.0184 - val_accuracy: 0.9138\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 947us/step - loss: 0.0176 - accuracy: 0.8297 - val_loss: 0.0151 - val_accuracy: 0.9483\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 877us/step - loss: 0.0140 - accuracy: 0.8769 - val_loss: 0.0122 - val_accuracy: 0.9310\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0115 - accuracy: 0.8751 - val_loss: 0.0100 - val_accuracy: 0.9655\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0098 - accuracy: 0.9331 - val_loss: 0.0085 - val_accuracy: 0.9483\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0086 - accuracy: 0.9355 - val_loss: 0.0078 - val_accuracy: 0.9483\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0090 - accuracy: 0.8983 - val_loss: 0.0063 - val_accuracy: 0.9483\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 818us/step - loss: 0.0072 - accuracy: 0.9276 - val_loss: 0.0060 - val_accuracy: 0.9310\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 984us/step - loss: 0.0075 - accuracy: 0.9135 - val_loss: 0.0052 - val_accuracy: 0.9483\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 886us/step - loss: 0.0064 - accuracy: 0.9174 - val_loss: 0.0051 - val_accuracy: 0.9483\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 894us/step - loss: 0.0059 - accuracy: 0.8958 - val_loss: 0.0054 - val_accuracy: 0.9310\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 910us/step - loss: 0.0057 - accuracy: 0.9288 - val_loss: 0.0046 - val_accuracy: 0.9310\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 966us/step - loss: 0.0051 - accuracy: 0.9367 - val_loss: 0.0047 - val_accuracy: 0.9310\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 881us/step - loss: 0.0051 - accuracy: 0.9100 - val_loss: 0.0043 - val_accuracy: 0.9310\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 935us/step - loss: 0.0049 - accuracy: 0.9183 - val_loss: 0.0044 - val_accuracy: 0.9483\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 0.9449 - val_loss: 0.0041 - val_accuracy: 0.9310\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0049 - accuracy: 0.9009 - val_loss: 0.0039 - val_accuracy: 0.9310\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 959us/step - loss: 0.0047 - accuracy: 0.9235 - val_loss: 0.0040 - val_accuracy: 0.9310\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 0.9120 - val_loss: 0.0038 - val_accuracy: 0.9483\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 975us/step - loss: 0.0045 - accuracy: 0.9119 - val_loss: 0.0038 - val_accuracy: 0.9483\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 886us/step - loss: 0.0044 - accuracy: 0.9321 - val_loss: 0.0046 - val_accuracy: 0.8621\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0051 - accuracy: 0.9089 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 910us/step - loss: 0.0039 - accuracy: 0.9213 - val_loss: 0.0033 - val_accuracy: 0.9310\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0040 - accuracy: 0.9199 - val_loss: 0.0033 - val_accuracy: 0.9310\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0045 - accuracy: 0.9195 - val_loss: 0.0035 - val_accuracy: 0.9138\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0038 - accuracy: 0.9213 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0037 - accuracy: 0.9256 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 803us/step - loss: 0.0039 - accuracy: 0.8980 - val_loss: 0.0032 - val_accuracy: 0.9483\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 990us/step - loss: 0.0036 - accuracy: 0.9121 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 926us/step - loss: 0.0039 - accuracy: 0.9126 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0035 - accuracy: 0.9310 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0038 - accuracy: 0.9208 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 903us/step - loss: 0.0036 - accuracy: 0.9362 - val_loss: 0.0030 - val_accuracy: 0.9483\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 860us/step - loss: 0.0034 - accuracy: 0.9289 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 0.0036 - accuracy: 0.9253 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 0.9212 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.9197 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 884us/step - loss: 0.0030 - accuracy: 0.9550 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 899us/step - loss: 0.0032 - accuracy: 0.9277 - val_loss: 0.0026 - val_accuracy: 0.9310\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0033 - accuracy: 0.9230 - val_loss: 0.0026 - val_accuracy: 0.9310\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0033 - accuracy: 0.9181 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 861us/step - loss: 0.0029 - accuracy: 0.9465 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 840us/step - loss: 0.0033 - accuracy: 0.9371 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 910us/step - loss: 0.0029 - accuracy: 0.9338 - val_loss: 0.0030 - val_accuracy: 0.8966\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 953us/step - loss: 0.0032 - accuracy: 0.9413 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 954us/step - loss: 0.0030 - accuracy: 0.9311 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 882us/step - loss: 0.0028 - accuracy: 0.9370 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 866us/step - loss: 0.0028 - accuracy: 0.9431 - val_loss: 0.0026 - val_accuracy: 0.9310\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 972us/step - loss: 0.0029 - accuracy: 0.9462 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 865us/step - loss: 0.0027 - accuracy: 0.9422 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0028 - accuracy: 0.9368 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 948us/step - loss: 0.0025 - accuracy: 0.9431 - val_loss: 0.0028 - val_accuracy: 0.8966\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 824us/step - loss: 0.0027 - accuracy: 0.9401 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 0.0027 - accuracy: 0.9477 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 902us/step - loss: 0.0024 - accuracy: 0.9315 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9490 - val_loss: 0.0033 - val_accuracy: 0.8966\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.9652 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 810us/step - loss: 0.0025 - accuracy: 0.9487 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 852us/step - loss: 0.0027 - accuracy: 0.9411 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 866us/step - loss: 0.0024 - accuracy: 0.9489 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 919us/step - loss: 0.0025 - accuracy: 0.9551 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 964us/step - loss: 0.0023 - accuracy: 0.9606 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 989us/step - loss: 0.0024 - accuracy: 0.9462 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 873us/step - loss: 0.0025 - accuracy: 0.9359 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 913us/step - loss: 0.0021 - accuracy: 0.9404 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 0.0022 - accuracy: 0.9672 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 931us/step - loss: 0.0021 - accuracy: 0.9578 - val_loss: 0.0020 - val_accuracy: 0.9138\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 944us/step - loss: 0.0023 - accuracy: 0.9607 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 934us/step - loss: 0.0020 - accuracy: 0.9552 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 0.0021 - accuracy: 0.9410 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0022 - accuracy: 0.9659 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 884us/step - loss: 0.0021 - accuracy: 0.9539 - val_loss: 0.0020 - val_accuracy: 0.9138\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 911us/step - loss: 0.0021 - accuracy: 0.9518 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 894us/step - loss: 0.0022 - accuracy: 0.9559 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9740 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 0.0019 - accuracy: 0.9710 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 948us/step - loss: 0.0018 - accuracy: 0.9542 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0019 - accuracy: 0.9741 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 905us/step - loss: 0.0020 - accuracy: 0.9643 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 905us/step - loss: 0.0017 - accuracy: 0.9636 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 833us/step - loss: 0.0019 - accuracy: 0.9561 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0017 - accuracy: 0.9884 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9648 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 980us/step - loss: 0.0018 - accuracy: 0.9686 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 990us/step - loss: 0.0018 - accuracy: 0.9596 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 963us/step - loss: 0.0016 - accuracy: 0.9816 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9776 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 0.0016 - accuracy: 0.9822 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9657 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0015 - accuracy: 0.9663 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 919us/step - loss: 0.0015 - accuracy: 0.9749 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 870us/step - loss: 0.0016 - accuracy: 0.9765 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9698 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 852us/step - loss: 0.0017 - accuracy: 0.9659 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9560 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 954us/step - loss: 0.0017 - accuracy: 0.9737 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 894us/step - loss: 0.0016 - accuracy: 0.9689 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0016 - accuracy: 0.9746 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 0.0016 - accuracy: 0.9823 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 788us/step - loss: 0.0015 - accuracy: 0.9580 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0016 - accuracy: 0.9671 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 0.0016 - accuracy: 0.9749 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0017 - accuracy: 0.9737 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 790us/step - loss: 0.0015 - accuracy: 0.9753 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0019 - accuracy: 0.9625 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 868us/step - loss: 0.0014 - accuracy: 0.9837 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 929us/step - loss: 0.0014 - accuracy: 0.9889 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 847us/step - loss: 0.0015 - accuracy: 0.9790 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 0.0015 - accuracy: 0.9769 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0014 - accuracy: 0.9860 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 949us/step - loss: 0.0015 - accuracy: 0.9827 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 890us/step - loss: 0.0014 - accuracy: 0.9869 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9834 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9892 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 921us/step - loss: 0.0015 - accuracy: 0.9547 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0015 - accuracy: 0.9728 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 970us/step - loss: 0.0014 - accuracy: 0.9751 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 754us/step - loss: 0.0015 - accuracy: 0.9746 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 830us/step - loss: 0.0014 - accuracy: 0.9883 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 910us/step - loss: 0.0012 - accuracy: 0.9905 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 853us/step - loss: 0.0015 - accuracy: 0.9697 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 891us/step - loss: 0.0014 - accuracy: 0.9761 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 816us/step - loss: 0.0013 - accuracy: 0.9786 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 788us/step - loss: 0.0013 - accuracy: 0.9843 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 749us/step - loss: 0.0012 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 875us/step - loss: 0.0015 - accuracy: 0.9587 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 847us/step - loss: 0.0014 - accuracy: 0.9637 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 914us/step - loss: 0.0014 - accuracy: 0.9873 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 778us/step - loss: 0.0013 - accuracy: 0.9743 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9844 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 919us/step - loss: 0.0013 - accuracy: 0.9779 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0013 - accuracy: 0.9736 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 853us/step - loss: 0.0013 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.0012 - accuracy: 0.9933 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 782us/step - loss: 0.0012 - accuracy: 0.9902 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 741us/step - loss: 0.0012 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 844us/step - loss: 0.0013 - accuracy: 0.9571 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 807us/step - loss: 0.0013 - accuracy: 0.9771 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0011 - accuracy: 0.9913 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 850us/step - loss: 0.0011 - accuracy: 0.9804 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 738us/step - loss: 0.0012 - accuracy: 0.9896 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.0012 - accuracy: 0.9868 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0015 - accuracy: 0.9671 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0012 - accuracy: 0.9855 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 800us/step - loss: 0.0010 - accuracy: 0.9847 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 785us/step - loss: 0.0012 - accuracy: 0.9838 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 892us/step - loss: 0.0013 - accuracy: 0.9839 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0011 - accuracy: 0.9718 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 0.0011 - accuracy: 0.9793 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 819us/step - loss: 0.0011 - accuracy: 0.9770 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9728 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9872 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 950us/step - loss: 0.0011 - accuracy: 0.9761 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 822us/step - loss: 0.0011 - accuracy: 0.9780 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 964us/step - loss: 0.0011 - accuracy: 0.9749 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0011 - accuracy: 0.9881 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 911us/step - loss: 0.0011 - accuracy: 0.9868 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 853us/step - loss: 0.0011 - accuracy: 0.9752 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9682 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0013 - accuracy: 0.9756 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0010 - accuracy: 0.9837 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0011 - accuracy: 0.9777 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 844us/step - loss: 0.0012 - accuracy: 0.9822 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 782us/step - loss: 0.0011 - accuracy: 0.9753 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 807us/step - loss: 0.0011 - accuracy: 0.9730 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 0.0012 - accuracy: 0.9728 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 839us/step - loss: 0.0011 - accuracy: 0.9937 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0010 - accuracy: 0.9676 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 945us/step - loss: 0.0011 - accuracy: 0.9942 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9755 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 953us/step - loss: 0.0011 - accuracy: 0.9881 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0012 - accuracy: 0.9776 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0011 - accuracy: 0.9911 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 886us/step - loss: 0.0011 - accuracy: 0.9882 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 862us/step - loss: 0.0011 - accuracy: 0.9836 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 918us/step - loss: 9.6987e-04 - accuracy: 0.9885 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 9.3743e-04 - accuracy: 0.9847 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 969us/step - loss: 9.1764e-04 - accuracy: 0.9820 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0010 - accuracy: 0.9793 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 927us/step - loss: 0.0010 - accuracy: 0.9858 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 849us/step - loss: 9.5943e-04 - accuracy: 0.9919 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0010 - accuracy: 0.9942 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "2/2 [==============================] - 0s 618us/step - loss: 0.0012 - accuracy: 0.9828\n",
            "Loss = 0.0012288566213101149, rmse = 0.982758641242981\n",
            "Loss array:  [0.0010347323259338737, 0.0011190316872671247, 0.0010019029723480344, 0.0011460670502856374, 0.0012288566213101149]\n",
            "####################### Iteration   5  #######################\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.5933 - val_loss: 0.0574 - val_accuracy: 0.7931\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 810us/step - loss: 0.0555 - accuracy: 0.7845 - val_loss: 0.0368 - val_accuracy: 0.8966\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 881us/step - loss: 0.0326 - accuracy: 0.8603 - val_loss: 0.0214 - val_accuracy: 0.8448\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 850us/step - loss: 0.0220 - accuracy: 0.8484 - val_loss: 0.0191 - val_accuracy: 0.8966\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0175 - accuracy: 0.8449 - val_loss: 0.0162 - val_accuracy: 0.9138\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0139 - accuracy: 0.9098 - val_loss: 0.0131 - val_accuracy: 0.9138\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0113 - accuracy: 0.9125 - val_loss: 0.0113 - val_accuracy: 0.9310\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 945us/step - loss: 0.0105 - accuracy: 0.9246 - val_loss: 0.0097 - val_accuracy: 0.9310\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 981us/step - loss: 0.0090 - accuracy: 0.9429 - val_loss: 0.0101 - val_accuracy: 0.9310\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 838us/step - loss: 0.0094 - accuracy: 0.8950 - val_loss: 0.0081 - val_accuracy: 0.9310\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 945us/step - loss: 0.0073 - accuracy: 0.9186 - val_loss: 0.0078 - val_accuracy: 0.9310\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 749us/step - loss: 0.0075 - accuracy: 0.9316 - val_loss: 0.0071 - val_accuracy: 0.9310\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 886us/step - loss: 0.0064 - accuracy: 0.9188 - val_loss: 0.0071 - val_accuracy: 0.9310\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 822us/step - loss: 0.0060 - accuracy: 0.9224 - val_loss: 0.0080 - val_accuracy: 0.8966\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 936us/step - loss: 0.0059 - accuracy: 0.9497 - val_loss: 0.0062 - val_accuracy: 0.9310\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0055 - accuracy: 0.9403 - val_loss: 0.0076 - val_accuracy: 0.8621\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 963us/step - loss: 0.0052 - accuracy: 0.9040 - val_loss: 0.0060 - val_accuracy: 0.9310\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 853us/step - loss: 0.0051 - accuracy: 0.9194 - val_loss: 0.0056 - val_accuracy: 0.9310\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 926us/step - loss: 0.0052 - accuracy: 0.9468 - val_loss: 0.0056 - val_accuracy: 0.9138\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 865us/step - loss: 0.0050 - accuracy: 0.9318 - val_loss: 0.0054 - val_accuracy: 0.9138\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 818us/step - loss: 0.0049 - accuracy: 0.9263 - val_loss: 0.0052 - val_accuracy: 0.9310\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 916us/step - loss: 0.0048 - accuracy: 0.9390 - val_loss: 0.0052 - val_accuracy: 0.9310\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 816us/step - loss: 0.0047 - accuracy: 0.9178 - val_loss: 0.0050 - val_accuracy: 0.9310\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 967us/step - loss: 0.0044 - accuracy: 0.9443 - val_loss: 0.0054 - val_accuracy: 0.8966\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0046 - accuracy: 0.9195 - val_loss: 0.0050 - val_accuracy: 0.9310\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9231 - val_loss: 0.0049 - val_accuracy: 0.9138\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 908us/step - loss: 0.0042 - accuracy: 0.9432 - val_loss: 0.0047 - val_accuracy: 0.9138\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0046 - accuracy: 0.9335 - val_loss: 0.0051 - val_accuracy: 0.8793\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 835us/step - loss: 0.0040 - accuracy: 0.9295 - val_loss: 0.0047 - val_accuracy: 0.8966\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0039 - accuracy: 0.9356 - val_loss: 0.0044 - val_accuracy: 0.9138\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 810us/step - loss: 0.0039 - accuracy: 0.9204 - val_loss: 0.0047 - val_accuracy: 0.9310\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 974us/step - loss: 0.0039 - accuracy: 0.9251 - val_loss: 0.0042 - val_accuracy: 0.9310\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 839us/step - loss: 0.0041 - accuracy: 0.9267 - val_loss: 0.0042 - val_accuracy: 0.9310\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 894us/step - loss: 0.0040 - accuracy: 0.9429 - val_loss: 0.0042 - val_accuracy: 0.9138\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 833us/step - loss: 0.0038 - accuracy: 0.9295 - val_loss: 0.0040 - val_accuracy: 0.9310\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 0.9269 - val_loss: 0.0040 - val_accuracy: 0.9310\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 860us/step - loss: 0.0037 - accuracy: 0.9334 - val_loss: 0.0040 - val_accuracy: 0.9138\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.9386 - val_loss: 0.0043 - val_accuracy: 0.8966\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 920us/step - loss: 0.0036 - accuracy: 0.9355 - val_loss: 0.0042 - val_accuracy: 0.8966\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 976us/step - loss: 0.0034 - accuracy: 0.9371 - val_loss: 0.0040 - val_accuracy: 0.8966\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0032 - accuracy: 0.9571 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0035 - accuracy: 0.9403 - val_loss: 0.0036 - val_accuracy: 0.9310\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 802us/step - loss: 0.0033 - accuracy: 0.9324 - val_loss: 0.0037 - val_accuracy: 0.9138\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 954us/step - loss: 0.0035 - accuracy: 0.9323 - val_loss: 0.0045 - val_accuracy: 0.9310\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0033 - accuracy: 0.9464 - val_loss: 0.0041 - val_accuracy: 0.9310\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 0.9527 - val_loss: 0.0039 - val_accuracy: 0.9138\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 856us/step - loss: 0.0033 - accuracy: 0.9244 - val_loss: 0.0049 - val_accuracy: 0.8966\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 0.0039 - accuracy: 0.9467 - val_loss: 0.0036 - val_accuracy: 0.9310\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 932us/step - loss: 0.0033 - accuracy: 0.9389 - val_loss: 0.0038 - val_accuracy: 0.9138\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9289 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 865us/step - loss: 0.0031 - accuracy: 0.9430 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 0.0030 - accuracy: 0.9407 - val_loss: 0.0034 - val_accuracy: 0.9310\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0029 - accuracy: 0.9561 - val_loss: 0.0034 - val_accuracy: 0.9310\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 914us/step - loss: 0.0032 - accuracy: 0.9619 - val_loss: 0.0033 - val_accuracy: 0.9310\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 853us/step - loss: 0.0029 - accuracy: 0.9451 - val_loss: 0.0038 - val_accuracy: 0.9138\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 989us/step - loss: 0.0032 - accuracy: 0.9217 - val_loss: 0.0033 - val_accuracy: 0.9138\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 857us/step - loss: 0.0027 - accuracy: 0.9478 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 962us/step - loss: 0.0028 - accuracy: 0.9625 - val_loss: 0.0035 - val_accuracy: 0.9310\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 0.0028 - accuracy: 0.9565 - val_loss: 0.0042 - val_accuracy: 0.8966\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.9459 - val_loss: 0.0037 - val_accuracy: 0.9138\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 838us/step - loss: 0.0027 - accuracy: 0.9533 - val_loss: 0.0035 - val_accuracy: 0.9310\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 999us/step - loss: 0.0032 - accuracy: 0.9399 - val_loss: 0.0033 - val_accuracy: 0.9310\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9444 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 947us/step - loss: 0.0027 - accuracy: 0.9365 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 816us/step - loss: 0.0026 - accuracy: 0.9636 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0027 - accuracy: 0.9425 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 781us/step - loss: 0.0030 - accuracy: 0.9361 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 0.0025 - accuracy: 0.9469 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 762us/step - loss: 0.0027 - accuracy: 0.9498 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 935us/step - loss: 0.0026 - accuracy: 0.9491 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 775us/step - loss: 0.0026 - accuracy: 0.9476 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 919us/step - loss: 0.0025 - accuracy: 0.9488 - val_loss: 0.0033 - val_accuracy: 0.9310\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0024 - accuracy: 0.9423 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 805us/step - loss: 0.0026 - accuracy: 0.9682 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 804us/step - loss: 0.0027 - accuracy: 0.9345 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9132 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9595 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 864us/step - loss: 0.0025 - accuracy: 0.9565 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 793us/step - loss: 0.0023 - accuracy: 0.9654 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 764us/step - loss: 0.0023 - accuracy: 0.9550 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9696 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 786us/step - loss: 0.0023 - accuracy: 0.9643 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 924us/step - loss: 0.0024 - accuracy: 0.9513 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0024 - accuracy: 0.9459 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 0.0022 - accuracy: 0.9579 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 782us/step - loss: 0.0024 - accuracy: 0.9558 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9649 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 825us/step - loss: 0.0025 - accuracy: 0.9480 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 996us/step - loss: 0.0021 - accuracy: 0.9756 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0023 - accuracy: 0.9439 - val_loss: 0.0026 - val_accuracy: 0.9310\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 0.0022 - accuracy: 0.9647 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.0022 - accuracy: 0.9694 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9575 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 938us/step - loss: 0.0020 - accuracy: 0.9716 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 903us/step - loss: 0.0020 - accuracy: 0.9623 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 817us/step - loss: 0.0021 - accuracy: 0.9599 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 920us/step - loss: 0.0021 - accuracy: 0.9540 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 795us/step - loss: 0.0021 - accuracy: 0.9516 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 903us/step - loss: 0.0023 - accuracy: 0.9608 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 870us/step - loss: 0.0023 - accuracy: 0.9396 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.0020 - accuracy: 0.9579 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 876us/step - loss: 0.0022 - accuracy: 0.9775 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 856us/step - loss: 0.0019 - accuracy: 0.9613 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0018 - accuracy: 0.9618 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 875us/step - loss: 0.0022 - accuracy: 0.9723 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 834us/step - loss: 0.0021 - accuracy: 0.9648 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9563 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9566 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0019 - accuracy: 0.9610 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 804us/step - loss: 0.0020 - accuracy: 0.9822 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 816us/step - loss: 0.0019 - accuracy: 0.9502 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.0019 - accuracy: 0.9784 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 800us/step - loss: 0.0019 - accuracy: 0.9604 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 964us/step - loss: 0.0018 - accuracy: 0.9680 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 822us/step - loss: 0.0020 - accuracy: 0.9639 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 847us/step - loss: 0.0018 - accuracy: 0.9630 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 781us/step - loss: 0.0019 - accuracy: 0.9603 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0016 - accuracy: 0.9576 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0019 - accuracy: 0.9735 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 844us/step - loss: 0.0019 - accuracy: 0.9627 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9492 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9764 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0016 - accuracy: 0.9596 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9633 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0017 - accuracy: 0.9750 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 987us/step - loss: 0.0016 - accuracy: 0.9605 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 868us/step - loss: 0.0017 - accuracy: 0.9597 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 973us/step - loss: 0.0017 - accuracy: 0.9626 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 834us/step - loss: 0.0017 - accuracy: 0.9497 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 966us/step - loss: 0.0017 - accuracy: 0.9683 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0016 - accuracy: 0.9688 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9654 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 854us/step - loss: 0.0015 - accuracy: 0.9726 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9608 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0015 - accuracy: 0.9597 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 0.0014 - accuracy: 0.9645 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0014 - accuracy: 0.9810 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 943us/step - loss: 0.0014 - accuracy: 0.9732 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 844us/step - loss: 0.0014 - accuracy: 0.9662 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 981us/step - loss: 0.0015 - accuracy: 0.9744 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 848us/step - loss: 0.0014 - accuracy: 0.9773 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0014 - accuracy: 0.9691 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 909us/step - loss: 0.0012 - accuracy: 0.9642 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 936us/step - loss: 0.0012 - accuracy: 0.9733 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0013 - accuracy: 0.9866 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 881us/step - loss: 0.0018 - accuracy: 0.9573 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0016 - accuracy: 0.9777 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 0.0012 - accuracy: 0.9642 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0014 - accuracy: 0.9606 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0013 - accuracy: 0.9765 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 943us/step - loss: 0.0013 - accuracy: 0.9520 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 957us/step - loss: 0.0011 - accuracy: 0.9797 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 959us/step - loss: 0.0011 - accuracy: 0.9709 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0014 - accuracy: 0.9760 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0012 - accuracy: 0.9690 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 894us/step - loss: 0.0013 - accuracy: 0.9687 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 849us/step - loss: 0.0012 - accuracy: 0.9760 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 849us/step - loss: 0.0012 - accuracy: 0.9666 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9608 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9720 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 871us/step - loss: 0.0011 - accuracy: 0.9723 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 891us/step - loss: 0.0011 - accuracy: 0.9628 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 857us/step - loss: 0.0012 - accuracy: 0.9652 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 865us/step - loss: 0.0010 - accuracy: 0.9809 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 886us/step - loss: 0.0011 - accuracy: 0.9716 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 918us/step - loss: 0.0012 - accuracy: 0.9814 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 906us/step - loss: 0.0010 - accuracy: 0.9834 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 910us/step - loss: 0.0012 - accuracy: 0.9718 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 957us/step - loss: 0.0011 - accuracy: 0.9738 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 959us/step - loss: 0.0010 - accuracy: 0.9774 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 980us/step - loss: 9.8153e-04 - accuracy: 0.9605 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 964us/step - loss: 0.0012 - accuracy: 0.9699 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 988us/step - loss: 0.0010 - accuracy: 0.9745 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 854us/step - loss: 0.0011 - accuracy: 0.9816 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9812 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9730 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 778us/step - loss: 0.0010 - accuracy: 0.9606 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 884us/step - loss: 9.2007e-04 - accuracy: 0.9821 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 799us/step - loss: 9.3170e-04 - accuracy: 0.9739 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 916us/step - loss: 9.0331e-04 - accuracy: 0.9615 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 869us/step - loss: 9.3980e-04 - accuracy: 0.9642 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 827us/step - loss: 9.6915e-04 - accuracy: 0.9654 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 862us/step - loss: 9.0886e-04 - accuracy: 0.9832 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 817us/step - loss: 0.0010 - accuracy: 0.9748 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 948us/step - loss: 0.0011 - accuracy: 0.9711 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "2/2 [==============================] - 0s 705us/step - loss: 0.0010 - accuracy: 0.9828\n",
            "Loss = 0.0010123703395947814, rmse = 0.982758641242981\n",
            "Loss array:  [0.0010347323259338737, 0.0011190316872671247, 0.0010019029723480344, 0.0011460670502856374, 0.0012288566213101149, 0.0010123703395947814]\n",
            "####################### Iteration   6  #######################\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.7527 - val_loss: 0.0519 - val_accuracy: 0.7069\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0442 - accuracy: 0.8215 - val_loss: 0.0361 - val_accuracy: 0.7586\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.8688 - val_loss: 0.0240 - val_accuracy: 0.7759\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 867us/step - loss: 0.0211 - accuracy: 0.8653 - val_loss: 0.0211 - val_accuracy: 0.8103\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0160 - accuracy: 0.8429 - val_loss: 0.0215 - val_accuracy: 0.8276\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 901us/step - loss: 0.0130 - accuracy: 0.8714 - val_loss: 0.0154 - val_accuracy: 0.8966\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 913us/step - loss: 0.0096 - accuracy: 0.9354 - val_loss: 0.0134 - val_accuracy: 0.8966\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 894us/step - loss: 0.0095 - accuracy: 0.9317 - val_loss: 0.0120 - val_accuracy: 0.8793\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 841us/step - loss: 0.0084 - accuracy: 0.9371 - val_loss: 0.0147 - val_accuracy: 0.8793\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0086 - accuracy: 0.9084 - val_loss: 0.0108 - val_accuracy: 0.8966\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 956us/step - loss: 0.0070 - accuracy: 0.9292 - val_loss: 0.0106 - val_accuracy: 0.8966\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 785us/step - loss: 0.0066 - accuracy: 0.9341 - val_loss: 0.0092 - val_accuracy: 0.8793\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 947us/step - loss: 0.0060 - accuracy: 0.9316 - val_loss: 0.0101 - val_accuracy: 0.9138\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 811us/step - loss: 0.0058 - accuracy: 0.9231 - val_loss: 0.0073 - val_accuracy: 0.9310\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0055 - accuracy: 0.9390 - val_loss: 0.0079 - val_accuracy: 0.9138\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.9453 - val_loss: 0.0067 - val_accuracy: 0.9310\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 0.9316 - val_loss: 0.0085 - val_accuracy: 0.9138\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0047 - accuracy: 0.9282 - val_loss: 0.0065 - val_accuracy: 0.9310\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 906us/step - loss: 0.0049 - accuracy: 0.9513 - val_loss: 0.0061 - val_accuracy: 0.9310\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 857us/step - loss: 0.0045 - accuracy: 0.9198 - val_loss: 0.0070 - val_accuracy: 0.9138\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 891us/step - loss: 0.0044 - accuracy: 0.9302 - val_loss: 0.0067 - val_accuracy: 0.9483\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 805us/step - loss: 0.0043 - accuracy: 0.9278 - val_loss: 0.0067 - val_accuracy: 0.9483\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.9274 - val_loss: 0.0059 - val_accuracy: 0.9310\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 810us/step - loss: 0.0043 - accuracy: 0.9098 - val_loss: 0.0052 - val_accuracy: 0.9310\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0043 - accuracy: 0.9104 - val_loss: 0.0071 - val_accuracy: 0.9310\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0036 - accuracy: 0.9257 - val_loss: 0.0050 - val_accuracy: 0.9310\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 938us/step - loss: 0.0039 - accuracy: 0.9197 - val_loss: 0.0052 - val_accuracy: 0.9310\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 834us/step - loss: 0.0042 - accuracy: 0.9436 - val_loss: 0.0047 - val_accuracy: 0.9310\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 0.9345 - val_loss: 0.0058 - val_accuracy: 0.9483\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0032 - accuracy: 0.9519 - val_loss: 0.0053 - val_accuracy: 0.9483\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 915us/step - loss: 0.0033 - accuracy: 0.9227 - val_loss: 0.0051 - val_accuracy: 0.9310\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 845us/step - loss: 0.0032 - accuracy: 0.9241 - val_loss: 0.0047 - val_accuracy: 0.9483\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 949us/step - loss: 0.0036 - accuracy: 0.9232 - val_loss: 0.0060 - val_accuracy: 0.9483\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 826us/step - loss: 0.0032 - accuracy: 0.9433 - val_loss: 0.0044 - val_accuracy: 0.9310\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 920us/step - loss: 0.0032 - accuracy: 0.9345 - val_loss: 0.0040 - val_accuracy: 0.9310\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 837us/step - loss: 0.0031 - accuracy: 0.9360 - val_loss: 0.0041 - val_accuracy: 0.9310\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 913us/step - loss: 0.0031 - accuracy: 0.9356 - val_loss: 0.0041 - val_accuracy: 0.9310\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 821us/step - loss: 0.0032 - accuracy: 0.9409 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 865us/step - loss: 0.0031 - accuracy: 0.9309 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 968us/step - loss: 0.0030 - accuracy: 0.9378 - val_loss: 0.0037 - val_accuracy: 0.9655\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 850us/step - loss: 0.0025 - accuracy: 0.9466 - val_loss: 0.0039 - val_accuracy: 0.9310\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 958us/step - loss: 0.0027 - accuracy: 0.9451 - val_loss: 0.0039 - val_accuracy: 0.9655\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 827us/step - loss: 0.0026 - accuracy: 0.9387 - val_loss: 0.0035 - val_accuracy: 0.9483\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9313 - val_loss: 0.0054 - val_accuracy: 0.9483\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0025 - accuracy: 0.9487 - val_loss: 0.0048 - val_accuracy: 0.9483\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 925us/step - loss: 0.0025 - accuracy: 0.9538 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 909us/step - loss: 0.0024 - accuracy: 0.9384 - val_loss: 0.0032 - val_accuracy: 0.9483\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 0.0026 - accuracy: 0.9446 - val_loss: 0.0033 - val_accuracy: 0.9655\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 887us/step - loss: 0.0024 - accuracy: 0.9418 - val_loss: 0.0036 - val_accuracy: 0.9655\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 993us/step - loss: 0.0024 - accuracy: 0.9473 - val_loss: 0.0032 - val_accuracy: 0.9655\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 865us/step - loss: 0.0024 - accuracy: 0.9499 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0023 - accuracy: 0.9385 - val_loss: 0.0036 - val_accuracy: 0.9655\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9437 - val_loss: 0.0036 - val_accuracy: 0.9655\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 917us/step - loss: 0.0022 - accuracy: 0.9658 - val_loss: 0.0038 - val_accuracy: 0.9655\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0021 - accuracy: 0.9423 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9581 - val_loss: 0.0032 - val_accuracy: 0.9655\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 842us/step - loss: 0.0019 - accuracy: 0.9402 - val_loss: 0.0027 - val_accuracy: 0.9828\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 974us/step - loss: 0.0021 - accuracy: 0.9491 - val_loss: 0.0032 - val_accuracy: 0.9655\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 864us/step - loss: 0.0020 - accuracy: 0.9543 - val_loss: 0.0027 - val_accuracy: 0.9828\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9554 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 971us/step - loss: 0.0021 - accuracy: 0.9588 - val_loss: 0.0046 - val_accuracy: 0.9655\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 934us/step - loss: 0.0022 - accuracy: 0.9536 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 977us/step - loss: 0.0022 - accuracy: 0.9460 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 902us/step - loss: 0.0017 - accuracy: 0.9477 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 0.0019 - accuracy: 0.9585 - val_loss: 0.0039 - val_accuracy: 0.9655\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9552 - val_loss: 0.0038 - val_accuracy: 0.9655\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9419 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 861us/step - loss: 0.0018 - accuracy: 0.9634 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 931us/step - loss: 0.0019 - accuracy: 0.9668 - val_loss: 0.0036 - val_accuracy: 0.9655\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0017 - accuracy: 0.9456 - val_loss: 0.0024 - val_accuracy: 0.9828\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 0.0018 - accuracy: 0.9594 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 866us/step - loss: 0.0016 - accuracy: 0.9568 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0019 - accuracy: 0.9602 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0018 - accuracy: 0.9693 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 964us/step - loss: 0.0019 - accuracy: 0.9466 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 855us/step - loss: 0.0020 - accuracy: 0.9449 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 963us/step - loss: 0.0017 - accuracy: 0.9481 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 853us/step - loss: 0.0016 - accuracy: 0.9727 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 991us/step - loss: 0.0016 - accuracy: 0.9726 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 921us/step - loss: 0.0016 - accuracy: 0.9510 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 939us/step - loss: 0.0017 - accuracy: 0.9672 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 822us/step - loss: 0.0016 - accuracy: 0.9543 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 811us/step - loss: 0.0017 - accuracy: 0.9610 - val_loss: 0.0025 - val_accuracy: 0.9828\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 994us/step - loss: 0.0016 - accuracy: 0.9404 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 994us/step - loss: 0.0014 - accuracy: 0.9608 - val_loss: 0.0025 - val_accuracy: 0.9828\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 911us/step - loss: 0.0016 - accuracy: 0.9576 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 860us/step - loss: 0.0015 - accuracy: 0.9556 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 0.0017 - accuracy: 0.9528 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 818us/step - loss: 0.0014 - accuracy: 0.9706 - val_loss: 0.0036 - val_accuracy: 0.9655\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 968us/step - loss: 0.0016 - accuracy: 0.9576 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 917us/step - loss: 0.0015 - accuracy: 0.9670 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9684 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9680 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0014 - accuracy: 0.9584 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 966us/step - loss: 0.0014 - accuracy: 0.9627 - val_loss: 0.0025 - val_accuracy: 0.9828\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 917us/step - loss: 0.0014 - accuracy: 0.9645 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9599 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0015 - accuracy: 0.9714 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 0.0013 - accuracy: 0.9706 - val_loss: 0.0042 - val_accuracy: 0.9655\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0014 - accuracy: 0.9551 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9617 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 890us/step - loss: 0.0014 - accuracy: 0.9664 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9712 - val_loss: 0.0027 - val_accuracy: 0.9828\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 0.0013 - accuracy: 0.9516 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9640 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 904us/step - loss: 0.0014 - accuracy: 0.9421 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9532 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 885us/step - loss: 0.0013 - accuracy: 0.9566 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 985us/step - loss: 0.0013 - accuracy: 0.9417 - val_loss: 0.0033 - val_accuracy: 0.9655\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0013 - accuracy: 0.9716 - val_loss: 0.0026 - val_accuracy: 0.9828\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9648 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 904us/step - loss: 0.0012 - accuracy: 0.9754 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 934us/step - loss: 0.0013 - accuracy: 0.9465 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 775us/step - loss: 0.0012 - accuracy: 0.9679 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9679 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 814us/step - loss: 0.0011 - accuracy: 0.9600 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9551 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.9957e-04 - accuracy: 0.9632 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 977us/step - loss: 0.0012 - accuracy: 0.9627 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 824us/step - loss: 0.0012 - accuracy: 0.9596 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 797us/step - loss: 0.0011 - accuracy: 0.9581 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 852us/step - loss: 0.0012 - accuracy: 0.9783 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 915us/step - loss: 0.0010 - accuracy: 0.9698 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0012 - accuracy: 0.9567 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0011 - accuracy: 0.9649 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 775us/step - loss: 0.0011 - accuracy: 0.9545 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0010 - accuracy: 0.9728 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 891us/step - loss: 0.0011 - accuracy: 0.9634 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 842us/step - loss: 0.0011 - accuracy: 0.9610 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 841us/step - loss: 0.0011 - accuracy: 0.9683 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.0011 - accuracy: 0.9663 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 816us/step - loss: 9.2982e-04 - accuracy: 0.9797 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 741us/step - loss: 0.0010 - accuracy: 0.9677 - val_loss: 0.0025 - val_accuracy: 0.9828\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9397 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9550 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 839us/step - loss: 0.0011 - accuracy: 0.9698 - val_loss: 0.0029 - val_accuracy: 0.9828\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 788us/step - loss: 0.0012 - accuracy: 0.9752 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 9.8160e-04 - accuracy: 0.9715 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 773us/step - loss: 9.6974e-04 - accuracy: 0.9701 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 873us/step - loss: 0.0010 - accuracy: 0.9744 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 803us/step - loss: 0.0011 - accuracy: 0.9510 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 0.0010 - accuracy: 0.9634 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 876us/step - loss: 9.9904e-04 - accuracy: 0.9601 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 820us/step - loss: 9.2112e-04 - accuracy: 0.9767 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 8.7873e-04 - accuracy: 0.9694 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 793us/step - loss: 0.0010 - accuracy: 0.9673 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 786us/step - loss: 0.0011 - accuracy: 0.9750 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 8.9479e-04 - accuracy: 0.9628 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 841us/step - loss: 9.0730e-04 - accuracy: 0.9699 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9707 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 9.4364e-04 - accuracy: 0.9585 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 721us/step - loss: 9.4976e-04 - accuracy: 0.9716 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 860us/step - loss: 9.0322e-04 - accuracy: 0.9708 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 831us/step - loss: 8.8407e-04 - accuracy: 0.9727 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 838us/step - loss: 8.5427e-04 - accuracy: 0.9663 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 806us/step - loss: 8.6648e-04 - accuracy: 0.9641 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 785us/step - loss: 8.9813e-04 - accuracy: 0.9737 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 855us/step - loss: 8.6007e-04 - accuracy: 0.9743 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 803us/step - loss: 9.9777e-04 - accuracy: 0.9807 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 934us/step - loss: 0.0010 - accuracy: 0.9432 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 783us/step - loss: 9.3042e-04 - accuracy: 0.9564 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2678e-04 - accuracy: 0.9702 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 869us/step - loss: 8.8027e-04 - accuracy: 0.9703 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 875us/step - loss: 8.5525e-04 - accuracy: 0.9727 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 798us/step - loss: 0.0010 - accuracy: 0.9675 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 838us/step - loss: 0.0011 - accuracy: 0.9672 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 862us/step - loss: 7.9757e-04 - accuracy: 0.9774 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 901us/step - loss: 9.5694e-04 - accuracy: 0.9620 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 884us/step - loss: 7.9491e-04 - accuracy: 0.9572 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 867us/step - loss: 8.3812e-04 - accuracy: 0.9663 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 847us/step - loss: 8.2626e-04 - accuracy: 0.9648 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9539 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 931us/step - loss: 7.9643e-04 - accuracy: 0.9632 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.5492e-04 - accuracy: 0.9880 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 950us/step - loss: 7.9847e-04 - accuracy: 0.9810 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 921us/step - loss: 9.2449e-04 - accuracy: 0.9657 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 838us/step - loss: 9.0752e-04 - accuracy: 0.9684 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 861us/step - loss: 7.4490e-04 - accuracy: 0.9792 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 856us/step - loss: 7.7887e-04 - accuracy: 0.9678 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 6.9961e-04 - accuracy: 0.9745 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 864us/step - loss: 7.3289e-04 - accuracy: 0.9701 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 865us/step - loss: 8.6398e-04 - accuracy: 0.9610 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 869us/step - loss: 7.3742e-04 - accuracy: 0.9592 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 7.4206e-04 - accuracy: 0.9700 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 892us/step - loss: 9.1619e-04 - accuracy: 0.9833 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "2/2 [==============================] - 0s 798us/step - loss: 0.0021 - accuracy: 0.9655\n",
            "Loss = 0.0020685915369540453, rmse = 0.9655172228813171\n",
            "Loss array:  [0.0010347323259338737, 0.0011190316872671247, 0.0010019029723480344, 0.0011460670502856374, 0.0012288566213101149, 0.0010123703395947814, 0.0020685915369540453]\n",
            "####################### Iteration   7  #######################\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.6818 - val_loss: 0.0374 - val_accuracy: 0.9310\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 0.0359 - accuracy: 0.8282 - val_loss: 0.0218 - val_accuracy: 0.8793\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0235 - accuracy: 0.8493 - val_loss: 0.0182 - val_accuracy: 0.8621\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 781us/step - loss: 0.0197 - accuracy: 0.8548 - val_loss: 0.0150 - val_accuracy: 0.9310\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 949us/step - loss: 0.0162 - accuracy: 0.8533 - val_loss: 0.0130 - val_accuracy: 0.9483\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 839us/step - loss: 0.0128 - accuracy: 0.8798 - val_loss: 0.0099 - val_accuracy: 0.9655\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 873us/step - loss: 0.0094 - accuracy: 0.9243 - val_loss: 0.0083 - val_accuracy: 0.9655\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 906us/step - loss: 0.0082 - accuracy: 0.9255 - val_loss: 0.0070 - val_accuracy: 0.9655\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 820us/step - loss: 0.0075 - accuracy: 0.9399 - val_loss: 0.0065 - val_accuracy: 0.9655\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 873us/step - loss: 0.0072 - accuracy: 0.9142 - val_loss: 0.0067 - val_accuracy: 0.9655\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 823us/step - loss: 0.0062 - accuracy: 0.9134 - val_loss: 0.0058 - val_accuracy: 0.9655\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 0.9355 - val_loss: 0.0057 - val_accuracy: 0.9655\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 920us/step - loss: 0.0056 - accuracy: 0.9236 - val_loss: 0.0054 - val_accuracy: 0.9655\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0051 - accuracy: 0.9228 - val_loss: 0.0070 - val_accuracy: 0.9483\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 905us/step - loss: 0.0051 - accuracy: 0.9340 - val_loss: 0.0053 - val_accuracy: 0.9828\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 881us/step - loss: 0.0048 - accuracy: 0.9467 - val_loss: 0.0073 - val_accuracy: 0.8793\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 904us/step - loss: 0.0044 - accuracy: 0.9121 - val_loss: 0.0057 - val_accuracy: 0.9483\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 881us/step - loss: 0.0042 - accuracy: 0.9156 - val_loss: 0.0057 - val_accuracy: 0.9655\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 881us/step - loss: 0.0044 - accuracy: 0.9437 - val_loss: 0.0048 - val_accuracy: 0.9828\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 946us/step - loss: 0.0042 - accuracy: 0.9084 - val_loss: 0.0051 - val_accuracy: 0.9483\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 0.0041 - accuracy: 0.9195 - val_loss: 0.0047 - val_accuracy: 0.9655\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 927us/step - loss: 0.0040 - accuracy: 0.9446 - val_loss: 0.0045 - val_accuracy: 0.9828\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 894us/step - loss: 0.0038 - accuracy: 0.9291 - val_loss: 0.0051 - val_accuracy: 0.9310\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 0.0040 - accuracy: 0.9242 - val_loss: 0.0050 - val_accuracy: 0.9655\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 994us/step - loss: 0.0040 - accuracy: 0.9011 - val_loss: 0.0043 - val_accuracy: 0.9828\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 0.9294 - val_loss: 0.0045 - val_accuracy: 0.9483\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 0.0034 - accuracy: 0.9319 - val_loss: 0.0056 - val_accuracy: 0.8966\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 969us/step - loss: 0.0040 - accuracy: 0.9366 - val_loss: 0.0064 - val_accuracy: 0.8793\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 945us/step - loss: 0.0034 - accuracy: 0.9273 - val_loss: 0.0044 - val_accuracy: 0.9483\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 865us/step - loss: 0.0033 - accuracy: 0.9559 - val_loss: 0.0040 - val_accuracy: 0.9828\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0032 - accuracy: 0.9409 - val_loss: 0.0039 - val_accuracy: 0.9828\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0032 - accuracy: 0.9197 - val_loss: 0.0044 - val_accuracy: 0.9310\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 915us/step - loss: 0.0034 - accuracy: 0.9450 - val_loss: 0.0036 - val_accuracy: 0.9828\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 963us/step - loss: 0.0032 - accuracy: 0.9443 - val_loss: 0.0046 - val_accuracy: 0.8966\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.9358 - val_loss: 0.0037 - val_accuracy: 0.9655\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0031 - accuracy: 0.9321 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 936us/step - loss: 0.0029 - accuracy: 0.9420 - val_loss: 0.0041 - val_accuracy: 0.9483\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0030 - accuracy: 0.9571 - val_loss: 0.0045 - val_accuracy: 0.9138\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9498 - val_loss: 0.0052 - val_accuracy: 0.8793\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9419 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9660 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0026 - accuracy: 0.9591 - val_loss: 0.0033 - val_accuracy: 0.9655\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9634 - val_loss: 0.0033 - val_accuracy: 0.9655\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 875us/step - loss: 0.0027 - accuracy: 0.9436 - val_loss: 0.0030 - val_accuracy: 0.9828\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 960us/step - loss: 0.0026 - accuracy: 0.9489 - val_loss: 0.0031 - val_accuracy: 0.9828\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0029 - accuracy: 0.9496 - val_loss: 0.0032 - val_accuracy: 0.9655\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 908us/step - loss: 0.0025 - accuracy: 0.9380 - val_loss: 0.0033 - val_accuracy: 0.9655\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 928us/step - loss: 0.0025 - accuracy: 0.9570 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9552 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9462 - val_loss: 0.0034 - val_accuracy: 0.9310\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 951us/step - loss: 0.0025 - accuracy: 0.9326 - val_loss: 0.0045 - val_accuracy: 0.8966\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 789us/step - loss: 0.0024 - accuracy: 0.9541 - val_loss: 0.0025 - val_accuracy: 0.9828\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0023 - accuracy: 0.9445 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0021 - accuracy: 0.9657 - val_loss: 0.0026 - val_accuracy: 0.9828\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9402 - val_loss: 0.0033 - val_accuracy: 0.9310\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0023 - accuracy: 0.9524 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 913us/step - loss: 0.0020 - accuracy: 0.9503 - val_loss: 0.0035 - val_accuracy: 0.8966\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0022 - accuracy: 0.9530 - val_loss: 0.0027 - val_accuracy: 0.9828\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0021 - accuracy: 0.9432 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0021 - accuracy: 0.9552 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0022 - accuracy: 0.9676 - val_loss: 0.0024 - val_accuracy: 0.9828\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 914us/step - loss: 0.0023 - accuracy: 0.9526 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9535 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9546 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0019 - accuracy: 0.9746 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 921us/step - loss: 0.0020 - accuracy: 0.9537 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 812us/step - loss: 0.0021 - accuracy: 0.9443 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 961us/step - loss: 0.0017 - accuracy: 0.9563 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 837us/step - loss: 0.0018 - accuracy: 0.9640 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 862us/step - loss: 0.0018 - accuracy: 0.9533 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0018 - accuracy: 0.9506 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 993us/step - loss: 0.0018 - accuracy: 0.9404 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 805us/step - loss: 0.0018 - accuracy: 0.9407 - val_loss: 0.0025 - val_accuracy: 0.9310\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 944us/step - loss: 0.0020 - accuracy: 0.9685 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0018 - accuracy: 0.9470 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 847us/step - loss: 0.0017 - accuracy: 0.9417 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 757us/step - loss: 0.0018 - accuracy: 0.9503 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9714 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 994us/step - loss: 0.0017 - accuracy: 0.9649 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0015 - accuracy: 0.9573 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0016 - accuracy: 0.9594 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 894us/step - loss: 0.0017 - accuracy: 0.9622 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0016 - accuracy: 0.9649 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.0017 - accuracy: 0.9524 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0016 - accuracy: 0.9525 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 826us/step - loss: 0.0016 - accuracy: 0.9768 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 805us/step - loss: 0.0015 - accuracy: 0.9678 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 753us/step - loss: 0.0016 - accuracy: 0.9542 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 901us/step - loss: 0.0014 - accuracy: 0.9697 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0016 - accuracy: 0.9546 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 777us/step - loss: 0.0015 - accuracy: 0.9796 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0014 - accuracy: 0.9707 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.0014 - accuracy: 0.9685 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 945us/step - loss: 0.0013 - accuracy: 0.9644 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9747 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 959us/step - loss: 0.0014 - accuracy: 0.9542 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0017 - accuracy: 0.9542 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0016 - accuracy: 0.9624 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 792us/step - loss: 0.0012 - accuracy: 0.9829 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 796us/step - loss: 0.0012 - accuracy: 0.9597 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 849us/step - loss: 0.0014 - accuracy: 0.9576 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 796us/step - loss: 0.0012 - accuracy: 0.9789 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 761us/step - loss: 0.0013 - accuracy: 0.9713 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 780us/step - loss: 0.0011 - accuracy: 0.9712 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 964us/step - loss: 0.0012 - accuracy: 0.9820 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 783us/step - loss: 0.0013 - accuracy: 0.9644 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 994us/step - loss: 0.0012 - accuracy: 0.9777 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0012 - accuracy: 0.9733 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9556 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 954us/step - loss: 0.0011 - accuracy: 0.9774 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9779 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 0.0011 - accuracy: 0.9812 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0013 - accuracy: 0.9650 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 0.0012 - accuracy: 0.9868 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 916us/step - loss: 0.0011 - accuracy: 0.9861 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 928us/step - loss: 0.0011 - accuracy: 0.9794 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 0.0011 - accuracy: 0.9800 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 919us/step - loss: 0.0010 - accuracy: 0.9635 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0011 - accuracy: 0.9826 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 867us/step - loss: 0.0011 - accuracy: 0.9703 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 985us/step - loss: 0.0010 - accuracy: 0.9756 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0012 - accuracy: 0.9848 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9850 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9684 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 890us/step - loss: 0.0010 - accuracy: 0.9748 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 0.0011 - accuracy: 0.9768 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 870us/step - loss: 9.5336e-04 - accuracy: 0.9876 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 906us/step - loss: 8.9805e-04 - accuracy: 0.9804 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 974us/step - loss: 0.0012 - accuracy: 0.9689 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 984us/step - loss: 0.0011 - accuracy: 0.9797 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0010 - accuracy: 0.9798 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.8652e-04 - accuracy: 0.9813 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 847us/step - loss: 9.7387e-04 - accuracy: 0.9713 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9747 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2181e-04 - accuracy: 0.9846 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.7996e-04 - accuracy: 0.9826 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 914us/step - loss: 9.9234e-04 - accuracy: 0.9815 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 965us/step - loss: 9.0498e-04 - accuracy: 0.9782 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 964us/step - loss: 9.4364e-04 - accuracy: 0.9662 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9755 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 840us/step - loss: 0.0010 - accuracy: 0.9806 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 953us/step - loss: 8.3844e-04 - accuracy: 0.9850 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 915us/step - loss: 9.3259e-04 - accuracy: 0.9835 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 927us/step - loss: 8.6513e-04 - accuracy: 0.9836 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 862us/step - loss: 7.9707e-04 - accuracy: 0.9851 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 931us/step - loss: 9.5589e-04 - accuracy: 0.9850 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 889us/step - loss: 9.3230e-04 - accuracy: 0.9804 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 887us/step - loss: 7.9897e-04 - accuracy: 0.9785 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9865 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9820 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 797us/step - loss: 9.0980e-04 - accuracy: 0.9834 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.1238e-04 - accuracy: 0.9882 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 795us/step - loss: 8.4415e-04 - accuracy: 0.9825 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 9.7156e-04 - accuracy: 0.9746 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 880us/step - loss: 9.1604e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 870us/step - loss: 8.2607e-04 - accuracy: 0.9829 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 835us/step - loss: 9.1762e-04 - accuracy: 0.9917 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 830us/step - loss: 7.8400e-04 - accuracy: 0.9797 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 803us/step - loss: 8.6345e-04 - accuracy: 0.9832 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 799us/step - loss: 9.3982e-04 - accuracy: 0.9634 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.7888e-04 - accuracy: 0.9777 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.5502e-04 - accuracy: 0.9844 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 817us/step - loss: 8.1218e-04 - accuracy: 0.9839 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 840us/step - loss: 8.3319e-04 - accuracy: 0.9793 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 874us/step - loss: 8.3433e-04 - accuracy: 0.9820 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 800us/step - loss: 8.5431e-04 - accuracy: 0.9893 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 980us/step - loss: 8.1714e-04 - accuracy: 0.9774 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 820us/step - loss: 8.2732e-04 - accuracy: 0.9734 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 974us/step - loss: 7.5851e-04 - accuracy: 0.9778 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 929us/step - loss: 8.1801e-04 - accuracy: 0.9876 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 963us/step - loss: 8.8345e-04 - accuracy: 0.9726 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.2900e-04 - accuracy: 0.9670 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1455e-04 - accuracy: 0.9770 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 877us/step - loss: 8.8083e-04 - accuracy: 0.9664 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 877us/step - loss: 8.3391e-04 - accuracy: 0.9872 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 848us/step - loss: 8.4420e-04 - accuracy: 0.9620 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1683e-04 - accuracy: 0.9694 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 845us/step - loss: 7.7718e-04 - accuracy: 0.9887 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 991us/step - loss: 7.2410e-04 - accuracy: 0.9904 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 7.1628e-04 - accuracy: 0.9841 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 936us/step - loss: 7.0441e-04 - accuracy: 0.9724 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 908us/step - loss: 8.3286e-04 - accuracy: 0.9667 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8128e-04 - accuracy: 0.9787 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.6819e-04 - accuracy: 0.9821 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 7.8456e-04 - accuracy: 0.9877 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Loss = 0.0011469752062112093, rmse = 1.0\n",
            "Loss array:  [0.0010347323259338737, 0.0011190316872671247, 0.0010019029723480344, 0.0011460670502856374, 0.0012288566213101149, 0.0010123703395947814, 0.0020685915369540453, 0.0011469752062112093]\n",
            "####################### Iteration   8  #######################\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.7241 - val_loss: 0.0436 - val_accuracy: 0.8276\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 976us/step - loss: 0.0362 - accuracy: 0.8331 - val_loss: 0.0268 - val_accuracy: 0.7759\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0244 - accuracy: 0.8531 - val_loss: 0.0211 - val_accuracy: 0.8276\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.8705 - val_loss: 0.0148 - val_accuracy: 0.8966\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 917us/step - loss: 0.0131 - accuracy: 0.8659 - val_loss: 0.0134 - val_accuracy: 0.9310\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 913us/step - loss: 0.0114 - accuracy: 0.9020 - val_loss: 0.0103 - val_accuracy: 0.9483\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0088 - accuracy: 0.9336 - val_loss: 0.0094 - val_accuracy: 0.9483\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 0.9249 - val_loss: 0.0086 - val_accuracy: 0.9483\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 917us/step - loss: 0.0075 - accuracy: 0.9294 - val_loss: 0.0082 - val_accuracy: 0.9483\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 928us/step - loss: 0.0075 - accuracy: 0.9135 - val_loss: 0.0073 - val_accuracy: 0.9310\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 872us/step - loss: 0.0067 - accuracy: 0.9009 - val_loss: 0.0070 - val_accuracy: 0.9483\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 0.9305 - val_loss: 0.0065 - val_accuracy: 0.9310\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 0.9219 - val_loss: 0.0064 - val_accuracy: 0.9483\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 910us/step - loss: 0.0057 - accuracy: 0.9226 - val_loss: 0.0063 - val_accuracy: 0.9138\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 961us/step - loss: 0.0056 - accuracy: 0.9313 - val_loss: 0.0054 - val_accuracy: 0.9310\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 870us/step - loss: 0.0050 - accuracy: 0.9515 - val_loss: 0.0054 - val_accuracy: 0.8966\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.8996 - val_loss: 0.0047 - val_accuracy: 0.9310\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 882us/step - loss: 0.0046 - accuracy: 0.9140 - val_loss: 0.0049 - val_accuracy: 0.9138\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 0.9342 - val_loss: 0.0044 - val_accuracy: 0.9310\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 834us/step - loss: 0.0046 - accuracy: 0.9192 - val_loss: 0.0042 - val_accuracy: 0.9310\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 991us/step - loss: 0.0044 - accuracy: 0.9264 - val_loss: 0.0044 - val_accuracy: 0.9310\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 0.0043 - accuracy: 0.9237 - val_loss: 0.0042 - val_accuracy: 0.9310\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.9386 - val_loss: 0.0040 - val_accuracy: 0.9310\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.9267 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 993us/step - loss: 0.0039 - accuracy: 0.9071 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 902us/step - loss: 0.0038 - accuracy: 0.9376 - val_loss: 0.0036 - val_accuracy: 0.9310\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 987us/step - loss: 0.0036 - accuracy: 0.9292 - val_loss: 0.0042 - val_accuracy: 0.8966\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0042 - accuracy: 0.9336 - val_loss: 0.0041 - val_accuracy: 0.8966\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 994us/step - loss: 0.0036 - accuracy: 0.9104 - val_loss: 0.0033 - val_accuracy: 0.9138\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 892us/step - loss: 0.0034 - accuracy: 0.9451 - val_loss: 0.0038 - val_accuracy: 0.9655\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 970us/step - loss: 0.0034 - accuracy: 0.9281 - val_loss: 0.0034 - val_accuracy: 0.9310\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.9285 - val_loss: 0.0032 - val_accuracy: 0.9138\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 908us/step - loss: 0.0035 - accuracy: 0.9257 - val_loss: 0.0040 - val_accuracy: 0.9655\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0033 - accuracy: 0.9400 - val_loss: 0.0032 - val_accuracy: 0.9138\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 922us/step - loss: 0.0033 - accuracy: 0.9288 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 913us/step - loss: 0.0031 - accuracy: 0.9336 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9307 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 966us/step - loss: 0.0030 - accuracy: 0.9527 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0029 - accuracy: 0.9358 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 0.0030 - accuracy: 0.9206 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 877us/step - loss: 0.0027 - accuracy: 0.9489 - val_loss: 0.0026 - val_accuracy: 0.9138\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 949us/step - loss: 0.0027 - accuracy: 0.9495 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 826us/step - loss: 0.0026 - accuracy: 0.9482 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 928us/step - loss: 0.0029 - accuracy: 0.9282 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0026 - accuracy: 0.9462 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0028 - accuracy: 0.9517 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 981us/step - loss: 0.0029 - accuracy: 0.9283 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 995us/step - loss: 0.0028 - accuracy: 0.9455 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 0.0028 - accuracy: 0.9360 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9360 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 988us/step - loss: 0.0027 - accuracy: 0.9483 - val_loss: 0.0030 - val_accuracy: 0.9138\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 899us/step - loss: 0.0025 - accuracy: 0.9363 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0023 - accuracy: 0.9425 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0022 - accuracy: 0.9725 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 826us/step - loss: 0.0024 - accuracy: 0.9443 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 798us/step - loss: 0.0024 - accuracy: 0.9311 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 0.0022 - accuracy: 0.9488 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 797us/step - loss: 0.0022 - accuracy: 0.9496 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0022 - accuracy: 0.9438 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 807us/step - loss: 0.0021 - accuracy: 0.9370 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 938us/step - loss: 0.0022 - accuracy: 0.9548 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0024 - accuracy: 0.9574 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 994us/step - loss: 0.0022 - accuracy: 0.9445 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 924us/step - loss: 0.0020 - accuracy: 0.9480 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0020 - accuracy: 0.9645 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 939us/step - loss: 0.0020 - accuracy: 0.9535 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 0.0023 - accuracy: 0.9527 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0020 - accuracy: 0.9442 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 838us/step - loss: 0.0020 - accuracy: 0.9574 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 855us/step - loss: 0.0019 - accuracy: 0.9483 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 826us/step - loss: 0.0019 - accuracy: 0.9546 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 886us/step - loss: 0.0017 - accuracy: 0.9502 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 944us/step - loss: 0.0019 - accuracy: 0.9578 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 953us/step - loss: 0.0018 - accuracy: 0.9672 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 821us/step - loss: 0.0019 - accuracy: 0.9493 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9437 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 0.0017 - accuracy: 0.9574 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 877us/step - loss: 0.0017 - accuracy: 0.9681 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 807us/step - loss: 0.0018 - accuracy: 0.9613 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 925us/step - loss: 0.0016 - accuracy: 0.9405 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 926us/step - loss: 0.0017 - accuracy: 0.9671 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9698 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 928us/step - loss: 0.0018 - accuracy: 0.9599 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0019 - accuracy: 0.9337 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 998us/step - loss: 0.0016 - accuracy: 0.9564 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0017 - accuracy: 0.9719 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 0.0016 - accuracy: 0.9601 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 0.0016 - accuracy: 0.9601 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9720 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 990us/step - loss: 0.0017 - accuracy: 0.9595 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 856us/step - loss: 0.0016 - accuracy: 0.9780 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 906us/step - loss: 0.0014 - accuracy: 0.9751 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9754 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9588 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0016 - accuracy: 0.9670 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 944us/step - loss: 0.0015 - accuracy: 0.9504 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9564 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 969us/step - loss: 0.0015 - accuracy: 0.9716 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 948us/step - loss: 0.0015 - accuracy: 0.9643 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9630 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9648 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9676 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9716 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0013 - accuracy: 0.9582 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0014 - accuracy: 0.9675 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 874us/step - loss: 0.0015 - accuracy: 0.9459 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 944us/step - loss: 0.0013 - accuracy: 0.9612 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0017 - accuracy: 0.9542 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 955us/step - loss: 0.0013 - accuracy: 0.9555 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.0014 - accuracy: 0.9722 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9707 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9659 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 995us/step - loss: 0.0015 - accuracy: 0.9630 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 838us/step - loss: 0.0014 - accuracy: 0.9738 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 963us/step - loss: 0.0014 - accuracy: 0.9760 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 997us/step - loss: 0.0012 - accuracy: 0.9657 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 937us/step - loss: 0.0013 - accuracy: 0.9635 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0011 - accuracy: 0.9533 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 912us/step - loss: 0.0013 - accuracy: 0.9547 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 915us/step - loss: 0.0015 - accuracy: 0.9583 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 845us/step - loss: 0.0013 - accuracy: 0.9413 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0014 - accuracy: 0.9804 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9679 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9624 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9630 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0012 - accuracy: 0.9726 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 944us/step - loss: 0.0011 - accuracy: 0.9803 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 902us/step - loss: 0.0011 - accuracy: 0.9839 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9550 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9663 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 955us/step - loss: 0.0013 - accuracy: 0.9596 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9745 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9603 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 922us/step - loss: 0.0012 - accuracy: 0.9650 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9540 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9580 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9858 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 934us/step - loss: 0.0011 - accuracy: 0.9680 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 951us/step - loss: 0.0011 - accuracy: 0.9732 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0012 - accuracy: 0.9821 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9709 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 985us/step - loss: 0.0010 - accuracy: 0.9633 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9809 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 926us/step - loss: 0.0011 - accuracy: 0.9780 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 877us/step - loss: 0.0010 - accuracy: 0.9798 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 964us/step - loss: 0.0011 - accuracy: 0.9693 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 883us/step - loss: 0.0012 - accuracy: 0.9620 - val_loss: 9.4454e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.8865e-04 - accuracy: 0.9781 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9722 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 967us/step - loss: 0.0015 - accuracy: 0.9707 - val_loss: 9.7425e-04 - val_accuracy: 0.9828\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 905us/step - loss: 0.0010 - accuracy: 0.9748 - val_loss: 9.8946e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 979us/step - loss: 0.0011 - accuracy: 0.9610 - val_loss: 9.1003e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 913us/step - loss: 0.0010 - accuracy: 0.9711 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9766 - val_loss: 9.7602e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 931us/step - loss: 0.0010 - accuracy: 0.9676 - val_loss: 8.6301e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 995us/step - loss: 9.2879e-04 - accuracy: 0.9708 - val_loss: 9.4719e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.0010 - accuracy: 0.9820 - val_loss: 9.6989e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9810 - val_loss: 9.7392e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0010 - accuracy: 0.9748 - val_loss: 9.6295e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9817 - val_loss: 9.5098e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 943us/step - loss: 9.5076e-04 - accuracy: 0.9786 - val_loss: 8.5794e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 836us/step - loss: 9.4346e-04 - accuracy: 0.9743 - val_loss: 9.0561e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 845us/step - loss: 9.7767e-04 - accuracy: 0.9808 - val_loss: 9.7338e-04 - val_accuracy: 0.9828\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 840us/step - loss: 9.9259e-04 - accuracy: 0.9733 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 862us/step - loss: 9.4432e-04 - accuracy: 0.9782 - val_loss: 8.6511e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9785 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 8.2549e-04 - accuracy: 0.9877 - val_loss: 9.9265e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 991us/step - loss: 0.0011 - accuracy: 0.9709 - val_loss: 8.6234e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.0276e-04 - accuracy: 0.9650 - val_loss: 9.5221e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.3474e-04 - accuracy: 0.9644 - val_loss: 8.9472e-04 - val_accuracy: 1.0000\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 892us/step - loss: 8.4436e-04 - accuracy: 0.9852 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 942us/step - loss: 9.3480e-04 - accuracy: 0.9711 - val_loss: 8.6386e-04 - val_accuracy: 0.9828\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 984us/step - loss: 9.2880e-04 - accuracy: 0.9751 - val_loss: 8.8238e-04 - val_accuracy: 0.9828\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 928us/step - loss: 9.6248e-04 - accuracy: 0.9920 - val_loss: 8.3379e-04 - val_accuracy: 1.0000\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 938us/step - loss: 0.0010 - accuracy: 0.9813 - val_loss: 8.5556e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9779 - val_loss: 8.8615e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 895us/step - loss: 9.6491e-04 - accuracy: 0.9769 - val_loss: 8.5438e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.4372e-04 - accuracy: 0.9862 - val_loss: 8.7723e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.7518e-04 - accuracy: 0.9803 - val_loss: 9.9728e-04 - val_accuracy: 0.9828\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.3085e-04 - accuracy: 0.9661 - val_loss: 8.8109e-04 - val_accuracy: 1.0000\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.1164e-04 - accuracy: 0.9686 - val_loss: 7.5706e-04 - val_accuracy: 1.0000\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 864us/step - loss: 9.3747e-04 - accuracy: 0.9733 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 8.6742e-04 - accuracy: 0.9538 - val_loss: 8.6383e-04 - val_accuracy: 1.0000\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 9.5462e-04 - accuracy: 0.9857 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.6450e-04 - accuracy: 0.9691 - val_loss: 8.1529e-04 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 812us/step - loss: 8.1530e-04 - accuracy: 1.0000\n",
            "Loss = 0.0008152950904332101, rmse = 1.0\n",
            "Loss array:  [0.0010347323259338737, 0.0011190316872671247, 0.0010019029723480344, 0.0011460670502856374, 0.0012288566213101149, 0.0010123703395947814, 0.0020685915369540453, 0.0011469752062112093, 0.0008152950904332101]\n",
            "####################### Iteration   9  #######################\n",
            "Epoch 1/185\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.6401 - val_loss: 0.0382 - val_accuracy: 0.9310\n",
            "Epoch 2/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.8138 - val_loss: 0.0245 - val_accuracy: 0.9310\n",
            "Epoch 3/185\n",
            "53/53 [==============================] - 0s 865us/step - loss: 0.0244 - accuracy: 0.8473 - val_loss: 0.0194 - val_accuracy: 0.9138\n",
            "Epoch 4/185\n",
            "53/53 [==============================] - 0s 841us/step - loss: 0.0212 - accuracy: 0.8530 - val_loss: 0.0178 - val_accuracy: 0.9138\n",
            "Epoch 5/185\n",
            "53/53 [==============================] - 0s 904us/step - loss: 0.0178 - accuracy: 0.8393 - val_loss: 0.0156 - val_accuracy: 0.9483\n",
            "Epoch 6/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0152 - accuracy: 0.8765 - val_loss: 0.0126 - val_accuracy: 0.9483\n",
            "Epoch 7/185\n",
            "53/53 [==============================] - 0s 885us/step - loss: 0.0131 - accuracy: 0.9315 - val_loss: 0.0103 - val_accuracy: 0.9483\n",
            "Epoch 8/185\n",
            "53/53 [==============================] - 0s 844us/step - loss: 0.0112 - accuracy: 0.9198 - val_loss: 0.0096 - val_accuracy: 0.9655\n",
            "Epoch 9/185\n",
            "53/53 [==============================] - 0s 976us/step - loss: 0.0105 - accuracy: 0.9175 - val_loss: 0.0084 - val_accuracy: 0.9483\n",
            "Epoch 10/185\n",
            "53/53 [==============================] - 0s 912us/step - loss: 0.0093 - accuracy: 0.9120 - val_loss: 0.0074 - val_accuracy: 0.9483\n",
            "Epoch 11/185\n",
            "53/53 [==============================] - 0s 923us/step - loss: 0.0088 - accuracy: 0.9138 - val_loss: 0.0065 - val_accuracy: 0.9483\n",
            "Epoch 12/185\n",
            "53/53 [==============================] - 0s 877us/step - loss: 0.0080 - accuracy: 0.9219 - val_loss: 0.0061 - val_accuracy: 0.9483\n",
            "Epoch 13/185\n",
            "53/53 [==============================] - 0s 931us/step - loss: 0.0074 - accuracy: 0.9241 - val_loss: 0.0060 - val_accuracy: 0.9655\n",
            "Epoch 14/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 0.9283 - val_loss: 0.0057 - val_accuracy: 0.9483\n",
            "Epoch 15/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 0.9255 - val_loss: 0.0048 - val_accuracy: 0.9483\n",
            "Epoch 16/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 0.9425 - val_loss: 0.0060 - val_accuracy: 0.9138\n",
            "Epoch 17/185\n",
            "53/53 [==============================] - 0s 898us/step - loss: 0.0061 - accuracy: 0.9003 - val_loss: 0.0053 - val_accuracy: 0.9138\n",
            "Epoch 18/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0056 - accuracy: 0.9158 - val_loss: 0.0051 - val_accuracy: 0.9138\n",
            "Epoch 19/185\n",
            "53/53 [==============================] - 0s 803us/step - loss: 0.0059 - accuracy: 0.9491 - val_loss: 0.0046 - val_accuracy: 0.9483\n",
            "Epoch 20/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 0.9159 - val_loss: 0.0041 - val_accuracy: 0.9483\n",
            "Epoch 21/185\n",
            "53/53 [==============================] - 0s 935us/step - loss: 0.0054 - accuracy: 0.9234 - val_loss: 0.0043 - val_accuracy: 0.9483\n",
            "Epoch 22/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.9193 - val_loss: 0.0040 - val_accuracy: 0.9483\n",
            "Epoch 23/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.9254 - val_loss: 0.0039 - val_accuracy: 0.9483\n",
            "Epoch 24/185\n",
            "53/53 [==============================] - 0s 948us/step - loss: 0.0048 - accuracy: 0.9298 - val_loss: 0.0039 - val_accuracy: 0.9483\n",
            "Epoch 25/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.9009 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "Epoch 26/185\n",
            "53/53 [==============================] - 0s 879us/step - loss: 0.0046 - accuracy: 0.9299 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "Epoch 27/185\n",
            "53/53 [==============================] - 0s 986us/step - loss: 0.0043 - accuracy: 0.9159 - val_loss: 0.0044 - val_accuracy: 0.9138\n",
            "Epoch 28/185\n",
            "53/53 [==============================] - 0s 811us/step - loss: 0.0050 - accuracy: 0.9101 - val_loss: 0.0051 - val_accuracy: 0.8966\n",
            "Epoch 29/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0044 - accuracy: 0.9113 - val_loss: 0.0042 - val_accuracy: 0.9310\n",
            "Epoch 30/185\n",
            "53/53 [==============================] - 0s 907us/step - loss: 0.0044 - accuracy: 0.9357 - val_loss: 0.0034 - val_accuracy: 0.9655\n",
            "Epoch 31/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0040 - accuracy: 0.9195 - val_loss: 0.0034 - val_accuracy: 0.9655\n",
            "Epoch 32/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 0.0037 - accuracy: 0.9253 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 33/185\n",
            "53/53 [==============================] - 0s 901us/step - loss: 0.0040 - accuracy: 0.9293 - val_loss: 0.0034 - val_accuracy: 0.9655\n",
            "Epoch 34/185\n",
            "53/53 [==============================] - 0s 899us/step - loss: 0.0038 - accuracy: 0.9296 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 35/185\n",
            "53/53 [==============================] - 0s 873us/step - loss: 0.0038 - accuracy: 0.9216 - val_loss: 0.0032 - val_accuracy: 0.9655\n",
            "Epoch 36/185\n",
            "53/53 [==============================] - 0s 814us/step - loss: 0.0036 - accuracy: 0.9233 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 37/185\n",
            "53/53 [==============================] - 0s 894us/step - loss: 0.0034 - accuracy: 0.9278 - val_loss: 0.0030 - val_accuracy: 0.9483\n",
            "Epoch 38/185\n",
            "53/53 [==============================] - 0s 862us/step - loss: 0.0032 - accuracy: 0.9499 - val_loss: 0.0034 - val_accuracy: 0.9483\n",
            "Epoch 39/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9281 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 40/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.9279 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 41/185\n",
            "53/53 [==============================] - 0s 911us/step - loss: 0.0030 - accuracy: 0.9310 - val_loss: 0.0031 - val_accuracy: 0.9483\n",
            "Epoch 42/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 0.0032 - accuracy: 0.9432 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "Epoch 43/185\n",
            "53/53 [==============================] - 0s 929us/step - loss: 0.0030 - accuracy: 0.9393 - val_loss: 0.0031 - val_accuracy: 0.9483\n",
            "Epoch 44/185\n",
            "53/53 [==============================] - 0s 914us/step - loss: 0.0033 - accuracy: 0.9211 - val_loss: 0.0029 - val_accuracy: 0.9655\n",
            "Epoch 45/185\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0030 - accuracy: 0.9432 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 46/185\n",
            "53/53 [==============================] - 0s 904us/step - loss: 0.0030 - accuracy: 0.9510 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 47/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9202 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 48/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0030 - accuracy: 0.9425 - val_loss: 0.0025 - val_accuracy: 0.9828\n",
            "Epoch 49/185\n",
            "53/53 [==============================] - 0s 921us/step - loss: 0.0030 - accuracy: 0.9444 - val_loss: 0.0025 - val_accuracy: 0.9828\n",
            "Epoch 50/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9385 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 51/185\n",
            "53/53 [==============================] - 0s 966us/step - loss: 0.0029 - accuracy: 0.9380 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 52/185\n",
            "53/53 [==============================] - 0s 766us/step - loss: 0.0026 - accuracy: 0.9327 - val_loss: 0.0025 - val_accuracy: 0.9828\n",
            "Epoch 53/185\n",
            "53/53 [==============================] - 0s 904us/step - loss: 0.0025 - accuracy: 0.9330 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "Epoch 54/185\n",
            "53/53 [==============================] - 0s 899us/step - loss: 0.0022 - accuracy: 0.9567 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 55/185\n",
            "53/53 [==============================] - 0s 847us/step - loss: 0.0024 - accuracy: 0.9362 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 56/185\n",
            "53/53 [==============================] - 0s 934us/step - loss: 0.0026 - accuracy: 0.9522 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 57/185\n",
            "53/53 [==============================] - 0s 873us/step - loss: 0.0022 - accuracy: 0.9373 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 58/185\n",
            "53/53 [==============================] - 0s 931us/step - loss: 0.0023 - accuracy: 0.9491 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 59/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9433 - val_loss: 0.0024 - val_accuracy: 0.9310\n",
            "Epoch 60/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9436 - val_loss: 0.0028 - val_accuracy: 0.9138\n",
            "Epoch 61/185\n",
            "53/53 [==============================] - 0s 914us/step - loss: 0.0021 - accuracy: 0.9603 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 62/185\n",
            "53/53 [==============================] - 0s 837us/step - loss: 0.0025 - accuracy: 0.9484 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 63/185\n",
            "53/53 [==============================] - 0s 987us/step - loss: 0.0022 - accuracy: 0.9494 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "Epoch 64/185\n",
            "53/53 [==============================] - 0s 868us/step - loss: 0.0023 - accuracy: 0.9307 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 65/185\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0022 - accuracy: 0.9626 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 66/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0020 - accuracy: 0.9517 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 67/185\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.0022 - accuracy: 0.9382 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 68/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9638 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 69/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9666 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 70/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 0.0019 - accuracy: 0.9545 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 71/185\n",
            "53/53 [==============================] - 0s 959us/step - loss: 0.0018 - accuracy: 0.9532 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 72/185\n",
            "53/53 [==============================] - 0s 797us/step - loss: 0.0018 - accuracy: 0.9445 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 73/185\n",
            "53/53 [==============================] - 0s 906us/step - loss: 0.0020 - accuracy: 0.9431 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 74/185\n",
            "53/53 [==============================] - 0s 854us/step - loss: 0.0017 - accuracy: 0.9631 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 75/185\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.0019 - accuracy: 0.9357 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 76/185\n",
            "53/53 [==============================] - 0s 932us/step - loss: 0.0019 - accuracy: 0.9430 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 77/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9548 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 78/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9723 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 79/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9492 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 80/185\n",
            "53/53 [==============================] - 0s 802us/step - loss: 0.0017 - accuracy: 0.9564 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 81/185\n",
            "53/53 [==============================] - 0s 949us/step - loss: 0.0017 - accuracy: 0.9641 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 82/185\n",
            "53/53 [==============================] - 0s 887us/step - loss: 0.0017 - accuracy: 0.9364 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 83/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9665 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 84/185\n",
            "53/53 [==============================] - 0s 788us/step - loss: 0.0018 - accuracy: 0.9523 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 85/185\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.0016 - accuracy: 0.9499 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 86/185\n",
            "53/53 [==============================] - 0s 850us/step - loss: 0.0016 - accuracy: 0.9684 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 87/185\n",
            "53/53 [==============================] - 0s 941us/step - loss: 0.0015 - accuracy: 0.9616 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 88/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9488 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 89/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9731 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 90/185\n",
            "53/53 [==============================] - 0s 853us/step - loss: 0.0016 - accuracy: 0.9670 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 91/185\n",
            "53/53 [==============================] - 0s 965us/step - loss: 0.0016 - accuracy: 0.9779 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 92/185\n",
            "53/53 [==============================] - 0s 783us/step - loss: 0.0015 - accuracy: 0.9628 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 93/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9660 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 94/185\n",
            "53/53 [==============================] - 0s 837us/step - loss: 0.0014 - accuracy: 0.9570 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 95/185\n",
            "53/53 [==============================] - 0s 916us/step - loss: 0.0016 - accuracy: 0.9576 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 96/185\n",
            "53/53 [==============================] - 0s 916us/step - loss: 0.0015 - accuracy: 0.9490 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 97/185\n",
            "53/53 [==============================] - 0s 915us/step - loss: 0.0015 - accuracy: 0.9603 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 98/185\n",
            "53/53 [==============================] - 0s 867us/step - loss: 0.0015 - accuracy: 0.9594 - val_loss: 0.0019 - val_accuracy: 0.9138\n",
            "Epoch 99/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9721 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 100/185\n",
            "53/53 [==============================] - 0s 840us/step - loss: 0.0014 - accuracy: 0.9615 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 101/185\n",
            "53/53 [==============================] - 0s 968us/step - loss: 0.0014 - accuracy: 0.9616 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 102/185\n",
            "53/53 [==============================] - 0s 854us/step - loss: 0.0013 - accuracy: 0.9708 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 103/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 0.0014 - accuracy: 0.9583 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 104/185\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0013 - accuracy: 0.9570 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 105/185\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.0013 - accuracy: 0.9589 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 106/185\n",
            "53/53 [==============================] - 0s 809us/step - loss: 0.0014 - accuracy: 0.9426 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 107/185\n",
            "53/53 [==============================] - 0s 870us/step - loss: 0.0011 - accuracy: 0.9682 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 108/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9482 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 109/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9587 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 110/185\n",
            "53/53 [==============================] - 0s 860us/step - loss: 0.0013 - accuracy: 0.9766 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 111/185\n",
            "53/53 [==============================] - 0s 891us/step - loss: 0.0011 - accuracy: 0.9660 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 112/185\n",
            "53/53 [==============================] - 0s 861us/step - loss: 0.0011 - accuracy: 0.9680 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 113/185\n",
            "53/53 [==============================] - 0s 952us/step - loss: 0.0013 - accuracy: 0.9677 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 114/185\n",
            "53/53 [==============================] - 0s 900us/step - loss: 0.0012 - accuracy: 0.9765 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 115/185\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0012 - accuracy: 0.9667 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 116/185\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0012 - accuracy: 0.9703 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 117/185\n",
            "53/53 [==============================] - 0s 909us/step - loss: 0.0013 - accuracy: 0.9772 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 118/185\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0011 - accuracy: 0.9588 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 119/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9575 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 120/185\n",
            "53/53 [==============================] - 0s 983us/step - loss: 0.0014 - accuracy: 0.9676 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 121/185\n",
            "53/53 [==============================] - 0s 920us/step - loss: 0.0011 - accuracy: 0.9668 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 122/185\n",
            "53/53 [==============================] - 0s 920us/step - loss: 0.0014 - accuracy: 0.9744 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 123/185\n",
            "53/53 [==============================] - 0s 926us/step - loss: 0.0011 - accuracy: 0.9736 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 124/185\n",
            "53/53 [==============================] - 0s 956us/step - loss: 0.0011 - accuracy: 0.9659 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 125/185\n",
            "53/53 [==============================] - 0s 940us/step - loss: 0.0012 - accuracy: 0.9654 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 126/185\n",
            "53/53 [==============================] - 0s 954us/step - loss: 0.0011 - accuracy: 0.9571 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 127/185\n",
            "53/53 [==============================] - 0s 899us/step - loss: 0.0011 - accuracy: 0.9792 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 128/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9761 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 129/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9558 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 130/185\n",
            "53/53 [==============================] - 0s 998us/step - loss: 0.0011 - accuracy: 0.9704 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 131/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9610 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 132/185\n",
            "53/53 [==============================] - 0s 899us/step - loss: 0.0011 - accuracy: 0.9650 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 133/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9669 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 134/185\n",
            "53/53 [==============================] - 0s 890us/step - loss: 0.0012 - accuracy: 0.9469 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 135/185\n",
            "53/53 [==============================] - 0s 973us/step - loss: 0.0011 - accuracy: 0.9499 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 136/185\n",
            "53/53 [==============================] - 0s 877us/step - loss: 0.0010 - accuracy: 0.9582 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 137/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0011 - accuracy: 0.9760 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 138/185\n",
            "53/53 [==============================] - 0s 772us/step - loss: 9.6683e-04 - accuracy: 0.9534 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 139/185\n",
            "53/53 [==============================] - 0s 929us/step - loss: 0.0010 - accuracy: 0.9721 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 140/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9677 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 141/185\n",
            "53/53 [==============================] - 0s 929us/step - loss: 0.0013 - accuracy: 0.9709 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 142/185\n",
            "53/53 [==============================] - 0s 908us/step - loss: 9.6942e-04 - accuracy: 0.9751 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 143/185\n",
            "53/53 [==============================] - 0s 932us/step - loss: 9.8832e-04 - accuracy: 0.9684 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 144/185\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0011 - accuracy: 0.9643 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 145/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.8669e-04 - accuracy: 0.9729 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 146/185\n",
            "53/53 [==============================] - 0s 934us/step - loss: 0.0010 - accuracy: 0.9791 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 147/185\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0011 - accuracy: 0.9605 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 148/185\n",
            "53/53 [==============================] - 0s 845us/step - loss: 9.0167e-04 - accuracy: 0.9768 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 149/185\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0011 - accuracy: 0.9745 - val_loss: 0.0019 - val_accuracy: 0.9138\n",
            "Epoch 150/185\n",
            "53/53 [==============================] - 0s 833us/step - loss: 0.0015 - accuracy: 0.9790 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 151/185\n",
            "53/53 [==============================] - 0s 906us/step - loss: 0.0010 - accuracy: 0.9617 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 152/185\n",
            "53/53 [==============================] - 0s 928us/step - loss: 0.0011 - accuracy: 0.9629 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 153/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2529e-04 - accuracy: 0.9641 - val_loss: 9.9454e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/185\n",
            "53/53 [==============================] - 0s 954us/step - loss: 9.9451e-04 - accuracy: 0.9888 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 155/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9522 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 156/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2898e-04 - accuracy: 0.9654 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 157/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9647 - val_loss: 9.4721e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/185\n",
            "53/53 [==============================] - 0s 978us/step - loss: 9.8428e-04 - accuracy: 0.9551 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 159/185\n",
            "53/53 [==============================] - 0s 867us/step - loss: 9.9174e-04 - accuracy: 0.9710 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 160/185\n",
            "53/53 [==============================] - 0s 878us/step - loss: 0.0010 - accuracy: 0.9535 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 161/185\n",
            "53/53 [==============================] - 0s 809us/step - loss: 0.0010 - accuracy: 0.9659 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 162/185\n",
            "53/53 [==============================] - 0s 903us/step - loss: 9.0398e-04 - accuracy: 0.9749 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 163/185\n",
            "53/53 [==============================] - 0s 802us/step - loss: 9.6571e-04 - accuracy: 0.9842 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 164/185\n",
            "53/53 [==============================] - 0s 827us/step - loss: 9.3867e-04 - accuracy: 0.9785 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 165/185\n",
            "53/53 [==============================] - 0s 796us/step - loss: 9.1939e-04 - accuracy: 0.9705 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 166/185\n",
            "53/53 [==============================] - 0s 932us/step - loss: 0.0011 - accuracy: 0.9756 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 167/185\n",
            "53/53 [==============================] - 0s 887us/step - loss: 8.8644e-04 - accuracy: 0.9768 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 168/185\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0011 - accuracy: 0.9579 - val_loss: 9.7511e-04 - val_accuracy: 0.9828\n",
            "Epoch 169/185\n",
            "53/53 [==============================] - 0s 936us/step - loss: 8.9641e-04 - accuracy: 0.9645 - val_loss: 9.3962e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/185\n",
            "53/53 [==============================] - 0s 746us/step - loss: 8.9784e-04 - accuracy: 0.9601 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 171/185\n",
            "53/53 [==============================] - 0s 829us/step - loss: 9.3424e-04 - accuracy: 0.9723 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 172/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9636 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 173/185\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 9.2026e-04 - accuracy: 0.9715 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 174/185\n",
            "53/53 [==============================] - 0s 933us/step - loss: 9.8917e-04 - accuracy: 0.9815 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 175/185\n",
            "53/53 [==============================] - 0s 959us/step - loss: 0.0010 - accuracy: 0.9756 - val_loss: 9.3677e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/185\n",
            "53/53 [==============================] - 0s 848us/step - loss: 9.5411e-04 - accuracy: 0.9746 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 177/185\n",
            "53/53 [==============================] - 0s 956us/step - loss: 9.6019e-04 - accuracy: 0.9660 - val_loss: 9.8063e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/185\n",
            "53/53 [==============================] - 0s 893us/step - loss: 8.1288e-04 - accuracy: 0.9759 - val_loss: 9.4673e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/185\n",
            "53/53 [==============================] - 0s 917us/step - loss: 8.3254e-04 - accuracy: 0.9756 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 180/185\n",
            "53/53 [==============================] - 0s 962us/step - loss: 9.8440e-04 - accuracy: 0.9660 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 181/185\n",
            "53/53 [==============================] - 0s 987us/step - loss: 8.8784e-04 - accuracy: 0.9683 - val_loss: 9.9927e-04 - val_accuracy: 1.0000\n",
            "Epoch 182/185\n",
            "53/53 [==============================] - 0s 935us/step - loss: 9.6815e-04 - accuracy: 0.9644 - val_loss: 9.1149e-04 - val_accuracy: 1.0000\n",
            "Epoch 183/185\n",
            "53/53 [==============================] - 0s 991us/step - loss: 8.0829e-04 - accuracy: 0.9519 - val_loss: 9.6964e-04 - val_accuracy: 1.0000\n",
            "Epoch 184/185\n",
            "53/53 [==============================] - 0s 905us/step - loss: 0.0010 - accuracy: 0.9730 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 185/185\n",
            "53/53 [==============================] - 0s 962us/step - loss: 8.4167e-04 - accuracy: 0.9726 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 850us/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Loss = 0.001199997146613896, rmse = 1.0\n",
            "Loss array:  [0.0010347323259338737, 0.0011190316872671247, 0.0010019029723480344, 0.0011460670502856374, 0.0012288566213101149, 0.0010123703395947814, 0.0020685915369540453, 0.0011469752062112093, 0.0008152950904332101, 0.001199997146613896]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "NUM_EPOCHS = 183 # 180\n",
        "BATCH_SIZE = 10\n",
        "K_FOLD_SPLITS = 10\n",
        "\n",
        "\n",
        "# Define the cross-validation process to be used inside cross_val_Score evaluation\n",
        "cv = KFold(n_splits=K_FOLD_SPLITS)\n",
        "\n",
        "# Handling for accommodating multiple targets\n",
        "Y1 = y_train_norm[:,0]\n",
        "Y2 = y_train_norm[:,1]\n",
        "targets = (Y1, Y2)\n",
        "\n",
        "X = X_train_norm\n",
        "\n",
        "i = 0\n",
        "arr_loss = list()\n",
        "arr_rmse = list()\n",
        "min_loss = 1000000\n",
        "best_model = None\n",
        "history = None\n",
        "history_best_model = None\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_indices, test_indices in cv.split(X_train):\n",
        "  print('####################### Iteration  ', i, ' #######################')\n",
        "  trainX, valX = np.array(X[train_indices]), np.array(X[test_indices])\n",
        "  trainY = np.vstack((Y1[train_indices], Y2[train_indices])).T\n",
        "  valY = np.vstack((Y1[test_indices], Y2[test_indices])).T\n",
        "\n",
        "  model = my_model()\n",
        "  history = model.fit(trainX, trainY,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            validation_data = (valX, valY)\n",
        "  )\n",
        "\n",
        "\n",
        "  #testing on validation set process\n",
        "  loss, rmse = model.evaluate(x = valX, y = valY, verbose=1)\n",
        "  print(f\"Loss = {loss}, rmse = {rmse}\" )\n",
        "\n",
        "  if loss < min_loss:\n",
        "    best_model = model\n",
        "    history_best_model = history\n",
        "    min_loss = loss\n",
        "\n",
        "  arr_loss.append(loss)\n",
        "  arr_rmse.append(rmse)\n",
        "  print('Loss array: ', arr_loss)\n",
        "  i+=1\n",
        "\n",
        "# Saving the best model within the k folds\n",
        "best_model.save(FILENAME_BEST_MODEL)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results\n",
        "- Plot of k-cross validation performance\n",
        "- Scatter Plot of prediction results against true values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "xKSkPnO4ETWD",
        "outputId": "564ee694-d414-4d21-bbd9-f838e7249dd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loss across k folds\n",
        "plot_line(arr_loss, \"Loss across k-folds\", \"Value of k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABqUUlEQVR4nO3dd3gU5d7G8e+mN1JIIAUCoUQ6oUdAxBIN6EGjosiLUkQ5SvWgHsQCiHpQARsqWFBsWFBARQQBwULvRQGlIxBCS++78/6xZmVNKIFkJyT357r2OtnZZ2Z+k4lnb5555hmLYRgGIiIiIlWIm9kFiIiIiLiaApCIiIhUOQpAIiIiUuUoAImIiEiVowAkIiIiVY4CkIiIiFQ5CkAiIiJS5SgAiYiISJWjACQiIiJVjgKQSAXVv39/YmJiLmjdcePGYbFYyragCmbfvn1YLBZmzJjh8n1bLBbGjRvneD9jxgwsFgv79u0757oxMTH079+/TOu5mL+Vi2HmORC5WApAIqVksVjO67Vs2TKzS63yhg8fjsViYdeuXWds8/jjj2OxWNiyZYsLKyu9w4cPM27cODZt2mR2KSKVgofZBYhcaj788EOn9x988AGLFi0qtrxJkyYXtZ+3334bm812Qes+8cQTPProoxe1/8qgT58+TJkyhZkzZzJmzJgS23zyySe0aNGCli1bXvB+7r77bu688068vb0veBvncvjwYZ566iliYmJo1aqV02cX87ciUlUpAImU0l133eX0ftWqVSxatKjY8n/Kzs7Gz8/vvPfj6el5QfUBeHh44OGh/7zj4+Np2LAhn3zySYkBaOXKlezdu5fnnnvuovbj7u6Ou7v7RW3jYlzM34pIVaVLYCLl4KqrrqJ58+asX7+eK6+8Ej8/Px577DEAvvrqK2688UaioqLw9vamQYMGPP3001itVqdt/HNcR9F4i0mTJvHWW2/RoEEDvL29ad++PWvXrnVat6QxQBaLhaFDhzJ37lyaN2+Ot7c3zZo1Y8GCBcXqX7ZsGe3atcPHx4cGDRrw5ptvnve4op9//pnbb7+dOnXq4O3tTXR0NP/5z3/IyckpdnwBAQEcOnSIpKQkAgICqFGjBg8//HCx30Vqair9+/cnKCiI4OBg+vXrR2pq6jlrAXsv0I4dO9iwYUOxz2bOnInFYqF3797k5+czZswY2rZtS1BQEP7+/nTp0oWlS5eecx8ljQEyDINnnnmG2rVr4+fnx9VXX82vv/5abN2TJ0/y8MMP06JFCwICAggMDKR79+5s3rzZ0WbZsmW0b98egAEDBjgusxaNvSlpDFBWVhYPPfQQ0dHReHt706hRIyZNmoRhGE7tSvN3cb5++OEHunTpgr+/P8HBwdx8881s377dqU1GRgYPPvggMTExeHt7U7NmTa677jqn8/THH39w2223ERERgY+PD7Vr1+bOO+8kLS3tgmsTKaJ/IoqUkxMnTtC9e3fuvPNO7rrrLsLDwwH7l2VAQAAjR44kICCAH374gTFjxpCens7EiRPPud2ZM2eSkZHBv//9bywWCy+88AK33nore/bsOWdPwC+//MLs2bMZPHgw1apV49VXX+W2227jwIEDhIaGArBx40a6detGZGQkTz31FFarlfHjx1OjRo3zOu5Zs2aRnZ3NAw88QGhoKGvWrGHKlCn8+eefzJo1y6mt1WolMTGR+Ph4Jk2axOLFi5k8eTINGjTggQceAOxB4uabb+aXX37h/vvvp0mTJsyZM4d+/fqdVz19+vThqaeeYubMmbRp08Zp359//jldunShTp06HD9+nHfeeYfevXtz3333kZGRwfTp00lMTGTNmjXFLjudy5gxY3jmmWe44YYbuOGGG9iwYQPXX389+fn5Tu327NnD3Llzuf3226lXrx5Hjx7lzTffpGvXrvz2229ERUXRpEkTxo8fz5gxYxg0aBBdunQBoFOnTiXu2zAMbrrpJpYuXcrAgQNp1aoVCxcu5JFHHuHQoUO89NJLTu3P5+/ifC1evJju3btTv359xo0bR05ODlOmTKFz585s2LDBEdTuv/9+vvjiC4YOHUrTpk05ceIEv/zyC9u3b6dNmzbk5+eTmJhIXl4ew4YNIyIigkOHDjFv3jxSU1MJCgoqVV0ixRgiclGGDBli/PM/pa5duxqAMW3atGLts7Oziy3797//bfj5+Rm5ubmOZf369TPq1q3reL93714DMEJDQ42TJ086ln/11VcGYHzzzTeOZWPHji1WE2B4eXkZu3btcizbvHmzARhTpkxxLOvRo4fh5+dnHDp0yLHsjz/+MDw8PIptsyQlHd+ECRMMi8Vi7N+/3+n4AGP8+PFObVu3bm20bdvW8X7u3LkGYLzwwguOZYWFhUaXLl0MwHjvvffOWVP79u2N2rVrG1ar1bFswYIFBmC8+eabjm3m5eU5rXfq1CkjPDzcuOeee5yWA8bYsWMd79977z0DMPbu3WsYhmGkpKQYXl5exo033mjYbDZHu8cee8wAjH79+jmW5ebmOtVlGPZz7e3t7fS7Wbt27RmP959/K0W/s2eeecapXc+ePQ2LxeL0N3C+fxclKfqbPL2mVq1aGTVr1jROnDjhtD03Nzejb9++jmVBQUHGkCFDzrjtjRs3GoAxa9ass9YgcqF0CUyknHh7ezNgwIBiy319fR0/Z2RkcPz4cbp06UJ2djY7duw453Z79epFSEiI431Rb8CePXvOuW5CQgINGjRwvG/ZsiWBgYGOda1WK4sXLyYpKYmoqChHu4YNG9K9e/dzbh+cjy8rK4vjx4/TqVMnDMNg48aNxdrff//9Tu+7dOnidCzz58/Hw8PD0SME9jE3w4YNO696wD5u688//+Snn35yLJs5cyZeXl7cfvvtjm16eXkBYLPZOHnyJIWFhbRr167Ey2dns3jxYvLz8xk2bJjTZcMHH3ywWFtvb2/c3Oz/V2y1Wjlx4gQBAQE0atSo1PstMn/+fNzd3Rk+fLjT8oceegjDMPjuu++clp/r7+J8HTlyhE2bNtG/f3+qV6/utL3rrruO+fPnO5YFBwezevVqDh8+XOK2inp4Fi5cSHZ2dqnqEDkfCkAi5aRWrVqOL9TT/frrr9xyyy0EBQURGBhIjRo1HAOoz2dsQ506dZzeF4WhU6dOlXrdovWL1k1JSSEnJ4eGDRsWa1fSspIcOHDA8QVYNK6na9euQPHj8/HxKXZp7fR6APbv309kZCQBAQFO7Ro1anRe9QDceeeduLu7M3PmTAByc3OZM2cO3bt3dwqT77//Pi1btsTHx4fQ0FBq1KjBt99+W+oxJ/v37wcgNjbWaXmNGjWc9gf2sPXSSy8RGxuLt7c3YWFh1KhRgy1btlzwWJf9+/cTFRVFtWrVnJYX3ZlYVF+Rc/1dlGa/UPK5adKkCcePHycrKwuAF154gW3bthEdHU2HDh0YN26cU+CqV68eI0eO5J133iEsLIzExERef/11jf+RMqMAJFJOTu8JKZKamkrXrl3ZvHkz48eP55tvvmHRokU8//zzAOd1K/OZ7jYy/jG4tazXPR9Wq5XrrruOb7/9llGjRjF37lwWLVrkGKz7z+Nz1Z1TRQNsv/zySwoKCvjmm2/IyMigT58+jjYfffQR/fv3p0GDBkyfPp0FCxawaNEirrnmmnK9xfx///sfI0eO5Morr+Sjjz5i4cKFLFq0iGbNmrns1vby/rsoyR133MGePXuYMmUKUVFRTJw4kWbNmjn1Tk2ePJktW7bw2GOPkZOTw/Dhw2nWrBl//vlnudUlVYcGQYu40LJlyzhx4gSzZ8/myiuvdCzfu3eviVX9rWbNmvj4+JQ4ceDZJhMssnXrVn7//Xfef/99+vbt61i+aNGiC66pbt26LFmyhMzMTKdeoJ07d5ZqO3369GHBggV89913zJw5k8DAQHr06OH4/IsvvqB+/frMnj3b6bLV2LFjL6hmsN/FVL9+fcfyY8eOFetV+eKLL7j66quZPn260/LU1FTCwsIc70szs3fdunVZvHgxGRkZTr1ARZdYi+ora0XbLenc7Nixg7CwMPz9/R3LIiMjGTx4MIMHDyYlJYU2bdrw7LPPOl1ubdGiBS1atOCJJ55gxYoVdO7cmWnTpvHMM8+UyzFI1aEeIBEXKvqX9un/ss7Pz+eNN94wqyQn7u7uJCQkMHfuXKexGbt27So2buRM64Pz8RmGwSuvvHLBNd1www0UFhYydepUxzKr1cqUKVNKtZ2kpCT8/Px44403+O6777j11lvx8fE5a+2rV69m5cqVpa45ISEBT09PpkyZ4rS9l19+uVhbd3f3Yj0ts2bN4tChQ07LioLD+dz+f8MNN2C1Wnnttdeclr/00ktYLJbzHs9VWpGRkbRq1Yr333/fqc5t27bx/fffc8MNNwD28/fPS1k1a9YkKiqKvLw8ANLT0yksLHRq06JFC9zc3BxtRC6GeoBEXKhTp06EhITQr18/x2MaPvzww3K91FBa48aN4/vvv6dz58488MADji/S5s2bn/MxDI0bN6ZBgwY8/PDDHDp0iMDAQL788stSjyU5XY8ePejcuTOPPvoo+/bto2nTpsyePbvUY0ECAgJISkpyjAM6/fIXwL/+9S9mz57NLbfcwo033sjevXuZNm0aTZs2JTMzs1T7KprPaMKECfzrX//ihhtuYOPGjXz33XdOvTpF+x0/fjwDBgygU6dObN26lY8//tip5wigQYMGBAcHM23aNKpVq4a/vz/x8fHUq1ev2P579OjB1VdfzeOPP86+ffuIi4vj+++/56uvvuLBBx90GvBc1iZOnEj37t3p2LEjAwcOdNwGHxQU5Hh+WkZGBrVr16Znz57ExcUREBDA4sWLWbt2LZMnTwbscwkNHTqU22+/ncsuu4zCwkI+/PBD3N3due2228qtfqk61AMk4kKhoaHMmzePyMhInnjiCSZNmsR1113HCy+8YHZpDm3btuW7774jJCSEJ598kunTpzN+/HiuvfZapx6Tknh6evLNN9/QqlUrJkyYwFNPPUVsbCwffPDBBdfj5ubG119/TZ8+ffjoo494/PHHqVWrFu+//36pt1UUeiIjI7nmmmucPuvfvz//+9//2Lx5M8OHD2fhwoV89NFHtGvX7oLqfuaZZ3jqqafYuHEjjzzyCLt37+b77793ugQE8Nhjj/HQQw+xcOFCRowYwYYNG/j222+Jjo52aufp6cn777+Pu7s7999/P7179+bHH38scd9Fv7MHH3yQefPm8eCDD/Lbb78xceJEXnzxxQs6nvOVkJDAggULCA0NZcyYMUyaNInLL7+c5cuXO8Kan58fgwcPZtOmTYwdO5b//Oc/7Ny5kzfeeIORI0cCEBcXR2JiIt988w0jR45k3LhxBAQE8N1333H55ZeX6zFI1WAxKtI/PUWkwkpKSuLXX3/ljz/+MLsUEZGLph4gESnmn4+t+OOPP5g/fz5XXXWVOQWJiJQx9QCJSDGRkZH079+f+vXrs3//fqZOnUpeXh4bN24sNreNiMilSIOgRaSYbt268cknn5CcnIy3tzcdO3bkf//7n8KPiFQa6gESERGRKkdjgERERKTKUQASERGRKkdjgEpgs9k4fPgw1apVK9X08yIiImIewzDIyMggKioKN7ez9/EoAJXg8OHDxSYhExERkUvDwYMHqV279lnbKACVoOjhgQcPHiQwMNDkakREROR8pKenEx0d7fQQ4DNRACpB0WWvwMBABSAREZFLzPkMX9EgaBEREalyFIBERESkylEAEhERkSpHY4BERKTcWa1WCgoKzC5DLnGenp64u7uXybYUgEREpNwYhkFycjKpqalmlyKVRHBwMBERERc9T58CkIiIlJui8FOzZk38/Pw0uaxcMMMwyM7OJiUlBYDIyMiL2p4CkIiIlAur1eoIP6GhoWaXI5WAr68vACkpKdSsWfOiLodpELSIiJSLojE/fn5+JlcilUnR39PFjilTABIRkXKly15Slsrq70kBSERERKocBSAREREXiImJ4eWXXz7v9suWLcNisZT7HXQzZswgODi4XPdRESkAiYiInMZisZz1NW7cuAva7tq1axk0aNB5t+/UqRNHjhwhKCjogvYnZ6e7wFwoPS+dUzmn8PP0o4Z/DbPLERGREhw5csTx82effcaYMWPYuXOnY1lAQIDjZ8MwsFqteHic++u0Ro3S/f++l5cXERERpVpHzp96gFxoyuopxLwSw+glo80uRUREziAiIsLxCgoKwmKxON7v2LGDatWq8d1339G2bVu8vb355Zdf2L17NzfffDPh4eEEBATQvn17Fi9e7LTdf14Cs1gsvPPOO9xyyy34+fkRGxvL119/7fj8n5fAii5VLVy4kCZNmhAQEEC3bt2cAlthYSHDhw8nODiY0NBQRo0aRb9+/UhKSirV72Dq1Kk0aNAALy8vGjVqxIcffuj4zDAMxo0bR506dfD29iYqKorhw4c7Pn/jjTeIjY3Fx8eH8PBwevbsWap9u4oCkAt5uNn/hVBoKzS5EhERcxiGQVZ+likvwzDK7DgeffRRnnvuObZv307Lli3JzMzkhhtuYMmSJWzcuJFu3brRo0cPDhw4cNbtPPXUU9xxxx1s2bKFG264gT59+nDy5Mkzts/OzmbSpEl8+OGH/PTTTxw4cICHH37Y8fnzzz/Pxx9/zHvvvcfy5ctJT09n7ty5pTq2OXPmMGLECB566CG2bdvGv//9bwYMGMDSpUsB+PLLL3nppZd48803+eOPP5g7dy4tWrQAYN26dQwfPpzx48ezc+dOFixYwJVXXlmq/buKLoG5kKe7J6AAJCJVV3ZBNgETAs7dsBxkjs7E38u/TLY1fvx4rrvuOsf76tWrExcX53j/9NNPM2fOHL7++muGDh16xu3079+f3r17A/C///2PV199lTVr1tCtW7cS2xcUFDBt2jQaNGgAwNChQxk/frzj8ylTpjB69GhuueUWAF577TXmz59fqmObNGkS/fv3Z/DgwQCMHDmSVatWMWnSJK6++moOHDhAREQECQkJeHp6UqdOHTp06ADAgQMH8Pf351//+hfVqlWjbt26tG7dulT7dxX1ALlQUQ9QgU0PBBQRuZS1a9fO6X1mZiYPP/wwTZo0ITg4mICAALZv337OHqCWLVs6fvb39ycwMNDxqIeS+Pn5OcIP2B8HUdQ+LS2No0ePOsIIgLu7O23bti3VsW3fvp3OnTs7LevcuTPbt28H4PbbbycnJ4f69etz3333MWfOHAoL7f+wv+6666hbty7169fn7rvv5uOPPyY7O7tU+3cV9QC5kKebeoBEpGrz8/Qjc3SmafsuK/7+zj1JDz/8MIsWLWLSpEk0bNgQX19fevbsSX5+/lm34+np6fTeYrFgs9lK1b4sL+2dj+joaHbu3MnixYtZtGgRgwcPZuLEifz4449Uq1aNDRs2sGzZMr7//nvGjBnDuHHjWLt2bYW71V49QC7k6AGyqgdIRKomi8WCv5e/Ka/ynJF6+fLl9O/fn1tuuYUWLVoQERHBvn37ym1/JQkKCiI8PJy1a9c6llmtVjZs2FCq7TRp0oTly5c7LVu+fDlNmzZ1vPf19aVHjx68+uqrLFu2jJUrV7J161YAPDw8SEhI4IUXXmDLli3s27ePH3744SKOrHyoB8iFNAZIRKRyio2NZfbs2fTo0QOLxcKTTz551p6c8jJs2DAmTJhAw4YNady4MVOmTOHUqVOlCn+PPPIId9xxB61btyYhIYFvvvmG2bNnO+5qmzFjBlarlfj4ePz8/Pjoo4/w9fWlbt26zJs3jz179nDllVcSEhLC/PnzsdlsNGrUqLwO+YIpALmQxgCJiFROL774Ivfccw+dOnUiLCyMUaNGkZ6e7vI6Ro0aRXJyMn379sXd3Z1BgwaRmJhYqqemJyUl8corrzBp0iRGjBhBvXr1eO+997jqqqsACA4O5rnnnmPkyJFYrVZatGjBN998Q2hoKMHBwcyePZtx48aRm5tLbGwsn3zyCc2aNSunI75wFsPVFw8vAenp6QQFBZGWlkZgYGCZbfezbZ9x55d3clXMVSztt7TMtisiUhHl5uayd+9e6tWrh4+Pj9nlVEk2m40mTZpwxx138PTTT5tdTpk4299Vab6/1QPkQhoDJCIi5Wn//v18//33dO3alby8PF577TX27t3L//3f/5ldWoWjQdAupIkQRUSkPLm5uTFjxgzat29P586d2bp1K4sXL6ZJkyZml1bhqAfIhTQIWkREylN0dHSxO7ikZOoBciENghYREakYKkQAev3114mJicHHx4f4+HjWrFlz1vazZs2icePG+Pj40KJFi2LTfPfv3x+LxeL0OtO04q6kiRBFREQqBtMD0GeffcbIkSMZO3YsGzZsIC4ujsTExDNOBb5ixQp69+7NwIED2bhxI0lJSSQlJbFt2zandkVPyC16ffLJJ644nLPSIGgREZGKwfQA9OKLL3LfffcxYMAAmjZtyrRp0/Dz8+Pdd98tsf0rr7xCt27deOSRR2jSpAlPP/00bdq04bXXXnNq5+3tTUREhOMVEhLiisM5K40BEhERqRhMDUD5+fmsX7+ehIQExzI3NzcSEhJYuXJlieusXLnSqT1AYmJisfbLli2jZs2aNGrUiAceeIATJ06csY68vDzS09OdXuVBY4BEREQqBlMD0PHjx7FarYSHhzstDw8PJzk5ucR1kpOTz9m+W7dufPDBByxZsoTnn3+eH3/8ke7du2O1Wkvc5oQJEwgKCnK8oqOjL/LISqYxQCIiIhWD6ZfAysOdd97JTTfdRIsWLUhKSmLevHmsXbuWZcuWldh+9OjRpKWlOV4HDx4sl7o0D5CISNVx1VVX8eCDDzrex8TE8PLLL591HYvFwty5cy9632W1nbMZN24crVq1Ktd9lCdTA1BYWBju7u4cPXrUafnRo0eJiIgocZ2IiIhStQeoX78+YWFh7Nq1q8TPvb29CQwMdHqVBw2CFhGp+Hr06HHGO4d//vlnLBYLW7ZsKfV2165dy6BBgy62PCdnCiFHjhyhe/fuZbqvysbUAOTl5UXbtm1ZsmSJY5nNZmPJkiV07NixxHU6duzo1B5g0aJFZ2wP8Oeff3LixAkiIyPLpvALpEHQIiIV38CBA1m0aBF//vlnsc/ee+892rVrR8uWLUu93Ro1auDn51cWJZ5TREQE3t7eLtnXpcr0S2AjR47k7bff5v3332f79u088MADZGVlMWDAAAD69u3L6NGjHe1HjBjBggULmDx5Mjt27GDcuHGsW7eOoUOHApCZmckjjzzCqlWr2LdvH0uWLOHmm2+mYcOGJCYmmnKMRTQIWkSk4vvXv/5FjRo1mDFjhtPyzMxMZs2axcCBAzlx4gS9e/emVq1a+Pn50aJFi3NOt/LPS2B//PEHV155JT4+PjRt2pRFixYVW2fUqFFcdtll+Pn5Ub9+fZ588kkKCuzfITNmzOCpp55i8+bNjjnvimr+5yWwrVu3cs011+Dr60toaCiDBg0iMzPT8Xn//v1JSkpi0qRJREZGEhoaypAhQxz7Oh82m43x48dTu3ZtvL29adWqFQsWLHB8np+fz9ChQ4mMjMTHx4e6desyYcIEAAzDYNy4cdSpUwdvb2+ioqIYPnz4ee/7Qpj+KIxevXpx7NgxxowZQ3JysuMXVjTQ+cCBA7i5/Z3TOnXqxMyZM3niiSd47LHHiI2NZe7cuTRv3hwAd3d3tmzZwvvvv09qaipRUVFcf/31PP3006anYQ2CFpGqzjAgO9ucffv5gcVy7nYeHh707duXGTNm8Pjjj2P5a6VZs2ZhtVrp3bs3mZmZtG3bllGjRhEYGMi3337L3XffTYMGDejQocM592Gz2bj11lsJDw9n9erVpKWlOY0XKlKtWjVmzJhBVFQUW7du5b777qNatWr897//pVevXmzbto0FCxawePFiAIKCgoptIysri8TERDp27MjatWtJSUnh3nvvZejQoU4hb+nSpURGRrJ06VJ27dpFr169aNWqFffdd9+5f2nYp6mZPHkyb775Jq1bt+bdd9/lpptu4tdffyU2NpZXX32Vr7/+ms8//5w6depw8OBBx5jbL7/8kpdeeolPP/2UZs2akZyczObNm89rvxfMkGLS0tIMwEhLSyvT7aZkphiMw2AchtVmLdNti4hUNDk5OcZvv/1m5OTkOJZlZhqGPQa5/pWZef61b9++3QCMpUuXOpZ16dLFuOuuu864zo033mg89NBDjvddu3Y1RowY4Xhft25d46WXXjIMwzAWLlxoeHh4GIcOHXJ8/t133xmAMWfOnDPuY+LEiUbbtm0d78eOHWvExcUVa3f6dt566y0jJCTEyDztF/Dtt98abm5uRnJysmEYhtGvXz+jbt26RmFhoaPN7bffbvTq1euMtfxz31FRUcazzz7r1KZ9+/bG4MGDDcMwjGHDhhnXXHONYbPZim1r8uTJxmWXXWbk5+efcX9FSvq7KlKa72/TL4FVJUVjgEC9QCIiFVnjxo3p1KmTY1LeXbt28fPPPzNw4EAArFYrTz/9NC1atKB69eoEBASwcOFCDhw4cF7b3759O9HR0URFRTmWlTSW9bPPPqNz585EREQQEBDAE088cd77OH1fcXFx+Pv7O5Z17twZm83Gzp07HcuaNWuGu7u7431kZOQZn8rwT+np6Rw+fJjOnTs7Le/cuTPbt28H7JfZNm3aRKNGjRg+fDjff/+9o93tt99OTk4O9evX57777mPOnDkUFpbv96QCkAsVjQEC3QkmIlWTnx9kZprzKu3444EDB/Lll1+SkZHBe++9R4MGDejatSsAEydO5JVXXmHUqFEsXbqUTZs2kZiYSH5+fpn9rlauXEmfPn244YYbmDdvHhs3buTxxx8v032cztPT0+m9xWLBZrOV2fbbtGnD3r17efrpp8nJyeGOO+6gZ8+egP0p9jt37uSNN97A19eXwYMHc+WVV5ZqDFJpmT4GqCopGgME6gESkarJYoHTOiIqtDvuuIMRI0Ywc+ZMPvjgAx544AHHeKDly5dz8803c9dddwH2MT2///47TZs2Pa9tN2nShIMHD3LkyBHHHcqrVq1yarNixQrq1q3L448/7li2f/9+pzZeXl5nnOT39H3NmDGDrKwsRy/Q8uXLcXNzo1GjRudV77kEBgYSFRXF8uXLHSGxaD+nj4kKDAykV69e9OrVi549e9KtWzdOnjxJ9erV8fX1pUePHvTo0YMhQ4bQuHFjtm7dSps2bcqkxn9SAHKh03uAFIBERCq2gIAAevXqxejRo0lPT6d///6Oz2JjY/niiy9YsWIFISEhvPjiixw9evS8A1BCQgKXXXYZ/fr1Y+LEiaSnpzsFnaJ9HDhwgE8//ZT27dvz7bffMmfOHKc2MTEx7N27l02bNlG7dm2qVatW7IafPn36MHbsWPr168e4ceM4duwYw4YN4+677y72ZIWL8cgjjzB27FgaNGhAq1ateO+999i0aRMff/wxYH/2Z2RkJK1bt8bNzY1Zs2YRERFBcHAwM2bMwGq1Eh8fj5+fHx999BG+vr7UrVu3zOr7J10CcyE3y9+/bt0KLyJS8Q0cOJBTp06RmJjoNF7niSeeoE2bNiQmJnLVVVcRERFBUlLSeW/Xzc2NOXPmkJOTQ4cOHbj33nt59tlnndrcdNNN/Oc//2Ho0KG0atWKFStW8OSTTzq1ue222+jWrRtXX301NWrUKPFWfD8/PxYuXMjJkydp3749PXv25Nprry32EPGLNXz4cEaOHMlDDz1EixYtWLBgAV9//TWxsbGA/Y62F154gXbt2tG+fXv27dvH/PnzcXNzIzg4mLfffpvOnTvTsmVLFi9ezDfffENoaGiZ1ng6i2EYRrlt/RKVnp5OUFAQaWlpZT4rtNfTXhTYCjj4n4PUDqxdptsWEalIcnNz2bt3L/Xq1cPHx8fscqSSONvfVWm+v9UD5GJ6HIaIiIj5FIBcTI/DEBERMZ8CkIvpcRgiIiLmUwByMT0OQ0RExHwKQC6mMUAiUtXoXhspS2X196QA5GIaAyQiVUXRzMLZZj39VCqlor+nf85cXVqaCNHFinqAFIBEpLJzd3cnODjY8TwpPz8/x0zKIqVlGAbZ2dmkpKQQHBzs9NyyC6EA5GIaBC0iVUlERATAeT9UU+RcgoODHX9XF0MByMU0CFpEqhKLxUJkZCQ1a9Ys1wdbStXg6el50T0/RRSAXEyDoEWkKnJ3dy+zLy6RsqBB0C6mQdAiIiLmUwByMY0BEhERMZ8CkItpDJCIiIj5FIBcTGOAREREzKcA5GIaAyQiImI+BSAX00SIIiIi5lMAcrGiMUAaBC0iImIeBSAXUw+QiIiI+RSAXEyDoEVERMynAORiGgQtIiJiPgUgF/OwaCJEERERsykAuZh6gERERMynAORiGgQtIiJiPgUgF3PcBq9B0CIiIqZRAHIx9QCJiIiYTwHIxYrGAGkQtIiIiHkUgFxMPUAiIiLmUwByoS1bYMuCdrD/Co0BEhERMZECkAvNmwdfvXATbOqnHiARERETKQC5kJfXXz9YvTQGSERExEQKQC7kCEA2T/UAiYiImEgByIVO7wFSABIRETGPApALeXr+9YMugYmIiJhKAciF1AMkIiJSMSgAudDfAchTt8GLiIiYSAHIhdQDJCIiUjEoALmQxgCJiIhUDApALqQeIBERkYpBAciFTp8HSGOAREREzKMA5EKnXwJTD5CIiIh5FIBcSJfAREREKgYFIBfSs8BEREQqBgUgFzp9HiD1AImIiJhHAciFnG6D1yBoERER0ygAuZDGAImIiFQMCkAupDFAIiIiFYMCkAs5AhBuFBTazCxFRESkSlMAciHHGCCgsEC/ehEREbNUiG/h119/nZiYGHx8fIiPj2fNmjVnbT9r1iwaN26Mj48PLVq0YP78+Wdse//992OxWHj55ZfLuOrS+7sHCAryLeYVIiIiUsWZHoA+++wzRo4cydixY9mwYQNxcXEkJiaSkpJSYvsVK1bQu3dvBg4cyMaNG0lKSiIpKYlt27YVaztnzhxWrVpFVFRUeR/GeXHuAVIAEhERMYvpAejFF1/kvvvuY8CAATRt2pRp06bh5+fHu+++W2L7V155hW7duvHII4/QpEkTnn76adq0acNrr73m1O7QoUMMGzaMjz/+GM/Tk4eJ3NzAw8MA7AHIMAyTKxIREamaTA1A+fn5rF+/noSEBMcyNzc3EhISWLlyZYnrrFy50qk9QGJiolN7m83G3XffzSOPPEKzZs3OWUdeXh7p6elOr/Jy+lxANkMDoUVERMxgagA6fvw4VquV8PBwp+Xh4eEkJyeXuE5ycvI52z///PN4eHgwfPjw86pjwoQJBAUFOV7R0dGlPJLzp1vhRUREzGf6JbCytn79el555RVmzJiBxXJ+42xGjx5NWlqa43Xw4MFyq8+zKADZ9DgMERERs5gagMLCwnB3d+fo0aNOy48ePUpERESJ60RERJy1/c8//0xKSgp16tTBw8MDDw8P9u/fz0MPPURMTEyJ2/T29iYwMNDpVV68T+8B0uMwRERETGFqAPLy8qJt27YsWbLEscxms7FkyRI6duxY4jodO3Z0ag+waNEiR/u7776bLVu2sGnTJscrKiqKRx55hIULF5bfwZyn08cAqQdIRETEHB5mFzBy5Ej69etHu3bt6NChAy+//DJZWVkMGDAAgL59+1KrVi0mTJgAwIgRI+jatSuTJ0/mxhtv5NNPP2XdunW89dZbAISGhhIaGuq0D09PTyIiImjUqJFrD64EXl5/XZZTABIRETGN6QGoV69eHDt2jDFjxpCcnEyrVq1YsGCBY6DzgQMHcHP7u6OqU6dOzJw5kyeeeILHHnuM2NhY5s6dS/Pmzc06hFL5exC0pwZBi4iImMRiaDKaYtLT0wkKCiItLa3MxwO1bQsbNgB9urF7yhvUD6lfptsXERGpqkrz/V3p7gKr6E4fA6RB0CIiIuZQAHKx0+cB0hggERERcygAuZjXafMAaQyQiIiIORSAXEw9QCIiIuZTAHIxjQESERExnwKQi6kHSERExHwKQC52+jxACkAiIiLmUAByMT0NXkRExHwKQC6mZ4GJiIiYTwHIxbz0NHgRERHTKQC52OnzAKkHSERExBwKQC6mMUAiIiLmUwByMY0BEhERMZ8CkItpDJCIiIj5FIBcTPMAiYiImE8ByMV0CUxERMR8CkAupkHQIiIi5lMAcjE9C0xERMR8CkAudvo8QBoELSIiYg4FIBfTGCARERHzKQC5mMYAiYiImE8ByMU0BkhERMR8CkAupnmAREREzKcA5GKnjwHSIGgRERFzKAC5mC6BiYiImE8ByMU0CFpERMR8CkAudvo8QOoBEhERMYcCkIs5jQFSD5CIiIgpFIBcTGOAREREzKcA5GJOY4B0F5iIiIgpFIBcTPMAiYiImE8ByMUcY4BsXhRYFYBERETMoADkYo4eICC/wDCvEBERkSpMAcjFnAJQvnl1iIiIVGUKQC7mHIDUAyQiImIGBSAXc3f/++eCfIt5hYiIiFRhCkAuZrGAh6cVgHzdBS8iImIKBSATeHraL30VFqgHSERExAwKQCbw8LIBGgQtIiJiFgUgE3h4FPUA6dcvIiJiBn0Dm8DTSwFIRETETPoGNkHRbNAFGgQtIiJiCgUgE3ipB0hERMRU+gY2gcdfPUAKQCIiIubQN7AJ1AMkIiJiLn0Dm8DL0z7/T2Gh5gESERExgwKQCby87f9rLXA/e0MREREpFwpAJvD6awyQApCIiIg5FIBM4OVlv/RlLVQAEhERMYMCkAm8/wpAhtUdwzBMrkZERKTqUQAyQVEPEFYvCm2F5hYjIiJSBSkAmcDHWwFIRETETApAJvA+rQeowKbnYYiIiLiaApAJfLz/+rVbPckrzDO3GBERkSqoQgSg119/nZiYGHx8fIiPj2fNmjVnbT9r1iwaN26Mj48PLVq0YP78+U6fjxs3jsaNG+Pv709ISAgJCQmsXr26PA+hVLy8igKQFzmFOeYWIyIiUgWZHoA+++wzRo4cydixY9mwYQNxcXEkJiaSkpJSYvsVK1bQu3dvBg4cyMaNG0lKSiIpKYlt27Y52lx22WW89tprbN26lV9++YWYmBiuv/56jh075qrDOisvr79+sHqRXZBtai0iIiJVkcUw+T7s+Ph42rdvz2uvvQaAzWYjOjqaYcOG8eijjxZr36tXL7Kyspg3b55j2eWXX06rVq2YNm1aiftIT08nKCiIxYsXc+21156zpqL2aWlpBAYGXuCRndljj8GECUD8y6yb3YW2UW3LfB8iIiJVTWm+v03tAcrPz2f9+vUkJCQ4lrm5uZGQkMDKlStLXGflypVO7QESExPP2D4/P5+33nqLoKAg4uLiSmyTl5dHenq606s8OXqAbJ7qARIRETGBqQHo+PHjWK1WwsPDnZaHh4eTnJxc4jrJycnn1X7evHkEBATg4+PDSy+9xKJFiwgLCytxmxMmTCAoKMjxio6OvoijOjfPvx6FoUtgIiIi5jB9DFB5ufrqq9m0aRMrVqygW7du3HHHHWccVzR69GjS0tIcr4MHD5ZrbRoDJCIiYi5TA1BYWBju7u4cPXrUafnRo0eJiIgocZ2IiIjzau/v70/Dhg25/PLLmT59Oh4eHkyfPr3EbXp7exMYGOj0Kk+nB6Csgqxy3ZeIiIgUZ2oA8vLyom3btixZssSxzGazsWTJEjp27FjiOh07dnRqD7Bo0aIztj99u3l5FWPOnb8DkMYAiYiImMHD7AJGjhxJv379aNeuHR06dODll18mKyuLAQMGANC3b19q1arFhAkTABgxYgRdu3Zl8uTJ3HjjjXz66aesW7eOt956C4CsrCyeffZZbrrpJiIjIzl+/Divv/46hw4d4vbbbzftOE+nMUAiIiLmMj0A9erVi2PHjjFmzBiSk5Np1aoVCxYscAx0PnDgAG5uf3dUderUiZkzZ/LEE0/w2GOPERsby9y5c2nevDkA7u7u7Nixg/fff5/jx48TGhpK+/bt+fnnn2nWrJkpx/hPGgMkIiJiLtPnAaqIynseoE8/hd69gZgfeOydJTx77bNlvg8REZGq5pKZB6iq0jxAIiIi5lIAMoHGAImIiJhLAcgETmOAChWAREREXO2CAtDBgwf5888/He/XrFnDgw8+6LgTS87OaR6gfM0DJCIi4moXFID+7//+j6VLlwL2R1Ncd911rFmzhscff5zx48eXaYGVkeYBEhERMdcFBaBt27bRoUMHAD7//HOaN2/OihUr+Pjjj5kxY0ZZ1lcpaQyQiIiIuS4oABUUFODt7Q3A4sWLuemmmwBo3LgxR44cKbvqKinNAyQiImKuCwpAzZo1Y9q0afz8888sWrSIbt26AXD48GFCQ0PLtMDKSAFIRETEXBcUgJ5//nnefPNNrrrqKnr37k1cXBwAX3/9tePSmJzZ6fMA6WGoIiIirndBj8K46qqrOH78OOnp6YSEhDiWDxo0CD8/vzIrrrLSGCARERFzXVAPUE5ODnl5eY7ws3//fl5++WV27txJzZo1y7TAykiXwERERMx1QQHo5ptv5oMPPgAgNTWV+Ph4Jk+eTFJSElOnTi3TAisjRwAy3MnOy0WPYxMREXGtCwpAGzZsoEuXLgB88cUXhIeHs3//fj744ANeffXVMi2wMnIEIACrJzmFOabVIiIiUhVdUADKzs6mWrVqAHz//ffceuutuLm5cfnll7N///4yLbAycowBArB66zKYiIiIi11QAGrYsCFz587l4MGDLFy4kOuvvx6AlJSUcz5+XsDbG9zd/3qT768AJCIi4mIXFIDGjBnDww8/TExMDB06dKBjx46AvTeodevWZVpgZWSxQHDwX29yQxSAREREXOyCboPv2bMnV1xxBUeOHHHMAQRw7bXXcsstt5RZcZVZSAicOAHkhOiBqCIiIi52QQEIICIigoiICMdT4WvXrq1JEEvBMX2SeoBERERc7oIugdlsNsaPH09QUBB169albt26BAcH8/TTT2Oz2cq6xkrJEYByFIBERERc7YJ6gB5//HGmT5/Oc889R+fOnQH45ZdfGDduHLm5uTz77LNlWmRlpB4gERER81xQAHr//fd55513HE+BB2jZsiW1atVi8ODBCkDn4fQeID0PTERExLUu6BLYyZMnady4cbHljRs35uTJkxddVFWgHiARERHzXFAAiouL47XXXiu2/LXXXqNly5YXXVRV4LgNXmOAREREXO6CLoG98MIL3HjjjSxevNgxB9DKlSs5ePAg8+fPL9MCKyvnHqA/Ta1FRESkqrmgHqCuXbvy+++/c8stt5Camkpqaiq33norv/76Kx9++GFZ11gpOY0B0jxAIiIiLnXB8wBFRUUVG+y8efNmpk+fzltvvXXRhVV2GgMkIiJingvqAZKLp3mAREREzKMAZBKnHqBCBSARERFXUgAyiSMAFfqSkVVgai0iIiJVTanGAN16661n/Tw1NfViaqlSAgPBYjEwDAtpqcqhIiIirlSqABQUFHTOz/v27XtRBVUVbm7gV62ArHQv0lPdzS5HRESkSilVAHrvvffKq44qqVqQPQBlpXuZXYqIiEiVomsvJgoMtgEoAImIiLiYApCJgv8KQDkZ3iZXIiIiUrUoAJmo6E6w3Ew/cwsRERGpYhSATFQ9xAJAvgKQiIiISykAmSi0uv3ur4KsAAzDMLkaERGRqkMByEQ1Qv+6CS83hJzCHHOLERERqUIUgExUM9TT/oOeByYiIuJSCkAmCg3969evJ8KLiIi4lAKQifREeBEREXMoAJno9CfCZ+VnmVqLiIhIVaIAZCL1AImIiJhDAchEjgBU6Edqpu4CExERcRUFIBMFBQEW++Mwjp0oNLcYERGRKkQByERubuDha7/0deykApCIiIirKACZzMvfPvj55EnNBC0iIuIqCkAm8w6w9wCdSlUAEhERcRUFIJP5VMsFIPWUxeRKREREqg4FIJP5VcsDFIBERERcSQHIZEHB9rvATp3SJTARERFXUQAyWdFcQGlp6gESERFxFQUgk4UGuwOQke5hciUiIiJVhwKQycKqewGQnelpciUiIiJVR4UIQK+//joxMTH4+PgQHx/PmjVrztp+1qxZNG7cGB8fH1q0aMH8+fMdnxUUFDBq1ChatGiBv78/UVFR9O3bl8OHD5f3YVyQiDAfAHIzvU2uREREpOowPQB99tlnjBw5krFjx7Jhwwbi4uJITEwkJSWlxPYrVqygd+/eDBw4kI0bN5KUlERSUhLbtm0DIDs7mw0bNvDkk0+yYcMGZs+ezc6dO7nppptceVjnLSrMH4CCbD8MQwOhRUREXMFimPytGx8fT/v27XnttdcAsNlsREdHM2zYMB599NFi7Xv16kVWVhbz5s1zLLv88stp1aoV06ZNK3Efa9eupUOHDuzfv586deqcs6b09HSCgoJIS0sjMDDwAo/s/Cz8IZtu1/pB9d/JOBJFgFdAue5PRESksirN97epPUD5+fmsX7+ehIQExzI3NzcSEhJYuXJlieusXLnSqT1AYmLiGdsDpKWlYbFYCA4OLvHzvLw80tPTnV6uEhHq+1cRQZzIPuGy/YqIiFRlpgag48ePY7VaCQ8Pd1oeHh5OcnJyieskJyeXqn1ubi6jRo2id+/eZ0yDEyZMICgoyPGKjo6+gKO5MMHBf93+nhvMiRwFIBEREVcwfQxQeSooKOCOO+7AMAymTp16xnajR48mLS3N8Tp48KDLanR0Slm9OXLqlMv2KyIiUpWZOvlMWFgY7u7uHD161Gn50aNHiYiIKHGdiIiI82pfFH7279/PDz/8cNZrgd7e3nh7m3MXVrVqgMUGhhsHU9KhqSlliIiIVCmm9gB5eXnRtm1blixZ4lhms9lYsmQJHTt2LHGdjh07OrUHWLRokVP7ovDzxx9/sHjxYkJDQ8vnAMqAmxt4+uYAcPhYtsnViIiIVA2mTz88cuRI+vXrR7t27ejQoQMvv/wyWVlZDBgwAIC+fftSq1YtJkyYAMCIESPo2rUrkydP5sYbb+TTTz9l3bp1vPXWW4A9/PTs2ZMNGzYwb948rFarY3xQ9erV8fLyMudAz8LbP5eCbH+OHFcAEhERcQXTA1CvXr04duwYY8aMITk5mVatWrFgwQLHQOcDBw7g5vZ3R1WnTp2YOXMmTzzxBI899hixsbHMnTuX5s2bA3Do0CG+/vprAFq1auW0r6VLl3LVVVe55LhKwzcgn8xjcOxkgdmliIiIVAmmzwNUEblyHiCA+q3+ZO/m2lzx0Cv8PGlEue9PRESkMrpk5gESu8AgewY9laosKiIi4goKQBVAyF9zAaWlWUyuREREpGpQAKoAQkPsQ7Ey03U6REREXEHfuBVAjeqeAGRleJpciYiISNWgAFQBhIf6AFCQ5Ue+Nd/kakRERCo/BaAK4PQHop7MOWluMSIiIlWAAlAFUL36X6chV0+EFxERcQUFoAogKOivH/REeBEREZdQAKoAHAEoTz1AIiIirqAAVAEEB//1Q24Qx7OPm1mKiIhIlaAAVAGc3gN0XD1AIiIi5U4BqAJwBCDDneQTmabWIiIiUhUoAFUAvr7g7mEF4MjxHJOrERERqfwUgCoAiwV8A+wTIB47pYkQRUREypsCUAUREGjvATpxstDkSkRERCo/BaAKIjDIAODkKZvJlYiIiFR+CkAVRHCQBYC0dJMLERERqQIUgCqIGtU9AMhMd6fAWmByNSIiIpWbAlAFUaO6t/2H3CCSM5PNLUZERKSSUwCqIEJC7JfAyA3iUMYhc4sRERGp5BSAKojTZ4M+lK4AJCIiUp4UgCqI058I/2f6n6bWIiIiUtkpAFUQpz8QVZfAREREypcCUAXhdAlMAUhERKRcKQBVEH/3AOkSmIiISHlTAKog/h4DpEHQIiIi5U0BqIJw9ADlhPJn2hEMwzCzHBERkUpNAaiCqFMHAgMNKPQl72ATTuacNLskERGRSksBqILw8ICrr/5rMsQ912kgtIiISDlSAKpArrvurx92X6dxQCIiIuVIAagCcQSgg53ZnXLE1FpEREQqMwWgCiQ2FvzDToLVm1XLvcwuR0REpNJSAKpALBa4rMN+ADavrGFyNSIiIpWXAlAF075LKgD7N8SaW4iIiEglpgBUwVxztX3+n4wD9Tl61ORiREREKikFoAqmWb2aELEBgB9+MLkYERGRSkoBqIKpHVgbotYBsO23ApOrERERqZwUgCqYIO8gPEPtcwBt35VjcjUiIiKVkwJQBWOxWKgekQnA3n1Wk6sRERGpnBSAKqCoaPulr0MHPUyuREREpHJSAKqAGtbzBOBEsh9WdQKJiIiUOQWgCqjNZRHgVoDN6s4RPRFDRESkzCkAVUDNI5pA4J8A7N9vcjEiIiKVkAJQBdS0RlMIsiefvXttJlcjIiJS+SgAVUB1g+riFmLvAdq085TJ1YiIiFQ+CkAVkLubOzWisgHY9keGydWIiIhUPgpAFVRMjP1/dQlMRESk7CkAVVBNG/oDcPSQj8mViIiIVD4KQBVU2yZhAGSkVMcwTC5GRESkklEAqqC6tIgBwFbgQ8oxXQYTEREpSwpAFVSTiPpQ7TAAa39LMbkaERGRykUBqILydPfEN8wefFZt03TQIiIiZUkBqAILjcwCYOvvaSZXIiIiUrkoAFVgderYRz/v3ltociUiIiKVi+kB6PXXXycmJgYfHx/i4+NZs2bNWdvPmjWLxo0b4+PjQ4sWLZg/f77T57Nnz+b6668nNDQUi8XCpk2byrH68tW4gS8Ah//0MrkSERGRysXUAPTZZ58xcuRIxo4dy4YNG4iLiyMxMZGUlJIH/a5YsYLevXszcOBANm7cSFJSEklJSWzbts3RJisriyuuuILnn3/eVYdRbto3qwFA6pHqFFgLTK5GRESk8rAYhnmzzMTHx9O+fXtee+01AGw2G9HR0QwbNoxHH320WPtevXqRlZXFvHnzHMsuv/xyWrVqxbRp05za7tu3j3r16rFx40ZatWpVqrrS09MJCgoiLS2NwMDA0h9YGTn4p406dQDDjVk/baFnl5am1SIiIlLRleb727QeoPz8fNavX09CQsLfxbi5kZCQwMqVK0tcZ+XKlU7tARITE8/Y/nzl5eWRnp7u9KoIomu7UbPVegBeeyPf5GpEREQqD9MC0PHjx7FarYSHhzstDw8PJzk5ucR1kpOTS9X+fE2YMIGgoCDHKzo6+qK2V5Zu6L0fgBXfNCInx+RiREREKgnTB0FXBKNHjyYtLc3xOnjwoNklOdxzexQE7aMgqxqffaZnYoiIiJQF0wJQWFgY7u7uHD161Gn50aNHiYiIKHGdiIiIUrU/X97e3gQGBjq9KooOtdvi0WE6AC+9lmtyNSIiIpWDaQHIy8uLtm3bsmTJEscym83GkiVL6NixY4nrdOzY0ak9wKJFi87YvjLw9vCm3b+2gFs+W9b7sn692RWJiIhc+ky9BDZy5Ejefvtt3n//fbZv384DDzxAVlYWAwYMAKBv376MHj3a0X7EiBEsWLCAyZMns2PHDsaNG8e6desYOnSoo83JkyfZtGkTv/32GwA7d+5k06ZNFz1OyEzXNm8BzT4HYNIkk4sRERGpBEwNQL169WLSpEmMGTOGVq1asWnTJhYsWOAY6HzgwAGOHPn7OVidOnVi5syZvPXWW8TFxfHFF18wd+5cmjdv7mjz9ddf07p1a2688UYA7rzzTlq3bl3sNvlLyRV1roDOEwH4/HPYs8fkgkRERC5xps4DVFFVlHmAHPXkpRPyfAi2D7+BXTfwwAPwxhtmVyUiIlKxXBLzAMn5C/QOJC48Dq6wz2793nvwj7HgIiIiUgoKQJeIga0HQt2f8Kq7ntxcjQUSERG5GApAl4iBbQYSWS2S/I5PAfYA9MEHJhclIiJyiVIAukT4ePjw387/hUbfEHjVOwDccw98/bXJhYmIiFyCFIAuIYPaDqJmQE3SrxxE5x67sFrhjjtg1y6zKxMREbm0KABdQvw8/Xi448PgZrCnyzVccWUBeXkaDyQiIlJaCkCXmCEdhnBZ6GUcyT6IT8JzAMyYobvCRERESkMB6BLj5+nHB0kf4GZxY7F1DLEtT5CXB6++anZlIiIilw4FoEtQfO14HrviMbDA4ZYPAvDGGwYZGebWJSIicqlQALpEPdn1SdpHtSer/kwI3UlqqoUnnj1hdlkiIiKXBAWgS5SXuxdL+y3lqWvG4tX1JQBefT6U554DPdxERETk7BSALmH+Xv6M6TqG397+L5Yu9gHRo0fDqFEKQSIiImejAFQJNKhen94PboXrHwJg4kT48EOTixIREanAFIAqiRHxI6DTi7hfOxaAIUNg926TixIREamgFIAqiQ61OhBfKx5r52eo23I/mZlw112Ql2d2ZSIiIhWPAlAlMjx+OLjZSLvhZnwCclm1Cvz8oE4duPZaGDkSPv4Y8vPNrlRERMRcCkCVSM+mPWkU2ohUn83k9rgdfE5is8HBg/DDD/DSS/ZeocmTza5URETEXApAlYiXuxcrB67k9Rtep+v1GfDfMHgoggff/owX30glsuMyACa/moXVam6tIiIiZrIYhm6Y/qf09HSCgoJIS0sjMDDQ7HIu2NM/Ps2YZWMACPQOJD0zD148BDmhfPJlBnfeWs3kCkVERMpOab6/1QNUiT1x5RM81NF+a3x6Xjpt6jQj5PJvABj9/D4TKxMRETGXh9kFSPmxWCxMvG4i0YHRGBgMbj+YTxpsoP9S2Le2KQvW/Ua3dk3NLlNERMTldAmsBJXlEtiZ1Gy+jWO/NqdG53lMfTiRiBqedOoEFovZlYmIiFw4XQKTsxr7UAQAx5b/i563eHLFFfD++yYXJSIi4kIKQFXQoLvCuPbWg1B7JdT4FYDHHoOsLJMLExERcREFoCrI0xMWfxnNxM+Ww7/bQPAejhyBTvd+wfQN0zmRfcLsEkVERMqVAlAV9lDHh3jg8oGQMBqALV92496nfyLsst34hJzks0V/mFyhiIhI+VAAqsIsFgtv3PgGB96ZzGUtT0FBAMx9Hw51IC+1Onfe7s2/P32StNw0xzq7Tu7ike8f4deUX02sXERE5OLoLrASVPa7wEqyfDlcfTX4+sKdA44z8/M8Mo/Ugro/Ej74LiZ3ew4PNw/u++Y+MvIziKoWxfpB64kIiDC7dBEREaB0398KQCWoigEI4NAhCAqCgADYvh3atS8kO8sDmnwBNw8En3TIrIH7vm5YI1fSpXUkS/ouwdPd0+zSRUREFIAuVlUNQP80bx4kJRlYrRYswfswLvsazy33U5DrBRYbNPmCpIE7+WDIg1Tzrsbx7ON8tOUjfD18uavlXfh7+TttLyMDNm6EsDCIjISQEJMOTEREKiUFoIukAPS3Vavg//4P9u79e1lMDOzb9/d79+i1xP1rJb9FPEGukQFAmF8Y/7n8P/zn8v/g6+lLYSFceSWsXPn3ekOHwpQpLjkMERGpAjQRopSZyy+399rce699jNC8ebBnD2zZAp1v3Afu+VgPtmfD1OHkTvuBppZbqR9Sn+PZx3n8h8e5fPrl7Di+g7FP57ByJbh55uNbLQeAqVMNpyB1JlYr3Hkn3HUX2GzlergiIlJFqAeoBOoBOn9Hkm08NmkXn75Vm9wMP3x8DHr/n8HBrN9ZcXQR2XVn4+1rI++tJWDzgFv7QMuZ8MH3sOc6uvbayIKPmnA82YdnnoGePSEhwXkfH34Iffvaf547F26+2eWHKSIilwBdArtICkCld+gQ3HMPfP/9mdsEtlnIfyat4veTO1m40MLJtz8Grwz8HmqF9cOvyPuzORb3AiLvHUzTzvuYdN0kmobG0aQJ7N5t30Z8vP0ymp5bJiIi/6QAdJEUgC6MzQaff26/g8ww4M8/Ye5cg1OnLFSvmcfOX70IC7Mnl7zCfOo3zuDw7lAIPADpdQAb4AbuufB/PfCIXUZC6icseLEn3oEZWHN9KMz3ZOlSuOoqM49UREQqIgWgi6QAVHby8+09Ng0bQq1azp+995691wjAzc3gyTdX8f3n9Vm5KBwsVmg8Bw51sIej60fCqQawdgixHfbyv/fWY7VZCQ8Ip2V4S6r7Vnf9wYmISIWiAHSRFIBcIy8P6tWDI0fg+efhv/+1LxswAD755O92PiEneXDma8xeu4Lfx84DwwOafwI+pyBsJ9T7gToNM/m/lncysM1A6gXX41TuKdwsbgpGIiJViALQRVIAcp1t2+C33+D2253H9WzbBi+/DAsW2P+3Z0+w2qxc0WMPq+bHFt9QwGG4egy0fheLGxg2C1g96RATR1KjJEJ8Q0jNTcXf05/usd1pWL2h0+p5efDDD9CgAcTGXvwYo3fftU8VMHYsuLtf3LZEROT8KABdJAWgiis9HWbPhhMn4NQpWLcOfv7ZIDv7r8QSvQKC9sPu6yA3GGK/g1YzIGw7uBWC/zHwTeWy0MvwcPPgePZxavnH4Pbp16z/KRwA/8A8rvzXn8x5LwZvL3fyCvP4eufXAHSK7kStwFolF/eXXbugUSP7mKgPPoC77y7HX4iIiDgoAF0kBaBLS14evPEGPPkkZGWdva3FvRCazsKIfxlqrQHDAnM+hK19sHjkY2CFQl8Agjt+ybBntjB99WccXnYDhO2Ay74jOjCaZjWb0Ti0MfVC6lGrWi0ahzWmWc1mANx3H7zzjn1/9erBjh3g5VWOvwAREQEUgC6aAtCl6eBBePVV8PaGbt3sj9r46CP44gtITbUPyE5P/7u9f7UCaoRb2bfLB9wKoPdNUH8xdf58hAMzngbDHZp8CQc6Q9ZfD3294nm45jFwKz4jY5vINnSrcS8Tbr8Xw+oJXumQH8i4F1IY+0jNMjnGkSPtcyFFRUH9+vD44/beJhERUQC6aApAldf69fbHb3z6qb3nqMirb58goO3XtItqR4vwFrz+VjZD/+3n+DwiwiA52X6ZrW3nU7TqvgGj9krSfDdzKONPNhzZQL41H757CVY/CDFLsTSdjTF/ClQ7jPd/mpPvlkp13+q0i2rn9KpVrRYWiwWbYWP3yd1sTdlK3aC6tIlsg+W0wUgrV0KnTs7H06ABbN0Kvr7l+VsTEbk0KABdJAWgyi8vD37/HX791f5g1q5di7eZOtXeo3Tvvfbnls2ZY79tPyfn7zaenhARATXCC8j33c9vq2tjy/fhvS8OERefSuc2oeQci4DLvoHrH4KQPbC/KyTHQf0lELEFd4s7/l7+WG1WsgqywOoOblZiQ2O5rv515BTmkJabzvoJL7B/c32Sbs3nqhuO8czjYRw/6k3vIb/z3yeyiQuPcwSm9Lx0PN088fUsnoy+2fkNP+7/kUc6PUJ4QHh5/YpFRFxOAegiKQDJmfz6K7z9tr03ZsMGKCws3qZdO1izxn4n2ezZ0LOngWFYcHc38K9mJT3V4+/GUWuh8Vyo8RsAblsGYNvZHUvQnxhXPAtxH4BHAey6Dj76HtzzYFgsBB+EX2+DWV/Ylz3QgpbNfElqlMSKP1ewdO9SfDx8uK/NfQyLH0a4XxSffJHDO6tmsppXofofRAfX5qs7v6JVRCt2HN/BzhM78XTzxNPNm3a12pg2hUBBgT1YioiUlgLQRVIAkvORnw/JyfZ5jIpep05Br172S1NFtm61j9X55hv7+7AwaN0ali2zf9mfTUBYGo067OXQjtok7wnD+4o3yEsYQjWvakQGRHHkzelk/NoZS9R6jLZTIWIzeGbbV/Y9CQHJkBoDc96HA1c6tutWLQVbt8H4xs2npn9N9qfthxMNYfl/YctdcNl8rhzyMTe16kyTGk2IrR5LiG8Ifp5+eLp5YjWsWLDg7eFdpr/TqVPt45zuuw9efBE8PM69jhl27oT9++G66/RYFpGKRAHoIikASXnYsgUyMuzPM/PwgGPH7BM+rltnf3xIaircdBP06QM//ggvvGAPWEUCAuCPXVYCQnII8AoAYM8eaNYMcnNL3qe7bxbWAgsU+tmfu1Z7F9bDceTlutkbtH8dam7F8vstGLsS7AO/i1T7E655EjCgwB/Ct0Ct1fYeqaKavAII9w+nXkg9mtVoRr3gemTmZ3Iy5yQ+Hj6E+YXh5+lHWl4aablpVPetTr2QetT0r4kFCwZ//9/P5nW+jOjVGmuhvbY67bZx9cPTqB7sRXXf6rSNbMvltS8nxDfknL/rrPws/Dz9nMZQnUlhIUz/MJNVP/uyaaM7KSkwbRr06FFy+xkz4P777ZdRJ0+2BzYRqRgUgC6SApBUBDk59l6ipUvtIemee+Cuu4q327wZPv7YPsD7t9/sX+iGYe+Nsv11s1rHToVMfSeblo2rUVBgYcwY++zb/3TjjfYA9sSYfPbsKuHefY9sCDwEuUFQ4AfB++yzcbvnQ1YNKPSB2quh7o/2eZgOdoLcEGj2OTT6GvL9YVc3yIywt4tcbw9U2SHw5kZIqwvRy+FIG/t0BKE7IOFRaPwV/JVlmtVoRqfoTjSv2ZzU3FSOZR0DwJpek+On8thc+AW/n9xJDb8aXFn3StpFtaO6b3VCfEII9gkm2CeYQxmH+Gnfzyz83mDnJ/diTW7qdJjuHjb+PeEHbrkVroq5Cg83D/Ly4JFH7IPoi1gs9rvybrrJ+bytWmWfULN27fM9267x22/Qv7893D343wxSslJoUL3BOdcTuVQoAF0kBSCpDPLy7JMyZmRA+/bFZ6ResMA+uLtGDbj5Zrjllr9vqc/Kss9ivWIFBAXZx+SsWmVw7NiFX+/xCcwkL8sHw/r3dS2LRx5u/qlg9cSaWR3vmgdoN+5+AtLa88sLD5N1qhoA1RvsxVb3B1L91tjHPOUFQXYYpNeCtDqQ0vzvqQoCDkODReB3HKye4J0OUevsPVhpdSG5FRzsCAe6QGbkX8WdhLZv2UPZr3fAtt5gKYTr/kuNjt/TKeQWfn55ECf3RQPgfvUzWNPDYP39uHnn0GHoFOp32E7q/rr8/PK9ZBy2Jx/fmK1EdPiZ6245Qnyjevh7+mMr9CA7zY/cTB9SUjPYcGoZ604uwicwi9jQhjQJa0Jiw0Sujrm6xEHsO4/v5PNfPyclK4VagbWoE1SHTtGdiAmOAcAwDPKsefh4+Ditd+IEdOhg7zUECO7zAKmx0xjcbjDPX/e8o1exKsjIsF9irVcP+va1L8vPh+eeg19+sf+OLBb7ZevGjc2tVUpHAegiKQCJFGcY9kt1J05AcLB9vqU9e+zjYaxWqFnT3ubnn2H5cntw6tzZHrxmzICjR+3badLEPkZq1So4fvzv7fv42ANX69b296mpMGkSvPQSZGefuz6Lmw03dyvWgvMfQe3pZeWOfid49ilf1pxcwHPLn2PDoU14z/uEvA13/LVhK1hsYPMEv2Nw8z3QaB5YPeDj+bDnur8O4CTkBdqfVeedBnnVgL8uNboVQMwyyIiE443tbf4pZLd90Hv0ckhuhfvRdgQEFxBU+zD+wZkU5PiQnupFyu/RcCjevo/OL0DzzyA5jsAdw3HPq0GW907yA3ZRK24nHeKCiAyIxGLz4usnh3JwcwPcPQvsvyOvDBjUFsL+oH5Ifa6tdy2GYeDu5k7u4Qac2NmYJu2OUa9hHseyj7Hl6Bb2nNpDsE8wNfxrEF8rnmtD7mX9ikDy8+29jaFNtvFR8mi2HN3CFZEJRB29h1aXhdKunRsBXv74e/mTl+VDoedJkjOP4OHmQeOwxmU+luxsliyBgQPtY7gA5s2z93yOHGn/Wztdi5ZWhrz1IZ3rtaN5zeYuq7EyKCiw/yMswMW5WgHoIikAiZSt/Hx7uImKgssusy8zDNi7F9LS7AGndm2oW7f4ukeP2qcg2LnTPnWBzWYPYCEh9nVq1bL/K71FC3Bzs/8L/scf7fv09LSPo1qzxn75p04daNUK2raFLl3sPSI+p3WUGIZBZn4mvu4BvP66hQ8/srF+nT3EXNbxd2777wLiGobTNqotNfxqsH7vLib+z4/l8+uScdI+b1S76//gnsc34E01Nv8Uw7ef12D31hrOB+VWiIdfJm6e+ZAXSH62c29NaXgEpFKYGVzyh9V/tw+GT42x95B5ZcA9V8B3r8D+qwiLyCHdezv5Wb72doEH4WRDONLu721c9o197NexZpAWDaF/QM2tsP9K+P0mMNz+bmuxQocp9ikeFk6Gk3+d7JpbIGKTfZ20GPujadpNg6Zf4FbtGI1qNKRFeAta1GyB1WZjy6Gd7NkLhZvvIGVdZ3x93Gje7iRxHTJo1u4U1Wvks31jEF9Or8eRA3607nSCyxOOUjvcF19CSc8sZMeRAxw8cZSwmgb163hxbFcMS76ox/Ifguw1eWZDgR+eAWlcM3ApC19JAqDPf7bStrUHY4bHkJnqCx0n49btvwxpP4QH2j3AusPr2Ji8kYbVG9K1bld8PHz5af+PbD++nc7Rneke2x0v94o59XtqKpw8aZ9EtTylpcGVV9r/gfTFF5CYWL77O50C0EVSABKpfAzjwu7Y2r/f/sXRsuWZ17da7cHLx8c+yP2ftmyBn36yX3KJi7OHttO3lZlpH0v0/vv2y5atWxvEND1B8vEcdv3uRXqqO34BhQRUs3JF+2CuucKf1avtPWSpqeDlZdDxumRiGp/ClhHBvt8DWLncg8KCv8OJh3cenUdOwb/5UrpWv5PJ/e4iJaXkA3JztxJW/yApu+o4B5yS1PkZ/FMgJwT2XeP0kXvASay5fvaxYWdisYLPKfsA/AJfsJ5HGAw48vflywvRbipc8wR8+D0cafv38stfhG4P2X/e0QM+tT8DkDZv2f/XIxei1kP1P+CPG2Hz3ZATChEb7ZdZGywiuMlG2tRuTtrB2qQfrEt+ph/5WX5YrWDDitXIJ8+WTa41hwA/LyKDQ4iO8CW2VQqRkeDh5oG10J2j+wPZ/3sQh3dX59SRINJSgvEJzKLNDRu4rMM+flzmzrbFLbFkRxIeXI3Imp54NF7A7tDXqO4XQpz1XsIKWkPIHtI8fmf/D9ezanZ7crI8uL13Do+MOYk14CD7U/eTmZ+Jv5c//p7+BHgF4O/lT741n5SsFHIKcuhQqwMNqzd03FSQmWm/hL5okX0etVtu+fu/D5sNevSwMX++/e/Gy8vgk0/A6pbDO+8YYLHy7wdP0qJVAdV9qxPqF3rh57EECkAXSQFIRC4FqamwerW9RysszPmz9HT7AHqbzd5TFhtr7zkrsnu3/XJlcDAEBtovbR48aL9kceut9u39/rt9aoLjx6F5c3sP2o4d9kAXHW3QqsdK9rp/RzXvalT3rY7bnm7879Ha7NljH1/2zDP2cPjpp3D4MHS4vIDYJjksWRDAO2+7sXmzfY6skrh72GjYfjfV4xeQWZDKse1NSPu9BTmHYsFww+JeQEj8t1RrtI70bZ1I3345hs2CzSMLi1c2vr4Gvt4e5KQGknOyOu7+qXi3+wS3tu/yr8sbM6DVALKTa9Hr+obkZXsR2nA3ncc9yrHcQxzOOIybxY1aP3/FL1+2KN1J8ci2P3g5/wK+O0J2Q6E3ZEThuHxaErd8sJ2hl8krwz727VxB0jPLHiTzA8C9wH5DQ+Cf9hCaU/3vV4E/+JzCKzANdzcP8rN8saZGFQu1lpA9uDf7BvJ9KVwzCDxyoO5PsPsM3T8tP2TwqMO8/n+jzl5nKSkAXSQFIBGRC1NQYA9mNWqcsymFhfZwdfy4/XKlr6+9F83HB/z8Sp4HKi0NNm2yX0qNLKETqOgr7fQpEKxW++XRknrwli61PzNw7Fh7wDtdbq59sHRmpr2eEyesrF/vzm+/2S+f3t2vgEaNbfy21ZsVK2DePIODB+078fEroH7TNELC8qkWaMXT0wI2Nyy4444XFsOT9OxcTmRkceSgF8m7w5162zx9cwirl0xE/WNERGcQXiuffb+FsXpeU3LS/fEPyuHG29KIanSYjQd2sne3O6kbric9JRgA76A0PGvsxXqiDjmnqhNcbw8eVz/LcbetsOAV+LPjuU/Q2YTstl8eTY2xh5zCfwzYv+VuPFp+QeHcabC5H/icwr3N+7hnR5G/yT6+rsmV2/ntxyYXV8c/KABdJAUgEREpLcOwzxZvGNC0afE7L88mNdU+3UVgIMTE2ANkSYEtN9feC9ekif1GhNPZbPZpMfz97T1+Revn54OXl3O7devsATQgwL7NvXvh0CH7+5AQqF7d/vL3h8Mpufz8206sFBBdM5AG0QHUb2AFiz0+ZGXCjz/4sOAbP1b94kO/e/L533hv3CxuZBfksHxNNq2b+xIWZJ+ba906ePRR+5QSTco2/1x6Aej1119n4sSJJCcnExcXx5QpU+jQocMZ28+aNYsnn3ySffv2ERsby/PPP88NN9zg+NwwDMaOHcvbb79NamoqnTt3ZurUqcTGxp5XPQpAIiIil57SfH+fY3Rb+fvss88YOXIkY8eOZcOGDcTFxZGYmEhKSkqJ7VesWEHv3r0ZOHAgGzduJCkpiaSkJLZt2+Zo88ILL/Dqq68ybdo0Vq9ejb+/P4mJieSeabpcERERqVJM7wGKj4+nffv2vPbaawDYbDaio6MZNmwYjz76aLH2vXr1Iisri3nz5jmWXX755bRq1Ypp06ZhGAZRUVE89NBDPPzwwwCkpaURHh7OjBkzuPPOO89Zk3qARERELj2XTA9Qfn4+69evJyEhwbHMzc2NhIQEVq5cWeI6K1eudGoPkJiY6Gi/d+9ekpOTndoEBQURHx9/xm3m5eWRnp7u9BIREZHKy9QAdPz4caxWK+Hh4U7Lw8PDST79KZCnSU5OPmv7ov8tzTYnTJhAUFCQ4xUdHX1BxyMiIiKXBtPHAFUEo0ePJi0tzfE6ePCg2SWJiIhIOTI1AIWFheHu7s7RoocE/eXo0aNERESUuE5ERMRZ2xf9b2m26e3tTWBgoNNLREREKi9TA5CXlxdt27ZlyZIljmU2m40lS5bQsWPJkzR17NjRqT3AokWLHO3r1atHRESEU5v09HRWr159xm2KiIhI1VLCPJuuNXLkSPr160e7du3o0KEDL7/8MllZWQwYMACAvn37UqtWLSZMmADAiBEj6Nq1K5MnT+bGG2/k008/Zd26dbz1lv1ZLRaLhQcffJBnnnmG2NhY6tWrx5NPPklUVBRJSUlmHaaIiIhUIKYHoF69enHs2DHGjBlDcnIyrVq1YsGCBY5BzAcOHMDN7e+Oqk6dOjFz5kyeeOIJHnvsMWJjY5k7dy7Nmzd3tPnvf/9LVlYWgwYNIjU1lSuuuIIFCxbg43PhT1wWERGRysP0eYAqIs0DJCIicum5ZOYBEhERETGDApCIiIhUOQpAIiIiUuUoAImIiEiVY/pdYBVR0bhwPRNMRETk0lH0vX0+93cpAJUgIyMDQM8EExERuQRlZGQQFBR01ja6Db4ENpuNw4cPU61aNSwWS5luOz09nejoaA4ePFhlbrHXMeuYK7OqeNw6Zh1zRWUYBhkZGURFRTnNIVgS9QCVwM3Njdq1a5frPqriM8d0zFVDVTxmqJrHrWOuGi61Yz5Xz08RDYIWERGRKkcBSERERKocBSAX8/b2ZuzYsXh7e5tdisvomKuGqnjMUDWPW8dcNVT2Y9YgaBEREaly1AMkIiIiVY4CkIiIiFQ5CkAiIiJS5SgAiYiISJWjAORCr7/+OjExMfj4+BAfH8+aNWvMLqnMTJgwgfbt21OtWjVq1qxJUlISO3fudGpz1VVXYbFYnF7333+/SRVfvHHjxhU7nsaNGzs+z83NZciQIYSGhhIQEMBtt93G0aNHTay4bMTExBQ7bovFwpAhQ4DKcZ5/+uknevToQVRUFBaLhblz5zp9bhgGY8aMITIyEl9fXxISEvjjjz+c2pw8eZI+ffoQGBhIcHAwAwcOJDMz04VHUTpnO+aCggJGjRpFixYt8Pf3Jyoqir59+3L48GGnbZT0t/Hcc8+5+EhK51znun///sWOqVu3bk5tKtO5Bkr879tisTBx4kRHm0vxXP+TApCLfPbZZ4wcOZKxY8eyYcMG4uLiSExMJCUlxezSysSPP/7IkCFDWLVqFYsWLaKgoIDrr7+erKwsp3b33XcfR44ccbxeeOEFkyouG82aNXM6nl9++cXx2X/+8x+++eYbZs2axY8//sjhw4e59dZbTay2bKxdu9bpmBctWgTA7bff7mhzqZ/nrKws4uLieP3110v8/IUXXuDVV19l2rRprF69Gn9/fxITE8nNzXW06dOnD7/++iuLFi1i3rx5/PTTTwwaNMhVh1BqZzvm7OxsNmzYwJNPPsmGDRuYPXs2O3fu5KabbirWdvz48U7nftiwYa4o/4Kd61wDdOvWzemYPvnkE6fPK9O5BpyO9ciRI7z77rtYLBZuu+02p3aX2rkuxhCX6NChgzFkyBDHe6vVakRFRRkTJkwwsaryk5KSYgDGjz/+6FjWtWtXY8SIEeYVVcbGjh1rxMXFlfhZamqq4enpacyaNcuxbPv27QZgrFy50kUVusaIESOMBg0aGDabzTCMyneeAWPOnDmO9zabzYiIiDAmTpzoWJaammp4e3sbn3zyiWEYhvHbb78ZgLF27VpHm++++86wWCzGoUOHXFb7hfrnMZdkzZo1BmDs37/fsaxu3brGSy+9VL7FlaOSjrtfv37GzTfffMZ1qsK5vvnmm41rrrnGadmlfq4NwzDUA+QC+fn5rF+/noSEBMcyNzc3EhISWLlypYmVlZ+0tDQAqlev7rT8448/JiwsjObNmzN69Giys7PNKK/M/PHHH0RFRVG/fn369OnDgQMHAFi/fj0FBQVO57xx48bUqVOnUp3z/Px8PvroI+655x6nBwdXtvN8ur1795KcnOx0boOCgoiPj3ec25UrVxIcHEy7du0cbRISEnBzc2P16tUur7k8pKWlYbFYCA4Odlr+3HPPERoaSuvWrZk4cSKFhYXmFFiGli1bRs2aNWnUqBEPPPAAJ06ccHxW2c/10aNH+fbbbxk4cGCxzy71c62HobrA8ePHsVqthIeHOy0PDw9nx44dJlVVfmw2Gw8++CCdO3emefPmjuX/93//R926dYmKimLLli2MGjWKnTt3Mnv2bBOrvXDx8fHMmDGDRo0aceTIEZ566im6dOnCtm3bSE5OxsvLq9iXQ3h4OMnJyeYUXA7mzp1Lamoq/fv3dyyrbOf5n4rOX0n/PRd9lpycTM2aNZ0+9/DwoHr16pXi/Ofm5jJq1Ch69+7t9JDM4cOH06ZNG6pXr86KFSsYPXo0R44c4cUXXzSx2ovTrVs3br31VurVq8fu3bt57LHH6N69OytXrsTd3b3Sn+v333+fatWqFbt8XxnOtQKQlLkhQ4awbds2p/EwgNM18RYtWhAZGcm1117L7t27adCggavLvGjdu3d3/NyyZUvi4+OpW7cun3/+Ob6+viZW5jrTp0+ne/fuREVFOZZVtvMszgoKCrjjjjswDIOpU6c6fTZy5EjHzy1btsTLy4t///vfTJgw4ZJ9nMKdd97p+LlFixa0bNmSBg0asGzZMq699loTK3ONd999lz59+uDj4+O0vDKca10Cc4GwsDDc3d2L3QF09OhRIiIiTKqqfAwdOpR58+axdOlSateufda28fHxAOzatcsVpZW74OBgLrvsMnbt2kVERAT5+fmkpqY6talM53z//v0sXryYe++996ztKtt5Ljp/Z/vvOSIiotgNDoWFhZw8efKSPv9F4Wf//v0sWrTIqfenJPHx8RQWFrJv3z7XFOgC9evXJywszPH3XFnPNcDPP//Mzp07z/nfOFya51oByAW8vLxo27YtS5YscSyz2WwsWbKEjh07mlhZ2TEMg6FDhzJnzhx++OEH6tWrd851Nm3aBEBkZGQ5V+camZmZ7N69m8jISNq2bYunp6fTOd+5cycHDhyoNOf8vffeo2bNmtx4441nbVfZznO9evWIiIhwOrfp6emsXr3acW47duxIamoq69evd7T54YcfsNlsjkB4qSkKP3/88QeLFy8mNDT0nOts2rQJNze3YpeILmV//vknJ06ccPw9V8ZzXWT69Om0bduWuLi4c7a9JM+12aOwq4pPP/3U8Pb2NmbMmGH89ttvxqBBg4zg4GAjOTnZ7NLKxAMPPGAEBQUZy5YtM44cOeJ4ZWdnG4ZhGLt27TLGjx9vrFu3zti7d6/x1VdfGfXr1zeuvPJKkyu/cA899JCxbNkyY+/evcby5cuNhIQEIywszEhJSTEMwzDuv/9+o06dOsYPP/xgrFu3zujYsaPRsWNHk6suG1ar1ahTp44xatQop+WV5TxnZGQYGzduNDZu3GgAxosvvmhs3LjRccfTc889ZwQHBxtfffWVsWXLFuPmm2826tWrZ+Tk5Di20a1bN6N169bG6tWrjV9++cWIjY01evfubdYhndPZjjk/P9+46aabjNq1axubNm1y+m88Ly/PMAzDWLFihfHSSy8ZmzZtMnbv3m189NFHRo0aNYy+ffuafGRnd7bjzsjIMB5++GFj5cqVxt69e43Fixcbbdq0MWJjY43c3FzHNirTuS6SlpZm+Pn5GVOnTi22/qV6rv9JAciFpkyZYtSpU8fw8vIyOnToYKxatcrsksoMUOLrvffeMwzDMA4cOGBceeWVRvXq1Q1vb2+jYcOGxiOPPGKkpaWZW/hF6NWrlxEZGWl4eXkZtWrVMnr16mXs2rXL8XlOTo4xePBgIyQkxPDz8zNuueUW48iRIyZWXHYWLlxoAMbOnTudlleW87x06dIS/5779etnGIb9Vvgnn3zSCA8PN7y9vY1rr7222O/ixIkTRu/evY2AgAAjMDDQGDBggJGRkWHC0Zyfsx3z3r17z/jf+NKlSw3DMIz169cb8fHxRlBQkOHj42M0adLE+N///ucUFCqisx13dna2cf311xs1atQwPD09jbp16xr33XdfsX+4VqZzXeTNN980fH19jdTU1GLrX6rn+p8shmEY5drFJCIiIlLBaAyQiIiIVDkKQCIiIlLlKACJiIhIlaMAJCIiIlWOApCIiIhUOQpAIiIiUuUoAImIiEiVowAkInIGFouFuXPnml2GiJQDBSARqZD69++PxWIp9urWrZvZpYlIJeBhdgEiImfSrVs33nvvPadl3t7eJlUjIpWJeoBEpMLy9vYmIiLC6RUSEgLYL09NnTqV7t274+vrS/369fniiy+c1t+6dSvXXHMNvr6+hIaGMmjQIDIzM53avPvuuzRr1gxvb28iIyMZOnSo0+fHjx/nlltuwc/Pj9jYWL7++mvHZ6dOnaJPnz7UqFEDX19fYmNjiwU2EamYFIBE5JL15JNPctttt7F582b69OnDnXfeyfbt2wHIysoiMTGRkJAQ1q5dy6xZs1i8eLFTwJk6dSpDhgxh0KBBbN26la+//pqGDRs67eOpp57ijjvuYMuWLdxwww306dOHkydPOvb/22+/8d1337F9+3amTp1KWFiY634BInLhzH4aq4hISfr162e4u7sb/v7+Tq9nn33WMAzDAIz777/faZ34+HjjgQceMAzDMN566y0jJCTEyMzMdHz+7bffGm5ubo6neUdFRRmPP/74GWsAjCeeeMLxPjMz0wCM7777zjAMw+jRo4cxYMCAsjlgEXEpjQESkQrr6quvZurUqU7Lqlev7vi5Y8eOTp917NiRTZs2AbB9+3bi4uLw9/d3fN65c2dsNhs7d+7EYrFw+PBhrr322rPW0LJlS8fP/v7+BAYGkpKSAsADDzzAbbfdxoYNG7j++utJSkqiU6dOF3SsIuJaCkAiUmH5+/sXuyRVVnx9fc+rnaenp9N7i8WCzWYDoHv37uzfv5/58+ezaNEirr32WoYMGcKkSZPKvF4RKVsaAyQil6xVq1YVe9+kSRMAmjRpwubNm8nKynJ8vnz5ctzc3GjUqBHVqlUjJiaGJUuWXFQNNWrUoF+/fnz00Ue8/PLLvPXWWxe1PRFxDfUAiUiFlZeXR3JystMyDw8Px0DjWbNm0a5dO6644go+/vhj1qxZw/Tp0wHo06cPY8eOpV+/fowbN45jx44xbNgw7r77bsLDwwEYN24c999/PzVr1qR79+5kZGSwfPlyhg0bdl71jRkzhrZt29KsWTPy8vKYN2+eI4CJSMWmACQiFdaCBQuIjIx0WtaoUSN27NgB2O/Q+vTTTxk8eDCRkZF88sknNG3aFAA/Pz8WLlzIiBEjaN++PX5+ftx22228+OKLjm3169eP3NxcXnrpJR5++GHCwsLo2bPnedfn5eXF6NGj2bdvH76+vnTp0oVPP/20DI5cRMqbxTAMw+wiRERKy2KxMGfOHJKSkswuRUQuQRoDJCIiIlWOApCIiIhUORoDJCKXJF29F5GLoR4gERERqXIUgERERKTKUQASERGRKkcBSERERKocBSARERGpchSAREREpMpRABIREZEqRwFIREREqhwFIBEREaly/h8TzO/5zaBAawAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training and Validation Loss\n",
        "plot_loss_curve(history_best_model, NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the test dataset\n",
        "X_test_norm = scaler_input.transform(X_test)\n",
        "y_test_norm = scaler_output.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-erJ0l_Yu4P",
        "outputId": "9cff94b2-e4ca-491b-8459-aeaa1eff7606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time: 0.0262 seconds\n",
            "Maxval here is:  24.41\n",
            "Maxval here is:  0.9278\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "Y_pred_normalized = best_model.predict(X_test_norm)\n",
        "end_time = time.time()\n",
        "Y_pred_normalized_entire = best_model.predict(dataset_x_norm)\n",
        "# Calculate elapsed time in seconds\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Elapsed time:\", round(elapsed_time, 3), \"seconds\")\n",
        "\n",
        "\n",
        "Y_pred = scaler_output.inverse_transform(Y_pred_normalized)\n",
        "Y_pred_entire = scaler_output.inverse_transform(Y_pred_normalized_entire)\n",
        "Y_actual = np.array(y_test)\n",
        "Y_actual_entire = np.array(df_targets)\n",
        "# Moisture Content\n",
        "scatter_plot(trueValues=Y_actual[:,0], \n",
        "             predictions=Y_pred[:,0], \n",
        "             title=\"Moisture Content\")\n",
        "a, b = np.polyfit(Y_pred[:, 0], Y_actual[:, 0], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,0]), max(Y_actual[:,0])), 1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_MC.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)\n",
        "\n",
        "# Bulk Density\n",
        "scatter_plot(trueValues=Y_actual[:,1], \n",
        "             predictions=Y_pred[:,1], \n",
        "             title=\"Bulk Density\")\n",
        "plt.xlim([min(min(Y_pred[:,1]), min(Y_actual[:,1]))-0.1, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1])\n",
        "a, b = np.polyfit(Y_pred[:, 1], Y_actual[:, 1], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1, 0.1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_BD.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Error analysis\n",
        "- R squared calculation\n",
        "- Mean accuracy error"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### R squared calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9926\n",
            "0.9441\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# MOISTURE CONTENT\n",
        "#   - R-squared\n",
        "# mc_r2_score = r2_score(Y_actual[:, 0], Y_pred[:, 0])\n",
        "mc_r2_score = calculate_r_squared(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"{:#.4g}\".format(mc_r2_score))\n",
        "\n",
        "# BULK DENSITY\n",
        "#   - R-squared\n",
        "# bd_r2_score = r2_score(Y_actual[:, 1], Y_pred[:, 1])\n",
        "bd_r2_score = calculate_r_squared(y_true=Y_actual[:, 1], y_pred=Y_pred[:, 1])\n",
        "print(\"{:#.4g}\".format(bd_r2_score))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE_MC:  0.3531\n",
            "RMSE_BD:  0.02443\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sigfig import round\n",
        "\n",
        "#MC\n",
        "rmse_mc = np.sqrt(mean_squared_error(Y_actual[:, 0], Y_pred[:, 0]))\n",
        "print('RMSE_MC: ', \"{0:.4g}\".format(rmse_mc))\n",
        "\n",
        "#BD\n",
        "rmse_bd = np.sqrt(mean_squared_error(Y_actual[:, 1], Y_pred[:, 1]))\n",
        "print('RMSE_BD: ', \"{0:.4g}\".format(rmse_bd))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will compare with the results from Trabelsi's paper. This is single moisture prediction \n",
        "\n",
        "R^2 : 0.993\\\n",
        "Mean Squared Error: 0.028\\\n",
        "Mean absolute Error: 0.135\\\n",
        "Min. Absolute Error: 0.004\\\n",
        "Max Absolute Error: 0.441"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9905\n",
            "Mean Squared Error:  0.1246\n",
            "Mean Absolute Error:  0.2859\n",
            "Min Absolute Error:  0.0018354797363286934\n",
            "Max Absolute Error:  0.8799495697021484\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,max_error, r2_score\n",
        "from sigfig import round\n",
        "\n",
        "mc_r2_score = r2_score(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual[:, 0], Y_pred[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual[:, 0], Y_pred[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual[:,0])):\n",
        "    sum = Y_actual[:,0][i] - Y_pred[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9927\n",
            "Mean Squared Error:  0.1047\n",
            "Mean Absolute Error:  0.2573\n",
            "Min Absolute Error:  0.00041519165039005657\n",
            "Max Absolute Error:  0.9580669403076172\n"
          ]
        }
      ],
      "source": [
        "mc_r2_score = r2_score(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual_entire[:,0])):\n",
        "    sum = Y_actual_entire[:,0][i] - Y_pred_entire[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
