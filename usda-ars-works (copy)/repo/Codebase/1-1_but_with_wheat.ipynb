{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "#GRAIN_TYPE = 'Wheat'\n",
        "#GRAIN_TYPE = 'newWheatData'\n",
        "GRAIN_TYPE = 'WheatAdded_Type'\n",
        "# GRAIN_TYPE = 'Oats'\n",
        "# GRAIN_TYPE = 'Barley'\n",
        "# GRAIN_TYPE = 'Sorghum'\n",
        "# GRAIN_TYPE = 'Soybeans'\n",
        "# GRAIN_TYPE = 'Corn'\n",
        "\n",
        "FILENAME_BEST_MODEL = 'Best models/target_2/hybrid_models/' + GRAIN_TYPE + '_t2_kcv_dnn_mc.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNGoIGbc0kw_",
        "outputId": "279cc9c8-32fd-4f89-e56b-83a0a31081dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ]
        }
      ],
      "source": [
        "#Import libraries\n",
        "import requests\n",
        "import pydot\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Data visualization\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "#Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Machine Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Activation, BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "np.random.seed(39)\n",
        "random.seed(39)\n",
        "tf.random.set_seed(39)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "# print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "nxHO_qH0Zi5J"
      },
      "outputs": [],
      "source": [
        "def calculate_r_squared(y_true, y_pred):\n",
        "   corr_matrix = np.corrcoef(y_true, y_pred)\n",
        "   corr = corr_matrix[0,1]\n",
        "   R_sq = corr**2\n",
        "   return R_sq\n",
        "\n",
        "def plot_loss_curve(history, epoch_size):\n",
        "    loss_train = history.history['loss']\n",
        "    loss_val = history.history['val_loss']\n",
        "    epochs = range(0,epoch_size)\n",
        "    \n",
        "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "    \n",
        "    plt.title('Training and Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_line(metric, title, xlabel):\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.title(title, fontsize = 16)\n",
        "    plt.plot(metric)\n",
        "    plt.xlabel(xlabel, fontsize = 14)\n",
        "    plt.grid()\n",
        "    plt.legend(loc= \"best\")\n",
        "    plt.show()\n",
        "\n",
        "def scatter_plot(trueValues, predictions, title):\n",
        "  plt.figure(figsize=(8,3))\n",
        "  ax = plt.axes()\n",
        "  maxVal = max( max(trueValues), max(predictions) )\n",
        "\n",
        "  ax.scatter(x=predictions, y=trueValues)\n",
        "  ax.plot([0, 1, maxVal], [0, 1, maxVal], label=\"Ideal fit\")\n",
        "  print('Maxval here is: ', maxVal)\n",
        "  plt.title(title, fontsize = 16)\n",
        "  plt.xlabel(\"Predictions\", fontsize = 14)\n",
        "  plt.ylabel(\"Real\", fontsize = 14)\n",
        "  plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "s3pvA5g-zdgv",
        "outputId": "7a7208f1-6b68-4eba-ad1d-9108d0df66ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From USDA:  ../Datasets/processed/WheatAdded_Type.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Variety</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>8.8258</td>\n",
              "      <td>-55.973</td>\n",
              "      <td>-415.973</td>\n",
              "      <td>2.416</td>\n",
              "      <td>0.243</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-6.341975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>10.2572</td>\n",
              "      <td>-114.289</td>\n",
              "      <td>-474.289</td>\n",
              "      <td>2.412</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-11.142320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>11.5679</td>\n",
              "      <td>-168.171</td>\n",
              "      <td>-528.171</td>\n",
              "      <td>2.395</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-14.537729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>12.8795</td>\n",
              "      <td>134.849</td>\n",
              "      <td>-585.151</td>\n",
              "      <td>2.390</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>10.470049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>13.7649</td>\n",
              "      <td>83.502</td>\n",
              "      <td>-636.498</td>\n",
              "      <td>2.371</td>\n",
              "      <td>0.238</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>6.066299</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 Variety  Freq  d(cm)    M%  Density     Attn    Phase  \\\n",
              "0           0  KANSAS   7.0    8.9  11.3   0.7356   8.8258  -55.973   \n",
              "1           1  KANSAS   8.0    8.9  11.3   0.7356  10.2572 -114.289   \n",
              "2           2  KANSAS   9.0    8.9  11.3   0.7356  11.5679 -168.171   \n",
              "3           3  KANSAS  10.0    8.9  11.3   0.7356  12.8795  134.849   \n",
              "4           4  KANSAS  11.0    8.9  11.3   0.7356  13.7649   83.502   \n",
              "\n",
              "   Phase_Corr  Permittivity_real  Permittivity_imaginary       Type  \\\n",
              "0    -415.973              2.416                   0.243  15.855506   \n",
              "1    -474.289              2.412                   0.246  15.855506   \n",
              "2    -528.171              2.395                   0.246  15.855506   \n",
              "3    -585.151              2.390                   0.246  15.855506   \n",
              "4    -636.498              2.371                   0.238  15.855506   \n",
              "\n",
              "   Phase/Attn  \n",
              "0   -6.341975  \n",
              "1  -11.142320  \n",
              "2  -14.537729  \n",
              "3   10.470049  \n",
              "4    6.066299  "
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#url dataset\n",
        "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
        "\n",
        "#read in excel format\n",
        "df = pd.read_csv(URL)\n",
        "#df = df[df['Variety'] == 'KANSAS']\n",
        "#df = df[(df['Density'] >= 0.72) & (df['Density'] <= 0.88)]\n",
        "\n",
        "print(\"From USDA: \", URL)\n",
        "\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUzjHHV2stm"
      },
      "source": [
        "# 2. Overview of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Xohz7dGh2sXH",
        "outputId": "7d018cd8-018a-45d3-b1b7-ba9fc14aa5e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>402.500000</td>\n",
              "      <td>10.811414</td>\n",
              "      <td>7.088834</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>0.796298</td>\n",
              "      <td>18.410033</td>\n",
              "      <td>-4.604663</td>\n",
              "      <td>-633.488065</td>\n",
              "      <td>2.912112</td>\n",
              "      <td>0.499187</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>-0.377074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>232.816451</td>\n",
              "      <td>3.530055</td>\n",
              "      <td>1.554604</td>\n",
              "      <td>3.794772</td>\n",
              "      <td>0.067384</td>\n",
              "      <td>5.946835</td>\n",
              "      <td>101.951444</td>\n",
              "      <td>219.510760</td>\n",
              "      <td>0.305758</td>\n",
              "      <td>0.186739</td>\n",
              "      <td>0.629743</td>\n",
              "      <td>6.071761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>10.260000</td>\n",
              "      <td>0.625400</td>\n",
              "      <td>8.002300</td>\n",
              "      <td>-179.335000</td>\n",
              "      <td>-1274.435000</td>\n",
              "      <td>2.340000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>15.352809</td>\n",
              "      <td>-17.418676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>201.250000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>13.680000</td>\n",
              "      <td>0.745400</td>\n",
              "      <td>13.524700</td>\n",
              "      <td>-88.842000</td>\n",
              "      <td>-793.405750</td>\n",
              "      <td>2.688500</td>\n",
              "      <td>0.337000</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-5.077754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>402.500000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>16.225000</td>\n",
              "      <td>0.801300</td>\n",
              "      <td>18.131600</td>\n",
              "      <td>-9.838500</td>\n",
              "      <td>-602.380500</td>\n",
              "      <td>2.861500</td>\n",
              "      <td>0.470500</td>\n",
              "      <td>16.400366</td>\n",
              "      <td>-0.589378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>603.750000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>18.810000</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>23.098000</td>\n",
              "      <td>80.957250</td>\n",
              "      <td>-456.055750</td>\n",
              "      <td>3.109750</td>\n",
              "      <td>0.639000</td>\n",
              "      <td>16.401988</td>\n",
              "      <td>4.300734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>805.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>24.410000</td>\n",
              "      <td>0.927800</td>\n",
              "      <td>29.897000</td>\n",
              "      <td>179.048000</td>\n",
              "      <td>-235.044000</td>\n",
              "      <td>4.038000</td>\n",
              "      <td>0.987000</td>\n",
              "      <td>17.344167</td>\n",
              "      <td>14.827701</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0        Freq       d(cm)          M%     Density        Attn  \\\n",
              "count  806.000000  806.000000  806.000000  806.000000  806.000000  806.000000   \n",
              "mean   402.500000   10.811414    7.088834   16.189541    0.796298   18.410033   \n",
              "std    232.816451    3.530055    1.554604    3.794772    0.067384    5.946835   \n",
              "min      0.000000    5.000000    4.400000   10.260000    0.625400    8.002300   \n",
              "25%    201.250000    8.000000    6.500000   13.680000    0.745400   13.524700   \n",
              "50%    402.500000   11.000000    7.700000   16.225000    0.801300   18.131600   \n",
              "75%    603.750000   13.000000    7.700000   18.810000    0.842000   23.098000   \n",
              "max    805.000000   18.000000    8.900000   24.410000    0.927800   29.897000   \n",
              "\n",
              "            Phase   Phase_Corr  Permittivity_real  Permittivity_imaginary  \\\n",
              "count  806.000000   806.000000         806.000000              806.000000   \n",
              "mean    -4.604663  -633.488065           2.912112                0.499187   \n",
              "std    101.951444   219.510760           0.305758                0.186739   \n",
              "min   -179.335000 -1274.435000           2.340000                0.220000   \n",
              "25%    -88.842000  -793.405750           2.688500                0.337000   \n",
              "50%     -9.838500  -602.380500           2.861500                0.470500   \n",
              "75%     80.957250  -456.055750           3.109750                0.639000   \n",
              "max    179.048000  -235.044000           4.038000                0.987000   \n",
              "\n",
              "             Type  Phase/Attn  \n",
              "count  806.000000  806.000000  \n",
              "mean    16.189541   -0.377074  \n",
              "std      0.629743    6.071761  \n",
              "min     15.352809  -17.418676  \n",
              "25%     15.855506   -5.077754  \n",
              "50%     16.400366   -0.589378  \n",
              "75%     16.401988    4.300734  \n",
              "max     17.344167   14.827701  "
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data summary\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmFqsYQyGnM",
        "outputId": "54445a7f-a2c8-452a-9651-42dbbe682d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(806, 13)"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimension of the dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fep-GIv4yUuf",
        "outputId": "c46072fa-aa7f-4549-9a1d-4c5b05d11112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unnamed: 0                0\n",
              "Variety                   0\n",
              "Freq                      0\n",
              "d(cm)                     0\n",
              "M%                        0\n",
              "Density                   0\n",
              "Attn                      0\n",
              "Phase                     0\n",
              "Phase_Corr                0\n",
              "Permittivity_real         0\n",
              "Permittivity_imaginary    0\n",
              "Type                      0\n",
              "Phase/Attn                0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check info about missing values in dataframe\n",
        "df.isnull().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_TKP9VymuK"
      },
      "source": [
        "# Exploratory Data Analysis\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz1g9T3FzhF0"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "\n",
        "1.   Convert dataframe to numpy array for flexibility.\n",
        "2. Split our data into training and testing datasets and store the target values in different variables.\n",
        "3.   Normalize the features by applying some operations in the data sets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "T0juhagf1M2I"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy array\n",
        "df_features = df[['Freq', \n",
        "                    'd(cm)', \n",
        "                    'Attn', \n",
        "                    'Phase', \n",
        "                    'Phase_Corr', \n",
        "                    'Permittivity_real', \n",
        "                    'Permittivity_imaginary',\n",
        "                    'Type',\n",
        "                    'Phase/Attn']]\n",
        "\n",
        "df_targets = df[['M%', 'Density']]\n",
        "# df_targets = df[['Density', 'M%']]\n",
        "\n",
        "dataset_x = df_features.to_numpy()\n",
        "dataset_y = df_targets.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting dataset to test and train+validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform train-test split on RAW DATA\n",
        "X_trainVal, X_test, y_trainVal, y_test = train_test_split(dataset_x, dataset_y, \n",
        "                                                    test_size=0.15\n",
        "                                                    ,random_state=42\n",
        "                                                    )\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainVal, y_trainVal, \n",
        "                                                    test_size=0.15 #validation split\n",
        "                                                    ,random_state=42\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Normalizing the data set\n",
        "scaler_input = MinMaxScaler()\n",
        "scaler_output = MinMaxScaler()\n",
        "\n",
        "# Normalize Train set\n",
        "X_train_norm = scaler_input.fit_transform(X_train)\n",
        "y_train_norm = scaler_output.fit_transform(y_train)\n",
        "\n",
        "# Normalize Validation set\n",
        "X_val_norm = scaler_input.fit_transform(X_val)\n",
        "y_val_norm = scaler_output.fit_transform(y_val)\n",
        "\n",
        "# Normalize the entire dataset (input features)\n",
        "dataset_x_norm = scaler_input.transform(dataset_x)  # Use transform, NOT fit_transform\n",
        "\n",
        "# Normalize the entire dataset (output targets)\n",
        "dataset_y_norm = scaler_output.transform(dataset_y)  # Use transform, NOT fit_transform\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKfjwMP0Tzn"
      },
      "source": [
        "# K-cross Validation\n",
        "* Input features: 7\n",
        "* Output targets: 2\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "l31WJZ7Z0ONb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_292 (Dense)            (None, 64)                640       \n",
            "_________________________________________________________________\n",
            "dense_293 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_294 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_295 (Dense)            (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 9,090\n",
            "Trainable params: 9,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import layers, Sequential, regularizers\n",
        "\n",
        "# Define the model-building function\n",
        "def my_model():\n",
        "  my_model = Sequential([\n",
        "    \n",
        "    layers.Dense(64, input_shape=(9,), activation='relu', \n",
        "                #  kernel_regularizer=regularizers.l2(0.01)\n",
        "                 ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.1),\n",
        "\n",
        "\n",
        "    layers.Dense(64, activation='relu', \n",
        "                # kernel_regularizer=regularizers.l2(0.01)\n",
        "                ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.1),````\n",
        "\n",
        "    layers.Dense(64, activation='relu', \n",
        "                # kernel_regularizer=regularizers.l2(0.01)\n",
        "                ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.2),\n",
        "    \n",
        "    layers.Dense(2, activation='linear')  # Output layer with 2 neurons for the two regression targets\n",
        "  ])\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.00062) # 0.0006 \n",
        "  my_model.compile(\n",
        "      optimizer = opt,\n",
        "      loss = 'mse',\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "\n",
        "  return my_model\n",
        "\n",
        "plot_model(my_model(), show_shapes=True, show_layer_names=True)\n",
        "my_model().summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running model with KCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khCKKB74hFVT",
        "outputId": "37e79cdf-4183-4559-f560-fceb2fc0c630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "####################### Iteration   0  #######################\n",
            "Epoch 1/180\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.6579 - val_loss: 0.0406 - val_accuracy: 0.7119\n",
            "Epoch 2/180\n",
            "53/53 [==============================] - 0s 528us/step - loss: 0.0396 - accuracy: 0.7906 - val_loss: 0.0218 - val_accuracy: 0.8475\n",
            "Epoch 3/180\n",
            "53/53 [==============================] - 0s 543us/step - loss: 0.0177 - accuracy: 0.8408 - val_loss: 0.0143 - val_accuracy: 0.8814\n",
            "Epoch 4/180\n",
            "53/53 [==============================] - 0s 527us/step - loss: 0.0139 - accuracy: 0.8655 - val_loss: 0.0153 - val_accuracy: 0.8475\n",
            "Epoch 5/180\n",
            "53/53 [==============================] - 0s 566us/step - loss: 0.0103 - accuracy: 0.8804 - val_loss: 0.0099 - val_accuracy: 0.8983\n",
            "Epoch 6/180\n",
            "53/53 [==============================] - 0s 549us/step - loss: 0.0090 - accuracy: 0.9084 - val_loss: 0.0110 - val_accuracy: 0.8983\n",
            "Epoch 7/180\n",
            "53/53 [==============================] - 0s 565us/step - loss: 0.0074 - accuracy: 0.9221 - val_loss: 0.0072 - val_accuracy: 0.9322\n",
            "Epoch 8/180\n",
            "53/53 [==============================] - 0s 520us/step - loss: 0.0059 - accuracy: 0.9247 - val_loss: 0.0065 - val_accuracy: 0.9322\n",
            "Epoch 9/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 0.0055 - accuracy: 0.9336 - val_loss: 0.0078 - val_accuracy: 0.8644\n",
            "Epoch 10/180\n",
            "53/53 [==============================] - 0s 525us/step - loss: 0.0055 - accuracy: 0.9111 - val_loss: 0.0057 - val_accuracy: 0.9322\n",
            "Epoch 11/180\n",
            "53/53 [==============================] - 0s 545us/step - loss: 0.0045 - accuracy: 0.9242 - val_loss: 0.0053 - val_accuracy: 0.9492\n",
            "Epoch 12/180\n",
            "53/53 [==============================] - 0s 555us/step - loss: 0.0050 - accuracy: 0.9239 - val_loss: 0.0082 - val_accuracy: 0.8475\n",
            "Epoch 13/180\n",
            "53/53 [==============================] - 0s 541us/step - loss: 0.0042 - accuracy: 0.9412 - val_loss: 0.0052 - val_accuracy: 0.8814\n",
            "Epoch 14/180\n",
            "53/53 [==============================] - 0s 545us/step - loss: 0.0037 - accuracy: 0.9272 - val_loss: 0.0039 - val_accuracy: 0.9661\n",
            "Epoch 15/180\n",
            "53/53 [==============================] - 0s 513us/step - loss: 0.0038 - accuracy: 0.9399 - val_loss: 0.0038 - val_accuracy: 0.9322\n",
            "Epoch 16/180\n",
            "53/53 [==============================] - 0s 513us/step - loss: 0.0030 - accuracy: 0.9411 - val_loss: 0.0046 - val_accuracy: 0.8814\n",
            "Epoch 17/180\n",
            "53/53 [==============================] - 0s 506us/step - loss: 0.0035 - accuracy: 0.9532 - val_loss: 0.0032 - val_accuracy: 0.9661\n",
            "Epoch 18/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 0.0028 - accuracy: 0.9585 - val_loss: 0.0031 - val_accuracy: 0.9153\n",
            "Epoch 19/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 0.0027 - accuracy: 0.9461 - val_loss: 0.0029 - val_accuracy: 0.9153\n",
            "Epoch 20/180\n",
            "53/53 [==============================] - 0s 510us/step - loss: 0.0025 - accuracy: 0.9375 - val_loss: 0.0035 - val_accuracy: 0.8983\n",
            "Epoch 21/180\n",
            "53/53 [==============================] - 0s 529us/step - loss: 0.0026 - accuracy: 0.9327 - val_loss: 0.0033 - val_accuracy: 0.8983\n",
            "Epoch 22/180\n",
            "53/53 [==============================] - 0s 512us/step - loss: 0.0024 - accuracy: 0.9250 - val_loss: 0.0023 - val_accuracy: 0.9661\n",
            "Epoch 23/180\n",
            "53/53 [==============================] - 0s 520us/step - loss: 0.0023 - accuracy: 0.9494 - val_loss: 0.0034 - val_accuracy: 0.8814\n",
            "Epoch 24/180\n",
            "53/53 [==============================] - 0s 523us/step - loss: 0.0025 - accuracy: 0.9521 - val_loss: 0.0028 - val_accuracy: 0.8983\n",
            "Epoch 25/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 0.0022 - accuracy: 0.9507 - val_loss: 0.0029 - val_accuracy: 0.9153\n",
            "Epoch 26/180\n",
            "53/53 [==============================] - 0s 507us/step - loss: 0.0025 - accuracy: 0.9490 - val_loss: 0.0022 - val_accuracy: 0.9661\n",
            "Epoch 27/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 0.0022 - accuracy: 0.9323 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "Epoch 28/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 0.0023 - accuracy: 0.9587 - val_loss: 0.0029 - val_accuracy: 0.8814\n",
            "Epoch 29/180\n",
            "53/53 [==============================] - 0s 606us/step - loss: 0.0021 - accuracy: 0.9489 - val_loss: 0.0022 - val_accuracy: 0.9661\n",
            "Epoch 30/180\n",
            "53/53 [==============================] - 0s 529us/step - loss: 0.0022 - accuracy: 0.9559 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 31/180\n",
            "53/53 [==============================] - 0s 515us/step - loss: 0.0019 - accuracy: 0.9595 - val_loss: 0.0025 - val_accuracy: 0.9661\n",
            "Epoch 32/180\n",
            "53/53 [==============================] - 0s 510us/step - loss: 0.0020 - accuracy: 0.9511 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 33/180\n",
            "53/53 [==============================] - 0s 537us/step - loss: 0.0018 - accuracy: 0.9505 - val_loss: 0.0024 - val_accuracy: 0.9322\n",
            "Epoch 34/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 0.0016 - accuracy: 0.9527 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 35/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 0.0017 - accuracy: 0.9465 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 36/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 0.0017 - accuracy: 0.9521 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 37/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 0.0017 - accuracy: 0.9650 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 38/180\n",
            "53/53 [==============================] - 0s 528us/step - loss: 0.0015 - accuracy: 0.9587 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 39/180\n",
            "53/53 [==============================] - 0s 549us/step - loss: 0.0018 - accuracy: 0.9727 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 40/180\n",
            "53/53 [==============================] - 0s 535us/step - loss: 0.0015 - accuracy: 0.9479 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 41/180\n",
            "53/53 [==============================] - 0s 549us/step - loss: 0.0018 - accuracy: 0.9480 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 42/180\n",
            "53/53 [==============================] - 0s 534us/step - loss: 0.0014 - accuracy: 0.9596 - val_loss: 0.0022 - val_accuracy: 0.9322\n",
            "Epoch 43/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 0.0014 - accuracy: 0.9581 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 44/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 0.0016 - accuracy: 0.9575 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 45/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 0.0014 - accuracy: 0.9540 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 46/180\n",
            "53/53 [==============================] - 0s 525us/step - loss: 0.0013 - accuracy: 0.9691 - val_loss: 0.0018 - val_accuracy: 0.9322\n",
            "Epoch 47/180\n",
            "53/53 [==============================] - 0s 532us/step - loss: 0.0014 - accuracy: 0.9611 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 48/180\n",
            "53/53 [==============================] - 0s 517us/step - loss: 0.0013 - accuracy: 0.9503 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 49/180\n",
            "53/53 [==============================] - 0s 536us/step - loss: 0.0016 - accuracy: 0.9611 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 50/180\n",
            "53/53 [==============================] - 0s 512us/step - loss: 0.0013 - accuracy: 0.9608 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 51/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0015 - accuracy: 0.9706 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 52/180\n",
            "53/53 [==============================] - 0s 504us/step - loss: 0.0014 - accuracy: 0.9429 - val_loss: 0.0028 - val_accuracy: 0.9153\n",
            "Epoch 53/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0019 - accuracy: 0.9200 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 54/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0014 - accuracy: 0.9667 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 55/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 0.0012 - accuracy: 0.9717 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 56/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 0.0013 - accuracy: 0.9679 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 57/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 0.0012 - accuracy: 0.9674 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 58/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 0.0012 - accuracy: 0.9667 - val_loss: 0.0020 - val_accuracy: 0.9322\n",
            "Epoch 59/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0013 - accuracy: 0.9533 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 60/180\n",
            "53/53 [==============================] - 0s 512us/step - loss: 0.0013 - accuracy: 0.9343 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 61/180\n",
            "53/53 [==============================] - 0s 512us/step - loss: 0.0011 - accuracy: 0.9697 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 62/180\n",
            "53/53 [==============================] - 0s 538us/step - loss: 0.0011 - accuracy: 0.9650 - val_loss: 0.0013 - val_accuracy: 0.9492\n",
            "Epoch 63/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 0.0010 - accuracy: 0.9669 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 64/180\n",
            "53/53 [==============================] - 0s 511us/step - loss: 0.0014 - accuracy: 0.9546 - val_loss: 9.7537e-04 - val_accuracy: 0.9492\n",
            "Epoch 65/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 0.0011 - accuracy: 0.9495 - val_loss: 9.7621e-04 - val_accuracy: 0.9661\n",
            "Epoch 66/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 0.0011 - accuracy: 0.9537 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 67/180\n",
            "53/53 [==============================] - 0s 514us/step - loss: 0.0013 - accuracy: 0.9445 - val_loss: 0.0014 - val_accuracy: 0.9322\n",
            "Epoch 68/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 0.0013 - accuracy: 0.9547 - val_loss: 0.0016 - val_accuracy: 0.9322\n",
            "Epoch 69/180\n",
            "53/53 [==============================] - 0s 515us/step - loss: 0.0012 - accuracy: 0.9573 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 70/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 9.2241e-04 - accuracy: 0.9653 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 71/180\n",
            "53/53 [==============================] - 0s 511us/step - loss: 9.4353e-04 - accuracy: 0.9638 - val_loss: 0.0015 - val_accuracy: 0.9322\n",
            "Epoch 72/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 0.0011 - accuracy: 0.9580 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 73/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 9.3259e-04 - accuracy: 0.9725 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 74/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 0.0012 - accuracy: 0.9562 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 75/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 9.6166e-04 - accuracy: 0.9669 - val_loss: 9.5214e-04 - val_accuracy: 0.9322\n",
            "Epoch 76/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 9.3382e-04 - accuracy: 0.9720 - val_loss: 8.2479e-04 - val_accuracy: 0.9661\n",
            "Epoch 77/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 9.2990e-04 - accuracy: 0.9699 - val_loss: 8.7845e-04 - val_accuracy: 0.9661\n",
            "Epoch 78/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 9.3625e-04 - accuracy: 0.9567 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 79/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 0.0012 - accuracy: 0.9669 - val_loss: 9.2652e-04 - val_accuracy: 0.9322\n",
            "Epoch 80/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 8.3356e-04 - accuracy: 0.9762 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 81/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 9.4037e-04 - accuracy: 0.9573 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 82/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 0.0010 - accuracy: 0.9711 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 83/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 9.4654e-04 - accuracy: 0.9706 - val_loss: 8.3389e-04 - val_accuracy: 0.9661\n",
            "Epoch 84/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 8.5819e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9322\n",
            "Epoch 85/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 0.0010 - accuracy: 0.9760 - val_loss: 7.3418e-04 - val_accuracy: 0.9831\n",
            "Epoch 86/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 8.6461e-04 - accuracy: 0.9718 - val_loss: 0.0018 - val_accuracy: 0.9492\n",
            "Epoch 87/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 9.0709e-04 - accuracy: 0.9797 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 88/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 8.6122e-04 - accuracy: 0.9702 - val_loss: 8.7593e-04 - val_accuracy: 0.9661\n",
            "Epoch 89/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 8.7957e-04 - accuracy: 0.9725 - val_loss: 9.5224e-04 - val_accuracy: 0.9492\n",
            "Epoch 90/180\n",
            "53/53 [==============================] - 0s 507us/step - loss: 8.8186e-04 - accuracy: 0.9807 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 91/180\n",
            "53/53 [==============================] - 0s 511us/step - loss: 9.1858e-04 - accuracy: 0.9842 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 92/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 8.0428e-04 - accuracy: 0.9764 - val_loss: 8.9592e-04 - val_accuracy: 0.9322\n",
            "Epoch 93/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 8.9113e-04 - accuracy: 0.9834 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 94/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 8.7291e-04 - accuracy: 0.9644 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 95/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 8.1323e-04 - accuracy: 0.9791 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 96/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 9.4956e-04 - accuracy: 0.9636 - val_loss: 0.0010 - val_accuracy: 0.9322\n",
            "Epoch 97/180\n",
            "53/53 [==============================] - 0s 517us/step - loss: 8.7289e-04 - accuracy: 0.9822 - val_loss: 6.9524e-04 - val_accuracy: 0.9831\n",
            "Epoch 98/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 7.6262e-04 - accuracy: 0.9714 - val_loss: 0.0014 - val_accuracy: 0.9153\n",
            "Epoch 99/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 0.0010 - accuracy: 0.9728 - val_loss: 9.6672e-04 - val_accuracy: 0.9492\n",
            "Epoch 100/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 7.8596e-04 - accuracy: 0.9751 - val_loss: 7.9125e-04 - val_accuracy: 0.9661\n",
            "Epoch 101/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 8.5214e-04 - accuracy: 0.9794 - val_loss: 6.6609e-04 - val_accuracy: 0.9831\n",
            "Epoch 102/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 7.7532e-04 - accuracy: 0.9683 - val_loss: 9.1414e-04 - val_accuracy: 0.9492\n",
            "Epoch 103/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 7.8347e-04 - accuracy: 0.9773 - val_loss: 7.8694e-04 - val_accuracy: 0.9492\n",
            "Epoch 104/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 6.3495e-04 - accuracy: 0.9822 - val_loss: 9.5426e-04 - val_accuracy: 0.9322\n",
            "Epoch 105/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 6.5376e-04 - accuracy: 0.9768 - val_loss: 7.6379e-04 - val_accuracy: 0.9492\n",
            "Epoch 106/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 9.7126e-04 - accuracy: 0.9636 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 107/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 9.6238e-04 - accuracy: 0.9763 - val_loss: 9.0445e-04 - val_accuracy: 0.9322\n",
            "Epoch 108/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 7.1337e-04 - accuracy: 0.9852 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 109/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 7.1820e-04 - accuracy: 0.9705 - val_loss: 8.2909e-04 - val_accuracy: 0.9661\n",
            "Epoch 110/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 6.3083e-04 - accuracy: 0.9899 - val_loss: 7.3941e-04 - val_accuracy: 0.9661\n",
            "Epoch 111/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 7.0809e-04 - accuracy: 0.9757 - val_loss: 7.1426e-04 - val_accuracy: 0.9661\n",
            "Epoch 112/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 5.8760e-04 - accuracy: 0.9788 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 113/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 6.6506e-04 - accuracy: 0.9828 - val_loss: 7.7575e-04 - val_accuracy: 0.9831\n",
            "Epoch 114/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 7.9334e-04 - accuracy: 0.9652 - val_loss: 0.0010 - val_accuracy: 0.9322\n",
            "Epoch 115/180\n",
            "53/53 [==============================] - 0s 507us/step - loss: 6.0738e-04 - accuracy: 0.9894 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 116/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 7.9478e-04 - accuracy: 0.9907 - val_loss: 8.8476e-04 - val_accuracy: 0.9661\n",
            "Epoch 117/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 6.9703e-04 - accuracy: 0.9745 - val_loss: 6.7089e-04 - val_accuracy: 0.9492\n",
            "Epoch 118/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 6.8516e-04 - accuracy: 0.9897 - val_loss: 8.0528e-04 - val_accuracy: 0.9831\n",
            "Epoch 119/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 6.9828e-04 - accuracy: 0.9869 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 120/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 7.5959e-04 - accuracy: 0.9845 - val_loss: 7.9957e-04 - val_accuracy: 0.9492\n",
            "Epoch 121/180\n",
            "53/53 [==============================] - 0s 561us/step - loss: 6.9966e-04 - accuracy: 0.9790 - val_loss: 9.2284e-04 - val_accuracy: 0.9492\n",
            "Epoch 122/180\n",
            "53/53 [==============================] - 0s 535us/step - loss: 7.9267e-04 - accuracy: 0.9688 - val_loss: 8.6734e-04 - val_accuracy: 0.9492\n",
            "Epoch 123/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 7.1821e-04 - accuracy: 0.9895 - val_loss: 0.0019 - val_accuracy: 0.9153\n",
            "Epoch 124/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 0.0010 - accuracy: 0.9703 - val_loss: 7.9314e-04 - val_accuracy: 0.9492\n",
            "Epoch 125/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 6.2930e-04 - accuracy: 0.9917 - val_loss: 8.3019e-04 - val_accuracy: 0.9661\n",
            "Epoch 126/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 6.8337e-04 - accuracy: 0.9795 - val_loss: 7.2994e-04 - val_accuracy: 0.9831\n",
            "Epoch 127/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 6.7571e-04 - accuracy: 0.9879 - val_loss: 0.0010 - val_accuracy: 0.9322\n",
            "Epoch 128/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 6.4002e-04 - accuracy: 0.9843 - val_loss: 7.3787e-04 - val_accuracy: 0.9661\n",
            "Epoch 129/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 6.4987e-04 - accuracy: 0.9758 - val_loss: 7.3022e-04 - val_accuracy: 0.9831\n",
            "Epoch 130/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 7.1856e-04 - accuracy: 0.9806 - val_loss: 8.3186e-04 - val_accuracy: 0.9831\n",
            "Epoch 131/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 8.7893e-04 - accuracy: 0.9912 - val_loss: 8.2499e-04 - val_accuracy: 0.9831\n",
            "Epoch 132/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 5.8299e-04 - accuracy: 0.9847 - val_loss: 6.9202e-04 - val_accuracy: 0.9661\n",
            "Epoch 133/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 6.6675e-04 - accuracy: 0.9815 - val_loss: 0.0019 - val_accuracy: 0.9153\n",
            "Epoch 134/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 8.9886e-04 - accuracy: 0.9741 - val_loss: 6.9541e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 6.5737e-04 - accuracy: 0.9644 - val_loss: 6.7691e-04 - val_accuracy: 0.9661\n",
            "Epoch 136/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 6.5962e-04 - accuracy: 0.9785 - val_loss: 9.8319e-04 - val_accuracy: 0.9661\n",
            "Epoch 137/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 8.2957e-04 - accuracy: 0.9759 - val_loss: 8.8223e-04 - val_accuracy: 0.9492\n",
            "Epoch 138/180\n",
            "53/53 [==============================] - 0s 523us/step - loss: 6.5961e-04 - accuracy: 0.9813 - val_loss: 9.8781e-04 - val_accuracy: 0.9831\n",
            "Epoch 139/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 5.7584e-04 - accuracy: 0.9798 - val_loss: 0.0018 - val_accuracy: 0.8983\n",
            "Epoch 140/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 0.0011 - accuracy: 0.9539 - val_loss: 8.8970e-04 - val_accuracy: 0.9492\n",
            "Epoch 141/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 7.0412e-04 - accuracy: 0.9850 - val_loss: 0.0011 - val_accuracy: 0.9153\n",
            "Epoch 142/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 7.2585e-04 - accuracy: 0.9813 - val_loss: 6.4758e-04 - val_accuracy: 0.9492\n",
            "Epoch 143/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 5.1331e-04 - accuracy: 0.9870 - val_loss: 6.7856e-04 - val_accuracy: 0.9831\n",
            "Epoch 144/180\n",
            "53/53 [==============================] - 0s 443us/step - loss: 6.3191e-04 - accuracy: 0.9780 - val_loss: 6.9655e-04 - val_accuracy: 0.9831\n",
            "Epoch 145/180\n",
            "53/53 [==============================] - 0s 541us/step - loss: 5.1261e-04 - accuracy: 0.9904 - val_loss: 9.2655e-04 - val_accuracy: 0.9661\n",
            "Epoch 146/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 6.1451e-04 - accuracy: 0.9840 - val_loss: 6.4671e-04 - val_accuracy: 0.9831\n",
            "Epoch 147/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 6.0588e-04 - accuracy: 0.9728 - val_loss: 0.0013 - val_accuracy: 0.9322\n",
            "Epoch 148/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 5.7417e-04 - accuracy: 0.9947 - val_loss: 8.3793e-04 - val_accuracy: 0.9322\n",
            "Epoch 149/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 5.1636e-04 - accuracy: 0.9873 - val_loss: 7.7983e-04 - val_accuracy: 0.9661\n",
            "Epoch 150/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 5.8923e-04 - accuracy: 0.9892 - val_loss: 8.1111e-04 - val_accuracy: 0.9831\n",
            "Epoch 151/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 6.2916e-04 - accuracy: 0.9916 - val_loss: 0.0010 - val_accuracy: 0.9492\n",
            "Epoch 152/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 4.7694e-04 - accuracy: 0.9792 - val_loss: 0.0012 - val_accuracy: 0.9322\n",
            "Epoch 153/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 5.6216e-04 - accuracy: 0.9885 - val_loss: 9.9534e-04 - val_accuracy: 0.9661\n",
            "Epoch 154/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 6.1845e-04 - accuracy: 0.9926 - val_loss: 8.0145e-04 - val_accuracy: 0.9322\n",
            "Epoch 155/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 5.7193e-04 - accuracy: 0.9875 - val_loss: 6.6550e-04 - val_accuracy: 0.9831\n",
            "Epoch 156/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 6.3371e-04 - accuracy: 0.9919 - val_loss: 8.4152e-04 - val_accuracy: 0.9661\n",
            "Epoch 157/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 6.5296e-04 - accuracy: 0.9834 - val_loss: 0.0011 - val_accuracy: 0.9153\n",
            "Epoch 158/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 5.9705e-04 - accuracy: 0.9915 - val_loss: 7.0464e-04 - val_accuracy: 0.9492\n",
            "Epoch 159/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 6.3143e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9322\n",
            "Epoch 160/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 7.2399e-04 - accuracy: 0.9874 - val_loss: 6.8435e-04 - val_accuracy: 0.9831\n",
            "Epoch 161/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 5.1399e-04 - accuracy: 0.9896 - val_loss: 7.4178e-04 - val_accuracy: 0.9831\n",
            "Epoch 162/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 5.6384e-04 - accuracy: 0.9771 - val_loss: 8.2565e-04 - val_accuracy: 0.9661\n",
            "Epoch 163/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 5.8974e-04 - accuracy: 0.9885 - val_loss: 7.6353e-04 - val_accuracy: 0.9831\n",
            "Epoch 164/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 9.0093e-04 - accuracy: 0.9893 - val_loss: 8.9621e-04 - val_accuracy: 0.9492\n",
            "Epoch 165/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 5.9802e-04 - accuracy: 0.9907 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 166/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 7.0720e-04 - accuracy: 0.9868 - val_loss: 7.3141e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/180\n",
            "53/53 [==============================] - 0s 538us/step - loss: 5.7465e-04 - accuracy: 0.9898 - val_loss: 0.0013 - val_accuracy: 0.9153\n",
            "Epoch 168/180\n",
            "53/53 [==============================] - 0s 560us/step - loss: 7.7932e-04 - accuracy: 0.9713 - val_loss: 0.0013 - val_accuracy: 0.9153\n",
            "Epoch 169/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 5.1822e-04 - accuracy: 0.9993 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "Epoch 170/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 5.3693e-04 - accuracy: 0.9888 - val_loss: 8.9794e-04 - val_accuracy: 0.9661\n",
            "Epoch 171/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 6.2157e-04 - accuracy: 0.9793 - val_loss: 6.5303e-04 - val_accuracy: 0.9831\n",
            "Epoch 172/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 4.4050e-04 - accuracy: 0.9889 - val_loss: 7.7096e-04 - val_accuracy: 0.9492\n",
            "Epoch 173/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 5.1396e-04 - accuracy: 0.9871 - val_loss: 7.7720e-04 - val_accuracy: 0.9492\n",
            "Epoch 174/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 4.4447e-04 - accuracy: 0.9948 - val_loss: 7.7475e-04 - val_accuracy: 0.9661\n",
            "Epoch 175/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 7.0875e-04 - accuracy: 0.9905 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 176/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 8.2155e-04 - accuracy: 0.9669 - val_loss: 7.6987e-04 - val_accuracy: 0.9322\n",
            "Epoch 177/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 5.8793e-04 - accuracy: 0.9835 - val_loss: 6.3366e-04 - val_accuracy: 0.9492\n",
            "Epoch 178/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 5.3184e-04 - accuracy: 0.9945 - val_loss: 8.1972e-04 - val_accuracy: 0.9492\n",
            "Epoch 179/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 7.0754e-04 - accuracy: 0.9848 - val_loss: 7.2065e-04 - val_accuracy: 0.9661\n",
            "Epoch 180/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 4.6392e-04 - accuracy: 0.9808 - val_loss: 0.0011 - val_accuracy: 0.9322\n",
            "2/2 [==============================] - 0s 522us/step - loss: 0.0011 - accuracy: 0.9322\n",
            "Loss = 0.0010908725671470165, rmse = 0.9322034120559692\n",
            "Loss array:  [0.0010908725671470165]\n",
            "####################### Iteration   1  #######################\n",
            "Epoch 1/180\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.7635 - val_loss: 0.0242 - val_accuracy: 0.8136\n",
            "Epoch 2/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 0.0190 - accuracy: 0.8549 - val_loss: 0.0160 - val_accuracy: 0.8136\n",
            "Epoch 3/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 0.0126 - accuracy: 0.9276 - val_loss: 0.0115 - val_accuracy: 0.8475\n",
            "Epoch 4/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 0.0097 - accuracy: 0.9097 - val_loss: 0.0087 - val_accuracy: 0.8644\n",
            "Epoch 5/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 0.0072 - accuracy: 0.9356 - val_loss: 0.0091 - val_accuracy: 0.8644\n",
            "Epoch 6/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 0.0061 - accuracy: 0.9174 - val_loss: 0.0069 - val_accuracy: 0.8644\n",
            "Epoch 7/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 0.0052 - accuracy: 0.9100 - val_loss: 0.0066 - val_accuracy: 0.8644\n",
            "Epoch 8/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 0.0044 - accuracy: 0.9330 - val_loss: 0.0065 - val_accuracy: 0.8305\n",
            "Epoch 9/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 0.0038 - accuracy: 0.9553 - val_loss: 0.0046 - val_accuracy: 0.8644\n",
            "Epoch 10/180\n",
            "53/53 [==============================] - 0s 437us/step - loss: 0.0035 - accuracy: 0.9242 - val_loss: 0.0048 - val_accuracy: 0.8644\n",
            "Epoch 11/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0035 - accuracy: 0.9226 - val_loss: 0.0050 - val_accuracy: 0.8644\n",
            "Epoch 12/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 0.0029 - accuracy: 0.9367 - val_loss: 0.0036 - val_accuracy: 0.8983\n",
            "Epoch 13/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 0.0027 - accuracy: 0.9522 - val_loss: 0.0041 - val_accuracy: 0.8644\n",
            "Epoch 14/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0028 - accuracy: 0.9428 - val_loss: 0.0049 - val_accuracy: 0.8983\n",
            "Epoch 15/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 0.0042 - accuracy: 0.9492 - val_loss: 0.0034 - val_accuracy: 0.8814\n",
            "Epoch 16/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0025 - accuracy: 0.9522 - val_loss: 0.0042 - val_accuracy: 0.8644\n",
            "Epoch 17/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 0.0023 - accuracy: 0.9465 - val_loss: 0.0036 - val_accuracy: 0.8814\n",
            "Epoch 18/180\n",
            "53/53 [==============================] - 0s 513us/step - loss: 0.0022 - accuracy: 0.9603 - val_loss: 0.0036 - val_accuracy: 0.8983\n",
            "Epoch 19/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 0.0019 - accuracy: 0.9395 - val_loss: 0.0046 - val_accuracy: 0.8814\n",
            "Epoch 20/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 0.0022 - accuracy: 0.9462 - val_loss: 0.0036 - val_accuracy: 0.9153\n",
            "Epoch 21/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 0.0025 - accuracy: 0.9295 - val_loss: 0.0027 - val_accuracy: 0.9322\n",
            "Epoch 22/180\n",
            "53/53 [==============================] - 0s 515us/step - loss: 0.0022 - accuracy: 0.9370 - val_loss: 0.0034 - val_accuracy: 0.9153\n",
            "Epoch 23/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 0.0019 - accuracy: 0.9311 - val_loss: 0.0038 - val_accuracy: 0.9153\n",
            "Epoch 24/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 0.0025 - accuracy: 0.9639 - val_loss: 0.0028 - val_accuracy: 0.9322\n",
            "Epoch 25/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 0.0019 - accuracy: 0.9541 - val_loss: 0.0028 - val_accuracy: 0.9322\n",
            "Epoch 26/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 0.0021 - accuracy: 0.9590 - val_loss: 0.0027 - val_accuracy: 0.9153\n",
            "Epoch 27/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 0.0018 - accuracy: 0.9337 - val_loss: 0.0026 - val_accuracy: 0.8983\n",
            "Epoch 28/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 0.0018 - accuracy: 0.9653 - val_loss: 0.0027 - val_accuracy: 0.9153\n",
            "Epoch 29/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 0.0020 - accuracy: 0.9350 - val_loss: 0.0044 - val_accuracy: 0.8983\n",
            "Epoch 30/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0018 - accuracy: 0.9577 - val_loss: 0.0029 - val_accuracy: 0.9322\n",
            "Epoch 31/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 0.0014 - accuracy: 0.9499 - val_loss: 0.0024 - val_accuracy: 0.9153\n",
            "Epoch 32/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0014 - accuracy: 0.9612 - val_loss: 0.0026 - val_accuracy: 0.9492\n",
            "Epoch 33/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 0.0013 - accuracy: 0.9459 - val_loss: 0.0020 - val_accuracy: 0.9322\n",
            "Epoch 34/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 0.0014 - accuracy: 0.9609 - val_loss: 0.0023 - val_accuracy: 0.9322\n",
            "Epoch 35/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 0.0012 - accuracy: 0.9439 - val_loss: 0.0022 - val_accuracy: 0.8983\n",
            "Epoch 36/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 0.0014 - accuracy: 0.9632 - val_loss: 0.0022 - val_accuracy: 0.8983\n",
            "Epoch 37/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 0.0012 - accuracy: 0.9659 - val_loss: 0.0030 - val_accuracy: 0.8983\n",
            "Epoch 38/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 0.0013 - accuracy: 0.9581 - val_loss: 0.0023 - val_accuracy: 0.9492\n",
            "Epoch 39/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 0.0012 - accuracy: 0.9784 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 40/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 0.0015 - accuracy: 0.9598 - val_loss: 0.0027 - val_accuracy: 0.9153\n",
            "Epoch 41/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 0.0011 - accuracy: 0.9602 - val_loss: 0.0029 - val_accuracy: 0.9322\n",
            "Epoch 42/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0013 - accuracy: 0.9624 - val_loss: 0.0024 - val_accuracy: 0.9153\n",
            "Epoch 43/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 0.0011 - accuracy: 0.9699 - val_loss: 0.0025 - val_accuracy: 0.9322\n",
            "Epoch 44/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 9.9251e-04 - accuracy: 0.9747 - val_loss: 0.0023 - val_accuracy: 0.9492\n",
            "Epoch 45/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 0.0011 - accuracy: 0.9627 - val_loss: 0.0024 - val_accuracy: 0.9322\n",
            "Epoch 46/180\n",
            "53/53 [==============================] - 0s 617us/step - loss: 0.0013 - accuracy: 0.9611 - val_loss: 0.0022 - val_accuracy: 0.9322\n",
            "Epoch 47/180\n",
            "53/53 [==============================] - 0s 549us/step - loss: 0.0011 - accuracy: 0.9666 - val_loss: 0.0020 - val_accuracy: 0.9492\n",
            "Epoch 48/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 9.0767e-04 - accuracy: 0.9601 - val_loss: 0.0020 - val_accuracy: 0.9322\n",
            "Epoch 49/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 9.3821e-04 - accuracy: 0.9683 - val_loss: 0.0020 - val_accuracy: 0.9322\n",
            "Epoch 50/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 7.9044e-04 - accuracy: 0.9728 - val_loss: 0.0023 - val_accuracy: 0.9322\n",
            "Epoch 51/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 9.1909e-04 - accuracy: 0.9822 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 52/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 0.0011 - accuracy: 0.9484 - val_loss: 0.0023 - val_accuracy: 0.9322\n",
            "Epoch 53/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 0.0011 - accuracy: 0.9614 - val_loss: 0.0017 - val_accuracy: 0.9492\n",
            "Epoch 54/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 0.0011 - accuracy: 0.9763 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 55/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 0.0011 - accuracy: 0.9673 - val_loss: 0.0020 - val_accuracy: 0.9492\n",
            "Epoch 56/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 8.4874e-04 - accuracy: 0.9849 - val_loss: 0.0023 - val_accuracy: 0.9153\n",
            "Epoch 57/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 0.0011 - accuracy: 0.9742 - val_loss: 0.0023 - val_accuracy: 0.9322\n",
            "Epoch 58/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 9.1851e-04 - accuracy: 0.9779 - val_loss: 0.0020 - val_accuracy: 0.9492\n",
            "Epoch 59/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 7.7032e-04 - accuracy: 0.9738 - val_loss: 0.0019 - val_accuracy: 0.9831\n",
            "Epoch 60/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 8.8396e-04 - accuracy: 0.9663 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 61/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 8.2945e-04 - accuracy: 0.9746 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 62/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 8.9519e-04 - accuracy: 0.9784 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 63/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 8.1849e-04 - accuracy: 0.9711 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 64/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 8.7413e-04 - accuracy: 0.9729 - val_loss: 0.0033 - val_accuracy: 0.9153\n",
            "Epoch 65/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 9.9619e-04 - accuracy: 0.9724 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 66/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 7.3426e-04 - accuracy: 0.9612 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 67/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 8.4663e-04 - accuracy: 0.9562 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 68/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 9.2516e-04 - accuracy: 0.9842 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 69/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 7.5840e-04 - accuracy: 0.9776 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 70/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 8.6095e-04 - accuracy: 0.9717 - val_loss: 0.0020 - val_accuracy: 0.9831\n",
            "Epoch 71/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 7.3337e-04 - accuracy: 0.9833 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 72/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 7.4210e-04 - accuracy: 0.9780 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 73/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 7.2973e-04 - accuracy: 0.9690 - val_loss: 0.0022 - val_accuracy: 0.9153\n",
            "Epoch 74/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 7.1274e-04 - accuracy: 0.9711 - val_loss: 0.0016 - val_accuracy: 0.9153\n",
            "Epoch 75/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 7.2982e-04 - accuracy: 0.9804 - val_loss: 0.0019 - val_accuracy: 0.9661\n",
            "Epoch 76/180\n",
            "53/53 [==============================] - 0s 513us/step - loss: 9.8844e-04 - accuracy: 0.9736 - val_loss: 0.0035 - val_accuracy: 0.9322\n",
            "Epoch 77/180\n",
            "53/53 [==============================] - 0s 511us/step - loss: 0.0012 - accuracy: 0.9627 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 78/180\n",
            "53/53 [==============================] - 0s 512us/step - loss: 8.8115e-04 - accuracy: 0.9618 - val_loss: 0.0017 - val_accuracy: 0.9322\n",
            "Epoch 79/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 7.5622e-04 - accuracy: 0.9763 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 80/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 7.7882e-04 - accuracy: 0.9838 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 81/180\n",
            "53/53 [==============================] - 0s 557us/step - loss: 6.3248e-04 - accuracy: 0.9893 - val_loss: 0.0017 - val_accuracy: 0.9661\n",
            "Epoch 82/180\n",
            "53/53 [==============================] - 0s 534us/step - loss: 6.9113e-04 - accuracy: 0.9725 - val_loss: 0.0014 - val_accuracy: 0.9492\n",
            "Epoch 83/180\n",
            "53/53 [==============================] - 0s 507us/step - loss: 6.6430e-04 - accuracy: 0.9715 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 84/180\n",
            "53/53 [==============================] - 0s 543us/step - loss: 7.1564e-04 - accuracy: 0.9927 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 85/180\n",
            "53/53 [==============================] - 0s 538us/step - loss: 6.0518e-04 - accuracy: 0.9931 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 86/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 6.1983e-04 - accuracy: 0.9745 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 87/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 6.4189e-04 - accuracy: 0.9921 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 88/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 6.4717e-04 - accuracy: 0.9828 - val_loss: 0.0016 - val_accuracy: 0.9661\n",
            "Epoch 89/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 5.5710e-04 - accuracy: 0.9884 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 90/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 7.8859e-04 - accuracy: 0.9680 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 91/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 6.9288e-04 - accuracy: 0.9837 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 92/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 5.2771e-04 - accuracy: 0.9880 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 93/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 6.4594e-04 - accuracy: 0.9719 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 94/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 5.5307e-04 - accuracy: 0.9778 - val_loss: 0.0011 - val_accuracy: 0.9492\n",
            "Epoch 95/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 6.6585e-04 - accuracy: 0.9894 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 96/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 5.4026e-04 - accuracy: 0.9860 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 97/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 6.7536e-04 - accuracy: 0.9837 - val_loss: 0.0020 - val_accuracy: 0.9661\n",
            "Epoch 98/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 6.1495e-04 - accuracy: 0.9960 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 99/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 7.5294e-04 - accuracy: 0.9694 - val_loss: 0.0021 - val_accuracy: 0.9661\n",
            "Epoch 100/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 8.8373e-04 - accuracy: 0.9673 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 101/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 7.8658e-04 - accuracy: 0.9796 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 102/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 7.5715e-04 - accuracy: 0.9532 - val_loss: 0.0012 - val_accuracy: 0.9492\n",
            "Epoch 103/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 5.3239e-04 - accuracy: 0.9809 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 104/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 6.3712e-04 - accuracy: 0.9767 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 105/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 5.1231e-04 - accuracy: 0.9798 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 106/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 5.7034e-04 - accuracy: 0.9828 - val_loss: 0.0017 - val_accuracy: 0.9831\n",
            "Epoch 107/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 5.4950e-04 - accuracy: 0.9889 - val_loss: 0.0015 - val_accuracy: 0.9322\n",
            "Epoch 108/180\n",
            "53/53 [==============================] - 0s 444us/step - loss: 6.8567e-04 - accuracy: 0.9834 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 109/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 5.7293e-04 - accuracy: 0.9905 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 110/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 5.4260e-04 - accuracy: 0.9870 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 111/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 6.1140e-04 - accuracy: 0.9795 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 112/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 5.0188e-04 - accuracy: 0.9785 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 113/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 5.3425e-04 - accuracy: 0.9866 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 114/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 6.1809e-04 - accuracy: 0.9805 - val_loss: 0.0012 - val_accuracy: 0.9661\n",
            "Epoch 115/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 6.8182e-04 - accuracy: 0.9770 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 116/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 5.9922e-04 - accuracy: 0.9832 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 117/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 7.8049e-04 - accuracy: 0.9838 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 118/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 5.5893e-04 - accuracy: 0.9820 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 119/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 5.3315e-04 - accuracy: 0.9903 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 120/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 5.2750e-04 - accuracy: 0.9970 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 121/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 4.9652e-04 - accuracy: 0.9917 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 122/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 7.7303e-04 - accuracy: 0.9748 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 123/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 9.9837e-04 - accuracy: 0.9848 - val_loss: 0.0016 - val_accuracy: 0.9492\n",
            "Epoch 124/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 7.9785e-04 - accuracy: 0.9727 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 125/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 4.5681e-04 - accuracy: 0.9810 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 126/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 5.7304e-04 - accuracy: 0.9911 - val_loss: 0.0014 - val_accuracy: 0.9661\n",
            "Epoch 127/180\n",
            "53/53 [==============================] - 0s 546us/step - loss: 7.0533e-04 - accuracy: 0.9873 - val_loss: 0.0011 - val_accuracy: 0.9661\n",
            "Epoch 128/180\n",
            "53/53 [==============================] - 0s 543us/step - loss: 5.6188e-04 - accuracy: 0.9825 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 129/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 5.7419e-04 - accuracy: 0.9792 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 130/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 6.2179e-04 - accuracy: 0.9760 - val_loss: 0.0018 - val_accuracy: 0.9831\n",
            "Epoch 131/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 7.1638e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
            "Epoch 132/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 5.6324e-04 - accuracy: 0.9708 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 133/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 5.3419e-04 - accuracy: 0.9882 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 134/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 6.2449e-04 - accuracy: 0.9766 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 135/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 5.4496e-04 - accuracy: 0.9767 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 136/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 5.0391e-04 - accuracy: 0.9878 - val_loss: 0.0018 - val_accuracy: 0.9661\n",
            "Epoch 137/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 5.1331e-04 - accuracy: 0.9630 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 138/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 5.8406e-04 - accuracy: 0.9844 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 139/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 5.4007e-04 - accuracy: 0.9842 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 140/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 6.0344e-04 - accuracy: 0.9927 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 141/180\n",
            "53/53 [==============================] - 0s 516us/step - loss: 4.7744e-04 - accuracy: 0.9814 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 142/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 5.8547e-04 - accuracy: 0.9857 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 143/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 4.4848e-04 - accuracy: 0.9944 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 144/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 5.0759e-04 - accuracy: 0.9880 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 145/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 4.1406e-04 - accuracy: 0.9871 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 146/180\n",
            "53/53 [==============================] - 0s 515us/step - loss: 4.9577e-04 - accuracy: 0.9924 - val_loss: 0.0015 - val_accuracy: 0.9831\n",
            "Epoch 147/180\n",
            "53/53 [==============================] - 0s 524us/step - loss: 6.5531e-04 - accuracy: 0.9556 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 148/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 5.0989e-04 - accuracy: 0.9868 - val_loss: 0.0015 - val_accuracy: 0.9492\n",
            "Epoch 149/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 8.3987e-04 - accuracy: 0.9788 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "Epoch 150/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 4.7785e-04 - accuracy: 0.9848 - val_loss: 0.0015 - val_accuracy: 0.9661\n",
            "Epoch 151/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 5.7820e-04 - accuracy: 0.9857 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 152/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 3.7203e-04 - accuracy: 0.9872 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 153/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 3.9854e-04 - accuracy: 0.9808 - val_loss: 9.4351e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 6.7994e-04 - accuracy: 0.9829 - val_loss: 0.0010 - val_accuracy: 0.9831\n",
            "Epoch 155/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 4.7987e-04 - accuracy: 0.9928 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 156/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 5.5146e-04 - accuracy: 0.9894 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 157/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 4.9520e-04 - accuracy: 0.9901 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 158/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 5.9284e-04 - accuracy: 0.9697 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 159/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 4.6429e-04 - accuracy: 0.9909 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 160/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 5.5743e-04 - accuracy: 0.9725 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 161/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 5.3241e-04 - accuracy: 0.9812 - val_loss: 0.0013 - val_accuracy: 0.9661\n",
            "Epoch 162/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 4.2335e-04 - accuracy: 0.9843 - val_loss: 9.7639e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/180\n",
            "53/53 [==============================] - 0s 526us/step - loss: 4.4394e-04 - accuracy: 0.9891 - val_loss: 0.0022 - val_accuracy: 0.9661\n",
            "Epoch 164/180\n",
            "53/53 [==============================] - 0s 580us/step - loss: 5.5078e-04 - accuracy: 0.9802 - val_loss: 8.6881e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 4.4966e-04 - accuracy: 0.9891 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 166/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 8.6430e-04 - accuracy: 0.9718 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 167/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 4.9052e-04 - accuracy: 0.9868 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 168/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 5.2669e-04 - accuracy: 0.9914 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 169/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 4.1916e-04 - accuracy: 0.9926 - val_loss: 9.9902e-04 - val_accuracy: 0.9831\n",
            "Epoch 170/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 5.2270e-04 - accuracy: 0.9918 - val_loss: 0.0016 - val_accuracy: 0.9831\n",
            "Epoch 171/180\n",
            "53/53 [==============================] - 0s 441us/step - loss: 0.0010 - accuracy: 0.9852 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 172/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 5.5417e-04 - accuracy: 0.9848 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 173/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 4.0046e-04 - accuracy: 0.9863 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 174/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 5.0187e-04 - accuracy: 0.9793 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 175/180\n",
            "53/53 [==============================] - 0s 438us/step - loss: 4.4313e-04 - accuracy: 0.9935 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 176/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 5.9510e-04 - accuracy: 0.9868 - val_loss: 9.7103e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/180\n",
            "53/53 [==============================] - 0s 515us/step - loss: 5.8553e-04 - accuracy: 0.9876 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 178/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 4.8328e-04 - accuracy: 0.9909 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 179/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 6.2637e-04 - accuracy: 0.9857 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 180/180\n",
            "53/53 [==============================] - 0s 444us/step - loss: 4.0007e-04 - accuracy: 0.9950 - val_loss: 0.0012 - val_accuracy: 0.9831\n",
            "2/2 [==============================] - 0s 504us/step - loss: 0.0012 - accuracy: 0.9831\n",
            "Loss = 0.0012283906107768416, rmse = 0.9830508232116699\n",
            "Loss array:  [0.0010908725671470165, 0.0012283906107768416]\n",
            "####################### Iteration   2  #######################\n",
            "Epoch 1/180\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.7510 - val_loss: 0.0179 - val_accuracy: 0.8621\n",
            "Epoch 2/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 0.0207 - accuracy: 0.8864 - val_loss: 0.0131 - val_accuracy: 0.8966\n",
            "Epoch 3/180\n",
            "53/53 [==============================] - 0s 433us/step - loss: 0.0143 - accuracy: 0.8813 - val_loss: 0.0093 - val_accuracy: 0.9310\n",
            "Epoch 4/180\n",
            "53/53 [==============================] - 0s 441us/step - loss: 0.0120 - accuracy: 0.9031 - val_loss: 0.0063 - val_accuracy: 0.9655\n",
            "Epoch 5/180\n",
            "53/53 [==============================] - 0s 515us/step - loss: 0.0080 - accuracy: 0.8978 - val_loss: 0.0042 - val_accuracy: 0.9655\n",
            "Epoch 6/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 0.0062 - accuracy: 0.9313 - val_loss: 0.0036 - val_accuracy: 0.9655\n",
            "Epoch 7/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 0.0050 - accuracy: 0.9265 - val_loss: 0.0032 - val_accuracy: 0.9655\n",
            "Epoch 8/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 0.0040 - accuracy: 0.9476 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 9/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 0.0043 - accuracy: 0.9436 - val_loss: 0.0026 - val_accuracy: 0.9828\n",
            "Epoch 10/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 0.0039 - accuracy: 0.9282 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 11/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 0.0035 - accuracy: 0.9449 - val_loss: 0.0023 - val_accuracy: 0.9828\n",
            "Epoch 12/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 0.0030 - accuracy: 0.9487 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 13/180\n",
            "53/53 [==============================] - 0s 438us/step - loss: 0.0030 - accuracy: 0.9300 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 14/180\n",
            "53/53 [==============================] - 0s 437us/step - loss: 0.0027 - accuracy: 0.9287 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 15/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0022 - accuracy: 0.9500 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 16/180\n",
            "53/53 [==============================] - 0s 436us/step - loss: 0.0020 - accuracy: 0.9611 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 17/180\n",
            "53/53 [==============================] - 0s 597us/step - loss: 0.0024 - accuracy: 0.9503 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 18/180\n",
            "53/53 [==============================] - 0s 521us/step - loss: 0.0030 - accuracy: 0.9361 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 19/180\n",
            "53/53 [==============================] - 0s 443us/step - loss: 0.0020 - accuracy: 0.9636 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 20/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 0.0019 - accuracy: 0.9555 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 21/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 0.0018 - accuracy: 0.9564 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 22/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0015 - accuracy: 0.9668 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 23/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 0.0020 - accuracy: 0.9418 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 24/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0014 - accuracy: 0.9565 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 25/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 0.0016 - accuracy: 0.9609 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 26/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 0.0016 - accuracy: 0.9493 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 27/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 0.0019 - accuracy: 0.9644 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 28/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 0.0012 - accuracy: 0.9621 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 29/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 0.0013 - accuracy: 0.9780 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 30/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 0.0013 - accuracy: 0.9554 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 31/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 0.0012 - accuracy: 0.9527 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 32/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 0.0011 - accuracy: 0.9779 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 33/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 0.0014 - accuracy: 0.9654 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 34/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 0.0013 - accuracy: 0.9662 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 35/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 0.0014 - accuracy: 0.9601 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 36/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 0.0011 - accuracy: 0.9564 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 37/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 9.2483e-04 - accuracy: 0.9831 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 38/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 9.9809e-04 - accuracy: 0.9667 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 39/180\n",
            "53/53 [==============================] - 0s 443us/step - loss: 9.6444e-04 - accuracy: 0.9747 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 40/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 9.2794e-04 - accuracy: 0.9716 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 41/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 9.7125e-04 - accuracy: 0.9804 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 42/180\n",
            "53/53 [==============================] - 0s 524us/step - loss: 9.9512e-04 - accuracy: 0.9740 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 43/180\n",
            "53/53 [==============================] - 0s 563us/step - loss: 8.7474e-04 - accuracy: 0.9612 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 44/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 0.0011 - accuracy: 0.9785 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 45/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0012 - accuracy: 0.9774 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 46/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 9.9899e-04 - accuracy: 0.9719 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 47/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 0.0010 - accuracy: 0.9692 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 48/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 9.3155e-04 - accuracy: 0.9796 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 49/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 8.0160e-04 - accuracy: 0.9626 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 50/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 9.6193e-04 - accuracy: 0.9690 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 51/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 9.0964e-04 - accuracy: 0.9792 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 52/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 9.5215e-04 - accuracy: 0.9748 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 53/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 6.9874e-04 - accuracy: 0.9867 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 54/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 8.9007e-04 - accuracy: 0.9818 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 55/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 9.6296e-04 - accuracy: 0.9651 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 56/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 7.4293e-04 - accuracy: 0.9778 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 57/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 7.7931e-04 - accuracy: 0.9735 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 58/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 8.0295e-04 - accuracy: 0.9739 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 59/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 8.3918e-04 - accuracy: 0.9739 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 60/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 8.0117e-04 - accuracy: 0.9886 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 61/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 9.7333e-04 - accuracy: 0.9836 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 62/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 7.3324e-04 - accuracy: 0.9876 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 63/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 8.1138e-04 - accuracy: 0.9623 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 64/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 8.8006e-04 - accuracy: 0.9767 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 65/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 7.7039e-04 - accuracy: 0.9826 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 66/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 7.8775e-04 - accuracy: 0.9847 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 67/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 6.9974e-04 - accuracy: 0.9815 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 68/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 7.5906e-04 - accuracy: 0.9748 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 69/180\n",
            "53/53 [==============================] - 0s 522us/step - loss: 6.1287e-04 - accuracy: 0.9872 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 70/180\n",
            "53/53 [==============================] - 0s 558us/step - loss: 8.1139e-04 - accuracy: 0.9644 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 71/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 6.6837e-04 - accuracy: 0.9844 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 72/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 8.0805e-04 - accuracy: 0.9878 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 73/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 6.3513e-04 - accuracy: 0.9711 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 74/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 9.8671e-04 - accuracy: 0.9577 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 75/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 5.6149e-04 - accuracy: 0.9945 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 76/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 0.0012 - accuracy: 0.9735 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 77/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 8.9219e-04 - accuracy: 0.9739 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 78/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 6.9520e-04 - accuracy: 0.9909 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 79/180\n",
            "53/53 [==============================] - 0s 445us/step - loss: 6.9901e-04 - accuracy: 0.9735 - val_loss: 9.4336e-04 - val_accuracy: 1.0000\n",
            "Epoch 80/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 5.6274e-04 - accuracy: 0.9933 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 81/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 6.3078e-04 - accuracy: 0.9859 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 82/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 6.0634e-04 - accuracy: 0.9896 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 83/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 5.1560e-04 - accuracy: 0.9952 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 84/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 5.9104e-04 - accuracy: 0.9938 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 85/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 5.8161e-04 - accuracy: 0.9888 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 86/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 7.3859e-04 - accuracy: 0.9958 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 87/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 6.8037e-04 - accuracy: 0.9807 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 88/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 5.7911e-04 - accuracy: 0.9803 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 89/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 5.7100e-04 - accuracy: 0.9953 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 90/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 6.1149e-04 - accuracy: 0.9885 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 91/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 4.7602e-04 - accuracy: 0.9775 - val_loss: 9.8530e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 6.2250e-04 - accuracy: 0.9829 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 93/180\n",
            "53/53 [==============================] - 0s 526us/step - loss: 4.5958e-04 - accuracy: 0.9953 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 94/180\n",
            "53/53 [==============================] - 0s 532us/step - loss: 7.6945e-04 - accuracy: 0.9774 - val_loss: 9.5562e-04 - val_accuracy: 0.9828\n",
            "Epoch 95/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 5.4505e-04 - accuracy: 0.9981 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 96/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 6.1152e-04 - accuracy: 0.9924 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 97/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 7.8931e-04 - accuracy: 0.9890 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 98/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 5.3231e-04 - accuracy: 0.9951 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 99/180\n",
            "53/53 [==============================] - 0s 520us/step - loss: 5.4222e-04 - accuracy: 0.9893 - val_loss: 9.0040e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 4.6075e-04 - accuracy: 0.9910 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 101/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 6.5331e-04 - accuracy: 0.9916 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 102/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 6.1917e-04 - accuracy: 0.9794 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 103/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 8.9103e-04 - accuracy: 0.9738 - val_loss: 8.3592e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 6.4646e-04 - accuracy: 0.9955 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 105/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 5.6482e-04 - accuracy: 0.9817 - val_loss: 9.4949e-04 - val_accuracy: 0.9828\n",
            "Epoch 106/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 4.9375e-04 - accuracy: 0.9931 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 107/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 5.2972e-04 - accuracy: 0.9778 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 108/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 8.1625e-04 - accuracy: 0.9774 - val_loss: 9.2684e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 5.1569e-04 - accuracy: 0.9897 - val_loss: 9.9752e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/180\n",
            "53/53 [==============================] - 0s 444us/step - loss: 4.9589e-04 - accuracy: 0.9793 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 111/180\n",
            "53/53 [==============================] - 0s 441us/step - loss: 4.9096e-04 - accuracy: 0.9945 - val_loss: 9.0709e-04 - val_accuracy: 0.9828\n",
            "Epoch 112/180\n",
            "53/53 [==============================] - 0s 437us/step - loss: 5.6055e-04 - accuracy: 0.9889 - val_loss: 9.3035e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/180\n",
            "53/53 [==============================] - 0s 442us/step - loss: 4.8458e-04 - accuracy: 0.9876 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 114/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 4.6078e-04 - accuracy: 0.9901 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 115/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 5.2786e-04 - accuracy: 0.9909 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 116/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 4.4116e-04 - accuracy: 0.9883 - val_loss: 8.0269e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 5.9940e-04 - accuracy: 0.9938 - val_loss: 9.1516e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 4.2245e-04 - accuracy: 0.9975 - val_loss: 8.9274e-04 - val_accuracy: 0.9828\n",
            "Epoch 119/180\n",
            "53/53 [==============================] - 0s 532us/step - loss: 4.7863e-04 - accuracy: 0.9972 - val_loss: 9.2244e-04 - val_accuracy: 0.9828\n",
            "Epoch 120/180\n",
            "53/53 [==============================] - 0s 561us/step - loss: 6.0001e-04 - accuracy: 0.9805 - val_loss: 9.1486e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 4.1403e-04 - accuracy: 0.9901 - val_loss: 9.4533e-04 - val_accuracy: 0.9828\n",
            "Epoch 122/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 6.2192e-04 - accuracy: 0.9919 - val_loss: 9.7190e-04 - val_accuracy: 0.9828\n",
            "Epoch 123/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 5.9230e-04 - accuracy: 0.9876 - val_loss: 9.8896e-04 - val_accuracy: 0.9828\n",
            "Epoch 124/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 5.8567e-04 - accuracy: 0.9758 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 125/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 6.7076e-04 - accuracy: 0.9978 - val_loss: 8.2321e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 4.6195e-04 - accuracy: 0.9930 - val_loss: 9.5648e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 4.3851e-04 - accuracy: 0.9915 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 128/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 4.2729e-04 - accuracy: 0.9924 - val_loss: 8.3492e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 5.2699e-04 - accuracy: 0.9914 - val_loss: 8.4908e-04 - val_accuracy: 0.9828\n",
            "Epoch 130/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 4.3059e-04 - accuracy: 0.9876 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 131/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 6.5037e-04 - accuracy: 0.9845 - val_loss: 9.7872e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 4.4754e-04 - accuracy: 0.9907 - val_loss: 8.9736e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 4.1479e-04 - accuracy: 0.9922 - val_loss: 9.2476e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 4.5659e-04 - accuracy: 0.9895 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 135/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 5.1121e-04 - accuracy: 0.9954 - val_loss: 9.1893e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 4.8962e-04 - accuracy: 0.9882 - val_loss: 9.4096e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 4.9388e-04 - accuracy: 0.9987 - val_loss: 9.3999e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 4.3384e-04 - accuracy: 0.9929 - val_loss: 9.3427e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 4.8908e-04 - accuracy: 0.9911 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 140/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 5.0199e-04 - accuracy: 0.9997 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 141/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 5.0064e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 142/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 4.7283e-04 - accuracy: 0.9935 - val_loss: 8.4697e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 3.7824e-04 - accuracy: 0.9914 - val_loss: 8.6731e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 5.2511e-04 - accuracy: 0.9902 - val_loss: 8.7683e-04 - val_accuracy: 0.9828\n",
            "Epoch 145/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 4.4877e-04 - accuracy: 0.9956 - val_loss: 9.4132e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/180\n",
            "53/53 [==============================] - 0s 531us/step - loss: 5.0943e-04 - accuracy: 0.9911 - val_loss: 8.4157e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/180\n",
            "53/53 [==============================] - 0s 524us/step - loss: 4.0580e-04 - accuracy: 0.9923 - val_loss: 9.3335e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 4.7123e-04 - accuracy: 0.9980 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 149/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 7.5017e-04 - accuracy: 0.9889 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 150/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 5.4819e-04 - accuracy: 0.9941 - val_loss: 9.7284e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 3.9249e-04 - accuracy: 0.9940 - val_loss: 8.3293e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 3.9494e-04 - accuracy: 0.9951 - val_loss: 9.1376e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 4.3845e-04 - accuracy: 0.9890 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 154/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 6.7981e-04 - accuracy: 0.9753 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 155/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 5.7882e-04 - accuracy: 0.9785 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 156/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 3.8666e-04 - accuracy: 0.9903 - val_loss: 8.9010e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 3.6408e-04 - accuracy: 0.9958 - val_loss: 7.6973e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 4.3060e-04 - accuracy: 0.9854 - val_loss: 9.2094e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 6.1211e-04 - accuracy: 0.9825 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 160/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 9.0914e-04 - accuracy: 0.9891 - val_loss: 9.8916e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 4.3992e-04 - accuracy: 0.9935 - val_loss: 8.7429e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 3.8103e-04 - accuracy: 0.9952 - val_loss: 8.4515e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 4.4590e-04 - accuracy: 0.9856 - val_loss: 8.3181e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 4.1827e-04 - accuracy: 0.9965 - val_loss: 8.7716e-04 - val_accuracy: 0.9828\n",
            "Epoch 165/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 4.9493e-04 - accuracy: 0.9801 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 166/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 4.5886e-04 - accuracy: 0.9934 - val_loss: 9.3161e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 5.0314e-04 - accuracy: 0.9909 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 168/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 5.4218e-04 - accuracy: 0.9846 - val_loss: 7.9914e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 4.4672e-04 - accuracy: 0.9815 - val_loss: 9.2904e-04 - val_accuracy: 0.9828\n",
            "Epoch 170/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 3.7974e-04 - accuracy: 0.9944 - val_loss: 8.4676e-04 - val_accuracy: 1.0000\n",
            "Epoch 171/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 3.5955e-04 - accuracy: 0.9988 - val_loss: 9.5097e-04 - val_accuracy: 0.9828\n",
            "Epoch 172/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 4.8508e-04 - accuracy: 0.9842 - val_loss: 9.7275e-04 - val_accuracy: 0.9483\n",
            "Epoch 173/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 4.2449e-04 - accuracy: 1.0000 - val_loss: 7.6840e-04 - val_accuracy: 1.0000\n",
            "Epoch 174/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 4.8124e-04 - accuracy: 0.9928 - val_loss: 8.2630e-04 - val_accuracy: 1.0000\n",
            "Epoch 175/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 3.8141e-04 - accuracy: 0.9926 - val_loss: 7.5480e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 3.8906e-04 - accuracy: 0.9886 - val_loss: 7.2647e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 5.2823e-04 - accuracy: 0.9869 - val_loss: 8.9622e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 4.0562e-04 - accuracy: 0.9977 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 179/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 0.0010 - accuracy: 0.9670 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 180/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 3.9827e-04 - accuracy: 0.9993 - val_loss: 8.9837e-04 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 527us/step - loss: 8.9837e-04 - accuracy: 1.0000\n",
            "Loss = 0.0008983692969195545, rmse = 1.0\n",
            "Loss array:  [0.0010908725671470165, 0.0012283906107768416, 0.0008983692969195545]\n",
            "####################### Iteration   3  #######################\n",
            "Epoch 1/180\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.5179 - val_loss: 0.0337 - val_accuracy: 0.8103\n",
            "Epoch 2/180\n",
            "53/53 [==============================] - 0s 530us/step - loss: 0.0294 - accuracy: 0.8784 - val_loss: 0.0159 - val_accuracy: 0.7931\n",
            "Epoch 3/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 0.0152 - accuracy: 0.8928 - val_loss: 0.0108 - val_accuracy: 0.8103\n",
            "Epoch 4/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 0.0127 - accuracy: 0.9087 - val_loss: 0.0092 - val_accuracy: 0.8448\n",
            "Epoch 5/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 0.0093 - accuracy: 0.8962 - val_loss: 0.0081 - val_accuracy: 0.8276\n",
            "Epoch 6/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 0.0088 - accuracy: 0.9220 - val_loss: 0.0068 - val_accuracy: 0.8621\n",
            "Epoch 7/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 0.0069 - accuracy: 0.9182 - val_loss: 0.0063 - val_accuracy: 0.8621\n",
            "Epoch 8/180\n",
            "53/53 [==============================] - 0s 443us/step - loss: 0.0057 - accuracy: 0.9387 - val_loss: 0.0061 - val_accuracy: 0.8276\n",
            "Epoch 9/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0054 - accuracy: 0.9404 - val_loss: 0.0069 - val_accuracy: 0.8276\n",
            "Epoch 10/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 0.0059 - accuracy: 0.8942 - val_loss: 0.0043 - val_accuracy: 0.8793\n",
            "Epoch 11/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 0.0043 - accuracy: 0.9201 - val_loss: 0.0052 - val_accuracy: 0.8448\n",
            "Epoch 12/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 0.0042 - accuracy: 0.9285 - val_loss: 0.0036 - val_accuracy: 0.8966\n",
            "Epoch 13/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 0.0036 - accuracy: 0.9160 - val_loss: 0.0032 - val_accuracy: 0.8966\n",
            "Epoch 14/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 0.0036 - accuracy: 0.9148 - val_loss: 0.0032 - val_accuracy: 0.8966\n",
            "Epoch 15/180\n",
            "53/53 [==============================] - 0s 520us/step - loss: 0.0033 - accuracy: 0.9423 - val_loss: 0.0046 - val_accuracy: 0.9138\n",
            "Epoch 16/180\n",
            "53/53 [==============================] - 0s 551us/step - loss: 0.0032 - accuracy: 0.9320 - val_loss: 0.0030 - val_accuracy: 0.8793\n",
            "Epoch 17/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 0.0032 - accuracy: 0.9297 - val_loss: 0.0037 - val_accuracy: 0.8621\n",
            "Epoch 18/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0029 - accuracy: 0.9359 - val_loss: 0.0033 - val_accuracy: 0.8621\n",
            "Epoch 19/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 0.0028 - accuracy: 0.9506 - val_loss: 0.0029 - val_accuracy: 0.8966\n",
            "Epoch 20/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 0.0027 - accuracy: 0.9255 - val_loss: 0.0023 - val_accuracy: 0.8966\n",
            "Epoch 21/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 0.0025 - accuracy: 0.9396 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "Epoch 22/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 0.0021 - accuracy: 0.9431 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 23/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 0.0021 - accuracy: 0.9518 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 24/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0021 - accuracy: 0.9444 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 25/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 0.0025 - accuracy: 0.9505 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 26/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0019 - accuracy: 0.9433 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "Epoch 27/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 0.0023 - accuracy: 0.9427 - val_loss: 0.0020 - val_accuracy: 0.9138\n",
            "Epoch 28/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 0.0018 - accuracy: 0.9383 - val_loss: 0.0024 - val_accuracy: 0.8966\n",
            "Epoch 29/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 0.0020 - accuracy: 0.9672 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 30/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 0.0016 - accuracy: 0.9603 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 31/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 0.0015 - accuracy: 0.9354 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 32/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 0.0015 - accuracy: 0.9558 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 33/180\n",
            "53/53 [==============================] - 0s 504us/step - loss: 0.0018 - accuracy: 0.9556 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 34/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 0.0015 - accuracy: 0.9419 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 35/180\n",
            "53/53 [==============================] - 0s 528us/step - loss: 0.0015 - accuracy: 0.9582 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 36/180\n",
            "53/53 [==============================] - 0s 542us/step - loss: 0.0012 - accuracy: 0.9637 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 37/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 0.0012 - accuracy: 0.9632 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 38/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 0.0012 - accuracy: 0.9544 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 39/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 0.0011 - accuracy: 0.9711 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 40/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0011 - accuracy: 0.9765 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 41/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 0.0012 - accuracy: 0.9661 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 42/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 0.0012 - accuracy: 0.9715 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 43/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0011 - accuracy: 0.9591 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 44/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 0.0014 - accuracy: 0.9533 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 45/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 0.0010 - accuracy: 0.9768 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 46/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 0.0011 - accuracy: 0.9589 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 47/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 9.3820e-04 - accuracy: 0.9743 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 48/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 0.0012 - accuracy: 0.9587 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 49/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 0.0010 - accuracy: 0.9710 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 50/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 9.7901e-04 - accuracy: 0.9597 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 51/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 8.8245e-04 - accuracy: 0.9710 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 52/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 8.9765e-04 - accuracy: 0.9747 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 53/180\n",
            "53/53 [==============================] - 0s 510us/step - loss: 9.4694e-04 - accuracy: 0.9805 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 54/180\n",
            "53/53 [==============================] - 0s 543us/step - loss: 0.0012 - accuracy: 0.9609 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 55/180\n",
            "53/53 [==============================] - 0s 507us/step - loss: 0.0012 - accuracy: 0.9658 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 56/180\n",
            "53/53 [==============================] - 0s 561us/step - loss: 8.7983e-04 - accuracy: 0.9798 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 57/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 9.5638e-04 - accuracy: 0.9592 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 58/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 9.4754e-04 - accuracy: 0.9626 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 59/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 9.7151e-04 - accuracy: 0.9610 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 60/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0012 - accuracy: 0.9786 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 61/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 0.0011 - accuracy: 0.9637 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 62/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0011 - accuracy: 0.9672 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 63/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 0.0015 - accuracy: 0.9526 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 64/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 0.0010 - accuracy: 0.9483 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 65/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 9.1372e-04 - accuracy: 0.9787 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 66/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0010 - accuracy: 0.9784 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 67/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 8.3396e-04 - accuracy: 0.9810 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 68/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 8.2534e-04 - accuracy: 0.9649 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 69/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 6.3261e-04 - accuracy: 0.9890 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 70/180\n",
            "53/53 [==============================] - 0s 518us/step - loss: 8.4376e-04 - accuracy: 0.9656 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 71/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 8.1763e-04 - accuracy: 0.9787 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 72/180\n",
            "53/53 [==============================] - 0s 541us/step - loss: 7.0269e-04 - accuracy: 0.9860 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 73/180\n",
            "53/53 [==============================] - 0s 587us/step - loss: 7.6470e-04 - accuracy: 0.9764 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 74/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 0.0012 - accuracy: 0.9596 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 75/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 7.8815e-04 - accuracy: 0.9812 - val_loss: 9.8598e-04 - val_accuracy: 0.9310\n",
            "Epoch 76/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 9.1146e-04 - accuracy: 0.9745 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 77/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 6.4364e-04 - accuracy: 0.9889 - val_loss: 9.8083e-04 - val_accuracy: 0.9310\n",
            "Epoch 78/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 7.3452e-04 - accuracy: 0.9918 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 79/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 7.2799e-04 - accuracy: 0.9836 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 80/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 7.3307e-04 - accuracy: 0.9930 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 81/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 7.6297e-04 - accuracy: 0.9875 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 82/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 7.2967e-04 - accuracy: 0.9896 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 83/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 7.6459e-04 - accuracy: 0.9797 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 84/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 9.1551e-04 - accuracy: 0.9629 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 85/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 7.1406e-04 - accuracy: 0.9816 - val_loss: 9.9027e-04 - val_accuracy: 0.9828\n",
            "Epoch 86/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 7.4079e-04 - accuracy: 0.9805 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 87/180\n",
            "53/53 [==============================] - 0s 537us/step - loss: 8.8048e-04 - accuracy: 0.9818 - val_loss: 9.5398e-04 - val_accuracy: 0.9483\n",
            "Epoch 88/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 7.2922e-04 - accuracy: 0.9794 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 89/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 9.0200e-04 - accuracy: 0.9795 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 90/180\n",
            "53/53 [==============================] - 0s 537us/step - loss: 7.9416e-04 - accuracy: 0.9839 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 91/180\n",
            "53/53 [==============================] - 0s 562us/step - loss: 6.7657e-04 - accuracy: 0.9775 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 92/180\n",
            "53/53 [==============================] - 0s 521us/step - loss: 7.9886e-04 - accuracy: 0.9799 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 93/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 5.9465e-04 - accuracy: 0.9857 - val_loss: 0.0010 - val_accuracy: 0.9310\n",
            "Epoch 94/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 7.9226e-04 - accuracy: 0.9809 - val_loss: 9.5639e-04 - val_accuracy: 0.9655\n",
            "Epoch 95/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 6.8194e-04 - accuracy: 0.9883 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 96/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 8.0373e-04 - accuracy: 0.9766 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 97/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 7.7969e-04 - accuracy: 0.9887 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 98/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 7.9936e-04 - accuracy: 0.9818 - val_loss: 9.7870e-04 - val_accuracy: 0.9483\n",
            "Epoch 99/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 7.5532e-04 - accuracy: 0.9736 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 100/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 5.9953e-04 - accuracy: 0.9840 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 101/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 7.7144e-04 - accuracy: 0.9868 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 102/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 6.7091e-04 - accuracy: 0.9836 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 103/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 8.7327e-04 - accuracy: 0.9688 - val_loss: 8.0802e-04 - val_accuracy: 0.9655\n",
            "Epoch 104/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 7.2875e-04 - accuracy: 0.9821 - val_loss: 8.9168e-04 - val_accuracy: 0.9655\n",
            "Epoch 105/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 7.6211e-04 - accuracy: 0.9872 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 106/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 9.1977e-04 - accuracy: 0.9698 - val_loss: 9.7424e-04 - val_accuracy: 0.9483\n",
            "Epoch 107/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 6.7339e-04 - accuracy: 0.9772 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 108/180\n",
            "53/53 [==============================] - 0s 562us/step - loss: 9.9190e-04 - accuracy: 0.9622 - val_loss: 8.4976e-04 - val_accuracy: 0.9655\n",
            "Epoch 109/180\n",
            "53/53 [==============================] - 0s 614us/step - loss: 6.4983e-04 - accuracy: 0.9933 - val_loss: 9.5026e-04 - val_accuracy: 0.9483\n",
            "Epoch 110/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 6.9820e-04 - accuracy: 0.9810 - val_loss: 8.2982e-04 - val_accuracy: 0.9483\n",
            "Epoch 111/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 7.0596e-04 - accuracy: 0.9916 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 112/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 6.2476e-04 - accuracy: 0.9902 - val_loss: 8.2688e-04 - val_accuracy: 0.9483\n",
            "Epoch 113/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 6.0245e-04 - accuracy: 0.9868 - val_loss: 9.2735e-04 - val_accuracy: 0.9483\n",
            "Epoch 114/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 5.8418e-04 - accuracy: 0.9850 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 115/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 8.0342e-04 - accuracy: 0.9909 - val_loss: 8.8187e-04 - val_accuracy: 0.9655\n",
            "Epoch 116/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 5.3884e-04 - accuracy: 0.9955 - val_loss: 8.3845e-04 - val_accuracy: 0.9828\n",
            "Epoch 117/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 7.8038e-04 - accuracy: 0.9866 - val_loss: 8.4868e-04 - val_accuracy: 0.9483\n",
            "Epoch 118/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 5.1962e-04 - accuracy: 0.9925 - val_loss: 9.1265e-04 - val_accuracy: 0.9655\n",
            "Epoch 119/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 6.6221e-04 - accuracy: 0.9857 - val_loss: 0.0010 - val_accuracy: 0.9310\n",
            "Epoch 120/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 6.4112e-04 - accuracy: 0.9753 - val_loss: 9.1846e-04 - val_accuracy: 0.9655\n",
            "Epoch 121/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 6.0322e-04 - accuracy: 0.9862 - val_loss: 9.8525e-04 - val_accuracy: 0.9655\n",
            "Epoch 122/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 6.7655e-04 - accuracy: 0.9834 - val_loss: 9.0336e-04 - val_accuracy: 0.9655\n",
            "Epoch 123/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 5.7889e-04 - accuracy: 0.9878 - val_loss: 9.0404e-04 - val_accuracy: 0.9828\n",
            "Epoch 124/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 6.2951e-04 - accuracy: 0.9821 - val_loss: 7.7943e-04 - val_accuracy: 0.9655\n",
            "Epoch 125/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 7.5252e-04 - accuracy: 0.9907 - val_loss: 9.8283e-04 - val_accuracy: 0.9310\n",
            "Epoch 126/180\n",
            "53/53 [==============================] - 0s 597us/step - loss: 5.4083e-04 - accuracy: 0.9757 - val_loss: 8.3491e-04 - val_accuracy: 0.9483\n",
            "Epoch 127/180\n",
            "53/53 [==============================] - 0s 533us/step - loss: 5.5369e-04 - accuracy: 0.9962 - val_loss: 9.7537e-04 - val_accuracy: 0.9655\n",
            "Epoch 128/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 6.2903e-04 - accuracy: 0.9875 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 129/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 6.5883e-04 - accuracy: 0.9848 - val_loss: 8.1969e-04 - val_accuracy: 0.9310\n",
            "Epoch 130/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 5.5587e-04 - accuracy: 0.9832 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 131/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 6.5290e-04 - accuracy: 0.9897 - val_loss: 9.3416e-04 - val_accuracy: 0.9483\n",
            "Epoch 132/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 5.2824e-04 - accuracy: 0.9976 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 133/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 6.4796e-04 - accuracy: 0.9777 - val_loss: 9.2465e-04 - val_accuracy: 0.9655\n",
            "Epoch 134/180\n",
            "53/53 [==============================] - 0s 438us/step - loss: 5.5787e-04 - accuracy: 0.9956 - val_loss: 9.5943e-04 - val_accuracy: 0.9310\n",
            "Epoch 135/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 6.5690e-04 - accuracy: 0.9910 - val_loss: 9.2434e-04 - val_accuracy: 0.9655\n",
            "Epoch 136/180\n",
            "53/53 [==============================] - 0s 443us/step - loss: 6.7691e-04 - accuracy: 0.9822 - val_loss: 8.2394e-04 - val_accuracy: 0.9655\n",
            "Epoch 137/180\n",
            "53/53 [==============================] - 0s 445us/step - loss: 5.8222e-04 - accuracy: 0.9962 - val_loss: 7.9097e-04 - val_accuracy: 0.9655\n",
            "Epoch 138/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 5.0264e-04 - accuracy: 0.9905 - val_loss: 8.0942e-04 - val_accuracy: 0.9483\n",
            "Epoch 139/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 5.5352e-04 - accuracy: 0.9907 - val_loss: 8.1414e-04 - val_accuracy: 0.9483\n",
            "Epoch 140/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 7.0236e-04 - accuracy: 0.9828 - val_loss: 8.7226e-04 - val_accuracy: 0.9655\n",
            "Epoch 141/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 5.2357e-04 - accuracy: 0.9864 - val_loss: 9.7822e-04 - val_accuracy: 0.9655\n",
            "Epoch 142/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 5.5624e-04 - accuracy: 0.9960 - val_loss: 8.6311e-04 - val_accuracy: 0.9828\n",
            "Epoch 143/180\n",
            "53/53 [==============================] - 0s 445us/step - loss: 4.9946e-04 - accuracy: 0.9894 - val_loss: 8.3749e-04 - val_accuracy: 0.9310\n",
            "Epoch 144/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 5.5882e-04 - accuracy: 0.9792 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 145/180\n",
            "53/53 [==============================] - 0s 519us/step - loss: 6.0807e-04 - accuracy: 0.9907 - val_loss: 8.1121e-04 - val_accuracy: 0.9483\n",
            "Epoch 146/180\n",
            "53/53 [==============================] - 0s 516us/step - loss: 6.0520e-04 - accuracy: 0.9796 - val_loss: 7.8650e-04 - val_accuracy: 0.9655\n",
            "Epoch 147/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 5.1912e-04 - accuracy: 0.9907 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 148/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 5.3234e-04 - accuracy: 0.9812 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 149/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 6.5551e-04 - accuracy: 0.9780 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 150/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 6.7857e-04 - accuracy: 0.9875 - val_loss: 7.8237e-04 - val_accuracy: 0.9655\n",
            "Epoch 151/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 5.7473e-04 - accuracy: 0.9907 - val_loss: 9.0744e-04 - val_accuracy: 0.9828\n",
            "Epoch 152/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 5.0233e-04 - accuracy: 0.9836 - val_loss: 9.2054e-04 - val_accuracy: 0.9655\n",
            "Epoch 153/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 5.9868e-04 - accuracy: 0.9884 - val_loss: 9.9239e-04 - val_accuracy: 0.9655\n",
            "Epoch 154/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 9.3011e-04 - accuracy: 0.9849 - val_loss: 8.8653e-04 - val_accuracy: 0.9483\n",
            "Epoch 155/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 6.5664e-04 - accuracy: 0.9805 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 156/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 8.0521e-04 - accuracy: 0.9735 - val_loss: 8.3297e-04 - val_accuracy: 0.9655\n",
            "Epoch 157/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 5.5374e-04 - accuracy: 0.9904 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 158/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 5.7051e-04 - accuracy: 0.9803 - val_loss: 8.2731e-04 - val_accuracy: 0.9655\n",
            "Epoch 159/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 5.0771e-04 - accuracy: 0.9869 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 160/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 6.4197e-04 - accuracy: 0.9802 - val_loss: 7.4252e-04 - val_accuracy: 0.9483\n",
            "Epoch 161/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 5.6931e-04 - accuracy: 0.9864 - val_loss: 8.3951e-04 - val_accuracy: 0.9655\n",
            "Epoch 162/180\n",
            "53/53 [==============================] - 0s 604us/step - loss: 4.8312e-04 - accuracy: 0.9959 - val_loss: 8.4059e-04 - val_accuracy: 0.9655\n",
            "Epoch 163/180\n",
            "53/53 [==============================] - 0s 601us/step - loss: 5.3491e-04 - accuracy: 0.9932 - val_loss: 7.8377e-04 - val_accuracy: 0.9655\n",
            "Epoch 164/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 5.3338e-04 - accuracy: 0.9892 - val_loss: 7.7634e-04 - val_accuracy: 0.9828\n",
            "Epoch 165/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 6.5624e-04 - accuracy: 0.9819 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 166/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 5.9417e-04 - accuracy: 0.9980 - val_loss: 8.2135e-04 - val_accuracy: 0.9483\n",
            "Epoch 167/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 5.6078e-04 - accuracy: 0.9911 - val_loss: 9.8914e-04 - val_accuracy: 0.9655\n",
            "Epoch 168/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 4.9678e-04 - accuracy: 0.9722 - val_loss: 9.8641e-04 - val_accuracy: 0.9310\n",
            "Epoch 169/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 5.1126e-04 - accuracy: 0.9952 - val_loss: 6.9949e-04 - val_accuracy: 0.9655\n",
            "Epoch 170/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 4.0660e-04 - accuracy: 0.9968 - val_loss: 7.3522e-04 - val_accuracy: 0.9483\n",
            "Epoch 171/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 4.1792e-04 - accuracy: 0.9951 - val_loss: 7.8519e-04 - val_accuracy: 0.9310\n",
            "Epoch 172/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 5.0469e-04 - accuracy: 0.9919 - val_loss: 8.9797e-04 - val_accuracy: 0.9483\n",
            "Epoch 173/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 6.6611e-04 - accuracy: 0.9637 - val_loss: 7.0283e-04 - val_accuracy: 0.9655\n",
            "Epoch 174/180\n",
            "53/53 [==============================] - 0s 443us/step - loss: 4.5955e-04 - accuracy: 0.9969 - val_loss: 6.7201e-04 - val_accuracy: 0.9655\n",
            "Epoch 175/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 4.2118e-04 - accuracy: 0.9887 - val_loss: 7.7489e-04 - val_accuracy: 0.9655\n",
            "Epoch 176/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 5.6628e-04 - accuracy: 0.9850 - val_loss: 7.3626e-04 - val_accuracy: 0.9483\n",
            "Epoch 177/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 6.4633e-04 - accuracy: 0.9879 - val_loss: 7.4647e-04 - val_accuracy: 0.9828\n",
            "Epoch 178/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 4.9093e-04 - accuracy: 0.9972 - val_loss: 8.3883e-04 - val_accuracy: 0.9655\n",
            "Epoch 179/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 5.4347e-04 - accuracy: 0.9904 - val_loss: 8.1393e-04 - val_accuracy: 0.9655\n",
            "Epoch 180/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 4.0805e-04 - accuracy: 0.9856 - val_loss: 9.3032e-04 - val_accuracy: 0.9310\n",
            "2/2 [==============================] - 0s 481us/step - loss: 9.3032e-04 - accuracy: 0.9310\n",
            "Loss = 0.0009303216356784105, rmse = 0.931034505367279\n",
            "Loss array:  [0.0010908725671470165, 0.0012283906107768416, 0.0008983692969195545, 0.0009303216356784105]\n",
            "####################### Iteration   4  #######################\n",
            "Epoch 1/180\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.6835 - val_loss: 0.0230 - val_accuracy: 0.8793\n",
            "Epoch 2/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 0.0196 - accuracy: 0.8355 - val_loss: 0.0143 - val_accuracy: 0.8966\n",
            "Epoch 3/180\n",
            "53/53 [==============================] - 0s 440us/step - loss: 0.0134 - accuracy: 0.8893 - val_loss: 0.0096 - val_accuracy: 0.9138\n",
            "Epoch 4/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 0.0111 - accuracy: 0.8723 - val_loss: 0.0066 - val_accuracy: 0.9310\n",
            "Epoch 5/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0077 - accuracy: 0.8912 - val_loss: 0.0053 - val_accuracy: 0.9310\n",
            "Epoch 6/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 0.0061 - accuracy: 0.9293 - val_loss: 0.0039 - val_accuracy: 0.9310\n",
            "Epoch 7/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0046 - accuracy: 0.9225 - val_loss: 0.0035 - val_accuracy: 0.9138\n",
            "Epoch 8/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 0.0041 - accuracy: 0.9328 - val_loss: 0.0036 - val_accuracy: 0.8966\n",
            "Epoch 9/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 0.0039 - accuracy: 0.9291 - val_loss: 0.0033 - val_accuracy: 0.8966\n",
            "Epoch 10/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 0.0032 - accuracy: 0.9130 - val_loss: 0.0027 - val_accuracy: 0.9138\n",
            "Epoch 11/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0028 - accuracy: 0.9145 - val_loss: 0.0031 - val_accuracy: 0.8966\n",
            "Epoch 12/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 0.0030 - accuracy: 0.9476 - val_loss: 0.0047 - val_accuracy: 0.8793\n",
            "Epoch 13/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0029 - accuracy: 0.9190 - val_loss: 0.0026 - val_accuracy: 0.8966\n",
            "Epoch 14/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 0.0027 - accuracy: 0.9182 - val_loss: 0.0022 - val_accuracy: 0.9138\n",
            "Epoch 15/180\n",
            "53/53 [==============================] - 0s 511us/step - loss: 0.0021 - accuracy: 0.9367 - val_loss: 0.0023 - val_accuracy: 0.8966\n",
            "Epoch 16/180\n",
            "53/53 [==============================] - 0s 562us/step - loss: 0.0023 - accuracy: 0.9390 - val_loss: 0.0022 - val_accuracy: 0.8966\n",
            "Epoch 17/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 0.0022 - accuracy: 0.9515 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 18/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 0.0024 - accuracy: 0.9200 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 19/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 0.0019 - accuracy: 0.9709 - val_loss: 0.0021 - val_accuracy: 0.9138\n",
            "Epoch 20/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 0.0015 - accuracy: 0.9436 - val_loss: 0.0023 - val_accuracy: 0.9310\n",
            "Epoch 21/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 0.0017 - accuracy: 0.9432 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 22/180\n",
            "53/53 [==============================] - 0s 445us/step - loss: 0.0016 - accuracy: 0.9434 - val_loss: 0.0024 - val_accuracy: 0.9138\n",
            "Epoch 23/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 0.0020 - accuracy: 0.9363 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 24/180\n",
            "53/53 [==============================] - 0s 445us/step - loss: 0.0015 - accuracy: 0.9668 - val_loss: 0.0019 - val_accuracy: 0.9138\n",
            "Epoch 25/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 0.0015 - accuracy: 0.9603 - val_loss: 0.0027 - val_accuracy: 0.9138\n",
            "Epoch 26/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 0.0017 - accuracy: 0.9513 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 27/180\n",
            "53/53 [==============================] - 0s 437us/step - loss: 0.0018 - accuracy: 0.9684 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 28/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 0.0012 - accuracy: 0.9413 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 29/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 0.0013 - accuracy: 0.9646 - val_loss: 0.0019 - val_accuracy: 0.9138\n",
            "Epoch 30/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 0.0014 - accuracy: 0.9626 - val_loss: 0.0018 - val_accuracy: 0.8966\n",
            "Epoch 31/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 0.0014 - accuracy: 0.9453 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 32/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 0.0011 - accuracy: 0.9445 - val_loss: 0.0016 - val_accuracy: 0.9138\n",
            "Epoch 33/180\n",
            "53/53 [==============================] - 0s 534us/step - loss: 0.0015 - accuracy: 0.9625 - val_loss: 0.0017 - val_accuracy: 0.9138\n",
            "Epoch 34/180\n",
            "53/53 [==============================] - 0s 555us/step - loss: 0.0013 - accuracy: 0.9670 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 35/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 0.0017 - accuracy: 0.9455 - val_loss: 0.0017 - val_accuracy: 0.9138\n",
            "Epoch 36/180\n",
            "53/53 [==============================] - 0s 445us/step - loss: 0.0012 - accuracy: 0.9717 - val_loss: 0.0018 - val_accuracy: 0.9138\n",
            "Epoch 37/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 0.0012 - accuracy: 0.9631 - val_loss: 0.0016 - val_accuracy: 0.9138\n",
            "Epoch 38/180\n",
            "53/53 [==============================] - 0s 504us/step - loss: 0.0011 - accuracy: 0.9640 - val_loss: 0.0016 - val_accuracy: 0.9138\n",
            "Epoch 39/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 0.0012 - accuracy: 0.9672 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 40/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 0.0011 - accuracy: 0.9722 - val_loss: 0.0016 - val_accuracy: 0.9138\n",
            "Epoch 41/180\n",
            "53/53 [==============================] - 0s 442us/step - loss: 9.2317e-04 - accuracy: 0.9818 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 42/180\n",
            "53/53 [==============================] - 0s 435us/step - loss: 0.0011 - accuracy: 0.9524 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 43/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 9.5573e-04 - accuracy: 0.9719 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 44/180\n",
            "53/53 [==============================] - 0s 437us/step - loss: 0.0011 - accuracy: 0.9536 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 45/180\n",
            "53/53 [==============================] - 0s 445us/step - loss: 0.0011 - accuracy: 0.9813 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 46/180\n",
            "53/53 [==============================] - 0s 440us/step - loss: 9.1514e-04 - accuracy: 0.9759 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 47/180\n",
            "53/53 [==============================] - 0s 444us/step - loss: 9.6788e-04 - accuracy: 0.9686 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 48/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 0.0011 - accuracy: 0.9607 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 49/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 9.0962e-04 - accuracy: 0.9659 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 50/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 8.7273e-04 - accuracy: 0.9604 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 51/180\n",
            "53/53 [==============================] - 0s 512us/step - loss: 8.6015e-04 - accuracy: 0.9662 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 52/180\n",
            "53/53 [==============================] - 0s 554us/step - loss: 8.2601e-04 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 53/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 8.4624e-04 - accuracy: 0.9597 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 54/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 9.7743e-04 - accuracy: 0.9717 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 55/180\n",
            "53/53 [==============================] - 0s 444us/step - loss: 9.5686e-04 - accuracy: 0.9539 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 56/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 8.2325e-04 - accuracy: 0.9714 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 57/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 7.5238e-04 - accuracy: 0.9666 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 58/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 9.6492e-04 - accuracy: 0.9598 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 59/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 0.9703 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 60/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 0.0010 - accuracy: 0.9686 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 61/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 9.4168e-04 - accuracy: 0.9734 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 62/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 9.3685e-04 - accuracy: 0.9710 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 63/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 9.9427e-04 - accuracy: 0.9700 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 64/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 7.3128e-04 - accuracy: 0.9775 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 65/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 7.0864e-04 - accuracy: 0.9785 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 66/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 8.8182e-04 - accuracy: 0.9806 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 67/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 7.3837e-04 - accuracy: 0.9803 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 68/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 8.7239e-04 - accuracy: 0.9770 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 69/180\n",
            "53/53 [==============================] - 0s 544us/step - loss: 5.4798e-04 - accuracy: 0.9850 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 70/180\n",
            "53/53 [==============================] - 0s 605us/step - loss: 7.8432e-04 - accuracy: 0.9775 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 71/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 8.0162e-04 - accuracy: 0.9832 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 72/180\n",
            "53/53 [==============================] - 0s 443us/step - loss: 6.9395e-04 - accuracy: 0.9687 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 73/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 6.7707e-04 - accuracy: 0.9736 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 74/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0010 - accuracy: 0.9677 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 75/180\n",
            "53/53 [==============================] - 0s 517us/step - loss: 6.5405e-04 - accuracy: 0.9731 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 76/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 7.6604e-04 - accuracy: 0.9737 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 77/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 5.9847e-04 - accuracy: 0.9857 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 78/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 6.3033e-04 - accuracy: 0.9891 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 79/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 8.3857e-04 - accuracy: 0.9829 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 80/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 5.8993e-04 - accuracy: 0.9854 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 81/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 6.3303e-04 - accuracy: 0.9853 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 82/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 9.9931e-04 - accuracy: 0.9636 - val_loss: 9.6288e-04 - val_accuracy: 0.9483\n",
            "Epoch 83/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 5.5396e-04 - accuracy: 0.9893 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 84/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 7.0932e-04 - accuracy: 0.9729 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 85/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 8.3818e-04 - accuracy: 0.9869 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 86/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 5.7508e-04 - accuracy: 0.9901 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 87/180\n",
            "53/53 [==============================] - 0s 521us/step - loss: 7.8653e-04 - accuracy: 0.9820 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 88/180\n",
            "53/53 [==============================] - 0s 566us/step - loss: 6.1925e-04 - accuracy: 0.9872 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 89/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 9.2549e-04 - accuracy: 0.9826 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 90/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 6.2362e-04 - accuracy: 0.9796 - val_loss: 9.5907e-04 - val_accuracy: 0.9483\n",
            "Epoch 91/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 5.2303e-04 - accuracy: 0.9902 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 92/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 6.5644e-04 - accuracy: 0.9890 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 93/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 5.6773e-04 - accuracy: 0.9820 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 94/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 7.1603e-04 - accuracy: 0.9818 - val_loss: 8.5473e-04 - val_accuracy: 0.9655\n",
            "Epoch 95/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 4.9263e-04 - accuracy: 0.9881 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 96/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 6.9239e-04 - accuracy: 0.9747 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 97/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 7.9887e-04 - accuracy: 0.9801 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 98/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 7.9187e-04 - accuracy: 0.9696 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 99/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 5.5041e-04 - accuracy: 0.9829 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 100/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 5.7995e-04 - accuracy: 0.9715 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 101/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 5.8200e-04 - accuracy: 0.9853 - val_loss: 8.6196e-04 - val_accuracy: 0.9655\n",
            "Epoch 102/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 5.0738e-04 - accuracy: 0.9965 - val_loss: 8.4887e-04 - val_accuracy: 0.9483\n",
            "Epoch 103/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 7.0318e-04 - accuracy: 0.9685 - val_loss: 8.7616e-04 - val_accuracy: 0.9655\n",
            "Epoch 104/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 5.8984e-04 - accuracy: 0.9932 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 105/180\n",
            "53/53 [==============================] - 0s 520us/step - loss: 6.1765e-04 - accuracy: 0.9831 - val_loss: 9.4858e-04 - val_accuracy: 0.9655\n",
            "Epoch 106/180\n",
            "53/53 [==============================] - 0s 549us/step - loss: 7.8381e-04 - accuracy: 0.9846 - val_loss: 9.2464e-04 - val_accuracy: 0.9655\n",
            "Epoch 107/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 5.1668e-04 - accuracy: 0.9928 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 108/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0011 - accuracy: 0.9857 - val_loss: 8.9633e-04 - val_accuracy: 0.9483\n",
            "Epoch 109/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 5.0843e-04 - accuracy: 0.9893 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 110/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 6.8494e-04 - accuracy: 0.9942 - val_loss: 8.6356e-04 - val_accuracy: 0.9655\n",
            "Epoch 111/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 5.1995e-04 - accuracy: 0.9906 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 112/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 5.3631e-04 - accuracy: 0.9915 - val_loss: 8.9142e-04 - val_accuracy: 0.9655\n",
            "Epoch 113/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 6.7270e-04 - accuracy: 0.9842 - val_loss: 9.3820e-04 - val_accuracy: 0.9828\n",
            "Epoch 114/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 6.6543e-04 - accuracy: 0.9886 - val_loss: 7.6021e-04 - val_accuracy: 0.9655\n",
            "Epoch 115/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 4.2952e-04 - accuracy: 0.9934 - val_loss: 9.1758e-04 - val_accuracy: 0.9655\n",
            "Epoch 116/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 4.8819e-04 - accuracy: 0.9870 - val_loss: 9.4343e-04 - val_accuracy: 0.9655\n",
            "Epoch 117/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 5.9970e-04 - accuracy: 0.9848 - val_loss: 7.8432e-04 - val_accuracy: 0.9655\n",
            "Epoch 118/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 3.8679e-04 - accuracy: 0.9885 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 119/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 5.3667e-04 - accuracy: 0.9975 - val_loss: 8.1781e-04 - val_accuracy: 0.9655\n",
            "Epoch 120/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 5.4279e-04 - accuracy: 0.9819 - val_loss: 7.2284e-04 - val_accuracy: 0.9655\n",
            "Epoch 121/180\n",
            "53/53 [==============================] - 0s 565us/step - loss: 5.1070e-04 - accuracy: 0.9856 - val_loss: 9.2430e-04 - val_accuracy: 0.9655\n",
            "Epoch 122/180\n",
            "53/53 [==============================] - 0s 541us/step - loss: 5.3805e-04 - accuracy: 0.9930 - val_loss: 9.0730e-04 - val_accuracy: 0.9655\n",
            "Epoch 123/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 4.8833e-04 - accuracy: 0.9865 - val_loss: 9.4047e-04 - val_accuracy: 0.9655\n",
            "Epoch 124/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 4.7740e-04 - accuracy: 0.9953 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 125/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 5.6667e-04 - accuracy: 0.9886 - val_loss: 7.9591e-04 - val_accuracy: 0.9655\n",
            "Epoch 126/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 5.2685e-04 - accuracy: 0.9886 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 127/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 5.9280e-04 - accuracy: 0.9899 - val_loss: 0.0010 - val_accuracy: 0.9310\n",
            "Epoch 128/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 5.3738e-04 - accuracy: 0.9973 - val_loss: 8.3411e-04 - val_accuracy: 0.9483\n",
            "Epoch 129/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 6.2229e-04 - accuracy: 0.9804 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 130/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 5.1833e-04 - accuracy: 0.9949 - val_loss: 7.8757e-04 - val_accuracy: 0.9655\n",
            "Epoch 131/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 4.7693e-04 - accuracy: 0.9897 - val_loss: 9.3743e-04 - val_accuracy: 0.9828\n",
            "Epoch 132/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 4.8827e-04 - accuracy: 0.9809 - val_loss: 9.1080e-04 - val_accuracy: 0.9483\n",
            "Epoch 133/180\n",
            "53/53 [==============================] - 0s 581us/step - loss: 5.9603e-04 - accuracy: 0.9878 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 134/180\n",
            "53/53 [==============================] - 0s 512us/step - loss: 8.1396e-04 - accuracy: 0.9896 - val_loss: 9.7197e-04 - val_accuracy: 0.9655\n",
            "Epoch 135/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 4.7417e-04 - accuracy: 0.9859 - val_loss: 0.0011 - val_accuracy: 0.9310\n",
            "Epoch 136/180\n",
            "53/53 [==============================] - 0s 513us/step - loss: 5.9620e-04 - accuracy: 0.9765 - val_loss: 8.2884e-04 - val_accuracy: 0.9655\n",
            "Epoch 137/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 4.6499e-04 - accuracy: 0.9940 - val_loss: 7.5710e-04 - val_accuracy: 0.9655\n",
            "Epoch 138/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 3.9953e-04 - accuracy: 0.9966 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 139/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 5.2343e-04 - accuracy: 0.9826 - val_loss: 7.9695e-04 - val_accuracy: 0.9483\n",
            "Epoch 140/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 5.2341e-04 - accuracy: 0.9819 - val_loss: 7.8954e-04 - val_accuracy: 0.9655\n",
            "Epoch 141/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 4.9018e-04 - accuracy: 0.9842 - val_loss: 9.4373e-04 - val_accuracy: 0.9655\n",
            "Epoch 142/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 5.1153e-04 - accuracy: 0.9838 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 143/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 4.3236e-04 - accuracy: 0.9957 - val_loss: 8.7786e-04 - val_accuracy: 0.9655\n",
            "Epoch 144/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 4.9608e-04 - accuracy: 0.9715 - val_loss: 7.6857e-04 - val_accuracy: 0.9483\n",
            "Epoch 145/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 4.2260e-04 - accuracy: 0.9864 - val_loss: 7.3784e-04 - val_accuracy: 0.9655\n",
            "Epoch 146/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 4.4139e-04 - accuracy: 0.9996 - val_loss: 9.2939e-04 - val_accuracy: 0.9655\n",
            "Epoch 147/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 4.6728e-04 - accuracy: 0.9870 - val_loss: 7.7244e-04 - val_accuracy: 0.9828\n",
            "Epoch 148/180\n",
            "53/53 [==============================] - 0s 602us/step - loss: 3.8244e-04 - accuracy: 0.9879 - val_loss: 7.6420e-04 - val_accuracy: 0.9655\n",
            "Epoch 149/180\n",
            "53/53 [==============================] - 0s 529us/step - loss: 4.1503e-04 - accuracy: 0.9894 - val_loss: 9.3141e-04 - val_accuracy: 0.9483\n",
            "Epoch 150/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 4.7958e-04 - accuracy: 0.9952 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 151/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 4.7897e-04 - accuracy: 0.9851 - val_loss: 8.0647e-04 - val_accuracy: 0.9655\n",
            "Epoch 152/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 4.9672e-04 - accuracy: 0.9800 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 153/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 5.9437e-04 - accuracy: 0.9869 - val_loss: 9.3898e-04 - val_accuracy: 0.9483\n",
            "Epoch 154/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 6.4433e-04 - accuracy: 0.9839 - val_loss: 8.0760e-04 - val_accuracy: 0.9828\n",
            "Epoch 155/180\n",
            "53/53 [==============================] - 0s 517us/step - loss: 3.8075e-04 - accuracy: 0.9911 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 156/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 7.0740e-04 - accuracy: 0.9855 - val_loss: 8.4872e-04 - val_accuracy: 0.9828\n",
            "Epoch 157/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 5.0170e-04 - accuracy: 0.9923 - val_loss: 7.6840e-04 - val_accuracy: 0.9483\n",
            "Epoch 158/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 4.8225e-04 - accuracy: 0.9854 - val_loss: 8.8019e-04 - val_accuracy: 0.9655\n",
            "Epoch 159/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 4.1952e-04 - accuracy: 0.9842 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 160/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 3.9996e-04 - accuracy: 0.9848 - val_loss: 7.3168e-04 - val_accuracy: 0.9828\n",
            "Epoch 161/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 3.7962e-04 - accuracy: 0.9927 - val_loss: 6.6505e-04 - val_accuracy: 0.9655\n",
            "Epoch 162/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 4.1606e-04 - accuracy: 0.9890 - val_loss: 8.2285e-04 - val_accuracy: 0.9655\n",
            "Epoch 163/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 5.0481e-04 - accuracy: 0.9750 - val_loss: 8.9981e-04 - val_accuracy: 0.9483\n",
            "Epoch 164/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 3.9331e-04 - accuracy: 0.9999 - val_loss: 8.1544e-04 - val_accuracy: 0.9655\n",
            "Epoch 165/180\n",
            "53/53 [==============================] - 0s 522us/step - loss: 6.0098e-04 - accuracy: 0.9923 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 166/180\n",
            "53/53 [==============================] - 0s 518us/step - loss: 5.3513e-04 - accuracy: 0.9608 - val_loss: 9.2233e-04 - val_accuracy: 0.9655\n",
            "Epoch 167/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 4.4067e-04 - accuracy: 0.9924 - val_loss: 0.0013 - val_accuracy: 0.9310\n",
            "Epoch 168/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 4.3375e-04 - accuracy: 0.9851 - val_loss: 7.0745e-04 - val_accuracy: 0.9828\n",
            "Epoch 169/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 3.6263e-04 - accuracy: 0.9944 - val_loss: 7.6210e-04 - val_accuracy: 0.9655\n",
            "Epoch 170/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 4.2455e-04 - accuracy: 0.9936 - val_loss: 7.4726e-04 - val_accuracy: 0.9828\n",
            "Epoch 171/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 4.3888e-04 - accuracy: 0.9886 - val_loss: 7.5580e-04 - val_accuracy: 0.9655\n",
            "Epoch 172/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 4.4467e-04 - accuracy: 0.9821 - val_loss: 7.1088e-04 - val_accuracy: 0.9655\n",
            "Epoch 173/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 4.1096e-04 - accuracy: 0.9756 - val_loss: 7.5386e-04 - val_accuracy: 0.9483\n",
            "Epoch 174/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 4.7033e-04 - accuracy: 0.9893 - val_loss: 7.8425e-04 - val_accuracy: 0.9655\n",
            "Epoch 175/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 4.5915e-04 - accuracy: 0.9892 - val_loss: 7.0005e-04 - val_accuracy: 0.9655\n",
            "Epoch 176/180\n",
            "53/53 [==============================] - 0s 423us/step - loss: 4.2261e-04 - accuracy: 0.9931 - val_loss: 7.1940e-04 - val_accuracy: 0.9655\n",
            "Epoch 177/180\n",
            "53/53 [==============================] - 0s 442us/step - loss: 3.8597e-04 - accuracy: 0.9957 - val_loss: 8.0730e-04 - val_accuracy: 0.9655\n",
            "Epoch 178/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 3.9562e-04 - accuracy: 0.9986 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 179/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 7.2026e-04 - accuracy: 0.9816 - val_loss: 8.1948e-04 - val_accuracy: 0.9655\n",
            "Epoch 180/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 3.8679e-04 - accuracy: 0.9871 - val_loss: 6.8591e-04 - val_accuracy: 0.9828\n",
            "2/2 [==============================] - 0s 466us/step - loss: 6.8591e-04 - accuracy: 0.9828\n",
            "Loss = 0.0006859108107164502, rmse = 0.982758641242981\n",
            "Loss array:  [0.0010908725671470165, 0.0012283906107768416, 0.0008983692969195545, 0.0009303216356784105, 0.0006859108107164502]\n",
            "####################### Iteration   5  #######################\n",
            "Epoch 1/180\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.6432 - val_loss: 0.0467 - val_accuracy: 0.8966\n",
            "Epoch 2/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 0.0374 - accuracy: 0.8829 - val_loss: 0.0176 - val_accuracy: 0.8793\n",
            "Epoch 3/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0154 - accuracy: 0.9415 - val_loss: 0.0110 - val_accuracy: 0.8966\n",
            "Epoch 4/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 0.0112 - accuracy: 0.9188 - val_loss: 0.0085 - val_accuracy: 0.9310\n",
            "Epoch 5/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 0.0079 - accuracy: 0.9049 - val_loss: 0.0067 - val_accuracy: 0.9310\n",
            "Epoch 6/180\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.0069 - accuracy: 0.9282 - val_loss: 0.0056 - val_accuracy: 0.9138\n",
            "Epoch 7/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 0.0053 - accuracy: 0.9347 - val_loss: 0.0048 - val_accuracy: 0.9310\n",
            "Epoch 8/180\n",
            "53/53 [==============================] - 0s 518us/step - loss: 0.0049 - accuracy: 0.9536 - val_loss: 0.0045 - val_accuracy: 0.9138\n",
            "Epoch 9/180\n",
            "53/53 [==============================] - 0s 518us/step - loss: 0.0049 - accuracy: 0.9431 - val_loss: 0.0049 - val_accuracy: 0.9310\n",
            "Epoch 10/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 0.0043 - accuracy: 0.9246 - val_loss: 0.0034 - val_accuracy: 0.9138\n",
            "Epoch 11/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0037 - accuracy: 0.9247 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 12/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 0.0035 - accuracy: 0.9491 - val_loss: 0.0031 - val_accuracy: 0.9138\n",
            "Epoch 13/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 0.0029 - accuracy: 0.9335 - val_loss: 0.0034 - val_accuracy: 0.8966\n",
            "Epoch 14/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 0.0029 - accuracy: 0.9369 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "Epoch 15/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 0.0023 - accuracy: 0.9619 - val_loss: 0.0037 - val_accuracy: 0.9138\n",
            "Epoch 16/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 0.0029 - accuracy: 0.9475 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 17/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 0.0025 - accuracy: 0.9361 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 18/180\n",
            "53/53 [==============================] - 0s 554us/step - loss: 0.0027 - accuracy: 0.9307 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 19/180\n",
            "53/53 [==============================] - 0s 550us/step - loss: 0.0025 - accuracy: 0.9618 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "Epoch 20/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 0.0020 - accuracy: 0.9401 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 21/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0021 - accuracy: 0.9372 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 22/180\n",
            "53/53 [==============================] - 0s 441us/step - loss: 0.0020 - accuracy: 0.9481 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 23/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 0.0019 - accuracy: 0.9519 - val_loss: 0.0019 - val_accuracy: 0.9138\n",
            "Epoch 24/180\n",
            "53/53 [==============================] - 0s 434us/step - loss: 0.0018 - accuracy: 0.9573 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 25/180\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9535 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "Epoch 26/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 0.0018 - accuracy: 0.9510 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 27/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 0.0025 - accuracy: 0.9598 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 28/180\n",
            "53/53 [==============================] - 0s 516us/step - loss: 0.0017 - accuracy: 0.9504 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 29/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 0.0016 - accuracy: 0.9548 - val_loss: 0.0025 - val_accuracy: 0.9138\n",
            "Epoch 30/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 0.0017 - accuracy: 0.9517 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 31/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0015 - accuracy: 0.9464 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 32/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 0.0013 - accuracy: 0.9534 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 33/180\n",
            "53/53 [==============================] - 0s 443us/step - loss: 0.0023 - accuracy: 0.9348 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 34/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 0.0014 - accuracy: 0.9779 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 35/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 0.0017 - accuracy: 0.9641 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 36/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 0.0012 - accuracy: 0.9633 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 37/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 0.0011 - accuracy: 0.9679 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 38/180\n",
            "53/53 [==============================] - 0s 542us/step - loss: 0.0012 - accuracy: 0.9637 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 39/180\n",
            "53/53 [==============================] - 0s 560us/step - loss: 0.0013 - accuracy: 0.9653 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 40/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0012 - accuracy: 0.9703 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 41/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 9.9129e-04 - accuracy: 0.9668 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 42/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 0.0011 - accuracy: 0.9571 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 43/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 0.0010 - accuracy: 0.9737 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 44/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 0.0013 - accuracy: 0.9609 - val_loss: 0.0017 - val_accuracy: 0.9310\n",
            "Epoch 45/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 0.0011 - accuracy: 0.9732 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 46/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 9.5891e-04 - accuracy: 0.9603 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 47/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 9.3285e-04 - accuracy: 0.9749 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 48/180\n",
            "53/53 [==============================] - 0s 504us/step - loss: 0.0011 - accuracy: 0.9644 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 49/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 8.3235e-04 - accuracy: 0.9723 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 50/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 9.9155e-04 - accuracy: 0.9723 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 51/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 9.3749e-04 - accuracy: 0.9620 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 52/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 8.4711e-04 - accuracy: 0.9745 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 53/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 7.7196e-04 - accuracy: 0.9846 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 54/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 9.9777e-04 - accuracy: 0.9661 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 55/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 8.9337e-04 - accuracy: 0.9729 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 56/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 8.9502e-04 - accuracy: 0.9553 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 57/180\n",
            "53/53 [==============================] - 0s 560us/step - loss: 8.0253e-04 - accuracy: 0.9733 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 58/180\n",
            "53/53 [==============================] - 0s 568us/step - loss: 9.3776e-04 - accuracy: 0.9879 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 59/180\n",
            "53/53 [==============================] - 0s 513us/step - loss: 9.4041e-04 - accuracy: 0.9731 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 60/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 8.4056e-04 - accuracy: 0.9763 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 61/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 0.0010 - accuracy: 0.9661 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 62/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0011 - accuracy: 0.9657 - val_loss: 0.0033 - val_accuracy: 0.9138\n",
            "Epoch 63/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 0.0017 - accuracy: 0.9706 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 64/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 0.0010 - accuracy: 0.9695 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 65/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 7.6722e-04 - accuracy: 0.9845 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 66/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 7.3270e-04 - accuracy: 0.9862 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 67/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 7.7653e-04 - accuracy: 0.9885 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 68/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 7.4574e-04 - accuracy: 0.9799 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 69/180\n",
            "53/53 [==============================] - 0s 517us/step - loss: 6.2588e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 70/180\n",
            "53/53 [==============================] - 0s 533us/step - loss: 6.8453e-04 - accuracy: 0.9816 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 71/180\n",
            "53/53 [==============================] - 0s 512us/step - loss: 7.5006e-04 - accuracy: 0.9931 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 72/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 5.9949e-04 - accuracy: 0.9794 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 73/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 7.8222e-04 - accuracy: 0.9688 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 74/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 0.0010 - accuracy: 0.9787 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 75/180\n",
            "53/53 [==============================] - 0s 510us/step - loss: 5.7304e-04 - accuracy: 0.9925 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 76/180\n",
            "53/53 [==============================] - 0s 544us/step - loss: 8.4585e-04 - accuracy: 0.9754 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 77/180\n",
            "53/53 [==============================] - 0s 550us/step - loss: 6.6790e-04 - accuracy: 0.9820 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 78/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 7.5787e-04 - accuracy: 0.9945 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 79/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 8.7636e-04 - accuracy: 0.9687 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 80/180\n",
            "53/53 [==============================] - 0s 443us/step - loss: 7.1355e-04 - accuracy: 0.9879 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 81/180\n",
            "53/53 [==============================] - 0s 444us/step - loss: 7.5513e-04 - accuracy: 0.9897 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 82/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 7.2378e-04 - accuracy: 0.9846 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 83/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 6.8843e-04 - accuracy: 0.9928 - val_loss: 0.0020 - val_accuracy: 0.9310\n",
            "Epoch 84/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 9.3701e-04 - accuracy: 0.9697 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 85/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 8.2627e-04 - accuracy: 0.9851 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 86/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 5.9075e-04 - accuracy: 0.9905 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 87/180\n",
            "53/53 [==============================] - 0s 535us/step - loss: 7.8643e-04 - accuracy: 0.9819 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 88/180\n",
            "53/53 [==============================] - 0s 538us/step - loss: 7.0512e-04 - accuracy: 0.9692 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 89/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 0.0013 - accuracy: 0.9849 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 90/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 6.5624e-04 - accuracy: 0.9930 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 91/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 5.8941e-04 - accuracy: 0.9905 - val_loss: 0.0016 - val_accuracy: 0.9310\n",
            "Epoch 92/180\n",
            "53/53 [==============================] - 0s 517us/step - loss: 7.5922e-04 - accuracy: 0.9813 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 93/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 4.7902e-04 - accuracy: 0.9971 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 94/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 6.4335e-04 - accuracy: 0.9853 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 95/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 6.3232e-04 - accuracy: 0.9935 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 96/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 7.0268e-04 - accuracy: 0.9766 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 97/180\n",
            "53/53 [==============================] - 0s 511us/step - loss: 7.8529e-04 - accuracy: 0.9708 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 98/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 7.2953e-04 - accuracy: 0.9875 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 99/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 6.6814e-04 - accuracy: 0.9857 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 100/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 4.9250e-04 - accuracy: 0.9869 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 101/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 6.2456e-04 - accuracy: 0.9888 - val_loss: 9.8586e-04 - val_accuracy: 0.9828\n",
            "Epoch 102/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 5.8292e-04 - accuracy: 0.9952 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 103/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 6.1092e-04 - accuracy: 0.9756 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 104/180\n",
            "53/53 [==============================] - 0s 517us/step - loss: 6.8927e-04 - accuracy: 0.9863 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 105/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 7.8127e-04 - accuracy: 0.9915 - val_loss: 9.8578e-04 - val_accuracy: 0.9655\n",
            "Epoch 106/180\n",
            "53/53 [==============================] - 0s 561us/step - loss: 7.4755e-04 - accuracy: 0.9837 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 107/180\n",
            "53/53 [==============================] - 0s 586us/step - loss: 5.6970e-04 - accuracy: 0.9711 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 108/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 7.5886e-04 - accuracy: 0.9808 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 109/180\n",
            "53/53 [==============================] - 0s 504us/step - loss: 7.4040e-04 - accuracy: 0.9828 - val_loss: 0.0014 - val_accuracy: 0.9310\n",
            "Epoch 110/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 8.2997e-04 - accuracy: 0.9794 - val_loss: 9.9429e-04 - val_accuracy: 0.9828\n",
            "Epoch 111/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 5.5242e-04 - accuracy: 0.9868 - val_loss: 9.7802e-04 - val_accuracy: 0.9655\n",
            "Epoch 112/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 5.9197e-04 - accuracy: 0.9892 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 113/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 6.7137e-04 - accuracy: 0.9881 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 114/180\n",
            "53/53 [==============================] - 0s 510us/step - loss: 7.8079e-04 - accuracy: 0.9896 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 115/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 6.4292e-04 - accuracy: 0.9936 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 116/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 4.8401e-04 - accuracy: 0.9920 - val_loss: 9.5100e-04 - val_accuracy: 0.9828\n",
            "Epoch 117/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 7.6442e-04 - accuracy: 0.9773 - val_loss: 9.8325e-04 - val_accuracy: 0.9483\n",
            "Epoch 118/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 4.0699e-04 - accuracy: 0.9901 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 119/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 7.1738e-04 - accuracy: 0.9741 - val_loss: 9.6310e-04 - val_accuracy: 0.9655\n",
            "Epoch 120/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 7.8805e-04 - accuracy: 0.9826 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 121/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 5.1215e-04 - accuracy: 0.9808 - val_loss: 9.5894e-04 - val_accuracy: 0.9828\n",
            "Epoch 122/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 5.5225e-04 - accuracy: 0.9925 - val_loss: 8.7851e-04 - val_accuracy: 0.9828\n",
            "Epoch 123/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 4.8035e-04 - accuracy: 0.9913 - val_loss: 9.3925e-04 - val_accuracy: 0.9655\n",
            "Epoch 124/180\n",
            "53/53 [==============================] - 0s 514us/step - loss: 5.7913e-04 - accuracy: 0.9887 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 125/180\n",
            "53/53 [==============================] - 0s 612us/step - loss: 6.5396e-04 - accuracy: 0.9834 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 126/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 5.4994e-04 - accuracy: 0.9970 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 127/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 5.4231e-04 - accuracy: 0.9834 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 128/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 4.5848e-04 - accuracy: 0.9899 - val_loss: 7.7463e-04 - val_accuracy: 0.9828\n",
            "Epoch 129/180\n",
            "53/53 [==============================] - 0s 506us/step - loss: 5.8038e-04 - accuracy: 0.9811 - val_loss: 9.4637e-04 - val_accuracy: 0.9483\n",
            "Epoch 130/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 4.7368e-04 - accuracy: 0.9944 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 131/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 5.3606e-04 - accuracy: 0.9897 - val_loss: 8.4850e-04 - val_accuracy: 0.9655\n",
            "Epoch 132/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 3.7716e-04 - accuracy: 0.9929 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 133/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 7.1851e-04 - accuracy: 0.9842 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 134/180\n",
            "53/53 [==============================] - 0s 436us/step - loss: 6.3696e-04 - accuracy: 0.9879 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 135/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 6.4259e-04 - accuracy: 0.9699 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 136/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 7.2461e-04 - accuracy: 0.9793 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 137/180\n",
            "53/53 [==============================] - 0s 510us/step - loss: 5.8792e-04 - accuracy: 0.9860 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 138/180\n",
            "53/53 [==============================] - 0s 506us/step - loss: 4.5768e-04 - accuracy: 0.9961 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 139/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 5.4517e-04 - accuracy: 0.9937 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 140/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 5.7802e-04 - accuracy: 0.9876 - val_loss: 9.2593e-04 - val_accuracy: 0.9655\n",
            "Epoch 141/180\n",
            "53/53 [==============================] - 0s 571us/step - loss: 5.2400e-04 - accuracy: 0.9931 - val_loss: 7.4618e-04 - val_accuracy: 0.9483\n",
            "Epoch 142/180\n",
            "53/53 [==============================] - 0s 533us/step - loss: 4.9711e-04 - accuracy: 0.9919 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 143/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 4.4045e-04 - accuracy: 0.9885 - val_loss: 9.1413e-04 - val_accuracy: 0.9655\n",
            "Epoch 144/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 4.4083e-04 - accuracy: 0.9868 - val_loss: 9.8816e-04 - val_accuracy: 0.9655\n",
            "Epoch 145/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 5.3794e-04 - accuracy: 0.9872 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 146/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 5.8190e-04 - accuracy: 0.9875 - val_loss: 9.5302e-04 - val_accuracy: 0.9483\n",
            "Epoch 147/180\n",
            "53/53 [==============================] - 0s 541us/step - loss: 4.8101e-04 - accuracy: 0.9899 - val_loss: 9.9094e-04 - val_accuracy: 0.9483\n",
            "Epoch 148/180\n",
            "53/53 [==============================] - 0s 555us/step - loss: 4.4586e-04 - accuracy: 0.9862 - val_loss: 8.2466e-04 - val_accuracy: 0.9655\n",
            "Epoch 149/180\n",
            "53/53 [==============================] - 0s 519us/step - loss: 4.2212e-04 - accuracy: 0.9915 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 150/180\n",
            "53/53 [==============================] - 0s 541us/step - loss: 5.2377e-04 - accuracy: 0.9849 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 151/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 6.2983e-04 - accuracy: 0.9846 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 152/180\n",
            "53/53 [==============================] - 0s 549us/step - loss: 4.7833e-04 - accuracy: 0.9791 - val_loss: 8.0172e-04 - val_accuracy: 0.9828\n",
            "Epoch 153/180\n",
            "53/53 [==============================] - 0s 517us/step - loss: 5.0109e-04 - accuracy: 0.9919 - val_loss: 0.0016 - val_accuracy: 0.9138\n",
            "Epoch 154/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 6.1536e-04 - accuracy: 0.9865 - val_loss: 9.3857e-04 - val_accuracy: 0.9655\n",
            "Epoch 155/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 4.6828e-04 - accuracy: 0.9758 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 156/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 5.1039e-04 - accuracy: 0.9756 - val_loss: 9.8966e-04 - val_accuracy: 0.9655\n",
            "Epoch 157/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 5.3154e-04 - accuracy: 0.9822 - val_loss: 9.3903e-04 - val_accuracy: 0.9483\n",
            "Epoch 158/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 5.8734e-04 - accuracy: 0.9897 - val_loss: 0.0010 - val_accuracy: 0.9483\n",
            "Epoch 159/180\n",
            "53/53 [==============================] - 0s 569us/step - loss: 4.7462e-04 - accuracy: 0.9766 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 160/180\n",
            "53/53 [==============================] - 0s 566us/step - loss: 5.2626e-04 - accuracy: 0.9808 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 161/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 4.9435e-04 - accuracy: 0.9852 - val_loss: 9.2163e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 3.7698e-04 - accuracy: 0.9864 - val_loss: 9.2171e-04 - val_accuracy: 0.9655\n",
            "Epoch 163/180\n",
            "53/53 [==============================] - 0s 542us/step - loss: 4.3736e-04 - accuracy: 0.9910 - val_loss: 9.1393e-04 - val_accuracy: 0.9655\n",
            "Epoch 164/180\n",
            "53/53 [==============================] - 0s 531us/step - loss: 4.8408e-04 - accuracy: 0.9941 - val_loss: 8.8511e-04 - val_accuracy: 0.9828\n",
            "Epoch 165/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 5.8368e-04 - accuracy: 0.9934 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
            "Epoch 166/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 5.1611e-04 - accuracy: 0.9935 - val_loss: 9.9939e-04 - val_accuracy: 0.9483\n",
            "Epoch 167/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 5.0837e-04 - accuracy: 0.9861 - val_loss: 8.7261e-04 - val_accuracy: 0.9655\n",
            "Epoch 168/180\n",
            "53/53 [==============================] - 0s 507us/step - loss: 3.9247e-04 - accuracy: 0.9918 - val_loss: 9.1844e-04 - val_accuracy: 0.9655\n",
            "Epoch 169/180\n",
            "53/53 [==============================] - 0s 510us/step - loss: 4.2589e-04 - accuracy: 0.9925 - val_loss: 8.7074e-04 - val_accuracy: 0.9828\n",
            "Epoch 170/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 5.8022e-04 - accuracy: 0.9751 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 171/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 3.7164e-04 - accuracy: 0.9771 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 172/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 5.9137e-04 - accuracy: 0.9778 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 173/180\n",
            "53/53 [==============================] - 0s 522us/step - loss: 5.1885e-04 - accuracy: 0.9702 - val_loss: 8.0706e-04 - val_accuracy: 0.9828\n",
            "Epoch 174/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 4.8080e-04 - accuracy: 0.9857 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 175/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 5.2707e-04 - accuracy: 0.9857 - val_loss: 9.9195e-04 - val_accuracy: 0.9655\n",
            "Epoch 176/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 4.3682e-04 - accuracy: 0.9772 - val_loss: 9.5391e-04 - val_accuracy: 0.9828\n",
            "Epoch 177/180\n",
            "53/53 [==============================] - 0s 550us/step - loss: 4.5131e-04 - accuracy: 0.9900 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 178/180\n",
            "53/53 [==============================] - 0s 525us/step - loss: 5.0256e-04 - accuracy: 0.9764 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 179/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 5.2374e-04 - accuracy: 0.9769 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 180/180\n",
            "53/53 [==============================] - 0s 440us/step - loss: 4.6196e-04 - accuracy: 0.9942 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "2/2 [==============================] - 0s 632us/step - loss: 0.0013 - accuracy: 0.9655\n",
            "Loss = 0.0013357028365135193, rmse = 0.9655172228813171\n",
            "Loss array:  [0.0010908725671470165, 0.0012283906107768416, 0.0008983692969195545, 0.0009303216356784105, 0.0006859108107164502, 0.0013357028365135193]\n",
            "####################### Iteration   6  #######################\n",
            "Epoch 1/180\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.7354 - val_loss: 0.0327 - val_accuracy: 0.7931\n",
            "Epoch 2/180\n",
            "53/53 [==============================] - 0s 504us/step - loss: 0.0251 - accuracy: 0.8393 - val_loss: 0.0206 - val_accuracy: 0.8103\n",
            "Epoch 3/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 0.0161 - accuracy: 0.8808 - val_loss: 0.0151 - val_accuracy: 0.8448\n",
            "Epoch 4/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 0.0128 - accuracy: 0.9087 - val_loss: 0.0128 - val_accuracy: 0.8793\n",
            "Epoch 5/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 0.0093 - accuracy: 0.8964 - val_loss: 0.0106 - val_accuracy: 0.8966\n",
            "Epoch 6/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 0.0074 - accuracy: 0.9203 - val_loss: 0.0089 - val_accuracy: 0.9138\n",
            "Epoch 7/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0056 - accuracy: 0.9379 - val_loss: 0.0080 - val_accuracy: 0.9138\n",
            "Epoch 8/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 0.0056 - accuracy: 0.9475 - val_loss: 0.0063 - val_accuracy: 0.9310\n",
            "Epoch 9/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 0.0050 - accuracy: 0.9210 - val_loss: 0.0065 - val_accuracy: 0.9310\n",
            "Epoch 10/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 0.0043 - accuracy: 0.9137 - val_loss: 0.0055 - val_accuracy: 0.9310\n",
            "Epoch 11/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 0.0042 - accuracy: 0.9252 - val_loss: 0.0074 - val_accuracy: 0.9483\n",
            "Epoch 12/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 0.0042 - accuracy: 0.9087 - val_loss: 0.0046 - val_accuracy: 0.9483\n",
            "Epoch 13/180\n",
            "53/53 [==============================] - 0s 521us/step - loss: 0.0034 - accuracy: 0.9298 - val_loss: 0.0045 - val_accuracy: 0.9310\n",
            "Epoch 14/180\n",
            "53/53 [==============================] - 0s 541us/step - loss: 0.0035 - accuracy: 0.9180 - val_loss: 0.0052 - val_accuracy: 0.9483\n",
            "Epoch 15/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 0.0028 - accuracy: 0.9423 - val_loss: 0.0041 - val_accuracy: 0.9483\n",
            "Epoch 16/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 0.0037 - accuracy: 0.9267 - val_loss: 0.0050 - val_accuracy: 0.9310\n",
            "Epoch 17/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 0.0034 - accuracy: 0.9166 - val_loss: 0.0053 - val_accuracy: 0.9483\n",
            "Epoch 18/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 0.0030 - accuracy: 0.9322 - val_loss: 0.0054 - val_accuracy: 0.9483\n",
            "Epoch 19/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 0.0030 - accuracy: 0.9471 - val_loss: 0.0039 - val_accuracy: 0.9138\n",
            "Epoch 20/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 0.0028 - accuracy: 0.9355 - val_loss: 0.0039 - val_accuracy: 0.9138\n",
            "Epoch 21/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 0.0024 - accuracy: 0.9384 - val_loss: 0.0049 - val_accuracy: 0.9483\n",
            "Epoch 22/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0025 - accuracy: 0.9292 - val_loss: 0.0048 - val_accuracy: 0.9310\n",
            "Epoch 23/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 0.0025 - accuracy: 0.9365 - val_loss: 0.0033 - val_accuracy: 0.9310\n",
            "Epoch 24/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 0.0022 - accuracy: 0.9479 - val_loss: 0.0044 - val_accuracy: 0.9483\n",
            "Epoch 25/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 0.0023 - accuracy: 0.9316 - val_loss: 0.0032 - val_accuracy: 0.9138\n",
            "Epoch 26/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 0.0023 - accuracy: 0.9401 - val_loss: 0.0037 - val_accuracy: 0.9310\n",
            "Epoch 27/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 0.0025 - accuracy: 0.9486 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 28/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 0.0021 - accuracy: 0.9504 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 29/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 0.0020 - accuracy: 0.9460 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 30/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 0.0021 - accuracy: 0.9564 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 31/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 0.0021 - accuracy: 0.9310 - val_loss: 0.0034 - val_accuracy: 0.9310\n",
            "Epoch 32/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0017 - accuracy: 0.9437 - val_loss: 0.0029 - val_accuracy: 0.9483\n",
            "Epoch 33/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 0.0025 - accuracy: 0.9132 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 34/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 0.0017 - accuracy: 0.9552 - val_loss: 0.0036 - val_accuracy: 0.9483\n",
            "Epoch 35/180\n",
            "53/53 [==============================] - 0s 557us/step - loss: 0.0018 - accuracy: 0.9372 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 36/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 0.0019 - accuracy: 0.9449 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 37/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 0.0016 - accuracy: 0.9477 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 38/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 0.0016 - accuracy: 0.9439 - val_loss: 0.0035 - val_accuracy: 0.9483\n",
            "Epoch 39/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0016 - accuracy: 0.9522 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 40/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 0.0015 - accuracy: 0.9645 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 41/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 0.0012 - accuracy: 0.9695 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 42/180\n",
            "53/53 [==============================] - 0s 524us/step - loss: 0.0013 - accuracy: 0.9600 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 43/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 0.0015 - accuracy: 0.9398 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 44/180\n",
            "53/53 [==============================] - 0s 512us/step - loss: 0.0015 - accuracy: 0.9452 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 45/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 0.0014 - accuracy: 0.9686 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 46/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 0.0011 - accuracy: 0.9671 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 47/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 0.0013 - accuracy: 0.9555 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 48/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 0.0013 - accuracy: 0.9591 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 49/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 0.0012 - accuracy: 0.9669 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 50/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0011 - accuracy: 0.9680 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 51/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 0.0011 - accuracy: 0.9640 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 52/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0012 - accuracy: 0.9679 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 53/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0016 - accuracy: 0.9603 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 54/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 0.0012 - accuracy: 0.9832 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 55/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 0.0011 - accuracy: 0.9568 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 56/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0011 - accuracy: 0.9646 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 57/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 0.0012 - accuracy: 0.9419 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 58/180\n",
            "53/53 [==============================] - 0s 537us/step - loss: 0.0012 - accuracy: 0.9774 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 59/180\n",
            "53/53 [==============================] - 0s 553us/step - loss: 0.0011 - accuracy: 0.9689 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 60/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 0.0012 - accuracy: 0.9651 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 61/180\n",
            "53/53 [==============================] - 0s 522us/step - loss: 0.0010 - accuracy: 0.9770 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 62/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 0.0011 - accuracy: 0.9556 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 63/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 0.0012 - accuracy: 0.9639 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 64/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 9.5217e-04 - accuracy: 0.9697 - val_loss: 0.0019 - val_accuracy: 0.9828\n",
            "Epoch 65/180\n",
            "53/53 [==============================] - 0s 506us/step - loss: 9.4179e-04 - accuracy: 0.9663 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 66/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 0.0010 - accuracy: 0.9832 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 67/180\n",
            "53/53 [==============================] - 0s 538us/step - loss: 9.2849e-04 - accuracy: 0.9738 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 68/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 9.0322e-04 - accuracy: 0.9867 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 69/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 0.0013 - accuracy: 0.9799 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 70/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 9.5145e-04 - accuracy: 0.9665 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 71/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 9.0411e-04 - accuracy: 0.9818 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 72/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 7.8021e-04 - accuracy: 0.9771 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 73/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 9.3669e-04 - accuracy: 0.9729 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 74/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 8.8994e-04 - accuracy: 0.9829 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 75/180\n",
            "53/53 [==============================] - 0s 539us/step - loss: 8.4840e-04 - accuracy: 0.9600 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 76/180\n",
            "53/53 [==============================] - 0s 539us/step - loss: 8.3974e-04 - accuracy: 0.9732 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 77/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 0.0011 - accuracy: 0.9750 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 78/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 7.0249e-04 - accuracy: 0.9781 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 79/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 9.1647e-04 - accuracy: 0.9859 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 80/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 7.4595e-04 - accuracy: 0.9794 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 81/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 8.5062e-04 - accuracy: 0.9826 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 82/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 7.7271e-04 - accuracy: 0.9821 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 83/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 9.8776e-04 - accuracy: 0.9606 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 84/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 8.1812e-04 - accuracy: 0.9706 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 85/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 7.9398e-04 - accuracy: 0.9845 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 86/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 8.2079e-04 - accuracy: 0.9765 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 87/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 9.0521e-04 - accuracy: 0.9827 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 88/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 8.7193e-04 - accuracy: 0.9811 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 89/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 0.0014 - accuracy: 0.9841 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 90/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 7.0637e-04 - accuracy: 0.9836 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 91/180\n",
            "53/53 [==============================] - 0s 515us/step - loss: 7.5386e-04 - accuracy: 0.9903 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 92/180\n",
            "53/53 [==============================] - 0s 601us/step - loss: 7.8063e-04 - accuracy: 0.9786 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 93/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 6.8621e-04 - accuracy: 0.9891 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 94/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 8.6030e-04 - accuracy: 0.9700 - val_loss: 0.0025 - val_accuracy: 0.9655\n",
            "Epoch 95/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 9.5617e-04 - accuracy: 0.9777 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 96/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 7.7768e-04 - accuracy: 0.9700 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 97/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 0.0012 - accuracy: 0.9625 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 98/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 0.0013 - accuracy: 0.9720 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 99/180\n",
            "53/53 [==============================] - 0s 516us/step - loss: 7.2216e-04 - accuracy: 0.9924 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 100/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 7.2243e-04 - accuracy: 0.9870 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 101/180\n",
            "53/53 [==============================] - 0s 526us/step - loss: 7.7640e-04 - accuracy: 0.9861 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 102/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 7.1270e-04 - accuracy: 0.9913 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 103/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 7.1872e-04 - accuracy: 0.9879 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 104/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 5.8420e-04 - accuracy: 0.9751 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 105/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 9.4417e-04 - accuracy: 0.9815 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 106/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 7.2262e-04 - accuracy: 0.9700 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 107/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 6.8889e-04 - accuracy: 0.9829 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 108/180\n",
            "53/53 [==============================] - 0s 635us/step - loss: 0.0010 - accuracy: 0.9701 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 109/180\n",
            "53/53 [==============================] - 0s 540us/step - loss: 6.3584e-04 - accuracy: 0.9771 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 110/180\n",
            "53/53 [==============================] - 0s 527us/step - loss: 0.0010 - accuracy: 0.9796 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 111/180\n",
            "53/53 [==============================] - 0s 526us/step - loss: 5.1696e-04 - accuracy: 0.9869 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 112/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 5.4184e-04 - accuracy: 0.9923 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 113/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 7.2793e-04 - accuracy: 0.9905 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 114/180\n",
            "53/53 [==============================] - 0s 521us/step - loss: 7.1004e-04 - accuracy: 0.9882 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 115/180\n",
            "53/53 [==============================] - 0s 514us/step - loss: 6.4044e-04 - accuracy: 0.9840 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 116/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 5.5701e-04 - accuracy: 0.9935 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 117/180\n",
            "53/53 [==============================] - 0s 514us/step - loss: 7.8048e-04 - accuracy: 0.9812 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 118/180\n",
            "53/53 [==============================] - 0s 517us/step - loss: 4.7891e-04 - accuracy: 0.9746 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 119/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 6.2637e-04 - accuracy: 0.9807 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 120/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 6.2446e-04 - accuracy: 0.9867 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 121/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 5.5532e-04 - accuracy: 0.9864 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 122/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 5.5276e-04 - accuracy: 0.9947 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 123/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 5.1764e-04 - accuracy: 0.9910 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 124/180\n",
            "53/53 [==============================] - 0s 600us/step - loss: 6.7190e-04 - accuracy: 0.9875 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 125/180\n",
            "53/53 [==============================] - 0s 583us/step - loss: 6.0659e-04 - accuracy: 0.9905 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 126/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 6.3138e-04 - accuracy: 0.9763 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 127/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 5.7105e-04 - accuracy: 0.9913 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 128/180\n",
            "53/53 [==============================] - 0s 549us/step - loss: 4.8573e-04 - accuracy: 0.9884 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 129/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 6.8792e-04 - accuracy: 0.9803 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 130/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 5.8134e-04 - accuracy: 0.9923 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 131/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 6.3702e-04 - accuracy: 0.9847 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 132/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 5.0038e-04 - accuracy: 0.9879 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 133/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 9.2754e-04 - accuracy: 0.9772 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 134/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 6.4304e-04 - accuracy: 0.9860 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 135/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 6.0079e-04 - accuracy: 0.9752 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 136/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 7.3322e-04 - accuracy: 0.9875 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 137/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 5.9454e-04 - accuracy: 0.9822 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 138/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 5.6232e-04 - accuracy: 0.9839 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 139/180\n",
            "53/53 [==============================] - 0s 606us/step - loss: 7.0511e-04 - accuracy: 0.9800 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 140/180\n",
            "53/53 [==============================] - 0s 572us/step - loss: 6.0732e-04 - accuracy: 0.9909 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 141/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 5.6419e-04 - accuracy: 0.9911 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 142/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 5.8863e-04 - accuracy: 0.9923 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 143/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 5.0498e-04 - accuracy: 0.9917 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 144/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 5.7548e-04 - accuracy: 0.9740 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 145/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 5.1513e-04 - accuracy: 0.9848 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 146/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 7.7911e-04 - accuracy: 0.9760 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 147/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 4.9288e-04 - accuracy: 0.9917 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 148/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 4.3118e-04 - accuracy: 0.9876 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 149/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 5.1162e-04 - accuracy: 0.9791 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 150/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 6.2478e-04 - accuracy: 0.9916 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 151/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 4.7632e-04 - accuracy: 0.9871 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 152/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 4.8071e-04 - accuracy: 0.9963 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 153/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 4.8477e-04 - accuracy: 0.9770 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 154/180\n",
            "53/53 [==============================] - 0s 577us/step - loss: 4.2984e-04 - accuracy: 0.9965 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 155/180\n",
            "53/53 [==============================] - 0s 712us/step - loss: 4.5644e-04 - accuracy: 0.9857 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 156/180\n",
            "53/53 [==============================] - 0s 514us/step - loss: 5.2836e-04 - accuracy: 0.9866 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 157/180\n",
            "53/53 [==============================] - 0s 545us/step - loss: 5.2336e-04 - accuracy: 0.9912 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 158/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 6.1298e-04 - accuracy: 0.9823 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 159/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 4.8612e-04 - accuracy: 0.9856 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 160/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 6.3208e-04 - accuracy: 0.9675 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 161/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 6.1568e-04 - accuracy: 0.9991 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 162/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 5.1514e-04 - accuracy: 0.9812 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 163/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 5.6038e-04 - accuracy: 0.9851 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 164/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 5.6976e-04 - accuracy: 0.9881 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 165/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 5.6726e-04 - accuracy: 0.9827 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 166/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 5.9927e-04 - accuracy: 0.9864 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 167/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 6.9918e-04 - accuracy: 0.9842 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 168/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 4.1921e-04 - accuracy: 0.9795 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 169/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 3.9384e-04 - accuracy: 0.9927 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 170/180\n",
            "53/53 [==============================] - 0s 580us/step - loss: 5.5797e-04 - accuracy: 0.9895 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 171/180\n",
            "53/53 [==============================] - 0s 551us/step - loss: 4.2218e-04 - accuracy: 0.9815 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 172/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 5.8821e-04 - accuracy: 0.9735 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 173/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 5.6935e-04 - accuracy: 0.9626 - val_loss: 9.6061e-04 - val_accuracy: 1.0000\n",
            "Epoch 174/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 4.7979e-04 - accuracy: 0.9942 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 175/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 5.3885e-04 - accuracy: 0.9832 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 176/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 5.4411e-04 - accuracy: 0.9914 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 177/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 5.0700e-04 - accuracy: 0.9877 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 178/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 3.5438e-04 - accuracy: 0.9970 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 179/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 5.0181e-04 - accuracy: 0.9919 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 180/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 4.4172e-04 - accuracy: 0.9936 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 561us/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Loss = 0.0010973649332299829, rmse = 1.0\n",
            "Loss array:  [0.0010908725671470165, 0.0012283906107768416, 0.0008983692969195545, 0.0009303216356784105, 0.0006859108107164502, 0.0013357028365135193, 0.0010973649332299829]\n",
            "####################### Iteration   7  #######################\n",
            "Epoch 1/180\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.6451 - val_loss: 0.0272 - val_accuracy: 0.8448\n",
            "Epoch 2/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 0.0266 - accuracy: 0.8223 - val_loss: 0.0170 - val_accuracy: 0.8103\n",
            "Epoch 3/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 0.0180 - accuracy: 0.8477 - val_loss: 0.0140 - val_accuracy: 0.8448\n",
            "Epoch 4/180\n",
            "53/53 [==============================] - 0s 574us/step - loss: 0.0140 - accuracy: 0.8686 - val_loss: 0.0091 - val_accuracy: 0.8793\n",
            "Epoch 5/180\n",
            "53/53 [==============================] - 0s 554us/step - loss: 0.0090 - accuracy: 0.8806 - val_loss: 0.0072 - val_accuracy: 0.9138\n",
            "Epoch 6/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 0.0071 - accuracy: 0.9122 - val_loss: 0.0062 - val_accuracy: 0.9310\n",
            "Epoch 7/180\n",
            "53/53 [==============================] - 0s 507us/step - loss: 0.0055 - accuracy: 0.9312 - val_loss: 0.0066 - val_accuracy: 0.9310\n",
            "Epoch 8/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 0.0050 - accuracy: 0.9141 - val_loss: 0.0059 - val_accuracy: 0.9310\n",
            "Epoch 9/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 0.0046 - accuracy: 0.9243 - val_loss: 0.0064 - val_accuracy: 0.8793\n",
            "Epoch 10/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 0.0039 - accuracy: 0.9323 - val_loss: 0.0054 - val_accuracy: 0.9483\n",
            "Epoch 11/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 0.0041 - accuracy: 0.9177 - val_loss: 0.0041 - val_accuracy: 0.9655\n",
            "Epoch 12/180\n",
            "53/53 [==============================] - 0s 527us/step - loss: 0.0041 - accuracy: 0.9327 - val_loss: 0.0043 - val_accuracy: 0.9655\n",
            "Epoch 13/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 0.0034 - accuracy: 0.9262 - val_loss: 0.0048 - val_accuracy: 0.9310\n",
            "Epoch 14/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 0.0036 - accuracy: 0.9282 - val_loss: 0.0037 - val_accuracy: 0.9828\n",
            "Epoch 15/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 0.0029 - accuracy: 0.9429 - val_loss: 0.0037 - val_accuracy: 0.9483\n",
            "Epoch 16/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 0.0033 - accuracy: 0.9541 - val_loss: 0.0034 - val_accuracy: 0.9655\n",
            "Epoch 17/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 0.0028 - accuracy: 0.9243 - val_loss: 0.0046 - val_accuracy: 0.9310\n",
            "Epoch 18/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 0.0027 - accuracy: 0.9164 - val_loss: 0.0033 - val_accuracy: 0.9655\n",
            "Epoch 19/180\n",
            "53/53 [==============================] - 0s 583us/step - loss: 0.0031 - accuracy: 0.9460 - val_loss: 0.0038 - val_accuracy: 0.9310\n",
            "Epoch 20/180\n",
            "53/53 [==============================] - 0s 627us/step - loss: 0.0035 - accuracy: 0.9194 - val_loss: 0.0032 - val_accuracy: 0.9655\n",
            "Epoch 21/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 0.0023 - accuracy: 0.9433 - val_loss: 0.0027 - val_accuracy: 0.9655\n",
            "Epoch 22/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 0.0024 - accuracy: 0.9329 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 23/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 0.0023 - accuracy: 0.9363 - val_loss: 0.0032 - val_accuracy: 0.9310\n",
            "Epoch 24/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 0.0021 - accuracy: 0.9408 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 25/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 0.0022 - accuracy: 0.9267 - val_loss: 0.0043 - val_accuracy: 0.8966\n",
            "Epoch 26/180\n",
            "53/53 [==============================] - 0s 504us/step - loss: 0.0024 - accuracy: 0.9454 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 27/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 0.0021 - accuracy: 0.9438 - val_loss: 0.0031 - val_accuracy: 0.9310\n",
            "Epoch 28/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 0.0024 - accuracy: 0.9442 - val_loss: 0.0024 - val_accuracy: 0.9828\n",
            "Epoch 29/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 0.0020 - accuracy: 0.9490 - val_loss: 0.0040 - val_accuracy: 0.8966\n",
            "Epoch 30/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 0.0021 - accuracy: 0.9386 - val_loss: 0.0028 - val_accuracy: 0.9655\n",
            "Epoch 31/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 0.0018 - accuracy: 0.9474 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 32/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 0.0015 - accuracy: 0.9393 - val_loss: 0.0023 - val_accuracy: 0.9483\n",
            "Epoch 33/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 0.0023 - accuracy: 0.9198 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 34/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 0.0017 - accuracy: 0.9550 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 35/180\n",
            "53/53 [==============================] - 0s 607us/step - loss: 0.0014 - accuracy: 0.9457 - val_loss: 0.0024 - val_accuracy: 0.9655\n",
            "Epoch 36/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 0.0016 - accuracy: 0.9455 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 37/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 0.0014 - accuracy: 0.9529 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 38/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 0.0013 - accuracy: 0.9551 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 39/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 0.0014 - accuracy: 0.9603 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 40/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 0.0014 - accuracy: 0.9553 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 41/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 0.0011 - accuracy: 0.9768 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 42/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 0.0011 - accuracy: 0.9564 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 43/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 0.0014 - accuracy: 0.9650 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 44/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 0.0012 - accuracy: 0.9537 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 45/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 0.0011 - accuracy: 0.9773 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 46/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 0.0011 - accuracy: 0.9720 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 47/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 0.0012 - accuracy: 0.9571 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 48/180\n",
            "53/53 [==============================] - 0s 583us/step - loss: 0.0011 - accuracy: 0.9556 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 49/180\n",
            "53/53 [==============================] - 0s 557us/step - loss: 0.0010 - accuracy: 0.9650 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 50/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 0.0014 - accuracy: 0.9456 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 51/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 9.4732e-04 - accuracy: 0.9641 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 52/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 9.7302e-04 - accuracy: 0.9624 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 53/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 0.0012 - accuracy: 0.9589 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 54/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 9.3545e-04 - accuracy: 0.9791 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 55/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 0.0012 - accuracy: 0.9666 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 56/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 0.0010 - accuracy: 0.9522 - val_loss: 0.0022 - val_accuracy: 0.9655\n",
            "Epoch 57/180\n",
            "53/53 [==============================] - 0s 613us/step - loss: 9.8554e-04 - accuracy: 0.9504 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 58/180\n",
            "53/53 [==============================] - 0s 554us/step - loss: 9.5317e-04 - accuracy: 0.9775 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 59/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 9.7008e-04 - accuracy: 0.9754 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 60/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 9.2265e-04 - accuracy: 0.9670 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 61/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 9.3740e-04 - accuracy: 0.9785 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 62/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 9.2133e-04 - accuracy: 0.9644 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 63/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 9.2797e-04 - accuracy: 0.9650 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 64/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 8.1058e-04 - accuracy: 0.9692 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 65/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 7.3617e-04 - accuracy: 0.9828 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 66/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 8.1816e-04 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 67/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 9.5204e-04 - accuracy: 0.9786 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 68/180\n",
            "53/53 [==============================] - 0s 445us/step - loss: 7.9527e-04 - accuracy: 0.9711 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 69/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 0.0011 - accuracy: 0.9772 - val_loss: 0.0026 - val_accuracy: 0.9310\n",
            "Epoch 70/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 8.3690e-04 - accuracy: 0.9738 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 71/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 0.0010 - accuracy: 0.9653 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 72/180\n",
            "53/53 [==============================] - 0s 538us/step - loss: 7.0066e-04 - accuracy: 0.9732 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 73/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 8.6884e-04 - accuracy: 0.9554 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 74/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 0.0010 - accuracy: 0.9734 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 75/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 7.3692e-04 - accuracy: 0.9696 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 76/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 6.7951e-04 - accuracy: 0.9751 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 77/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 7.8572e-04 - accuracy: 0.9815 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 78/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 6.7173e-04 - accuracy: 0.9831 - val_loss: 0.0019 - val_accuracy: 0.9310\n",
            "Epoch 79/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 8.7922e-04 - accuracy: 0.9836 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 80/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 7.4811e-04 - accuracy: 0.9803 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 81/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 7.7692e-04 - accuracy: 0.9733 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 82/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 9.0282e-04 - accuracy: 0.9833 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 83/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 9.9303e-04 - accuracy: 0.9817 - val_loss: 0.0014 - val_accuracy: 0.9483\n",
            "Epoch 84/180\n",
            "53/53 [==============================] - 0s 563us/step - loss: 8.5594e-04 - accuracy: 0.9666 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 85/180\n",
            "53/53 [==============================] - 0s 614us/step - loss: 7.0175e-04 - accuracy: 0.9695 - val_loss: 0.0019 - val_accuracy: 0.9483\n",
            "Epoch 86/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 8.9913e-04 - accuracy: 0.9762 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 87/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 8.0011e-04 - accuracy: 0.9801 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 88/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 7.5430e-04 - accuracy: 0.9753 - val_loss: 0.0028 - val_accuracy: 0.8621\n",
            "Epoch 89/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 0.0014 - accuracy: 0.9654 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 90/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 6.4458e-04 - accuracy: 0.9777 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 91/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 6.9931e-04 - accuracy: 0.9950 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 92/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 6.9533e-04 - accuracy: 0.9851 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 93/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 6.0271e-04 - accuracy: 0.9886 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 94/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 7.0639e-04 - accuracy: 0.9733 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 95/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 6.4151e-04 - accuracy: 0.9888 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 96/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 8.0990e-04 - accuracy: 0.9651 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 97/180\n",
            "53/53 [==============================] - 0s 442us/step - loss: 7.5387e-04 - accuracy: 0.9718 - val_loss: 0.0018 - val_accuracy: 0.9310\n",
            "Epoch 98/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 8.3389e-04 - accuracy: 0.9750 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 99/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 6.7706e-04 - accuracy: 0.9687 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 100/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 4.4009e-04 - accuracy: 0.9859 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 101/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 5.7296e-04 - accuracy: 0.9851 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 102/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 6.8090e-04 - accuracy: 0.9916 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 103/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 8.0233e-04 - accuracy: 0.9781 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 104/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 5.2700e-04 - accuracy: 0.9717 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 105/180\n",
            "53/53 [==============================] - 0s 550us/step - loss: 9.5472e-04 - accuracy: 0.9748 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 106/180\n",
            "53/53 [==============================] - 0s 611us/step - loss: 6.8990e-04 - accuracy: 0.9729 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 107/180\n",
            "53/53 [==============================] - 0s 528us/step - loss: 6.9467e-04 - accuracy: 0.9802 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 108/180\n",
            "53/53 [==============================] - 0s 526us/step - loss: 5.6432e-04 - accuracy: 0.9873 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 109/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 6.9834e-04 - accuracy: 0.9638 - val_loss: 0.0025 - val_accuracy: 0.8793\n",
            "Epoch 110/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 0.0010 - accuracy: 0.9753 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 111/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 5.2507e-04 - accuracy: 0.9857 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 112/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 5.4494e-04 - accuracy: 0.9889 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 113/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 6.5496e-04 - accuracy: 0.9872 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 114/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 5.6153e-04 - accuracy: 0.9749 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 115/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 6.1422e-04 - accuracy: 0.9874 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 116/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 7.3230e-04 - accuracy: 0.9770 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 117/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 7.0889e-04 - accuracy: 0.9845 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 118/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 5.4391e-04 - accuracy: 0.9843 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 119/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 6.1284e-04 - accuracy: 0.9792 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 120/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 5.6831e-04 - accuracy: 0.9813 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 121/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 5.4458e-04 - accuracy: 0.9789 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 122/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 5.1764e-04 - accuracy: 0.9944 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 123/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 5.0658e-04 - accuracy: 0.9894 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 124/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 5.5811e-04 - accuracy: 0.9947 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 125/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 7.8225e-04 - accuracy: 0.9851 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 126/180\n",
            "53/53 [==============================] - 0s 529us/step - loss: 5.2662e-04 - accuracy: 0.9852 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 127/180\n",
            "53/53 [==============================] - 0s 533us/step - loss: 5.4770e-04 - accuracy: 0.9858 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 128/180\n",
            "53/53 [==============================] - 0s 532us/step - loss: 7.7970e-04 - accuracy: 0.9838 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 129/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 7.3152e-04 - accuracy: 0.9620 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 130/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 5.7394e-04 - accuracy: 0.9974 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 131/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 4.8971e-04 - accuracy: 0.9872 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 132/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 4.8052e-04 - accuracy: 0.9906 - val_loss: 9.6594e-04 - val_accuracy: 0.9828\n",
            "Epoch 133/180\n",
            "53/53 [==============================] - 0s 443us/step - loss: 6.0405e-04 - accuracy: 0.9752 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 134/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 5.4984e-04 - accuracy: 0.9835 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 135/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 7.6567e-04 - accuracy: 0.9744 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 136/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 5.8191e-04 - accuracy: 0.9826 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 137/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 5.6891e-04 - accuracy: 0.9800 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 138/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 5.1847e-04 - accuracy: 0.9823 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 139/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 5.3838e-04 - accuracy: 0.9850 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 140/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 7.9766e-04 - accuracy: 0.9707 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 141/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 8.0024e-04 - accuracy: 0.9897 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 142/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 5.6119e-04 - accuracy: 0.9876 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 143/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 4.5757e-04 - accuracy: 0.9856 - val_loss: 9.9934e-04 - val_accuracy: 0.9655\n",
            "Epoch 144/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 4.9279e-04 - accuracy: 0.9935 - val_loss: 9.5608e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 4.3781e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 146/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 8.9436e-04 - accuracy: 0.9673 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 147/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 4.6258e-04 - accuracy: 0.9908 - val_loss: 9.6247e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 4.1536e-04 - accuracy: 0.9850 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 149/180\n",
            "53/53 [==============================] - 0s 551us/step - loss: 4.1523e-04 - accuracy: 0.9914 - val_loss: 9.1815e-04 - val_accuracy: 0.9828\n",
            "Epoch 150/180\n",
            "53/53 [==============================] - 0s 520us/step - loss: 4.7900e-04 - accuracy: 0.9915 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "Epoch 151/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 5.5002e-04 - accuracy: 0.9895 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 152/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 5.8459e-04 - accuracy: 0.9928 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 153/180\n",
            "53/53 [==============================] - 0s 702us/step - loss: 4.7137e-04 - accuracy: 0.9932 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 154/180\n",
            "53/53 [==============================] - 0s 578us/step - loss: 4.8609e-04 - accuracy: 0.9814 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 155/180\n",
            "53/53 [==============================] - 0s 520us/step - loss: 5.4129e-04 - accuracy: 0.9826 - val_loss: 9.2158e-04 - val_accuracy: 0.9828\n",
            "Epoch 156/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 6.8536e-04 - accuracy: 0.9829 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 157/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 6.6096e-04 - accuracy: 0.9852 - val_loss: 9.3131e-04 - val_accuracy: 0.9828\n",
            "Epoch 158/180\n",
            "53/53 [==============================] - 0s 521us/step - loss: 5.8664e-04 - accuracy: 0.9934 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 159/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 5.2880e-04 - accuracy: 0.9860 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 160/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 5.2631e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 161/180\n",
            "53/53 [==============================] - 0s 507us/step - loss: 6.7092e-04 - accuracy: 0.9777 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 162/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 4.6762e-04 - accuracy: 0.9694 - val_loss: 0.0016 - val_accuracy: 0.9483\n",
            "Epoch 163/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 5.4802e-04 - accuracy: 0.9861 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 164/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 4.2824e-04 - accuracy: 0.9950 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 165/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 6.6363e-04 - accuracy: 0.9947 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 166/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 5.3450e-04 - accuracy: 0.9958 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 167/180\n",
            "53/53 [==============================] - 0s 516us/step - loss: 4.9320e-04 - accuracy: 0.9892 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 168/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 4.8942e-04 - accuracy: 0.9911 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 169/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 4.3442e-04 - accuracy: 0.9867 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 170/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 4.6025e-04 - accuracy: 0.9882 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 171/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 4.2812e-04 - accuracy: 0.9786 - val_loss: 9.2655e-04 - val_accuracy: 1.0000\n",
            "Epoch 172/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 6.2799e-04 - accuracy: 0.9767 - val_loss: 0.0016 - val_accuracy: 0.9655\n",
            "Epoch 173/180\n",
            "53/53 [==============================] - 0s 670us/step - loss: 5.4517e-04 - accuracy: 0.9752 - val_loss: 8.7356e-04 - val_accuracy: 0.9828\n",
            "Epoch 174/180\n",
            "53/53 [==============================] - 0s 524us/step - loss: 4.3443e-04 - accuracy: 0.9840 - val_loss: 9.6709e-04 - val_accuracy: 0.9828\n",
            "Epoch 175/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 5.3309e-04 - accuracy: 0.9841 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 176/180\n",
            "53/53 [==============================] - 0s 542us/step - loss: 5.0353e-04 - accuracy: 0.9787 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 177/180\n",
            "53/53 [==============================] - 0s 516us/step - loss: 5.7528e-04 - accuracy: 0.9867 - val_loss: 9.1499e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 4.2913e-04 - accuracy: 0.9939 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 179/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 5.1495e-04 - accuracy: 0.9912 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 180/180\n",
            "53/53 [==============================] - 0s 529us/step - loss: 5.6565e-04 - accuracy: 0.9891 - val_loss: 0.0011 - val_accuracy: 0.9483\n",
            "2/2 [==============================] - 0s 575us/step - loss: 0.0011 - accuracy: 0.9483\n",
            "Loss = 0.0011438981164246798, rmse = 0.9482758641242981\n",
            "Loss array:  [0.0010908725671470165, 0.0012283906107768416, 0.0008983692969195545, 0.0009303216356784105, 0.0006859108107164502, 0.0013357028365135193, 0.0010973649332299829, 0.0011438981164246798]\n",
            "####################### Iteration   8  #######################\n",
            "Epoch 1/180\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.2701 - accuracy: 0.5435 - val_loss: 0.0351 - val_accuracy: 0.7759\n",
            "Epoch 2/180\n",
            "53/53 [==============================] - 0s 514us/step - loss: 0.0271 - accuracy: 0.7943 - val_loss: 0.0248 - val_accuracy: 0.7586\n",
            "Epoch 3/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 0.0211 - accuracy: 0.8450 - val_loss: 0.0183 - val_accuracy: 0.7931\n",
            "Epoch 4/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 0.0159 - accuracy: 0.8459 - val_loss: 0.0139 - val_accuracy: 0.8966\n",
            "Epoch 5/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0113 - accuracy: 0.8679 - val_loss: 0.0107 - val_accuracy: 0.9310\n",
            "Epoch 6/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 0.0091 - accuracy: 0.9015 - val_loss: 0.0085 - val_accuracy: 0.9138\n",
            "Epoch 7/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 0.0070 - accuracy: 0.9400 - val_loss: 0.0078 - val_accuracy: 0.8966\n",
            "Epoch 8/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 0.0063 - accuracy: 0.8935 - val_loss: 0.0061 - val_accuracy: 0.9483\n",
            "Epoch 9/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 0.0053 - accuracy: 0.9205 - val_loss: 0.0056 - val_accuracy: 0.9483\n",
            "Epoch 10/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0046 - accuracy: 0.9102 - val_loss: 0.0048 - val_accuracy: 0.9310\n",
            "Epoch 11/180\n",
            "53/53 [==============================] - 0s 511us/step - loss: 0.0049 - accuracy: 0.9008 - val_loss: 0.0056 - val_accuracy: 0.9483\n",
            "Epoch 12/180\n",
            "53/53 [==============================] - 0s 550us/step - loss: 0.0043 - accuracy: 0.9280 - val_loss: 0.0044 - val_accuracy: 0.9310\n",
            "Epoch 13/180\n",
            "53/53 [==============================] - 0s 511us/step - loss: 0.0039 - accuracy: 0.9270 - val_loss: 0.0040 - val_accuracy: 0.9310\n",
            "Epoch 14/180\n",
            "53/53 [==============================] - 0s 442us/step - loss: 0.0034 - accuracy: 0.9194 - val_loss: 0.0051 - val_accuracy: 0.9483\n",
            "Epoch 15/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 0.0035 - accuracy: 0.9463 - val_loss: 0.0036 - val_accuracy: 0.9310\n",
            "Epoch 16/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0035 - accuracy: 0.9226 - val_loss: 0.0034 - val_accuracy: 0.9310\n",
            "Epoch 17/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 0.0030 - accuracy: 0.9200 - val_loss: 0.0033 - val_accuracy: 0.9310\n",
            "Epoch 18/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 0.0030 - accuracy: 0.9031 - val_loss: 0.0033 - val_accuracy: 0.9483\n",
            "Epoch 19/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 0.0032 - accuracy: 0.9427 - val_loss: 0.0029 - val_accuracy: 0.9310\n",
            "Epoch 20/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0028 - accuracy: 0.9251 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 21/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 0.0025 - accuracy: 0.9452 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 22/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 0.0024 - accuracy: 0.9213 - val_loss: 0.0030 - val_accuracy: 0.9310\n",
            "Epoch 23/180\n",
            "53/53 [==============================] - 0s 518us/step - loss: 0.0024 - accuracy: 0.9358 - val_loss: 0.0027 - val_accuracy: 0.9310\n",
            "Epoch 24/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 0.0024 - accuracy: 0.9257 - val_loss: 0.0028 - val_accuracy: 0.9310\n",
            "Epoch 25/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 0.0023 - accuracy: 0.9286 - val_loss: 0.0026 - val_accuracy: 0.9483\n",
            "Epoch 26/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 0.0024 - accuracy: 0.9434 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 27/180\n",
            "53/53 [==============================] - 0s 444us/step - loss: 0.0021 - accuracy: 0.9421 - val_loss: 0.0022 - val_accuracy: 0.9310\n",
            "Epoch 28/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 0.0022 - accuracy: 0.9491 - val_loss: 0.0021 - val_accuracy: 0.9310\n",
            "Epoch 29/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0023 - accuracy: 0.9443 - val_loss: 0.0031 - val_accuracy: 0.9483\n",
            "Epoch 30/180\n",
            "53/53 [==============================] - 0s 515us/step - loss: 0.0021 - accuracy: 0.9388 - val_loss: 0.0025 - val_accuracy: 0.9483\n",
            "Epoch 31/180\n",
            "53/53 [==============================] - 0s 551us/step - loss: 0.0020 - accuracy: 0.9429 - val_loss: 0.0024 - val_accuracy: 0.9483\n",
            "Epoch 32/180\n",
            "53/53 [==============================] - 0s 558us/step - loss: 0.0018 - accuracy: 0.9237 - val_loss: 0.0028 - val_accuracy: 0.9483\n",
            "Epoch 33/180\n",
            "53/53 [==============================] - 0s 501us/step - loss: 0.0025 - accuracy: 0.9401 - val_loss: 0.0022 - val_accuracy: 0.9483\n",
            "Epoch 34/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 0.0023 - accuracy: 0.9290 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 35/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 0.0016 - accuracy: 0.9492 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 36/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 0.0018 - accuracy: 0.9553 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 37/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 0.0017 - accuracy: 0.9518 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 38/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0015 - accuracy: 0.9566 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 39/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0015 - accuracy: 0.9623 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 40/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 0.0020 - accuracy: 0.9404 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 41/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 0.0013 - accuracy: 0.9647 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 42/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 0.0012 - accuracy: 0.9644 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 43/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 0.0013 - accuracy: 0.9473 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 44/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 0.0013 - accuracy: 0.9425 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 45/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 0.0012 - accuracy: 0.9576 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 46/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 0.0012 - accuracy: 0.9639 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 47/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 0.0014 - accuracy: 0.9358 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 48/180\n",
            "53/53 [==============================] - 0s 485us/step - loss: 0.0011 - accuracy: 0.9705 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 49/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 0.0012 - accuracy: 0.9615 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 50/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 0.0012 - accuracy: 0.9478 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 51/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 0.0011 - accuracy: 0.9685 - val_loss: 0.0015 - val_accuracy: 0.9483\n",
            "Epoch 52/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 0.0011 - accuracy: 0.9523 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 53/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 0.0011 - accuracy: 0.9644 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 54/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 9.9246e-04 - accuracy: 0.9775 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 55/180\n",
            "53/53 [==============================] - 0s 516us/step - loss: 0.0012 - accuracy: 0.9360 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 56/180\n",
            "53/53 [==============================] - 0s 544us/step - loss: 9.3115e-04 - accuracy: 0.9755 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 57/180\n",
            "53/53 [==============================] - 0s 568us/step - loss: 0.0012 - accuracy: 0.9422 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 58/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 9.1191e-04 - accuracy: 0.9576 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 59/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 9.5238e-04 - accuracy: 0.9617 - val_loss: 9.8646e-04 - val_accuracy: 0.9828\n",
            "Epoch 60/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 9.5477e-04 - accuracy: 0.9570 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 61/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 9.1877e-04 - accuracy: 0.9717 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 62/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 9.7419e-04 - accuracy: 0.9712 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 63/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 0.0011 - accuracy: 0.9556 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 64/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 9.0839e-04 - accuracy: 0.9639 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 65/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 0.0012 - accuracy: 0.9766 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 66/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 9.5860e-04 - accuracy: 0.9660 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 67/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 0.0012 - accuracy: 0.9676 - val_loss: 0.0018 - val_accuracy: 0.9655\n",
            "Epoch 68/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 0.0011 - accuracy: 0.9628 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 69/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 0.0016 - accuracy: 0.9780 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 70/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 0.0013 - accuracy: 0.9479 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 71/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 9.1672e-04 - accuracy: 0.9843 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 72/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 7.8543e-04 - accuracy: 0.9674 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 73/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 9.3578e-04 - accuracy: 0.9795 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 74/180\n",
            "53/53 [==============================] - 0s 519us/step - loss: 0.0011 - accuracy: 0.9819 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 75/180\n",
            "53/53 [==============================] - 0s 547us/step - loss: 7.6497e-04 - accuracy: 0.9633 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 76/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 7.3012e-04 - accuracy: 0.9815 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 77/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 9.5604e-04 - accuracy: 0.9821 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 78/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 7.3376e-04 - accuracy: 0.9843 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 79/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 0.0012 - accuracy: 0.9749 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 80/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 9.9116e-04 - accuracy: 0.9652 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 81/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 9.0896e-04 - accuracy: 0.9748 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 82/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 8.7177e-04 - accuracy: 0.9846 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 83/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 7.6782e-04 - accuracy: 0.9811 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 84/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 8.9445e-04 - accuracy: 0.9649 - val_loss: 9.0173e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 8.0872e-04 - accuracy: 0.9637 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 86/180\n",
            "53/53 [==============================] - 0s 515us/step - loss: 9.7273e-04 - accuracy: 0.9754 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 87/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 8.1601e-04 - accuracy: 0.9788 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 88/180\n",
            "53/53 [==============================] - 0s 545us/step - loss: 7.2847e-04 - accuracy: 0.9870 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 89/180\n",
            "53/53 [==============================] - 0s 542us/step - loss: 0.0016 - accuracy: 0.9717 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 90/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 8.2369e-04 - accuracy: 0.9630 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 91/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 8.9305e-04 - accuracy: 0.9833 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 92/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 8.3826e-04 - accuracy: 0.9729 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 93/180\n",
            "53/53 [==============================] - 0s 451us/step - loss: 6.3957e-04 - accuracy: 0.9927 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 94/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 6.8037e-04 - accuracy: 0.9824 - val_loss: 8.6508e-04 - val_accuracy: 0.9828\n",
            "Epoch 95/180\n",
            "53/53 [==============================] - 0s 515us/step - loss: 6.5963e-04 - accuracy: 0.9847 - val_loss: 8.7849e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 7.0328e-04 - accuracy: 0.9778 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 97/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 0.0011 - accuracy: 0.9649 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 98/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 0.0012 - accuracy: 0.9758 - val_loss: 9.0183e-04 - val_accuracy: 0.9828\n",
            "Epoch 99/180\n",
            "53/53 [==============================] - 0s 514us/step - loss: 7.9295e-04 - accuracy: 0.9777 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 100/180\n",
            "53/53 [==============================] - 0s 506us/step - loss: 6.2221e-04 - accuracy: 0.9757 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 101/180\n",
            "53/53 [==============================] - 0s 494us/step - loss: 7.0384e-04 - accuracy: 0.9854 - val_loss: 7.9394e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 7.0404e-04 - accuracy: 0.9945 - val_loss: 8.1548e-04 - val_accuracy: 0.9828\n",
            "Epoch 103/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 6.6773e-04 - accuracy: 0.9864 - val_loss: 8.2325e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 5.3264e-04 - accuracy: 0.9797 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 105/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 0.0013 - accuracy: 0.9692 - val_loss: 9.0642e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/180\n",
            "53/53 [==============================] - 0s 638us/step - loss: 6.7080e-04 - accuracy: 0.9764 - val_loss: 8.5275e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/180\n",
            "53/53 [==============================] - 0s 555us/step - loss: 6.1407e-04 - accuracy: 0.9836 - val_loss: 7.4998e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 6.1165e-04 - accuracy: 0.9899 - val_loss: 8.2909e-04 - val_accuracy: 0.9828\n",
            "Epoch 109/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 5.2749e-04 - accuracy: 0.9790 - val_loss: 0.0018 - val_accuracy: 0.9828\n",
            "Epoch 110/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 8.8805e-04 - accuracy: 0.9771 - val_loss: 8.4336e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 5.9069e-04 - accuracy: 0.9845 - val_loss: 8.3126e-04 - val_accuracy: 1.0000\n",
            "Epoch 112/180\n",
            "53/53 [==============================] - 0s 447us/step - loss: 5.2581e-04 - accuracy: 0.9867 - val_loss: 8.2134e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 6.8439e-04 - accuracy: 0.9813 - val_loss: 9.5245e-04 - val_accuracy: 1.0000\n",
            "Epoch 114/180\n",
            "53/53 [==============================] - 0s 439us/step - loss: 6.1176e-04 - accuracy: 0.9865 - val_loss: 8.1822e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 5.9045e-04 - accuracy: 0.9927 - val_loss: 7.9343e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 5.5851e-04 - accuracy: 0.9862 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 117/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 9.0134e-04 - accuracy: 0.9738 - val_loss: 8.0236e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/180\n",
            "53/53 [==============================] - 0s 453us/step - loss: 4.8105e-04 - accuracy: 0.9835 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 119/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 6.4929e-04 - accuracy: 0.9920 - val_loss: 7.3343e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/180\n",
            "53/53 [==============================] - 0s 512us/step - loss: 5.1013e-04 - accuracy: 0.9911 - val_loss: 7.2061e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 6.0057e-04 - accuracy: 0.9910 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 122/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 7.5109e-04 - accuracy: 0.9886 - val_loss: 8.7835e-04 - val_accuracy: 0.9828\n",
            "Epoch 123/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 5.9412e-04 - accuracy: 0.9872 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 124/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 6.3713e-04 - accuracy: 0.9913 - val_loss: 9.8539e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 6.6029e-04 - accuracy: 0.9866 - val_loss: 7.7630e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 5.2632e-04 - accuracy: 0.9807 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 127/180\n",
            "53/53 [==============================] - 0s 510us/step - loss: 5.8225e-04 - accuracy: 0.9902 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 128/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 6.1856e-04 - accuracy: 0.9857 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 129/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 6.7848e-04 - accuracy: 0.9737 - val_loss: 8.6557e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 5.4965e-04 - accuracy: 0.9933 - val_loss: 8.2122e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/180\n",
            "53/53 [==============================] - 0s 512us/step - loss: 5.6534e-04 - accuracy: 0.9870 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 132/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 5.4659e-04 - accuracy: 0.9930 - val_loss: 8.2542e-04 - val_accuracy: 0.9828\n",
            "Epoch 133/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 7.1182e-04 - accuracy: 0.9714 - val_loss: 8.3346e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 6.1632e-04 - accuracy: 0.9797 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 135/180\n",
            "53/53 [==============================] - 0s 537us/step - loss: 6.0978e-04 - accuracy: 0.9756 - val_loss: 8.4857e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/180\n",
            "53/53 [==============================] - 0s 550us/step - loss: 5.0429e-04 - accuracy: 0.9925 - val_loss: 7.7313e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 5.5800e-04 - accuracy: 0.9814 - val_loss: 7.9675e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 4.7206e-04 - accuracy: 0.9960 - val_loss: 8.5240e-04 - val_accuracy: 0.9828\n",
            "Epoch 139/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 6.3777e-04 - accuracy: 0.9840 - val_loss: 7.8332e-04 - val_accuracy: 0.9828\n",
            "Epoch 140/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 6.5857e-04 - accuracy: 0.9765 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 141/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 7.6987e-04 - accuracy: 0.9877 - val_loss: 7.9827e-04 - val_accuracy: 0.9828\n",
            "Epoch 142/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 6.0620e-04 - accuracy: 0.9918 - val_loss: 8.9081e-04 - val_accuracy: 0.9828\n",
            "Epoch 143/180\n",
            "53/53 [==============================] - 0s 506us/step - loss: 5.3521e-04 - accuracy: 0.9746 - val_loss: 7.9502e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 5.4796e-04 - accuracy: 0.9925 - val_loss: 9.7897e-04 - val_accuracy: 0.9828\n",
            "Epoch 145/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 5.4072e-04 - accuracy: 0.9885 - val_loss: 7.7858e-04 - val_accuracy: 0.9828\n",
            "Epoch 146/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 8.2924e-04 - accuracy: 0.9656 - val_loss: 8.6443e-04 - val_accuracy: 0.9828\n",
            "Epoch 147/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 5.5753e-04 - accuracy: 0.9774 - val_loss: 8.5350e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 6.2860e-04 - accuracy: 0.9771 - val_loss: 8.7526e-04 - val_accuracy: 0.9828\n",
            "Epoch 149/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 5.0025e-04 - accuracy: 0.9758 - val_loss: 7.6015e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 5.3703e-04 - accuracy: 0.9834 - val_loss: 8.4197e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 5.7482e-04 - accuracy: 0.9838 - val_loss: 8.2497e-04 - val_accuracy: 0.9828\n",
            "Epoch 152/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 5.3427e-04 - accuracy: 0.9983 - val_loss: 8.6141e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/180\n",
            "53/53 [==============================] - 0s 560us/step - loss: 5.2759e-04 - accuracy: 0.9840 - val_loss: 0.0015 - val_accuracy: 0.9828\n",
            "Epoch 154/180\n",
            "53/53 [==============================] - 0s 569us/step - loss: 6.0082e-04 - accuracy: 0.9708 - val_loss: 9.5216e-04 - val_accuracy: 0.9828\n",
            "Epoch 155/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 4.8327e-04 - accuracy: 0.9912 - val_loss: 9.3014e-04 - val_accuracy: 0.9828\n",
            "Epoch 156/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 5.8021e-04 - accuracy: 0.9784 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 157/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 5.4702e-04 - accuracy: 0.9924 - val_loss: 8.6675e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 4.2572e-04 - accuracy: 0.9945 - val_loss: 9.6194e-04 - val_accuracy: 0.9828\n",
            "Epoch 159/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 5.1889e-04 - accuracy: 0.9787 - val_loss: 9.6337e-04 - val_accuracy: 0.9828\n",
            "Epoch 160/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 5.8393e-04 - accuracy: 0.9779 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 161/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 7.3348e-04 - accuracy: 0.9854 - val_loss: 8.4048e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 3.9042e-04 - accuracy: 0.9910 - val_loss: 8.6529e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 5.1102e-04 - accuracy: 0.9902 - val_loss: 7.5434e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 4.4809e-04 - accuracy: 0.9991 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 165/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 8.5532e-04 - accuracy: 0.9763 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 166/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 6.2312e-04 - accuracy: 0.9962 - val_loss: 9.3674e-04 - val_accuracy: 0.9828\n",
            "Epoch 167/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 4.8782e-04 - accuracy: 0.9782 - val_loss: 8.7861e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/180\n",
            "53/53 [==============================] - 0s 502us/step - loss: 4.4600e-04 - accuracy: 0.9963 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 169/180\n",
            "53/53 [==============================] - 0s 536us/step - loss: 5.6107e-04 - accuracy: 0.9929 - val_loss: 8.4101e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/180\n",
            "53/53 [==============================] - 0s 536us/step - loss: 5.9961e-04 - accuracy: 0.9906 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 171/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 5.4418e-04 - accuracy: 0.9855 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 172/180\n",
            "53/53 [==============================] - 0s 446us/step - loss: 5.3378e-04 - accuracy: 0.9627 - val_loss: 8.5400e-04 - val_accuracy: 1.0000\n",
            "Epoch 173/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 4.4774e-04 - accuracy: 0.9914 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 174/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 7.1294e-04 - accuracy: 0.9697 - val_loss: 7.4456e-04 - val_accuracy: 0.9828\n",
            "Epoch 175/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 5.0503e-04 - accuracy: 0.9931 - val_loss: 7.9430e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 5.5541e-04 - accuracy: 0.9940 - val_loss: 9.1470e-04 - val_accuracy: 0.9828\n",
            "Epoch 177/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 7.0124e-04 - accuracy: 0.9884 - val_loss: 8.9832e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 6.3771e-04 - accuracy: 0.9840 - val_loss: 8.7086e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 8.2088e-04 - accuracy: 0.9861 - val_loss: 8.9663e-04 - val_accuracy: 1.0000\n",
            "Epoch 180/180\n",
            "53/53 [==============================] - 0s 454us/step - loss: 5.3820e-04 - accuracy: 0.9878 - val_loss: 8.9566e-04 - val_accuracy: 0.9828\n",
            "2/2 [==============================] - 0s 510us/step - loss: 8.9566e-04 - accuracy: 0.9828\n",
            "Loss = 0.0008956624078564346, rmse = 0.982758641242981\n",
            "Loss array:  [0.0010908725671470165, 0.0012283906107768416, 0.0008983692969195545, 0.0009303216356784105, 0.0006859108107164502, 0.0013357028365135193, 0.0010973649332299829, 0.0011438981164246798, 0.0008956624078564346]\n",
            "####################### Iteration   9  #######################\n",
            "Epoch 1/180\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.5992 - val_loss: 0.0366 - val_accuracy: 0.8966\n",
            "Epoch 2/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 0.0303 - accuracy: 0.7962 - val_loss: 0.0220 - val_accuracy: 0.8966\n",
            "Epoch 3/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 0.0202 - accuracy: 0.8536 - val_loss: 0.0154 - val_accuracy: 0.9138\n",
            "Epoch 4/180\n",
            "53/53 [==============================] - 0s 443us/step - loss: 0.0158 - accuracy: 0.8661 - val_loss: 0.0120 - val_accuracy: 0.9138\n",
            "Epoch 5/180\n",
            "53/53 [==============================] - 0s 432us/step - loss: 0.0112 - accuracy: 0.8580 - val_loss: 0.0106 - val_accuracy: 0.9655\n",
            "Epoch 6/180\n",
            "53/53 [==============================] - 0s 449us/step - loss: 0.0089 - accuracy: 0.8894 - val_loss: 0.0076 - val_accuracy: 0.9483\n",
            "Epoch 7/180\n",
            "53/53 [==============================] - 0s 438us/step - loss: 0.0071 - accuracy: 0.9361 - val_loss: 0.0074 - val_accuracy: 0.9310\n",
            "Epoch 8/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 0.0065 - accuracy: 0.9149 - val_loss: 0.0057 - val_accuracy: 0.9483\n",
            "Epoch 9/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 0.0056 - accuracy: 0.9175 - val_loss: 0.0060 - val_accuracy: 0.9483\n",
            "Epoch 10/180\n",
            "53/53 [==============================] - 0s 442us/step - loss: 0.0048 - accuracy: 0.9003 - val_loss: 0.0047 - val_accuracy: 0.9483\n",
            "Epoch 11/180\n",
            "53/53 [==============================] - 0s 452us/step - loss: 0.0049 - accuracy: 0.9103 - val_loss: 0.0051 - val_accuracy: 0.9655\n",
            "Epoch 12/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 0.0047 - accuracy: 0.9273 - val_loss: 0.0043 - val_accuracy: 0.9483\n",
            "Epoch 13/180\n",
            "53/53 [==============================] - 0s 448us/step - loss: 0.0039 - accuracy: 0.9308 - val_loss: 0.0038 - val_accuracy: 0.9483\n",
            "Epoch 14/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 0.0036 - accuracy: 0.9265 - val_loss: 0.0040 - val_accuracy: 0.9655\n",
            "Epoch 15/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 0.0033 - accuracy: 0.9396 - val_loss: 0.0031 - val_accuracy: 0.9655\n",
            "Epoch 16/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 0.0032 - accuracy: 0.9418 - val_loss: 0.0030 - val_accuracy: 0.9655\n",
            "Epoch 17/180\n",
            "53/53 [==============================] - 0s 450us/step - loss: 0.0028 - accuracy: 0.9445 - val_loss: 0.0027 - val_accuracy: 0.9483\n",
            "Epoch 18/180\n",
            "53/53 [==============================] - 0s 534us/step - loss: 0.0026 - accuracy: 0.9387 - val_loss: 0.0034 - val_accuracy: 0.9655\n",
            "Epoch 19/180\n",
            "53/53 [==============================] - 0s 545us/step - loss: 0.0032 - accuracy: 0.9507 - val_loss: 0.0026 - val_accuracy: 0.9655\n",
            "Epoch 20/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 0.0026 - accuracy: 0.9119 - val_loss: 0.0023 - val_accuracy: 0.9655\n",
            "Epoch 21/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 0.0022 - accuracy: 0.9467 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 22/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 0.0020 - accuracy: 0.9259 - val_loss: 0.0020 - val_accuracy: 0.9655\n",
            "Epoch 23/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 0.0023 - accuracy: 0.9439 - val_loss: 0.0020 - val_accuracy: 0.9483\n",
            "Epoch 24/180\n",
            "53/53 [==============================] - 0s 465us/step - loss: 0.0021 - accuracy: 0.9509 - val_loss: 0.0021 - val_accuracy: 0.9655\n",
            "Epoch 25/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 0.0019 - accuracy: 0.9336 - val_loss: 0.0021 - val_accuracy: 0.9483\n",
            "Epoch 26/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 0.0022 - accuracy: 0.9687 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 27/180\n",
            "53/53 [==============================] - 0s 514us/step - loss: 0.0017 - accuracy: 0.9481 - val_loss: 0.0017 - val_accuracy: 0.9655\n",
            "Epoch 28/180\n",
            "53/53 [==============================] - 0s 476us/step - loss: 0.0018 - accuracy: 0.9611 - val_loss: 0.0017 - val_accuracy: 0.9483\n",
            "Epoch 29/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 0.0018 - accuracy: 0.9465 - val_loss: 0.0023 - val_accuracy: 0.9138\n",
            "Epoch 30/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 0.0016 - accuracy: 0.9507 - val_loss: 0.0018 - val_accuracy: 0.9483\n",
            "Epoch 31/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 0.0017 - accuracy: 0.9570 - val_loss: 0.0022 - val_accuracy: 0.9828\n",
            "Epoch 32/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 0.0014 - accuracy: 0.9399 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 33/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 0.0018 - accuracy: 0.9464 - val_loss: 0.0017 - val_accuracy: 0.9828\n",
            "Epoch 34/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 0.0016 - accuracy: 0.9501 - val_loss: 0.0015 - val_accuracy: 0.9655\n",
            "Epoch 35/180\n",
            "53/53 [==============================] - 0s 534us/step - loss: 0.0013 - accuracy: 0.9537 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 36/180\n",
            "53/53 [==============================] - 0s 597us/step - loss: 0.0014 - accuracy: 0.9435 - val_loss: 0.0021 - val_accuracy: 0.9828\n",
            "Epoch 37/180\n",
            "53/53 [==============================] - 0s 510us/step - loss: 0.0014 - accuracy: 0.9717 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
            "Epoch 38/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 0.0015 - accuracy: 0.9653 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 39/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 0.0011 - accuracy: 0.9706 - val_loss: 0.0013 - val_accuracy: 0.9483\n",
            "Epoch 40/180\n",
            "53/53 [==============================] - 0s 484us/step - loss: 0.0013 - accuracy: 0.9597 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 41/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 9.2218e-04 - accuracy: 0.9705 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 42/180\n",
            "53/53 [==============================] - 0s 511us/step - loss: 9.1993e-04 - accuracy: 0.9730 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 43/180\n",
            "53/53 [==============================] - 0s 481us/step - loss: 0.0013 - accuracy: 0.9593 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 44/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 0.0010 - accuracy: 0.9576 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 45/180\n",
            "53/53 [==============================] - 0s 499us/step - loss: 8.7021e-04 - accuracy: 0.9704 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 46/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 9.6486e-04 - accuracy: 0.9793 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 47/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 9.0970e-04 - accuracy: 0.9707 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 48/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 9.1463e-04 - accuracy: 0.9764 - val_loss: 0.0014 - val_accuracy: 0.9655\n",
            "Epoch 49/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 8.2106e-04 - accuracy: 0.9808 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 50/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 0.0013 - accuracy: 0.9510 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 51/180\n",
            "53/53 [==============================] - 0s 495us/step - loss: 9.5277e-04 - accuracy: 0.9683 - val_loss: 0.0026 - val_accuracy: 0.9138\n",
            "Epoch 52/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 0.0013 - accuracy: 0.9358 - val_loss: 0.0016 - val_accuracy: 0.9828\n",
            "Epoch 53/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 8.8937e-04 - accuracy: 0.9757 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 54/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 7.6658e-04 - accuracy: 0.9813 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 55/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 8.2245e-04 - accuracy: 0.9710 - val_loss: 0.0014 - val_accuracy: 0.9828\n",
            "Epoch 56/180\n",
            "53/53 [==============================] - 0s 497us/step - loss: 8.4259e-04 - accuracy: 0.9737 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 57/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 8.2940e-04 - accuracy: 0.9600 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 58/180\n",
            "53/53 [==============================] - 0s 650us/step - loss: 7.9520e-04 - accuracy: 0.9864 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 59/180\n",
            "53/53 [==============================] - 0s 578us/step - loss: 9.9481e-04 - accuracy: 0.9673 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 60/180\n",
            "53/53 [==============================] - 0s 506us/step - loss: 8.4987e-04 - accuracy: 0.9578 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 61/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 7.6365e-04 - accuracy: 0.9857 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 62/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 7.5903e-04 - accuracy: 0.9779 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 63/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 7.3748e-04 - accuracy: 0.9685 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 64/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 7.9111e-04 - accuracy: 0.9708 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 65/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 7.3942e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 66/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 7.5565e-04 - accuracy: 0.9817 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 67/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 7.3597e-04 - accuracy: 0.9696 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 68/180\n",
            "53/53 [==============================] - 0s 459us/step - loss: 6.7834e-04 - accuracy: 0.9869 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 69/180\n",
            "53/53 [==============================] - 0s 462us/step - loss: 9.3469e-04 - accuracy: 0.9792 - val_loss: 9.8588e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 7.9753e-04 - accuracy: 0.9794 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 71/180\n",
            "53/53 [==============================] - 0s 506us/step - loss: 7.4399e-04 - accuracy: 0.9864 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 72/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 6.0027e-04 - accuracy: 0.9790 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 73/180\n",
            "53/53 [==============================] - 0s 480us/step - loss: 7.6913e-04 - accuracy: 0.9891 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 74/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 7.2089e-04 - accuracy: 0.9893 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 75/180\n",
            "53/53 [==============================] - 0s 563us/step - loss: 6.3824e-04 - accuracy: 0.9892 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 76/180\n",
            "53/53 [==============================] - 0s 546us/step - loss: 7.6525e-04 - accuracy: 0.9759 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 77/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 8.6475e-04 - accuracy: 0.9879 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 78/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 7.0930e-04 - accuracy: 0.9872 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 79/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 0.0010 - accuracy: 0.9856 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 80/180\n",
            "53/53 [==============================] - 0s 488us/step - loss: 8.2477e-04 - accuracy: 0.9752 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 81/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 9.1166e-04 - accuracy: 0.9728 - val_loss: 9.7434e-04 - val_accuracy: 0.9828\n",
            "Epoch 82/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 6.6406e-04 - accuracy: 0.9864 - val_loss: 9.9923e-04 - val_accuracy: 0.9828\n",
            "Epoch 83/180\n",
            "53/53 [==============================] - 0s 478us/step - loss: 6.9316e-04 - accuracy: 0.9804 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 84/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 7.4609e-04 - accuracy: 0.9853 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 85/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 5.7981e-04 - accuracy: 0.9893 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 86/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 6.8884e-04 - accuracy: 0.9922 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
            "Epoch 87/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 7.9311e-04 - accuracy: 0.9940 - val_loss: 9.8822e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 7.0906e-04 - accuracy: 0.9844 - val_loss: 0.0019 - val_accuracy: 0.9655\n",
            "Epoch 89/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 0.0013 - accuracy: 0.9841 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 90/180\n",
            "53/53 [==============================] - 0s 461us/step - loss: 6.0380e-04 - accuracy: 0.9912 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 91/180\n",
            "53/53 [==============================] - 0s 518us/step - loss: 5.8849e-04 - accuracy: 0.9963 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 92/180\n",
            "53/53 [==============================] - 0s 578us/step - loss: 6.6659e-04 - accuracy: 0.9867 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 93/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 5.4345e-04 - accuracy: 0.9947 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 94/180\n",
            "53/53 [==============================] - 0s 509us/step - loss: 5.8869e-04 - accuracy: 0.9839 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 95/180\n",
            "53/53 [==============================] - 0s 489us/step - loss: 6.2831e-04 - accuracy: 0.9828 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 96/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 6.7937e-04 - accuracy: 0.9876 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 97/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 7.5613e-04 - accuracy: 0.9896 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 98/180\n",
            "53/53 [==============================] - 0s 483us/step - loss: 8.9803e-04 - accuracy: 0.9751 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 99/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 7.6517e-04 - accuracy: 0.9876 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 100/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 4.8366e-04 - accuracy: 0.9778 - val_loss: 0.0012 - val_accuracy: 0.9655\n",
            "Epoch 101/180\n",
            "53/53 [==============================] - 0s 514us/step - loss: 6.4609e-04 - accuracy: 0.9917 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 102/180\n",
            "53/53 [==============================] - 0s 535us/step - loss: 7.1847e-04 - accuracy: 0.9926 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 103/180\n",
            "53/53 [==============================] - 0s 564us/step - loss: 5.4904e-04 - accuracy: 0.9904 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 104/180\n",
            "53/53 [==============================] - 0s 546us/step - loss: 6.8993e-04 - accuracy: 0.9746 - val_loss: 0.0013 - val_accuracy: 0.9655\n",
            "Epoch 105/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 9.5741e-04 - accuracy: 0.9789 - val_loss: 0.0012 - val_accuracy: 0.9483\n",
            "Epoch 106/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 6.1388e-04 - accuracy: 0.9811 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 107/180\n",
            "53/53 [==============================] - 0s 474us/step - loss: 5.2852e-04 - accuracy: 0.9817 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 108/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 6.1520e-04 - accuracy: 0.9906 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 109/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 5.0737e-04 - accuracy: 0.9843 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 110/180\n",
            "53/53 [==============================] - 0s 519us/step - loss: 6.0313e-04 - accuracy: 0.9778 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 111/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 5.3563e-04 - accuracy: 0.9906 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 112/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 4.2402e-04 - accuracy: 0.9905 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 113/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 6.1892e-04 - accuracy: 0.9938 - val_loss: 9.0712e-04 - val_accuracy: 0.9828\n",
            "Epoch 114/180\n",
            "53/53 [==============================] - 0s 553us/step - loss: 5.2408e-04 - accuracy: 0.9907 - val_loss: 8.0839e-04 - val_accuracy: 0.9828\n",
            "Epoch 115/180\n",
            "53/53 [==============================] - 0s 493us/step - loss: 5.5729e-04 - accuracy: 0.9947 - val_loss: 9.1878e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 4.5623e-04 - accuracy: 0.9948 - val_loss: 9.7297e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/180\n",
            "53/53 [==============================] - 0s 529us/step - loss: 7.4517e-04 - accuracy: 0.9855 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 118/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 4.6749e-04 - accuracy: 0.9866 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 119/180\n",
            "53/53 [==============================] - 0s 559us/step - loss: 5.2472e-04 - accuracy: 0.9877 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 120/180\n",
            "53/53 [==============================] - 0s 624us/step - loss: 5.1885e-04 - accuracy: 0.9911 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 121/180\n",
            "53/53 [==============================] - 0s 517us/step - loss: 6.3155e-04 - accuracy: 0.9878 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 122/180\n",
            "53/53 [==============================] - 0s 541us/step - loss: 8.5416e-04 - accuracy: 0.9884 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 123/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 5.3150e-04 - accuracy: 0.9867 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 124/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 4.9218e-04 - accuracy: 0.9886 - val_loss: 9.9601e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/180\n",
            "53/53 [==============================] - 0s 487us/step - loss: 5.2293e-04 - accuracy: 0.9938 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 126/180\n",
            "53/53 [==============================] - 0s 505us/step - loss: 4.4672e-04 - accuracy: 0.9925 - val_loss: 0.0010 - val_accuracy: 0.9655\n",
            "Epoch 127/180\n",
            "53/53 [==============================] - 0s 542us/step - loss: 5.0424e-04 - accuracy: 0.9962 - val_loss: 9.6592e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/180\n",
            "53/53 [==============================] - 0s 536us/step - loss: 6.5288e-04 - accuracy: 0.9808 - val_loss: 0.0011 - val_accuracy: 0.9655\n",
            "Epoch 129/180\n",
            "53/53 [==============================] - 0s 537us/step - loss: 5.6993e-04 - accuracy: 0.9762 - val_loss: 9.1361e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/180\n",
            "53/53 [==============================] - 0s 486us/step - loss: 5.0980e-04 - accuracy: 0.9945 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 131/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 4.3286e-04 - accuracy: 0.9973 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 132/180\n",
            "53/53 [==============================] - 0s 482us/step - loss: 5.4897e-04 - accuracy: 0.9852 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 133/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 5.4826e-04 - accuracy: 0.9778 - val_loss: 8.9109e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 4.2596e-04 - accuracy: 0.9793 - val_loss: 8.7039e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/180\n",
            "53/53 [==============================] - 0s 458us/step - loss: 4.8066e-04 - accuracy: 0.9869 - val_loss: 9.7710e-04 - val_accuracy: 0.9828\n",
            "Epoch 136/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 4.9057e-04 - accuracy: 0.9978 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 137/180\n",
            "53/53 [==============================] - 0s 470us/step - loss: 4.8221e-04 - accuracy: 0.9966 - val_loss: 8.6096e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 4.1839e-04 - accuracy: 0.9984 - val_loss: 9.9124e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 5.7183e-04 - accuracy: 0.9920 - val_loss: 8.7407e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 8.0277e-04 - accuracy: 0.9800 - val_loss: 9.7024e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 6.2103e-04 - accuracy: 0.9855 - val_loss: 8.1153e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/180\n",
            "53/53 [==============================] - 0s 508us/step - loss: 5.0785e-04 - accuracy: 0.9948 - val_loss: 9.8729e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 4.6170e-04 - accuracy: 0.9977 - val_loss: 9.2398e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 3.7874e-04 - accuracy: 0.9957 - val_loss: 9.2543e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/180\n",
            "53/53 [==============================] - 0s 503us/step - loss: 4.5610e-04 - accuracy: 0.9902 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 146/180\n",
            "53/53 [==============================] - 0s 552us/step - loss: 6.3501e-04 - accuracy: 0.9782 - val_loss: 8.0410e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/180\n",
            "53/53 [==============================] - 0s 511us/step - loss: 4.7933e-04 - accuracy: 0.9952 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 148/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 4.4215e-04 - accuracy: 0.9849 - val_loss: 8.2976e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/180\n",
            "53/53 [==============================] - 0s 473us/step - loss: 4.0254e-04 - accuracy: 0.9910 - val_loss: 9.0827e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 4.9406e-04 - accuracy: 0.9866 - val_loss: 8.7267e-04 - val_accuracy: 0.9655\n",
            "Epoch 151/180\n",
            "53/53 [==============================] - 0s 466us/step - loss: 5.5316e-04 - accuracy: 0.9980 - val_loss: 9.8996e-04 - val_accuracy: 0.9828\n",
            "Epoch 152/180\n",
            "53/53 [==============================] - 0s 490us/step - loss: 5.0188e-04 - accuracy: 0.9923 - val_loss: 0.0010 - val_accuracy: 0.9828\n",
            "Epoch 153/180\n",
            "53/53 [==============================] - 0s 498us/step - loss: 4.6118e-04 - accuracy: 0.9888 - val_loss: 9.6671e-04 - val_accuracy: 0.9828\n",
            "Epoch 154/180\n",
            "53/53 [==============================] - 0s 519us/step - loss: 4.1328e-04 - accuracy: 0.9870 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 155/180\n",
            "53/53 [==============================] - 0s 467us/step - loss: 4.3884e-04 - accuracy: 0.9823 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 156/180\n",
            "53/53 [==============================] - 0s 525us/step - loss: 4.8019e-04 - accuracy: 0.9826 - val_loss: 8.1338e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/180\n",
            "53/53 [==============================] - 0s 492us/step - loss: 4.1043e-04 - accuracy: 0.9967 - val_loss: 8.8520e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/180\n",
            "53/53 [==============================] - 0s 460us/step - loss: 4.8014e-04 - accuracy: 0.9964 - val_loss: 8.3986e-04 - val_accuracy: 0.9655\n",
            "Epoch 159/180\n",
            "53/53 [==============================] - 0s 457us/step - loss: 4.4864e-04 - accuracy: 0.9858 - val_loss: 8.8076e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/180\n",
            "53/53 [==============================] - 0s 456us/step - loss: 5.7508e-04 - accuracy: 0.9874 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 161/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 6.4068e-04 - accuracy: 0.9848 - val_loss: 8.7856e-04 - val_accuracy: 0.9828\n",
            "Epoch 162/180\n",
            "53/53 [==============================] - 0s 455us/step - loss: 4.6433e-04 - accuracy: 0.9795 - val_loss: 8.4643e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 4.1771e-04 - accuracy: 0.9982 - val_loss: 7.5404e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/180\n",
            "53/53 [==============================] - 0s 477us/step - loss: 3.8209e-04 - accuracy: 0.9991 - val_loss: 8.7773e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/180\n",
            "53/53 [==============================] - 0s 479us/step - loss: 6.1036e-04 - accuracy: 0.9883 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 166/180\n",
            "53/53 [==============================] - 0s 500us/step - loss: 4.9790e-04 - accuracy: 0.9903 - val_loss: 8.4208e-04 - val_accuracy: 0.9828\n",
            "Epoch 167/180\n",
            "53/53 [==============================] - 0s 596us/step - loss: 4.3396e-04 - accuracy: 0.9842 - val_loss: 8.1075e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/180\n",
            "53/53 [==============================] - 0s 584us/step - loss: 3.8823e-04 - accuracy: 0.9866 - val_loss: 7.6547e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/180\n",
            "53/53 [==============================] - 0s 513us/step - loss: 3.3888e-04 - accuracy: 0.9853 - val_loss: 9.5983e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/180\n",
            "53/53 [==============================] - 0s 491us/step - loss: 4.4900e-04 - accuracy: 0.9992 - val_loss: 8.7700e-04 - val_accuracy: 1.0000\n",
            "Epoch 171/180\n",
            "53/53 [==============================] - 0s 496us/step - loss: 5.0309e-04 - accuracy: 0.9902 - val_loss: 9.0705e-04 - val_accuracy: 1.0000\n",
            "Epoch 172/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 5.4389e-04 - accuracy: 0.9763 - val_loss: 8.1437e-04 - val_accuracy: 0.9828\n",
            "Epoch 173/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 4.9181e-04 - accuracy: 0.9868 - val_loss: 8.6249e-04 - val_accuracy: 0.9828\n",
            "Epoch 174/180\n",
            "53/53 [==============================] - 0s 463us/step - loss: 4.3343e-04 - accuracy: 0.9869 - val_loss: 9.1925e-04 - val_accuracy: 1.0000\n",
            "Epoch 175/180\n",
            "53/53 [==============================] - 0s 464us/step - loss: 4.3346e-04 - accuracy: 0.9941 - val_loss: 8.5620e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/180\n",
            "53/53 [==============================] - 0s 468us/step - loss: 4.2230e-04 - accuracy: 0.9981 - val_loss: 8.5023e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/180\n",
            "53/53 [==============================] - 0s 469us/step - loss: 6.5891e-04 - accuracy: 0.9841 - val_loss: 0.0012 - val_accuracy: 0.9310\n",
            "Epoch 178/180\n",
            "53/53 [==============================] - 0s 472us/step - loss: 9.1219e-04 - accuracy: 0.9726 - val_loss: 8.3442e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/180\n",
            "53/53 [==============================] - 0s 475us/step - loss: 5.0452e-04 - accuracy: 0.9890 - val_loss: 8.5770e-04 - val_accuracy: 1.0000\n",
            "Epoch 180/180\n",
            "53/53 [==============================] - 0s 471us/step - loss: 4.2325e-04 - accuracy: 0.9953 - val_loss: 8.7145e-04 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 452us/step - loss: 8.7145e-04 - accuracy: 1.0000\n",
            "Loss = 0.0008714535506442189, rmse = 1.0\n",
            "Loss array:  [0.0010908725671470165, 0.0012283906107768416, 0.0008983692969195545, 0.0009303216356784105, 0.0006859108107164502, 0.0013357028365135193, 0.0010973649332299829, 0.0011438981164246798, 0.0008956624078564346, 0.0008714535506442189]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "NUM_EPOCHS = 180 # 180\n",
        "BATCH_SIZE = 10\n",
        "K_FOLD_SPLITS = 10\n",
        "\n",
        "\n",
        "# Define the cross-validation process to be used inside cross_val_Score evaluation\n",
        "cv = KFold(n_splits=K_FOLD_SPLITS)\n",
        "\n",
        "# Handling for accommodating multiple targets\n",
        "Y1 = y_train_norm[:,0]\n",
        "Y2 = y_train_norm[:,1]\n",
        "targets = (Y1, Y2)\n",
        "\n",
        "X = X_train_norm\n",
        "\n",
        "i = 0\n",
        "arr_loss = list()\n",
        "arr_rmse = list()\n",
        "min_loss = 1000000\n",
        "best_model = None\n",
        "history = None\n",
        "history_best_model = None\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_indices, test_indices in cv.split(X_train):\n",
        "  print('####################### Iteration  ', i, ' #######################')\n",
        "  trainX, valX = np.array(X[train_indices]), np.array(X[test_indices])\n",
        "  trainY = np.vstack((Y1[train_indices], Y2[train_indices])).T\n",
        "  valY = np.vstack((Y1[test_indices], Y2[test_indices])).T\n",
        "\n",
        "  model = my_model()\n",
        "  history = model.fit(trainX, trainY,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            validation_data = (valX, valY)\n",
        "  )\n",
        "\n",
        "\n",
        "  #testing on validation set process\n",
        "  loss, rmse = model.evaluate(x = valX, y = valY, verbose=1)\n",
        "  print(f\"Loss = {loss}, rmse = {rmse}\" )\n",
        "\n",
        "  if loss < min_loss:\n",
        "    best_model = model\n",
        "    history_best_model = history\n",
        "    min_loss = loss\n",
        "\n",
        "  arr_loss.append(loss)\n",
        "  arr_rmse.append(rmse)\n",
        "  print('Loss array: ', arr_loss)\n",
        "  i+=1\n",
        "\n",
        "# Saving the best model within the k folds\n",
        "best_model.save(FILENAME_BEST_MODEL)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results\n",
        "- Plot of k-cross validation performance\n",
        "- Scatter Plot of prediction results against true values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "xKSkPnO4ETWD",
        "outputId": "564ee694-d414-4d21-bbd9-f838e7249dd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loss across k folds\n",
        "plot_line(arr_loss, \"Loss across k-folds\", \"Value of k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training and Validation Loss\n",
        "plot_loss_curve(history_best_model, NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the test dataset\n",
        "X_test_norm = scaler_input.transform(X_test)\n",
        "y_test_norm = scaler_output.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-erJ0l_Yu4P",
        "outputId": "9cff94b2-e4ca-491b-8459-aeaa1eff7606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time: 0.0278 seconds\n",
            "Maxval here is:  25.612844\n",
            "Maxval here is:  0.9278\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "Y_pred_normalized = best_model.predict(X_test_norm)\n",
        "end_time = time.time()\n",
        "Y_pred_normalized_entire = best_model.predict(dataset_x_norm)\n",
        "# Calculate elapsed time in seconds\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Elapsed time:\", round(elapsed_time, 3), \"seconds\")\n",
        "\n",
        "\n",
        "Y_pred = scaler_output.inverse_transform(Y_pred_normalized)\n",
        "Y_pred_entire = scaler_output.inverse_transform(Y_pred_normalized_entire)\n",
        "Y_actual = np.array(y_test)\n",
        "Y_actual_entire = np.array(df_targets)\n",
        "# Moisture Content\n",
        "scatter_plot(trueValues=Y_actual[:,0], \n",
        "             predictions=Y_pred[:,0], \n",
        "             title=\"Moisture Content\")\n",
        "a, b = np.polyfit(Y_pred[:, 0], Y_actual[:, 0], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,0]), max(Y_actual[:,0])), 1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_MC.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)\n",
        "\n",
        "# Bulk Density\n",
        "scatter_plot(trueValues=Y_actual[:,1], \n",
        "             predictions=Y_pred[:,1], \n",
        "             title=\"Bulk Density\")\n",
        "plt.xlim([min(min(Y_pred[:,1]), min(Y_actual[:,1]))-0.1, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1])\n",
        "a, b = np.polyfit(Y_pred[:, 1], Y_actual[:, 1], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1, 0.1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_BD.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Error analysis\n",
        "- R squared calculation\n",
        "- Mean accuracy error"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### R squared calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9931\n",
            "0.9496\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# MOISTURE CONTENT\n",
        "#   - R-squared\n",
        "# mc_r2_score = r2_score(Y_actual[:, 0], Y_pred[:, 0])\n",
        "mc_r2_score = calculate_r_squared(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"{:#.4g}\".format(mc_r2_score))\n",
        "\n",
        "# BULK DENSITY\n",
        "#   - R-squared\n",
        "# bd_r2_score = r2_score(Y_actual[:, 1], Y_pred[:, 1])\n",
        "bd_r2_score = calculate_r_squared(y_true=Y_actual[:, 1], y_pred=Y_pred[:, 1])\n",
        "print(\"{:#.4g}\".format(bd_r2_score))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE_MC:  0.3092\n",
            "RMSE_BD:  0.02648\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sigfig import round\n",
        "\n",
        "#MC\n",
        "rmse_mc = np.sqrt(mean_squared_error(Y_actual[:, 0], Y_pred[:, 0]))\n",
        "print('RMSE_MC: ', \"{0:.4g}\".format(rmse_mc))\n",
        "\n",
        "#BD\n",
        "rmse_bd = np.sqrt(mean_squared_error(Y_actual[:, 1], Y_pred[:, 1]))\n",
        "print('RMSE_BD: ', \"{0:.4g}\".format(rmse_bd))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will compare with the results from Trabelsi's paper. This is single moisture prediction \n",
        "\n",
        "R^2 : 0.993\\\n",
        "Mean Squared Error: 0.028\\\n",
        "Mean absolute Error: 0.135\\\n",
        "Min. Absolute Error: 0.004\\\n",
        "Max Absolute Error: 0.441"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9927\n",
            "Mean Squared Error:  0.09561\n",
            "Mean Absolute Error:  0.2382\n",
            "Min Absolute Error:  0.005610275268555398\n",
            "Max Absolute Error:  1.2028444671630858\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,max_error, r2_score\n",
        "from sigfig import round\n",
        "\n",
        "mc_r2_score = r2_score(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual[:, 0], Y_pred[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual[:, 0], Y_pred[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual[:,0])):\n",
        "    sum = Y_actual[:,0][i] - Y_pred[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9950\n",
            "Mean Squared Error:  0.07256\n",
            "Mean Absolute Error:  0.2074\n",
            "Min Absolute Error:  0.0006674194335936079\n",
            "Max Absolute Error:  1.3109439086914065\n"
          ]
        }
      ],
      "source": [
        "mc_r2_score = r2_score(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual_entire[:,0])):\n",
        "    sum = Y_actual_entire[:,0][i] - Y_pred_entire[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
