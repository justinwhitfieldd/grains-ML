{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 610,
      "metadata": {},
      "outputs": [],
      "source": [
        "#GRAIN_TYPE = 'Wheat'\n",
        "#GRAIN_TYPE = 'newWheatData'\n",
        "GRAIN_TYPE = 'CornAdded_Type'\n",
        "# GRAIN_TYPE = 'Oats'\n",
        "# GRAIN_TYPE = 'Barley'\n",
        "# GRAIN_TYPE = 'Sorghum'\n",
        "# GRAIN_TYPE = 'Soybeans'\n",
        "# GRAIN_TYPE = 'Corn'\n",
        "\n",
        "FILENAME_BEST_MODEL = 'Best models/target_2/hybrid_models/' + GRAIN_TYPE + '_t2_kcv_dnn_mc.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 611,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNGoIGbc0kw_",
        "outputId": "279cc9c8-32fd-4f89-e56b-83a0a31081dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ]
        }
      ],
      "source": [
        "#Import libraries\n",
        "import requests\n",
        "import pydot\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Data visualization\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "#Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Machine Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Activation, BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "np.random.seed(39)\n",
        "random.seed(39)\n",
        "tf.random.set_seed(39)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 612,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "# print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 613,
      "metadata": {
        "id": "nxHO_qH0Zi5J"
      },
      "outputs": [],
      "source": [
        "def calculate_r_squared(y_true, y_pred):\n",
        "   corr_matrix = np.corrcoef(y_true, y_pred)\n",
        "   corr = corr_matrix[0,1]\n",
        "   R_sq = corr**2\n",
        "   return R_sq\n",
        "\n",
        "def plot_loss_curve(history, epoch_size):\n",
        "    loss_train = history.history['loss']\n",
        "    loss_val = history.history['val_loss']\n",
        "    epochs = range(0,epoch_size)\n",
        "    \n",
        "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "    \n",
        "    plt.title('Training and Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_line(metric, title, xlabel):\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.title(title, fontsize = 16)\n",
        "    plt.plot(metric)\n",
        "    plt.xlabel(xlabel, fontsize = 14)\n",
        "    plt.grid()\n",
        "    plt.legend(loc= \"best\")\n",
        "    plt.show()\n",
        "\n",
        "def scatter_plot(trueValues, predictions, title):\n",
        "  plt.figure(figsize=(8,3))\n",
        "  ax = plt.axes()\n",
        "  maxVal = max( max(trueValues), max(predictions) )\n",
        "\n",
        "  ax.scatter(x=predictions, y=trueValues)\n",
        "  ax.plot([0, 1, maxVal], [0, 1, maxVal], label=\"Ideal fit\")\n",
        "  print('Maxval here is: ', maxVal)\n",
        "  plt.title(title, fontsize = 16)\n",
        "  plt.xlabel(\"Predictions\", fontsize = 14)\n",
        "  plt.ylabel(\"Real\", fontsize = 14)\n",
        "  plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 614,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "s3pvA5g-zdgv",
        "outputId": "7a7208f1-6b68-4eba-ad1d-9108d0df66ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From USDA:  ../Datasets/processed/CornAdded_Type.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Variety</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>HI BRED 31D58</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>26.23</td>\n",
              "      <td>0.5602</td>\n",
              "      <td>9.2688</td>\n",
              "      <td>142.982</td>\n",
              "      <td>-217.018</td>\n",
              "      <td>3.595</td>\n",
              "      <td>0.984</td>\n",
              "      <td>26.271327</td>\n",
              "      <td>15.426161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>HI BRED 31D58</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>26.23</td>\n",
              "      <td>0.5602</td>\n",
              "      <td>11.9033</td>\n",
              "      <td>114.498</td>\n",
              "      <td>-245.502</td>\n",
              "      <td>3.476</td>\n",
              "      <td>1.067</td>\n",
              "      <td>26.271327</td>\n",
              "      <td>9.619013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>HI BRED 31D58</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>26.23</td>\n",
              "      <td>0.5602</td>\n",
              "      <td>14.9916</td>\n",
              "      <td>85.785</td>\n",
              "      <td>-274.215</td>\n",
              "      <td>3.383</td>\n",
              "      <td>1.163</td>\n",
              "      <td>26.271327</td>\n",
              "      <td>5.722204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>HI BRED 31D58</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>26.23</td>\n",
              "      <td>0.5602</td>\n",
              "      <td>17.7882</td>\n",
              "      <td>63.083</td>\n",
              "      <td>-296.917</td>\n",
              "      <td>3.252</td>\n",
              "      <td>1.205</td>\n",
              "      <td>26.271327</td>\n",
              "      <td>3.546340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>HI BRED 31D58</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>26.23</td>\n",
              "      <td>0.5602</td>\n",
              "      <td>20.2646</td>\n",
              "      <td>38.844</td>\n",
              "      <td>-321.156</td>\n",
              "      <td>3.165</td>\n",
              "      <td>1.224</td>\n",
              "      <td>26.271327</td>\n",
              "      <td>1.916840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0        Variety  Freq  d(cm)     M%  Density     Attn    Phase  \\\n",
              "0           0  HI BRED 31D58   6.0    3.3  26.23   0.5602   9.2688  142.982   \n",
              "1           1  HI BRED 31D58   7.0    3.3  26.23   0.5602  11.9033  114.498   \n",
              "2           2  HI BRED 31D58   8.0    3.3  26.23   0.5602  14.9916   85.785   \n",
              "3           3  HI BRED 31D58   9.0    3.3  26.23   0.5602  17.7882   63.083   \n",
              "4           4  HI BRED 31D58  10.0    3.3  26.23   0.5602  20.2646   38.844   \n",
              "\n",
              "   Phase_Corr  Permittivity_real  Permittivity_imaginary       Type  \\\n",
              "0    -217.018              3.595                   0.984  26.271327   \n",
              "1    -245.502              3.476                   1.067  26.271327   \n",
              "2    -274.215              3.383                   1.163  26.271327   \n",
              "3    -296.917              3.252                   1.205  26.271327   \n",
              "4    -321.156              3.165                   1.224  26.271327   \n",
              "\n",
              "   Phase/Attn  \n",
              "0   15.426161  \n",
              "1    9.619013  \n",
              "2    5.722204  \n",
              "3    3.546340  \n",
              "4    1.916840  "
            ]
          },
          "execution_count": 614,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#url dataset\n",
        "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
        "\n",
        "#read in excel format\n",
        "df = pd.read_csv(URL)\n",
        "#df = df[df['Variety'] == 'KANSAS']\n",
        "#df = df[(df['Density'] >= 0.72) & (df['Density'] <= 0.88)]\n",
        "\n",
        "print(\"From USDA: \", URL)\n",
        "\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUzjHHV2stm"
      },
      "source": [
        "# 2. Overview of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 615,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Xohz7dGh2sXH",
        "outputId": "7d018cd8-018a-45d3-b1b7-ba9fc14aa5e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1325.000000</td>\n",
              "      <td>1325.000000</td>\n",
              "      <td>1325.000000</td>\n",
              "      <td>1325.000000</td>\n",
              "      <td>1325.000000</td>\n",
              "      <td>1325.000000</td>\n",
              "      <td>1325.000000</td>\n",
              "      <td>1325.000000</td>\n",
              "      <td>1325.000000</td>\n",
              "      <td>1325.000000</td>\n",
              "      <td>1325.000000</td>\n",
              "      <td>1325.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>667.980377</td>\n",
              "      <td>9.616604</td>\n",
              "      <td>5.283170</td>\n",
              "      <td>19.173464</td>\n",
              "      <td>0.732730</td>\n",
              "      <td>18.574415</td>\n",
              "      <td>7.843992</td>\n",
              "      <td>-462.193766</td>\n",
              "      <td>3.241382</td>\n",
              "      <td>0.900775</td>\n",
              "      <td>19.173464</td>\n",
              "      <td>1.172074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>388.591085</td>\n",
              "      <td>3.036191</td>\n",
              "      <td>2.049772</td>\n",
              "      <td>7.206516</td>\n",
              "      <td>0.101502</td>\n",
              "      <td>6.337757</td>\n",
              "      <td>89.287814</td>\n",
              "      <td>190.960971</td>\n",
              "      <td>0.603906</td>\n",
              "      <td>0.508211</td>\n",
              "      <td>4.172839</td>\n",
              "      <td>6.073271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.060000</td>\n",
              "      <td>0.448800</td>\n",
              "      <td>8.002300</td>\n",
              "      <td>-179.974000</td>\n",
              "      <td>-1115.206000</td>\n",
              "      <td>2.405000</td>\n",
              "      <td>0.242000</td>\n",
              "      <td>10.530000</td>\n",
              "      <td>-16.206737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>331.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>13.910000</td>\n",
              "      <td>0.663100</td>\n",
              "      <td>13.112200</td>\n",
              "      <td>-54.978000</td>\n",
              "      <td>-573.131000</td>\n",
              "      <td>2.780000</td>\n",
              "      <td>0.477000</td>\n",
              "      <td>15.875592</td>\n",
              "      <td>-2.823299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>662.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>18.580000</td>\n",
              "      <td>0.748300</td>\n",
              "      <td>18.344300</td>\n",
              "      <td>11.128000</td>\n",
              "      <td>-402.701000</td>\n",
              "      <td>3.094000</td>\n",
              "      <td>0.821000</td>\n",
              "      <td>18.743091</td>\n",
              "      <td>0.566702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1007.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>25.430000</td>\n",
              "      <td>0.816100</td>\n",
              "      <td>24.152200</td>\n",
              "      <td>77.870000</td>\n",
              "      <td>-323.806000</td>\n",
              "      <td>3.526000</td>\n",
              "      <td>1.213000</td>\n",
              "      <td>22.657120</td>\n",
              "      <td>4.866332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1338.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>34.400000</td>\n",
              "      <td>0.901700</td>\n",
              "      <td>29.897000</td>\n",
              "      <td>179.949000</td>\n",
              "      <td>-150.217000</td>\n",
              "      <td>5.979000</td>\n",
              "      <td>3.294000</td>\n",
              "      <td>26.271327</td>\n",
              "      <td>20.488695</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0         Freq        d(cm)           M%      Density  \\\n",
              "count  1325.000000  1325.000000  1325.000000  1325.000000  1325.000000   \n",
              "mean    667.980377     9.616604     5.283170    19.173464     0.732730   \n",
              "std     388.591085     3.036191     2.049772     7.206516     0.101502   \n",
              "min       0.000000     5.000000     2.000000     8.060000     0.448800   \n",
              "25%     331.000000     7.000000     3.300000    13.910000     0.663100   \n",
              "50%     662.000000     9.000000     4.400000    18.580000     0.748300   \n",
              "75%    1007.000000    12.000000     7.700000    25.430000     0.816100   \n",
              "max    1338.000000    18.000000     8.500000    34.400000     0.901700   \n",
              "\n",
              "              Attn        Phase   Phase_Corr  Permittivity_real  \\\n",
              "count  1325.000000  1325.000000  1325.000000        1325.000000   \n",
              "mean     18.574415     7.843992  -462.193766           3.241382   \n",
              "std       6.337757    89.287814   190.960971           0.603906   \n",
              "min       8.002300  -179.974000 -1115.206000           2.405000   \n",
              "25%      13.112200   -54.978000  -573.131000           2.780000   \n",
              "50%      18.344300    11.128000  -402.701000           3.094000   \n",
              "75%      24.152200    77.870000  -323.806000           3.526000   \n",
              "max      29.897000   179.949000  -150.217000           5.979000   \n",
              "\n",
              "       Permittivity_imaginary         Type   Phase/Attn  \n",
              "count             1325.000000  1325.000000  1325.000000  \n",
              "mean                 0.900775    19.173464     1.172074  \n",
              "std                  0.508211     4.172839     6.073271  \n",
              "min                  0.242000    10.530000   -16.206737  \n",
              "25%                  0.477000    15.875592    -2.823299  \n",
              "50%                  0.821000    18.743091     0.566702  \n",
              "75%                  1.213000    22.657120     4.866332  \n",
              "max                  3.294000    26.271327    20.488695  "
            ]
          },
          "execution_count": 615,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data summary\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 616,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmFqsYQyGnM",
        "outputId": "54445a7f-a2c8-452a-9651-42dbbe682d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1325, 13)"
            ]
          },
          "execution_count": 616,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimension of the dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 617,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fep-GIv4yUuf",
        "outputId": "c46072fa-aa7f-4549-9a1d-4c5b05d11112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unnamed: 0                0\n",
              "Variety                   0\n",
              "Freq                      0\n",
              "d(cm)                     0\n",
              "M%                        0\n",
              "Density                   0\n",
              "Attn                      0\n",
              "Phase                     0\n",
              "Phase_Corr                0\n",
              "Permittivity_real         0\n",
              "Permittivity_imaginary    0\n",
              "Type                      0\n",
              "Phase/Attn                0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 617,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check info about missing values in dataframe\n",
        "df.isnull().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_TKP9VymuK"
      },
      "source": [
        "# Exploratory Data Analysis\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz1g9T3FzhF0"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "\n",
        "1.   Convert dataframe to numpy array for flexibility.\n",
        "2. Split our data into training and testing datasets and store the target values in different variables.\n",
        "3.   Normalize the features by applying some operations in the data sets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 618,
      "metadata": {
        "id": "T0juhagf1M2I"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy array\n",
        "df_features = df[['Freq', \n",
        "                    'd(cm)', \n",
        "                    'Attn', \n",
        "                    'Phase', \n",
        "                    'Phase_Corr', \n",
        "                    'Permittivity_real', \n",
        "                    'Permittivity_imaginary',\n",
        "                    'Type']]\n",
        "\n",
        "df_targets = df[['M%', 'Density']]\n",
        "# df_targets = df[['Density', 'M%']]\n",
        "\n",
        "dataset_x = df_features.to_numpy()\n",
        "dataset_y = df_targets.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting dataset to test and train+validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 619,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform train-test split on RAW DATA\n",
        "X_trainVal, X_test, y_trainVal, y_test = train_test_split(dataset_x, dataset_y, \n",
        "                                                    test_size=0.15\n",
        "                                                    ,random_state=42\n",
        "                                                    )\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainVal, y_trainVal, \n",
        "                                                    test_size=0.15 #validation split\n",
        "                                                    ,random_state=42\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 620,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Normalizing the data set\n",
        "scaler_input = MinMaxScaler()\n",
        "scaler_output = MinMaxScaler()\n",
        "\n",
        "# Normalize Train set\n",
        "X_train_norm = scaler_input.fit_transform(X_train)\n",
        "y_train_norm = scaler_output.fit_transform(y_train)\n",
        "\n",
        "# Normalize Validation set\n",
        "X_val_norm = scaler_input.fit_transform(X_val)\n",
        "y_val_norm = scaler_output.fit_transform(y_val)\n",
        "\n",
        "# Normalize the entire dataset (input features)\n",
        "dataset_x_norm = scaler_input.transform(dataset_x)  # Use transform, NOT fit_transform\n",
        "\n",
        "# Normalize the entire dataset (output targets)\n",
        "dataset_y_norm = scaler_output.transform(dataset_y)  # Use transform, NOT fit_transform\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKfjwMP0Tzn"
      },
      "source": [
        "# K-cross Validation\n",
        "* Input features: 7\n",
        "* Output targets: 2\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 621,
      "metadata": {
        "id": "l31WJZ7Z0ONb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_349\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1396 (Dense)           (None, 64)                576       \n",
            "_________________________________________________________________\n",
            "dense_1397 (Dense)           (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_1398 (Dense)           (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_1399 (Dense)           (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 9,026\n",
            "Trainable params: 9,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import layers, Sequential, regularizers\n",
        "\n",
        "# Define the model-building function\n",
        "def my_model():\n",
        "  my_model = Sequential([\n",
        "    \n",
        "    layers.Dense(64, input_shape=(8,), activation='relu', \n",
        "                #  kernel_regularizer=regularizers.l2(0.01)\n",
        "                 ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.1),\n",
        "\n",
        "\n",
        "    layers.Dense(64, activation='relu', \n",
        "                # kernel_regularizer=regularizers.l2(0.01)\n",
        "                ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.1),````\n",
        "\n",
        "    layers.Dense(64, activation='relu', \n",
        "                # kernel_regularizer=regularizers.l2(0.01)\n",
        "                ),\n",
        "    # layers.BatchNormalization(),  # Batch normalization layer\n",
        "    # layers.Dropout(0.2),\n",
        "    \n",
        "    layers.Dense(2, activation='linear')  # Output layer with 2 neurons for the two regression targets\n",
        "  ])\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.0001) # 0.0006 \n",
        "  my_model.compile(\n",
        "      optimizer = opt,\n",
        "      loss = 'mse',\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "\n",
        "  return my_model\n",
        "\n",
        "plot_model(my_model(), show_shapes=True, show_layer_names=True)\n",
        "my_model().summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running model with KCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 622,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khCKKB74hFVT",
        "outputId": "37e79cdf-4183-4559-f560-fceb2fc0c630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "####################### Iteration   0  #######################\n",
            "Epoch 1/160\n",
            "87/87 [==============================] - 0s 886us/step - loss: 0.2445 - accuracy: 0.6370 - val_loss: 0.1029 - val_accuracy: 0.6562\n",
            "Epoch 2/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0899 - accuracy: 0.6112 - val_loss: 0.0532 - val_accuracy: 0.6562\n",
            "Epoch 3/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0541 - accuracy: 0.6030 - val_loss: 0.0382 - val_accuracy: 0.6562\n",
            "Epoch 4/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0366 - accuracy: 0.6097 - val_loss: 0.0254 - val_accuracy: 0.8021\n",
            "Epoch 5/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0247 - accuracy: 0.8082 - val_loss: 0.0176 - val_accuracy: 0.9167\n",
            "Epoch 6/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0185 - accuracy: 0.9183 - val_loss: 0.0141 - val_accuracy: 0.9167\n",
            "Epoch 7/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0138 - accuracy: 0.9355 - val_loss: 0.0125 - val_accuracy: 0.9167\n",
            "Epoch 8/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0130 - accuracy: 0.9562 - val_loss: 0.0115 - val_accuracy: 0.9375\n",
            "Epoch 9/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0120 - accuracy: 0.9548 - val_loss: 0.0108 - val_accuracy: 0.9583\n",
            "Epoch 10/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0110 - accuracy: 0.9490 - val_loss: 0.0101 - val_accuracy: 0.9583\n",
            "Epoch 11/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0108 - accuracy: 0.9593 - val_loss: 0.0096 - val_accuracy: 0.9583\n",
            "Epoch 12/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0096 - accuracy: 0.9503 - val_loss: 0.0097 - val_accuracy: 0.9479\n",
            "Epoch 13/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0093 - accuracy: 0.9518 - val_loss: 0.0088 - val_accuracy: 0.9479\n",
            "Epoch 14/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0086 - accuracy: 0.9534 - val_loss: 0.0083 - val_accuracy: 0.9479\n",
            "Epoch 15/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0089 - accuracy: 0.9484 - val_loss: 0.0080 - val_accuracy: 0.9479\n",
            "Epoch 16/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0082 - accuracy: 0.9523 - val_loss: 0.0075 - val_accuracy: 0.9479\n",
            "Epoch 17/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0080 - accuracy: 0.9602 - val_loss: 0.0072 - val_accuracy: 0.9479\n",
            "Epoch 18/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0077 - accuracy: 0.9614 - val_loss: 0.0070 - val_accuracy: 0.9479\n",
            "Epoch 19/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0076 - accuracy: 0.9515 - val_loss: 0.0067 - val_accuracy: 0.9479\n",
            "Epoch 20/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0072 - accuracy: 0.9547 - val_loss: 0.0065 - val_accuracy: 0.9479\n",
            "Epoch 21/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0069 - accuracy: 0.9574 - val_loss: 0.0063 - val_accuracy: 0.9479\n",
            "Epoch 22/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0064 - accuracy: 0.9612 - val_loss: 0.0060 - val_accuracy: 0.9479\n",
            "Epoch 23/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0064 - accuracy: 0.9602 - val_loss: 0.0058 - val_accuracy: 0.9479\n",
            "Epoch 24/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0059 - accuracy: 0.9656 - val_loss: 0.0059 - val_accuracy: 0.9479\n",
            "Epoch 25/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0061 - accuracy: 0.9655 - val_loss: 0.0056 - val_accuracy: 0.9479\n",
            "Epoch 26/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0055 - accuracy: 0.9703 - val_loss: 0.0055 - val_accuracy: 0.9479\n",
            "Epoch 27/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0053 - accuracy: 0.9618 - val_loss: 0.0054 - val_accuracy: 0.9479\n",
            "Epoch 28/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0053 - accuracy: 0.9620 - val_loss: 0.0055 - val_accuracy: 0.9479\n",
            "Epoch 29/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0051 - accuracy: 0.9568 - val_loss: 0.0051 - val_accuracy: 0.9479\n",
            "Epoch 30/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0052 - accuracy: 0.9685 - val_loss: 0.0053 - val_accuracy: 0.9479\n",
            "Epoch 31/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0046 - accuracy: 0.9612 - val_loss: 0.0052 - val_accuracy: 0.9479\n",
            "Epoch 32/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0049 - accuracy: 0.9615 - val_loss: 0.0049 - val_accuracy: 0.9479\n",
            "Epoch 33/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0048 - accuracy: 0.9724 - val_loss: 0.0049 - val_accuracy: 0.9479\n",
            "Epoch 34/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0045 - accuracy: 0.9599 - val_loss: 0.0046 - val_accuracy: 0.9479\n",
            "Epoch 35/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0046 - accuracy: 0.9703 - val_loss: 0.0044 - val_accuracy: 0.9479\n",
            "Epoch 36/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0047 - accuracy: 0.9753 - val_loss: 0.0048 - val_accuracy: 0.9479\n",
            "Epoch 37/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0041 - accuracy: 0.9629 - val_loss: 0.0042 - val_accuracy: 0.9479\n",
            "Epoch 38/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0044 - accuracy: 0.9673 - val_loss: 0.0041 - val_accuracy: 0.9479\n",
            "Epoch 39/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0043 - accuracy: 0.9674 - val_loss: 0.0041 - val_accuracy: 0.9375\n",
            "Epoch 40/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0042 - accuracy: 0.9670 - val_loss: 0.0042 - val_accuracy: 0.9479\n",
            "Epoch 41/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0042 - accuracy: 0.9585 - val_loss: 0.0041 - val_accuracy: 0.9479\n",
            "Epoch 42/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0042 - accuracy: 0.9657 - val_loss: 0.0045 - val_accuracy: 0.9479\n",
            "Epoch 43/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0044 - accuracy: 0.9634 - val_loss: 0.0040 - val_accuracy: 0.9375\n",
            "Epoch 44/160\n",
            "87/87 [==============================] - 0s 448us/step - loss: 0.0038 - accuracy: 0.9690 - val_loss: 0.0038 - val_accuracy: 0.9479\n",
            "Epoch 45/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0037 - accuracy: 0.9600 - val_loss: 0.0038 - val_accuracy: 0.9375\n",
            "Epoch 46/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0037 - accuracy: 0.9691 - val_loss: 0.0038 - val_accuracy: 0.9375\n",
            "Epoch 47/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0039 - accuracy: 0.9617 - val_loss: 0.0037 - val_accuracy: 0.9479\n",
            "Epoch 48/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0036 - accuracy: 0.9686 - val_loss: 0.0036 - val_accuracy: 0.9479\n",
            "Epoch 49/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0038 - accuracy: 0.9610 - val_loss: 0.0038 - val_accuracy: 0.9375\n",
            "Epoch 50/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0040 - accuracy: 0.9778 - val_loss: 0.0035 - val_accuracy: 0.9479\n",
            "Epoch 51/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0038 - accuracy: 0.9552 - val_loss: 0.0035 - val_accuracy: 0.9479\n",
            "Epoch 52/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0039 - accuracy: 0.9696 - val_loss: 0.0037 - val_accuracy: 0.9375\n",
            "Epoch 53/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0037 - accuracy: 0.9669 - val_loss: 0.0035 - val_accuracy: 0.9375\n",
            "Epoch 54/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0037 - accuracy: 0.9654 - val_loss: 0.0035 - val_accuracy: 0.9375\n",
            "Epoch 55/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0033 - accuracy: 0.9585 - val_loss: 0.0037 - val_accuracy: 0.9375\n",
            "Epoch 56/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0036 - accuracy: 0.9642 - val_loss: 0.0034 - val_accuracy: 0.9583\n",
            "Epoch 57/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0035 - accuracy: 0.9628 - val_loss: 0.0038 - val_accuracy: 0.9375\n",
            "Epoch 58/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0034 - accuracy: 0.9663 - val_loss: 0.0033 - val_accuracy: 0.9583\n",
            "Epoch 59/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0032 - accuracy: 0.9572 - val_loss: 0.0033 - val_accuracy: 0.9583\n",
            "Epoch 60/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0035 - accuracy: 0.9495 - val_loss: 0.0034 - val_accuracy: 0.9583\n",
            "Epoch 61/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0036 - accuracy: 0.9595 - val_loss: 0.0033 - val_accuracy: 0.9583\n",
            "Epoch 62/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0033 - accuracy: 0.9668 - val_loss: 0.0033 - val_accuracy: 0.9583\n",
            "Epoch 63/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0032 - accuracy: 0.9631 - val_loss: 0.0033 - val_accuracy: 0.9583\n",
            "Epoch 64/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0033 - accuracy: 0.9637 - val_loss: 0.0034 - val_accuracy: 0.9375\n",
            "Epoch 65/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0032 - accuracy: 0.9647 - val_loss: 0.0033 - val_accuracy: 0.9479\n",
            "Epoch 66/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0031 - accuracy: 0.9696 - val_loss: 0.0033 - val_accuracy: 0.9479\n",
            "Epoch 67/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0033 - accuracy: 0.9640 - val_loss: 0.0033 - val_accuracy: 0.9479\n",
            "Epoch 68/160\n",
            "87/87 [==============================] - 0s 505us/step - loss: 0.0032 - accuracy: 0.9671 - val_loss: 0.0035 - val_accuracy: 0.9375\n",
            "Epoch 69/160\n",
            "87/87 [==============================] - 0s 461us/step - loss: 0.0031 - accuracy: 0.9706 - val_loss: 0.0032 - val_accuracy: 0.9479\n",
            "Epoch 70/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0029 - accuracy: 0.9693 - val_loss: 0.0036 - val_accuracy: 0.9375\n",
            "Epoch 71/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0031 - accuracy: 0.9739 - val_loss: 0.0040 - val_accuracy: 0.9375\n",
            "Epoch 72/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0033 - accuracy: 0.9661 - val_loss: 0.0031 - val_accuracy: 0.9583\n",
            "Epoch 73/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0035 - accuracy: 0.9554 - val_loss: 0.0032 - val_accuracy: 0.9583\n",
            "Epoch 74/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0031 - accuracy: 0.9584 - val_loss: 0.0031 - val_accuracy: 0.9583\n",
            "Epoch 75/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0028 - accuracy: 0.9655 - val_loss: 0.0033 - val_accuracy: 0.9479\n",
            "Epoch 76/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0029 - accuracy: 0.9667 - val_loss: 0.0033 - val_accuracy: 0.9583\n",
            "Epoch 77/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0030 - accuracy: 0.9711 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 78/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0032 - accuracy: 0.9578 - val_loss: 0.0032 - val_accuracy: 0.9583\n",
            "Epoch 79/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0030 - accuracy: 0.9663 - val_loss: 0.0030 - val_accuracy: 0.9583\n",
            "Epoch 80/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0028 - accuracy: 0.9706 - val_loss: 0.0030 - val_accuracy: 0.9583\n",
            "Epoch 81/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0031 - accuracy: 0.9613 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 82/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0028 - accuracy: 0.9680 - val_loss: 0.0030 - val_accuracy: 0.9583\n",
            "Epoch 83/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0028 - accuracy: 0.9749 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 84/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0027 - accuracy: 0.9726 - val_loss: 0.0032 - val_accuracy: 0.9479\n",
            "Epoch 85/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0029 - accuracy: 0.9695 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 86/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0025 - accuracy: 0.9765 - val_loss: 0.0030 - val_accuracy: 0.9583\n",
            "Epoch 87/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0027 - accuracy: 0.9782 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 88/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0030 - accuracy: 0.9575 - val_loss: 0.0030 - val_accuracy: 0.9688\n",
            "Epoch 89/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0030 - accuracy: 0.9634 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 90/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0027 - accuracy: 0.9762 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 91/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0027 - accuracy: 0.9631 - val_loss: 0.0032 - val_accuracy: 0.9583\n",
            "Epoch 92/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0029 - accuracy: 0.9710 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 93/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0028 - accuracy: 0.9661 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 94/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0028 - accuracy: 0.9732 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 95/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0024 - accuracy: 0.9707 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 96/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0025 - accuracy: 0.9764 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 97/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0027 - accuracy: 0.9732 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 98/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0027 - accuracy: 0.9763 - val_loss: 0.0032 - val_accuracy: 0.9583\n",
            "Epoch 99/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0024 - accuracy: 0.9868 - val_loss: 0.0032 - val_accuracy: 0.9479\n",
            "Epoch 100/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0031 - accuracy: 0.9762 - val_loss: 0.0030 - val_accuracy: 0.9583\n",
            "Epoch 101/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0025 - accuracy: 0.9771 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 102/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0024 - accuracy: 0.9703 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 103/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0026 - accuracy: 0.9734 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 104/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0028 - accuracy: 0.9617 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 105/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0024 - accuracy: 0.9801 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 106/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0028 - accuracy: 0.9637 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 107/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0024 - accuracy: 0.9777 - val_loss: 0.0030 - val_accuracy: 0.9583\n",
            "Epoch 108/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0025 - accuracy: 0.9744 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 109/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0025 - accuracy: 0.9698 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 110/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0025 - accuracy: 0.9704 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 111/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0025 - accuracy: 0.9748 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 112/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0024 - accuracy: 0.9657 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 113/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0026 - accuracy: 0.9741 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 114/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0025 - accuracy: 0.9794 - val_loss: 0.0030 - val_accuracy: 0.9479\n",
            "Epoch 115/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0028 - accuracy: 0.9708 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 116/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0025 - accuracy: 0.9682 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 117/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0027 - accuracy: 0.9641 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 118/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0025 - accuracy: 0.9636 - val_loss: 0.0030 - val_accuracy: 0.9479\n",
            "Epoch 119/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0025 - accuracy: 0.9738 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 120/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0025 - accuracy: 0.9780 - val_loss: 0.0030 - val_accuracy: 0.9479\n",
            "Epoch 121/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0026 - accuracy: 0.9762 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 122/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0027 - accuracy: 0.9609 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 123/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0025 - accuracy: 0.9668 - val_loss: 0.0030 - val_accuracy: 0.9583\n",
            "Epoch 124/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0028 - accuracy: 0.9701 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 125/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0023 - accuracy: 0.9667 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 126/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0026 - accuracy: 0.9679 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 127/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0028 - accuracy: 0.9694 - val_loss: 0.0024 - val_accuracy: 0.9688\n",
            "Epoch 128/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0024 - accuracy: 0.9742 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 129/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0028 - accuracy: 0.9756 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 130/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0024 - accuracy: 0.9731 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 131/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0022 - accuracy: 0.9725 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 132/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0022 - accuracy: 0.9684 - val_loss: 0.0024 - val_accuracy: 0.9688\n",
            "Epoch 133/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0024 - accuracy: 0.9756 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 134/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0020 - accuracy: 0.9747 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 135/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0025 - accuracy: 0.9702 - val_loss: 0.0031 - val_accuracy: 0.9479\n",
            "Epoch 136/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0027 - accuracy: 0.9767 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 137/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0022 - accuracy: 0.9723 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 138/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0028 - accuracy: 0.9584 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 139/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0024 - accuracy: 0.9718 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 140/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0026 - accuracy: 0.9685 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 141/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0025 - accuracy: 0.9745 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 142/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0026 - accuracy: 0.9700 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 143/160\n",
            "87/87 [==============================] - 0s 479us/step - loss: 0.0024 - accuracy: 0.9802 - val_loss: 0.0026 - val_accuracy: 0.9688\n",
            "Epoch 144/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0024 - accuracy: 0.9724 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 145/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0028 - accuracy: 0.9523 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 146/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0028 - accuracy: 0.9635 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 147/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0026 - accuracy: 0.9767 - val_loss: 0.0024 - val_accuracy: 0.9688\n",
            "Epoch 148/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0023 - accuracy: 0.9643 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 149/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0026 - accuracy: 0.9806 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 150/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0025 - accuracy: 0.9747 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 151/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0024 - accuracy: 0.9706 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 152/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0023 - accuracy: 0.9775 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 153/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0023 - accuracy: 0.9737 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 154/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0023 - accuracy: 0.9622 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 155/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0025 - accuracy: 0.9776 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 156/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0024 - accuracy: 0.9616 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 157/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0023 - accuracy: 0.9721 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 158/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0020 - accuracy: 0.9721 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 159/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0027 - accuracy: 0.9747 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 160/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0022 - accuracy: 0.9608 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "3/3 [==============================] - 0s 618us/step - loss: 0.0026 - accuracy: 0.9583\n",
            "Loss = 0.002609268995001912, rmse = 0.9583333134651184\n",
            "Loss array:  [0.002609268995001912]\n",
            "####################### Iteration   1  #######################\n",
            "Epoch 1/160\n",
            "87/87 [==============================] - 0s 831us/step - loss: 0.1511 - accuracy: 0.7503 - val_loss: 0.0378 - val_accuracy: 0.7396\n",
            "Epoch 2/160\n",
            "87/87 [==============================] - 0s 443us/step - loss: 0.0393 - accuracy: 0.7750 - val_loss: 0.0227 - val_accuracy: 0.8854\n",
            "Epoch 3/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0237 - accuracy: 0.8803 - val_loss: 0.0155 - val_accuracy: 0.8958\n",
            "Epoch 4/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0164 - accuracy: 0.9235 - val_loss: 0.0130 - val_accuracy: 0.9167\n",
            "Epoch 5/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0137 - accuracy: 0.9373 - val_loss: 0.0119 - val_accuracy: 0.9167\n",
            "Epoch 6/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0142 - accuracy: 0.9595 - val_loss: 0.0110 - val_accuracy: 0.9167\n",
            "Epoch 7/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0117 - accuracy: 0.9587 - val_loss: 0.0105 - val_accuracy: 0.9271\n",
            "Epoch 8/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0111 - accuracy: 0.9675 - val_loss: 0.0098 - val_accuracy: 0.9271\n",
            "Epoch 9/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0112 - accuracy: 0.9652 - val_loss: 0.0092 - val_accuracy: 0.9375\n",
            "Epoch 10/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0097 - accuracy: 0.9496 - val_loss: 0.0087 - val_accuracy: 0.9375\n",
            "Epoch 11/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0096 - accuracy: 0.9615 - val_loss: 0.0083 - val_accuracy: 0.9375\n",
            "Epoch 12/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0086 - accuracy: 0.9568 - val_loss: 0.0086 - val_accuracy: 0.9375\n",
            "Epoch 13/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0087 - accuracy: 0.9637 - val_loss: 0.0075 - val_accuracy: 0.9375\n",
            "Epoch 14/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0080 - accuracy: 0.9694 - val_loss: 0.0074 - val_accuracy: 0.9375\n",
            "Epoch 15/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0077 - accuracy: 0.9500 - val_loss: 0.0074 - val_accuracy: 0.9375\n",
            "Epoch 16/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0074 - accuracy: 0.9607 - val_loss: 0.0068 - val_accuracy: 0.9167\n",
            "Epoch 17/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0072 - accuracy: 0.9620 - val_loss: 0.0066 - val_accuracy: 0.9375\n",
            "Epoch 18/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0071 - accuracy: 0.9713 - val_loss: 0.0064 - val_accuracy: 0.9167\n",
            "Epoch 19/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0072 - accuracy: 0.9546 - val_loss: 0.0063 - val_accuracy: 0.9375\n",
            "Epoch 20/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0066 - accuracy: 0.9574 - val_loss: 0.0060 - val_accuracy: 0.9271\n",
            "Epoch 21/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0063 - accuracy: 0.9653 - val_loss: 0.0058 - val_accuracy: 0.9167\n",
            "Epoch 22/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0060 - accuracy: 0.9692 - val_loss: 0.0057 - val_accuracy: 0.9479\n",
            "Epoch 23/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0060 - accuracy: 0.9550 - val_loss: 0.0056 - val_accuracy: 0.9271\n",
            "Epoch 24/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0058 - accuracy: 0.9701 - val_loss: 0.0057 - val_accuracy: 0.9375\n",
            "Epoch 25/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0057 - accuracy: 0.9614 - val_loss: 0.0053 - val_accuracy: 0.9375\n",
            "Epoch 26/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0054 - accuracy: 0.9677 - val_loss: 0.0053 - val_accuracy: 0.9271\n",
            "Epoch 27/160\n",
            "87/87 [==============================] - 0s 384us/step - loss: 0.0052 - accuracy: 0.9698 - val_loss: 0.0051 - val_accuracy: 0.9479\n",
            "Epoch 28/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0055 - accuracy: 0.9579 - val_loss: 0.0053 - val_accuracy: 0.9479\n",
            "Epoch 29/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0054 - accuracy: 0.9629 - val_loss: 0.0050 - val_accuracy: 0.9479\n",
            "Epoch 30/160\n",
            "87/87 [==============================] - 0s 386us/step - loss: 0.0053 - accuracy: 0.9754 - val_loss: 0.0051 - val_accuracy: 0.9583\n",
            "Epoch 31/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0050 - accuracy: 0.9663 - val_loss: 0.0051 - val_accuracy: 0.9583\n",
            "Epoch 32/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0052 - accuracy: 0.9656 - val_loss: 0.0049 - val_accuracy: 0.9583\n",
            "Epoch 33/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0050 - accuracy: 0.9678 - val_loss: 0.0046 - val_accuracy: 0.9688\n",
            "Epoch 34/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0050 - accuracy: 0.9671 - val_loss: 0.0045 - val_accuracy: 0.9688\n",
            "Epoch 35/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0047 - accuracy: 0.9697 - val_loss: 0.0044 - val_accuracy: 0.9479\n",
            "Epoch 36/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0048 - accuracy: 0.9756 - val_loss: 0.0046 - val_accuracy: 0.9583\n",
            "Epoch 37/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0045 - accuracy: 0.9627 - val_loss: 0.0043 - val_accuracy: 0.9479\n",
            "Epoch 38/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0045 - accuracy: 0.9668 - val_loss: 0.0043 - val_accuracy: 0.9583\n",
            "Epoch 39/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0047 - accuracy: 0.9636 - val_loss: 0.0042 - val_accuracy: 0.9375\n",
            "Epoch 40/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0045 - accuracy: 0.9724 - val_loss: 0.0042 - val_accuracy: 0.9583\n",
            "Epoch 41/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0047 - accuracy: 0.9580 - val_loss: 0.0042 - val_accuracy: 0.9688\n",
            "Epoch 42/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0047 - accuracy: 0.9582 - val_loss: 0.0045 - val_accuracy: 0.9688\n",
            "Epoch 43/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0047 - accuracy: 0.9663 - val_loss: 0.0041 - val_accuracy: 0.9583\n",
            "Epoch 44/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0041 - accuracy: 0.9624 - val_loss: 0.0040 - val_accuracy: 0.9583\n",
            "Epoch 45/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0039 - accuracy: 0.9626 - val_loss: 0.0038 - val_accuracy: 0.9583\n",
            "Epoch 46/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0042 - accuracy: 0.9629 - val_loss: 0.0040 - val_accuracy: 0.9792\n",
            "Epoch 47/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0041 - accuracy: 0.9647 - val_loss: 0.0038 - val_accuracy: 0.9688\n",
            "Epoch 48/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0040 - accuracy: 0.9619 - val_loss: 0.0038 - val_accuracy: 0.9688\n",
            "Epoch 49/160\n",
            "87/87 [==============================] - 0s 382us/step - loss: 0.0042 - accuracy: 0.9611 - val_loss: 0.0038 - val_accuracy: 0.9792\n",
            "Epoch 50/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0043 - accuracy: 0.9715 - val_loss: 0.0037 - val_accuracy: 0.9688\n",
            "Epoch 51/160\n",
            "87/87 [==============================] - 0s 467us/step - loss: 0.0041 - accuracy: 0.9563 - val_loss: 0.0036 - val_accuracy: 0.9688\n",
            "Epoch 52/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0042 - accuracy: 0.9721 - val_loss: 0.0036 - val_accuracy: 0.9792\n",
            "Epoch 53/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0040 - accuracy: 0.9654 - val_loss: 0.0036 - val_accuracy: 0.9792\n",
            "Epoch 54/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0038 - accuracy: 0.9696 - val_loss: 0.0035 - val_accuracy: 0.9583\n",
            "Epoch 55/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0036 - accuracy: 0.9708 - val_loss: 0.0035 - val_accuracy: 0.9688\n",
            "Epoch 56/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0039 - accuracy: 0.9530 - val_loss: 0.0035 - val_accuracy: 0.9688\n",
            "Epoch 57/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0036 - accuracy: 0.9578 - val_loss: 0.0034 - val_accuracy: 0.9688\n",
            "Epoch 58/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0037 - accuracy: 0.9672 - val_loss: 0.0035 - val_accuracy: 0.9479\n",
            "Epoch 59/160\n",
            "87/87 [==============================] - 0s 440us/step - loss: 0.0034 - accuracy: 0.9564 - val_loss: 0.0037 - val_accuracy: 0.9479\n",
            "Epoch 60/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0039 - accuracy: 0.9446 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 61/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0036 - accuracy: 0.9667 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 62/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0037 - accuracy: 0.9633 - val_loss: 0.0034 - val_accuracy: 0.9479\n",
            "Epoch 63/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0034 - accuracy: 0.9595 - val_loss: 0.0032 - val_accuracy: 0.9688\n",
            "Epoch 64/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0035 - accuracy: 0.9666 - val_loss: 0.0034 - val_accuracy: 0.9792\n",
            "Epoch 65/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0035 - accuracy: 0.9628 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 66/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0033 - accuracy: 0.9633 - val_loss: 0.0033 - val_accuracy: 0.9792\n",
            "Epoch 67/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0034 - accuracy: 0.9659 - val_loss: 0.0032 - val_accuracy: 0.9688\n",
            "Epoch 68/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0032 - accuracy: 0.9716 - val_loss: 0.0039 - val_accuracy: 0.9688\n",
            "Epoch 69/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0032 - accuracy: 0.9619 - val_loss: 0.0032 - val_accuracy: 0.9583\n",
            "Epoch 70/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0030 - accuracy: 0.9746 - val_loss: 0.0035 - val_accuracy: 0.9688\n",
            "Epoch 71/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0032 - accuracy: 0.9763 - val_loss: 0.0034 - val_accuracy: 0.9688\n",
            "Epoch 72/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0033 - accuracy: 0.9626 - val_loss: 0.0031 - val_accuracy: 0.9688\n",
            "Epoch 73/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0035 - accuracy: 0.9640 - val_loss: 0.0030 - val_accuracy: 0.9688\n",
            "Epoch 74/160\n",
            "87/87 [==============================] - 0s 386us/step - loss: 0.0033 - accuracy: 0.9535 - val_loss: 0.0030 - val_accuracy: 0.9688\n",
            "Epoch 75/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0028 - accuracy: 0.9672 - val_loss: 0.0031 - val_accuracy: 0.9688\n",
            "Epoch 76/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0031 - accuracy: 0.9632 - val_loss: 0.0030 - val_accuracy: 0.9583\n",
            "Epoch 77/160\n",
            "87/87 [==============================] - 0s 378us/step - loss: 0.0033 - accuracy: 0.9707 - val_loss: 0.0030 - val_accuracy: 0.9583\n",
            "Epoch 78/160\n",
            "87/87 [==============================] - 0s 383us/step - loss: 0.0032 - accuracy: 0.9586 - val_loss: 0.0031 - val_accuracy: 0.9792\n",
            "Epoch 79/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0033 - accuracy: 0.9656 - val_loss: 0.0030 - val_accuracy: 0.9688\n",
            "Epoch 80/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0030 - accuracy: 0.9676 - val_loss: 0.0030 - val_accuracy: 0.9688\n",
            "Epoch 81/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0031 - accuracy: 0.9696 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 82/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0028 - accuracy: 0.9659 - val_loss: 0.0036 - val_accuracy: 0.9479\n",
            "Epoch 83/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0031 - accuracy: 0.9769 - val_loss: 0.0029 - val_accuracy: 0.9792\n",
            "Epoch 84/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0028 - accuracy: 0.9700 - val_loss: 0.0031 - val_accuracy: 0.9792\n",
            "Epoch 85/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0032 - accuracy: 0.9632 - val_loss: 0.0030 - val_accuracy: 0.9583\n",
            "Epoch 86/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0025 - accuracy: 0.9801 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 87/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0029 - accuracy: 0.9861 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 88/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0030 - accuracy: 0.9711 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 89/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0031 - accuracy: 0.9643 - val_loss: 0.0028 - val_accuracy: 0.9479\n",
            "Epoch 90/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0028 - accuracy: 0.9699 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 91/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0029 - accuracy: 0.9650 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 92/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0029 - accuracy: 0.9729 - val_loss: 0.0028 - val_accuracy: 0.9479\n",
            "Epoch 93/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0029 - accuracy: 0.9746 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 94/160\n",
            "87/87 [==============================] - 0s 478us/step - loss: 0.0028 - accuracy: 0.9723 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 95/160\n",
            "87/87 [==============================] - 0s 547us/step - loss: 0.0024 - accuracy: 0.9711 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 96/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0027 - accuracy: 0.9766 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 97/160\n",
            "87/87 [==============================] - 0s 450us/step - loss: 0.0027 - accuracy: 0.9584 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 98/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0028 - accuracy: 0.9755 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 99/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0025 - accuracy: 0.9721 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 100/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0029 - accuracy: 0.9756 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 101/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0024 - accuracy: 0.9704 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 102/160\n",
            "87/87 [==============================] - 0s 441us/step - loss: 0.0024 - accuracy: 0.9703 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 103/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0026 - accuracy: 0.9725 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 104/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0028 - accuracy: 0.9707 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 105/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0024 - accuracy: 0.9781 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 106/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0028 - accuracy: 0.9629 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 107/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0023 - accuracy: 0.9805 - val_loss: 0.0030 - val_accuracy: 0.9479\n",
            "Epoch 108/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0026 - accuracy: 0.9695 - val_loss: 0.0026 - val_accuracy: 0.9688\n",
            "Epoch 109/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0025 - accuracy: 0.9702 - val_loss: 0.0027 - val_accuracy: 0.9688\n",
            "Epoch 110/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0025 - accuracy: 0.9720 - val_loss: 0.0027 - val_accuracy: 0.9688\n",
            "Epoch 111/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0026 - accuracy: 0.9782 - val_loss: 0.0026 - val_accuracy: 0.9688\n",
            "Epoch 112/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0023 - accuracy: 0.9754 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 113/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0028 - accuracy: 0.9703 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 114/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0025 - accuracy: 0.9792 - val_loss: 0.0026 - val_accuracy: 0.9792\n",
            "Epoch 115/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0026 - accuracy: 0.9661 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 116/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0025 - accuracy: 0.9712 - val_loss: 0.0030 - val_accuracy: 0.9688\n",
            "Epoch 117/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0028 - accuracy: 0.9690 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 118/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0024 - accuracy: 0.9748 - val_loss: 0.0026 - val_accuracy: 0.9688\n",
            "Epoch 119/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0023 - accuracy: 0.9749 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 120/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0025 - accuracy: 0.9804 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 121/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0026 - accuracy: 0.9777 - val_loss: 0.0026 - val_accuracy: 0.9479\n",
            "Epoch 122/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0027 - accuracy: 0.9673 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 123/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0025 - accuracy: 0.9672 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 124/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0028 - accuracy: 0.9748 - val_loss: 0.0024 - val_accuracy: 0.9688\n",
            "Epoch 125/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0021 - accuracy: 0.9783 - val_loss: 0.0027 - val_accuracy: 0.9583\n",
            "Epoch 126/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0024 - accuracy: 0.9763 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 127/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0026 - accuracy: 0.9688 - val_loss: 0.0024 - val_accuracy: 0.9688\n",
            "Epoch 128/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0023 - accuracy: 0.9841 - val_loss: 0.0026 - val_accuracy: 0.9688\n",
            "Epoch 129/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0026 - accuracy: 0.9757 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 130/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0025 - accuracy: 0.9692 - val_loss: 0.0024 - val_accuracy: 0.9688\n",
            "Epoch 131/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0021 - accuracy: 0.9751 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 132/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0022 - accuracy: 0.9734 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 133/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0025 - accuracy: 0.9852 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 134/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0020 - accuracy: 0.9813 - val_loss: 0.0027 - val_accuracy: 0.9688\n",
            "Epoch 135/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0023 - accuracy: 0.9671 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 136/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0031 - accuracy: 0.9645 - val_loss: 0.0024 - val_accuracy: 0.9792\n",
            "Epoch 137/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0022 - accuracy: 0.9734 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 138/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0027 - accuracy: 0.9666 - val_loss: 0.0027 - val_accuracy: 0.9688\n",
            "Epoch 139/160\n",
            "87/87 [==============================] - 0s 385us/step - loss: 0.0022 - accuracy: 0.9777 - val_loss: 0.0025 - val_accuracy: 0.9688\n",
            "Epoch 140/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0025 - accuracy: 0.9733 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 141/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0025 - accuracy: 0.9776 - val_loss: 0.0023 - val_accuracy: 0.9688\n",
            "Epoch 142/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0026 - accuracy: 0.9769 - val_loss: 0.0023 - val_accuracy: 0.9688\n",
            "Epoch 143/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0024 - accuracy: 0.9792 - val_loss: 0.0026 - val_accuracy: 0.9479\n",
            "Epoch 144/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0023 - accuracy: 0.9761 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 145/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0026 - accuracy: 0.9651 - val_loss: 0.0023 - val_accuracy: 0.9688\n",
            "Epoch 146/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0027 - accuracy: 0.9619 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 147/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0024 - accuracy: 0.9828 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 148/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0021 - accuracy: 0.9793 - val_loss: 0.0023 - val_accuracy: 0.9583\n",
            "Epoch 149/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0026 - accuracy: 0.9770 - val_loss: 0.0023 - val_accuracy: 0.9583\n",
            "Epoch 150/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0026 - accuracy: 0.9680 - val_loss: 0.0027 - val_accuracy: 0.9688\n",
            "Epoch 151/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0024 - accuracy: 0.9774 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 152/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0023 - accuracy: 0.9805 - val_loss: 0.0023 - val_accuracy: 0.9688\n",
            "Epoch 153/160\n",
            "87/87 [==============================] - 0s 446us/step - loss: 0.0021 - accuracy: 0.9821 - val_loss: 0.0023 - val_accuracy: 0.9688\n",
            "Epoch 154/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0024 - accuracy: 0.9692 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 155/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0024 - accuracy: 0.9702 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 156/160\n",
            "87/87 [==============================] - 0s 443us/step - loss: 0.0023 - accuracy: 0.9692 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 157/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0021 - accuracy: 0.9749 - val_loss: 0.0023 - val_accuracy: 0.9583\n",
            "Epoch 158/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0020 - accuracy: 0.9776 - val_loss: 0.0024 - val_accuracy: 0.9792\n",
            "Epoch 159/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0024 - accuracy: 0.9825 - val_loss: 0.0023 - val_accuracy: 0.9688\n",
            "Epoch 160/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0021 - accuracy: 0.9762 - val_loss: 0.0023 - val_accuracy: 0.9583\n",
            "3/3 [==============================] - 0s 527us/step - loss: 0.0023 - accuracy: 0.9583\n",
            "Loss = 0.0022859082091599703, rmse = 0.9583333134651184\n",
            "Loss array:  [0.002609268995001912, 0.0022859082091599703]\n",
            "####################### Iteration   2  #######################\n",
            "Epoch 1/160\n",
            "87/87 [==============================] - 0s 3ms/step - loss: 0.2395 - accuracy: 0.5031 - val_loss: 0.0813 - val_accuracy: 0.8125\n",
            "Epoch 2/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0553 - accuracy: 0.8268 - val_loss: 0.0273 - val_accuracy: 0.8750\n",
            "Epoch 3/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0242 - accuracy: 0.9132 - val_loss: 0.0164 - val_accuracy: 0.9375\n",
            "Epoch 4/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0141 - accuracy: 0.9449 - val_loss: 0.0141 - val_accuracy: 0.9479\n",
            "Epoch 5/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0122 - accuracy: 0.9484 - val_loss: 0.0131 - val_accuracy: 0.9479\n",
            "Epoch 6/160\n",
            "87/87 [==============================] - 0s 385us/step - loss: 0.0127 - accuracy: 0.9543 - val_loss: 0.0118 - val_accuracy: 0.9583\n",
            "Epoch 7/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0099 - accuracy: 0.9566 - val_loss: 0.0111 - val_accuracy: 0.9479\n",
            "Epoch 8/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0096 - accuracy: 0.9670 - val_loss: 0.0101 - val_accuracy: 0.9583\n",
            "Epoch 9/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0101 - accuracy: 0.9638 - val_loss: 0.0095 - val_accuracy: 0.9583\n",
            "Epoch 10/160\n",
            "87/87 [==============================] - 0s 494us/step - loss: 0.0087 - accuracy: 0.9522 - val_loss: 0.0087 - val_accuracy: 0.9583\n",
            "Epoch 11/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0086 - accuracy: 0.9541 - val_loss: 0.0083 - val_accuracy: 0.9688\n",
            "Epoch 12/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0075 - accuracy: 0.9512 - val_loss: 0.0087 - val_accuracy: 0.9479\n",
            "Epoch 13/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0078 - accuracy: 0.9626 - val_loss: 0.0075 - val_accuracy: 0.9896\n",
            "Epoch 14/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0069 - accuracy: 0.9596 - val_loss: 0.0072 - val_accuracy: 0.9896\n",
            "Epoch 15/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0066 - accuracy: 0.9496 - val_loss: 0.0071 - val_accuracy: 0.9792\n",
            "Epoch 16/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0063 - accuracy: 0.9484 - val_loss: 0.0068 - val_accuracy: 0.9896\n",
            "Epoch 17/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0063 - accuracy: 0.9628 - val_loss: 0.0066 - val_accuracy: 0.9792\n",
            "Epoch 18/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0066 - accuracy: 0.9689 - val_loss: 0.0064 - val_accuracy: 0.9792\n",
            "Epoch 19/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0064 - accuracy: 0.9551 - val_loss: 0.0062 - val_accuracy: 0.9896\n",
            "Epoch 20/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0059 - accuracy: 0.9587 - val_loss: 0.0059 - val_accuracy: 0.9896\n",
            "Epoch 21/160\n",
            "87/87 [==============================] - 0s 382us/step - loss: 0.0057 - accuracy: 0.9635 - val_loss: 0.0058 - val_accuracy: 0.9896\n",
            "Epoch 22/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0054 - accuracy: 0.9648 - val_loss: 0.0057 - val_accuracy: 0.9688\n",
            "Epoch 23/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0054 - accuracy: 0.9557 - val_loss: 0.0055 - val_accuracy: 0.9896\n",
            "Epoch 24/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0052 - accuracy: 0.9703 - val_loss: 0.0054 - val_accuracy: 0.9896\n",
            "Epoch 25/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0053 - accuracy: 0.9516 - val_loss: 0.0053 - val_accuracy: 0.9896\n",
            "Epoch 26/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0046 - accuracy: 0.9749 - val_loss: 0.0051 - val_accuracy: 0.9896\n",
            "Epoch 27/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0047 - accuracy: 0.9556 - val_loss: 0.0049 - val_accuracy: 0.9792\n",
            "Epoch 28/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0051 - accuracy: 0.9539 - val_loss: 0.0049 - val_accuracy: 0.9896\n",
            "Epoch 29/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0045 - accuracy: 0.9545 - val_loss: 0.0047 - val_accuracy: 0.9792\n",
            "Epoch 30/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0047 - accuracy: 0.9661 - val_loss: 0.0048 - val_accuracy: 0.9896\n",
            "Epoch 31/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0046 - accuracy: 0.9613 - val_loss: 0.0047 - val_accuracy: 0.9896\n",
            "Epoch 32/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0045 - accuracy: 0.9689 - val_loss: 0.0043 - val_accuracy: 0.9896\n",
            "Epoch 33/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0042 - accuracy: 0.9529 - val_loss: 0.0041 - val_accuracy: 0.9896\n",
            "Epoch 34/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0043 - accuracy: 0.9627 - val_loss: 0.0040 - val_accuracy: 0.9896\n",
            "Epoch 35/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0040 - accuracy: 0.9703 - val_loss: 0.0039 - val_accuracy: 0.9896\n",
            "Epoch 36/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0042 - accuracy: 0.9731 - val_loss: 0.0039 - val_accuracy: 0.9896\n",
            "Epoch 37/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0037 - accuracy: 0.9557 - val_loss: 0.0037 - val_accuracy: 0.9896\n",
            "Epoch 38/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0038 - accuracy: 0.9635 - val_loss: 0.0037 - val_accuracy: 0.9792\n",
            "Epoch 39/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0041 - accuracy: 0.9594 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 40/160\n",
            "87/87 [==============================] - 0s 453us/step - loss: 0.0036 - accuracy: 0.9704 - val_loss: 0.0037 - val_accuracy: 0.9896\n",
            "Epoch 41/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0039 - accuracy: 0.9487 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 42/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0039 - accuracy: 0.9539 - val_loss: 0.0041 - val_accuracy: 0.9896\n",
            "Epoch 43/160\n",
            "87/87 [==============================] - 0s 456us/step - loss: 0.0041 - accuracy: 0.9658 - val_loss: 0.0032 - val_accuracy: 0.9896\n",
            "Epoch 44/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0035 - accuracy: 0.9638 - val_loss: 0.0034 - val_accuracy: 0.9792\n",
            "Epoch 45/160\n",
            "87/87 [==============================] - 0s 523us/step - loss: 0.0032 - accuracy: 0.9723 - val_loss: 0.0031 - val_accuracy: 0.9896\n",
            "Epoch 46/160\n",
            "87/87 [==============================] - 0s 452us/step - loss: 0.0036 - accuracy: 0.9609 - val_loss: 0.0032 - val_accuracy: 0.9896\n",
            "Epoch 47/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0035 - accuracy: 0.9608 - val_loss: 0.0032 - val_accuracy: 0.9792\n",
            "Epoch 48/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0034 - accuracy: 0.9675 - val_loss: 0.0031 - val_accuracy: 0.9792\n",
            "Epoch 49/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0037 - accuracy: 0.9678 - val_loss: 0.0030 - val_accuracy: 0.9792\n",
            "Epoch 50/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0037 - accuracy: 0.9783 - val_loss: 0.0030 - val_accuracy: 0.9792\n",
            "Epoch 51/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0034 - accuracy: 0.9460 - val_loss: 0.0030 - val_accuracy: 0.9792\n",
            "Epoch 52/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0037 - accuracy: 0.9662 - val_loss: 0.0030 - val_accuracy: 0.9792\n",
            "Epoch 53/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0035 - accuracy: 0.9622 - val_loss: 0.0029 - val_accuracy: 0.9792\n",
            "Epoch 54/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0033 - accuracy: 0.9690 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 55/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0030 - accuracy: 0.9671 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 56/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0032 - accuracy: 0.9605 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 57/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0030 - accuracy: 0.9557 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 58/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0031 - accuracy: 0.9632 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 59/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0029 - accuracy: 0.9596 - val_loss: 0.0030 - val_accuracy: 0.9792\n",
            "Epoch 60/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0032 - accuracy: 0.9476 - val_loss: 0.0029 - val_accuracy: 0.9792\n",
            "Epoch 61/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0032 - accuracy: 0.9639 - val_loss: 0.0026 - val_accuracy: 0.9792\n",
            "Epoch 62/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0031 - accuracy: 0.9648 - val_loss: 0.0029 - val_accuracy: 0.9792\n",
            "Epoch 63/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0031 - accuracy: 0.9634 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 64/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0030 - accuracy: 0.9618 - val_loss: 0.0026 - val_accuracy: 0.9792\n",
            "Epoch 65/160\n",
            "87/87 [==============================] - 0s 446us/step - loss: 0.0030 - accuracy: 0.9671 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 66/160\n",
            "87/87 [==============================] - 0s 450us/step - loss: 0.0030 - accuracy: 0.9673 - val_loss: 0.0026 - val_accuracy: 0.9792\n",
            "Epoch 67/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0029 - accuracy: 0.9653 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 68/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0029 - accuracy: 0.9683 - val_loss: 0.0027 - val_accuracy: 0.9896\n",
            "Epoch 69/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0027 - accuracy: 0.9643 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 70/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0027 - accuracy: 0.9714 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 71/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0030 - accuracy: 0.9709 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 72/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0030 - accuracy: 0.9669 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 73/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0033 - accuracy: 0.9581 - val_loss: 0.0024 - val_accuracy: 0.9792\n",
            "Epoch 74/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0029 - accuracy: 0.9564 - val_loss: 0.0024 - val_accuracy: 0.9792\n",
            "Epoch 75/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0025 - accuracy: 0.9663 - val_loss: 0.0024 - val_accuracy: 0.9792\n",
            "Epoch 76/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0028 - accuracy: 0.9680 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 77/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0030 - accuracy: 0.9724 - val_loss: 0.0024 - val_accuracy: 0.9792\n",
            "Epoch 78/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0029 - accuracy: 0.9669 - val_loss: 0.0024 - val_accuracy: 0.9688\n",
            "Epoch 79/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0029 - accuracy: 0.9687 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 80/160\n",
            "87/87 [==============================] - 0s 471us/step - loss: 0.0027 - accuracy: 0.9685 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 81/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0029 - accuracy: 0.9714 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 82/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0025 - accuracy: 0.9716 - val_loss: 0.0026 - val_accuracy: 0.9792\n",
            "Epoch 83/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0027 - accuracy: 0.9787 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 84/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0026 - accuracy: 0.9760 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 85/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0029 - accuracy: 0.9689 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 86/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0024 - accuracy: 0.9821 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 87/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0023 - accuracy: 0.9835 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 88/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0027 - accuracy: 0.9612 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 89/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0027 - accuracy: 0.9748 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 90/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0026 - accuracy: 0.9686 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 91/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0026 - accuracy: 0.9649 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 92/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0027 - accuracy: 0.9680 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 93/160\n",
            "87/87 [==============================] - 0s 479us/step - loss: 0.0026 - accuracy: 0.9725 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 94/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0026 - accuracy: 0.9783 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 95/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0022 - accuracy: 0.9747 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 96/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0023 - accuracy: 0.9735 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 97/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0024 - accuracy: 0.9634 - val_loss: 0.0020 - val_accuracy: 0.9792\n",
            "Epoch 98/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0024 - accuracy: 0.9789 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 99/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0021 - accuracy: 0.9761 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 100/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0027 - accuracy: 0.9749 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 101/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0023 - accuracy: 0.9738 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 102/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0022 - accuracy: 0.9628 - val_loss: 0.0020 - val_accuracy: 0.9792\n",
            "Epoch 103/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0024 - accuracy: 0.9774 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 104/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0026 - accuracy: 0.9653 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 105/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0021 - accuracy: 0.9771 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 106/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0024 - accuracy: 0.9615 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 107/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0021 - accuracy: 0.9751 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 108/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0023 - accuracy: 0.9712 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 109/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0023 - accuracy: 0.9640 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 110/160\n",
            "87/87 [==============================] - 0s 446us/step - loss: 0.0023 - accuracy: 0.9730 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 111/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0023 - accuracy: 0.9803 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 112/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0020 - accuracy: 0.9761 - val_loss: 0.0026 - val_accuracy: 0.9792\n",
            "Epoch 113/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0025 - accuracy: 0.9711 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 114/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0023 - accuracy: 0.9794 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 115/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0025 - accuracy: 0.9673 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 116/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0023 - accuracy: 0.9741 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 117/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0025 - accuracy: 0.9682 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 118/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0021 - accuracy: 0.9686 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 119/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0021 - accuracy: 0.9760 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 120/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0022 - accuracy: 0.9788 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 121/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0023 - accuracy: 0.9694 - val_loss: 0.0020 - val_accuracy: 0.9792\n",
            "Epoch 122/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0025 - accuracy: 0.9674 - val_loss: 0.0023 - val_accuracy: 0.9688\n",
            "Epoch 123/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0023 - accuracy: 0.9714 - val_loss: 0.0025 - val_accuracy: 0.9583\n",
            "Epoch 124/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0025 - accuracy: 0.9720 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 125/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0020 - accuracy: 0.9668 - val_loss: 0.0020 - val_accuracy: 0.9792\n",
            "Epoch 126/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0022 - accuracy: 0.9719 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 127/160\n",
            "87/87 [==============================] - 0s 447us/step - loss: 0.0024 - accuracy: 0.9696 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 128/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0021 - accuracy: 0.9784 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 129/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0026 - accuracy: 0.9681 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 130/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0023 - accuracy: 0.9636 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 131/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0020 - accuracy: 0.9730 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 132/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0021 - accuracy: 0.9681 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 133/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0024 - accuracy: 0.9801 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 134/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0018 - accuracy: 0.9761 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 135/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0022 - accuracy: 0.9655 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 136/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0024 - accuracy: 0.9724 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 137/160\n",
            "87/87 [==============================] - 0s 499us/step - loss: 0.0018 - accuracy: 0.9712 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 138/160\n",
            "87/87 [==============================] - 0s 447us/step - loss: 0.0024 - accuracy: 0.9673 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 139/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0020 - accuracy: 0.9745 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 140/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0025 - accuracy: 0.9762 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 141/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0023 - accuracy: 0.9766 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 142/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0024 - accuracy: 0.9750 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 143/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0023 - accuracy: 0.9812 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 144/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0022 - accuracy: 0.9734 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 145/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0025 - accuracy: 0.9638 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 146/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0022 - accuracy: 0.9677 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 147/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0023 - accuracy: 0.9758 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 148/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0020 - accuracy: 0.9686 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 149/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0023 - accuracy: 0.9780 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 150/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0022 - accuracy: 0.9729 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 151/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0022 - accuracy: 0.9758 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 152/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0021 - accuracy: 0.9699 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 153/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0020 - accuracy: 0.9690 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 154/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0021 - accuracy: 0.9724 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 155/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0023 - accuracy: 0.9738 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 156/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0020 - accuracy: 0.9613 - val_loss: 0.0019 - val_accuracy: 0.9792\n",
            "Epoch 157/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0020 - accuracy: 0.9719 - val_loss: 0.0018 - val_accuracy: 0.9688\n",
            "Epoch 158/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0018 - accuracy: 0.9818 - val_loss: 0.0020 - val_accuracy: 0.9688\n",
            "Epoch 159/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0022 - accuracy: 0.9764 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 160/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0020 - accuracy: 0.9728 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "3/3 [==============================] - 0s 659us/step - loss: 0.0019 - accuracy: 0.9688\n",
            "Loss = 0.0018555676797404885, rmse = 0.96875\n",
            "Loss array:  [0.002609268995001912, 0.0022859082091599703, 0.0018555676797404885]\n",
            "####################### Iteration   3  #######################\n",
            "Epoch 1/160\n",
            "87/87 [==============================] - 0s 818us/step - loss: 0.3938 - accuracy: 0.3814 - val_loss: 0.2556 - val_accuracy: 0.5521\n",
            "Epoch 2/160\n",
            "87/87 [==============================] - 0s 465us/step - loss: 0.2247 - accuracy: 0.6039 - val_loss: 0.0951 - val_accuracy: 0.8125\n",
            "Epoch 3/160\n",
            "87/87 [==============================] - 0s 446us/step - loss: 0.0785 - accuracy: 0.8718 - val_loss: 0.0323 - val_accuracy: 0.8333\n",
            "Epoch 4/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0325 - accuracy: 0.8601 - val_loss: 0.0216 - val_accuracy: 0.8750\n",
            "Epoch 5/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0222 - accuracy: 0.8747 - val_loss: 0.0167 - val_accuracy: 0.9271\n",
            "Epoch 6/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0194 - accuracy: 0.9277 - val_loss: 0.0145 - val_accuracy: 0.9271\n",
            "Epoch 7/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0155 - accuracy: 0.9352 - val_loss: 0.0131 - val_accuracy: 0.9688\n",
            "Epoch 8/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0157 - accuracy: 0.9550 - val_loss: 0.0119 - val_accuracy: 0.9792\n",
            "Epoch 9/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0156 - accuracy: 0.9473 - val_loss: 0.0108 - val_accuracy: 0.9896\n",
            "Epoch 10/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0125 - accuracy: 0.9468 - val_loss: 0.0098 - val_accuracy: 0.9896\n",
            "Epoch 11/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0125 - accuracy: 0.9474 - val_loss: 0.0089 - val_accuracy: 0.9896\n",
            "Epoch 12/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0109 - accuracy: 0.9371 - val_loss: 0.0086 - val_accuracy: 0.9792\n",
            "Epoch 13/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0105 - accuracy: 0.9529 - val_loss: 0.0079 - val_accuracy: 0.9792\n",
            "Epoch 14/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0100 - accuracy: 0.9472 - val_loss: 0.0075 - val_accuracy: 0.9792\n",
            "Epoch 15/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0091 - accuracy: 0.9372 - val_loss: 0.0072 - val_accuracy: 0.9792\n",
            "Epoch 16/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0089 - accuracy: 0.9485 - val_loss: 0.0070 - val_accuracy: 0.9792\n",
            "Epoch 17/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0089 - accuracy: 0.9629 - val_loss: 0.0065 - val_accuracy: 0.9792\n",
            "Epoch 18/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0091 - accuracy: 0.9590 - val_loss: 0.0064 - val_accuracy: 0.9792\n",
            "Epoch 19/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0086 - accuracy: 0.9355 - val_loss: 0.0063 - val_accuracy: 0.9792\n",
            "Epoch 20/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0082 - accuracy: 0.9476 - val_loss: 0.0065 - val_accuracy: 0.9896\n",
            "Epoch 21/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0076 - accuracy: 0.9580 - val_loss: 0.0060 - val_accuracy: 0.9792\n",
            "Epoch 22/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0076 - accuracy: 0.9387 - val_loss: 0.0059 - val_accuracy: 0.9688\n",
            "Epoch 23/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0077 - accuracy: 0.9472 - val_loss: 0.0058 - val_accuracy: 0.9688\n",
            "Epoch 24/160\n",
            "87/87 [==============================] - 0s 455us/step - loss: 0.0074 - accuracy: 0.9657 - val_loss: 0.0057 - val_accuracy: 0.9688\n",
            "Epoch 25/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0073 - accuracy: 0.9523 - val_loss: 0.0056 - val_accuracy: 0.9688\n",
            "Epoch 26/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0068 - accuracy: 0.9656 - val_loss: 0.0055 - val_accuracy: 0.9688\n",
            "Epoch 27/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0065 - accuracy: 0.9495 - val_loss: 0.0055 - val_accuracy: 0.9688\n",
            "Epoch 28/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0069 - accuracy: 0.9484 - val_loss: 0.0059 - val_accuracy: 0.9896\n",
            "Epoch 29/160\n",
            "87/87 [==============================] - 0s 448us/step - loss: 0.0071 - accuracy: 0.9428 - val_loss: 0.0053 - val_accuracy: 0.9688\n",
            "Epoch 30/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0065 - accuracy: 0.9637 - val_loss: 0.0054 - val_accuracy: 0.9792\n",
            "Epoch 31/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0062 - accuracy: 0.9616 - val_loss: 0.0053 - val_accuracy: 0.9792\n",
            "Epoch 32/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0064 - accuracy: 0.9600 - val_loss: 0.0050 - val_accuracy: 0.9688\n",
            "Epoch 33/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0064 - accuracy: 0.9521 - val_loss: 0.0049 - val_accuracy: 0.9688\n",
            "Epoch 34/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0063 - accuracy: 0.9563 - val_loss: 0.0049 - val_accuracy: 0.9688\n",
            "Epoch 35/160\n",
            "87/87 [==============================] - 0s 446us/step - loss: 0.0058 - accuracy: 0.9717 - val_loss: 0.0048 - val_accuracy: 0.9688\n",
            "Epoch 36/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0058 - accuracy: 0.9642 - val_loss: 0.0049 - val_accuracy: 0.9792\n",
            "Epoch 37/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0057 - accuracy: 0.9568 - val_loss: 0.0046 - val_accuracy: 0.9688\n",
            "Epoch 38/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0056 - accuracy: 0.9673 - val_loss: 0.0046 - val_accuracy: 0.9688\n",
            "Epoch 39/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0058 - accuracy: 0.9587 - val_loss: 0.0045 - val_accuracy: 0.9688\n",
            "Epoch 40/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0052 - accuracy: 0.9628 - val_loss: 0.0046 - val_accuracy: 0.9792\n",
            "Epoch 41/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0055 - accuracy: 0.9409 - val_loss: 0.0043 - val_accuracy: 0.9688\n",
            "Epoch 42/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0055 - accuracy: 0.9586 - val_loss: 0.0046 - val_accuracy: 0.9792\n",
            "Epoch 43/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0056 - accuracy: 0.9565 - val_loss: 0.0042 - val_accuracy: 0.9688\n",
            "Epoch 44/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0051 - accuracy: 0.9649 - val_loss: 0.0042 - val_accuracy: 0.9688\n",
            "Epoch 45/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0045 - accuracy: 0.9653 - val_loss: 0.0041 - val_accuracy: 0.9688\n",
            "Epoch 46/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0049 - accuracy: 0.9633 - val_loss: 0.0043 - val_accuracy: 0.9792\n",
            "Epoch 47/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0051 - accuracy: 0.9658 - val_loss: 0.0040 - val_accuracy: 0.9688\n",
            "Epoch 48/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0045 - accuracy: 0.9713 - val_loss: 0.0039 - val_accuracy: 0.9688\n",
            "Epoch 49/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0050 - accuracy: 0.9612 - val_loss: 0.0038 - val_accuracy: 0.9688\n",
            "Epoch 50/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0050 - accuracy: 0.9759 - val_loss: 0.0038 - val_accuracy: 0.9792\n",
            "Epoch 51/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0046 - accuracy: 0.9572 - val_loss: 0.0038 - val_accuracy: 0.9792\n",
            "Epoch 52/160\n",
            "87/87 [==============================] - 0s 452us/step - loss: 0.0047 - accuracy: 0.9640 - val_loss: 0.0037 - val_accuracy: 0.9688\n",
            "Epoch 53/160\n",
            "87/87 [==============================] - 0s 443us/step - loss: 0.0046 - accuracy: 0.9637 - val_loss: 0.0036 - val_accuracy: 0.9688\n",
            "Epoch 54/160\n",
            "87/87 [==============================] - 0s 458us/step - loss: 0.0043 - accuracy: 0.9714 - val_loss: 0.0037 - val_accuracy: 0.9792\n",
            "Epoch 55/160\n",
            "87/87 [==============================] - 0s 449us/step - loss: 0.0044 - accuracy: 0.9683 - val_loss: 0.0036 - val_accuracy: 0.9583\n",
            "Epoch 56/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0043 - accuracy: 0.9633 - val_loss: 0.0035 - val_accuracy: 0.9583\n",
            "Epoch 57/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0042 - accuracy: 0.9630 - val_loss: 0.0035 - val_accuracy: 0.9688\n",
            "Epoch 58/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0040 - accuracy: 0.9682 - val_loss: 0.0035 - val_accuracy: 0.9479\n",
            "Epoch 59/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0037 - accuracy: 0.9692 - val_loss: 0.0035 - val_accuracy: 0.9479\n",
            "Epoch 60/160\n",
            "87/87 [==============================] - 0s 388us/step - loss: 0.0041 - accuracy: 0.9441 - val_loss: 0.0034 - val_accuracy: 0.9688\n",
            "Epoch 61/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0042 - accuracy: 0.9668 - val_loss: 0.0033 - val_accuracy: 0.9792\n",
            "Epoch 62/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0040 - accuracy: 0.9730 - val_loss: 0.0033 - val_accuracy: 0.9583\n",
            "Epoch 63/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0039 - accuracy: 0.9687 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 64/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0039 - accuracy: 0.9738 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 65/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0038 - accuracy: 0.9664 - val_loss: 0.0032 - val_accuracy: 0.9583\n",
            "Epoch 66/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0038 - accuracy: 0.9688 - val_loss: 0.0033 - val_accuracy: 0.9792\n",
            "Epoch 67/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0038 - accuracy: 0.9719 - val_loss: 0.0031 - val_accuracy: 0.9792\n",
            "Epoch 68/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0037 - accuracy: 0.9715 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 69/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0035 - accuracy: 0.9655 - val_loss: 0.0031 - val_accuracy: 0.9688\n",
            "Epoch 70/160\n",
            "87/87 [==============================] - 0s 382us/step - loss: 0.0033 - accuracy: 0.9827 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 71/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0038 - accuracy: 0.9734 - val_loss: 0.0034 - val_accuracy: 0.9792\n",
            "Epoch 72/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0041 - accuracy: 0.9476 - val_loss: 0.0031 - val_accuracy: 0.9792\n",
            "Epoch 73/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0040 - accuracy: 0.9690 - val_loss: 0.0030 - val_accuracy: 0.9688\n",
            "Epoch 74/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0037 - accuracy: 0.9578 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 75/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0033 - accuracy: 0.9628 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 76/160\n",
            "87/87 [==============================] - 0s 499us/step - loss: 0.0038 - accuracy: 0.9669 - val_loss: 0.0030 - val_accuracy: 0.9479\n",
            "Epoch 77/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0038 - accuracy: 0.9701 - val_loss: 0.0028 - val_accuracy: 0.9583\n",
            "Epoch 78/160\n",
            "87/87 [==============================] - 0s 386us/step - loss: 0.0036 - accuracy: 0.9678 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 79/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0037 - accuracy: 0.9711 - val_loss: 0.0027 - val_accuracy: 0.9688\n",
            "Epoch 80/160\n",
            "87/87 [==============================] - 0s 385us/step - loss: 0.0035 - accuracy: 0.9709 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 81/160\n",
            "87/87 [==============================] - 0s 382us/step - loss: 0.0036 - accuracy: 0.9682 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 82/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0033 - accuracy: 0.9711 - val_loss: 0.0031 - val_accuracy: 0.9479\n",
            "Epoch 83/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0036 - accuracy: 0.9684 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 84/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0034 - accuracy: 0.9768 - val_loss: 0.0028 - val_accuracy: 0.9896\n",
            "Epoch 85/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0037 - accuracy: 0.9716 - val_loss: 0.0027 - val_accuracy: 0.9688\n",
            "Epoch 86/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0029 - accuracy: 0.9780 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 87/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0029 - accuracy: 0.9839 - val_loss: 0.0026 - val_accuracy: 0.9688\n",
            "Epoch 88/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0033 - accuracy: 0.9623 - val_loss: 0.0026 - val_accuracy: 0.9688\n",
            "Epoch 89/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0034 - accuracy: 0.9724 - val_loss: 0.0026 - val_accuracy: 0.9688\n",
            "Epoch 90/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0033 - accuracy: 0.9749 - val_loss: 0.0025 - val_accuracy: 0.9688\n",
            "Epoch 91/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0030 - accuracy: 0.9741 - val_loss: 0.0025 - val_accuracy: 0.9688\n",
            "Epoch 92/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0032 - accuracy: 0.9686 - val_loss: 0.0025 - val_accuracy: 0.9688\n",
            "Epoch 93/160\n",
            "87/87 [==============================] - 0s 387us/step - loss: 0.0034 - accuracy: 0.9728 - val_loss: 0.0026 - val_accuracy: 0.9792\n",
            "Epoch 94/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0031 - accuracy: 0.9806 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 95/160\n",
            "87/87 [==============================] - 0s 449us/step - loss: 0.0028 - accuracy: 0.9826 - val_loss: 0.0025 - val_accuracy: 0.9688\n",
            "Epoch 96/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0033 - accuracy: 0.9691 - val_loss: 0.0026 - val_accuracy: 0.9583\n",
            "Epoch 97/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0028 - accuracy: 0.9679 - val_loss: 0.0024 - val_accuracy: 0.9792\n",
            "Epoch 98/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0031 - accuracy: 0.9788 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 99/160\n",
            "87/87 [==============================] - 0s 460us/step - loss: 0.0030 - accuracy: 0.9761 - val_loss: 0.0024 - val_accuracy: 0.9792\n",
            "Epoch 100/160\n",
            "87/87 [==============================] - 0s 446us/step - loss: 0.0033 - accuracy: 0.9792 - val_loss: 0.0024 - val_accuracy: 0.9792\n",
            "Epoch 101/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0027 - accuracy: 0.9780 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 102/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0029 - accuracy: 0.9670 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 103/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0032 - accuracy: 0.9780 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 104/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0032 - accuracy: 0.9732 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 105/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0028 - accuracy: 0.9761 - val_loss: 0.0024 - val_accuracy: 0.9792\n",
            "Epoch 106/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0031 - accuracy: 0.9566 - val_loss: 0.0023 - val_accuracy: 0.9688\n",
            "Epoch 107/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0028 - accuracy: 0.9759 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 108/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0030 - accuracy: 0.9677 - val_loss: 0.0023 - val_accuracy: 0.9688\n",
            "Epoch 109/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0029 - accuracy: 0.9655 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 110/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0028 - accuracy: 0.9761 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 111/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0029 - accuracy: 0.9806 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 112/160\n",
            "87/87 [==============================] - 0s 444us/step - loss: 0.0026 - accuracy: 0.9783 - val_loss: 0.0024 - val_accuracy: 0.9792\n",
            "Epoch 113/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0033 - accuracy: 0.9667 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 114/160\n",
            "87/87 [==============================] - 0s 379us/step - loss: 0.0028 - accuracy: 0.9848 - val_loss: 0.0024 - val_accuracy: 0.9583\n",
            "Epoch 115/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0031 - accuracy: 0.9709 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 116/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0030 - accuracy: 0.9752 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 117/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0030 - accuracy: 0.9680 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 118/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0028 - accuracy: 0.9723 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 119/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0026 - accuracy: 0.9678 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 120/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0029 - accuracy: 0.9793 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 121/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0029 - accuracy: 0.9700 - val_loss: 0.0023 - val_accuracy: 0.9688\n",
            "Epoch 122/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0031 - accuracy: 0.9686 - val_loss: 0.0023 - val_accuracy: 0.9688\n",
            "Epoch 123/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0028 - accuracy: 0.9717 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 124/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0030 - accuracy: 0.9720 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 125/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0026 - accuracy: 0.9729 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 126/160\n",
            "87/87 [==============================] - 0s 468us/step - loss: 0.0028 - accuracy: 0.9725 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 127/160\n",
            "87/87 [==============================] - 0s 453us/step - loss: 0.0030 - accuracy: 0.9730 - val_loss: 0.0022 - val_accuracy: 0.9583\n",
            "Epoch 128/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0026 - accuracy: 0.9753 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 129/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0030 - accuracy: 0.9698 - val_loss: 0.0022 - val_accuracy: 0.9583\n",
            "Epoch 130/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0027 - accuracy: 0.9710 - val_loss: 0.0022 - val_accuracy: 0.9583\n",
            "Epoch 131/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0025 - accuracy: 0.9728 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 132/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0026 - accuracy: 0.9722 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 133/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0028 - accuracy: 0.9842 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 134/160\n",
            "87/87 [==============================] - 0s 440us/step - loss: 0.0024 - accuracy: 0.9735 - val_loss: 0.0023 - val_accuracy: 0.9792\n",
            "Epoch 135/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0025 - accuracy: 0.9700 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 136/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0030 - accuracy: 0.9731 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 137/160\n",
            "87/87 [==============================] - 0s 454us/step - loss: 0.0025 - accuracy: 0.9764 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 138/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0030 - accuracy: 0.9627 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 139/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0025 - accuracy: 0.9706 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 140/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0029 - accuracy: 0.9721 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 141/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0027 - accuracy: 0.9797 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 142/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0029 - accuracy: 0.9773 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 143/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0028 - accuracy: 0.9852 - val_loss: 0.0025 - val_accuracy: 0.9375\n",
            "Epoch 144/160\n",
            "87/87 [==============================] - 0s 489us/step - loss: 0.0026 - accuracy: 0.9815 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 145/160\n",
            "87/87 [==============================] - 0s 440us/step - loss: 0.0030 - accuracy: 0.9643 - val_loss: 0.0022 - val_accuracy: 0.9688\n",
            "Epoch 146/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0027 - accuracy: 0.9698 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 147/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0030 - accuracy: 0.9813 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 148/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0024 - accuracy: 0.9764 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 149/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0028 - accuracy: 0.9786 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 150/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0030 - accuracy: 0.9722 - val_loss: 0.0025 - val_accuracy: 0.9792\n",
            "Epoch 151/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0027 - accuracy: 0.9672 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 152/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0026 - accuracy: 0.9697 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 153/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0026 - accuracy: 0.9763 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 154/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0028 - accuracy: 0.9635 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 155/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0028 - accuracy: 0.9673 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 156/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0027 - accuracy: 0.9638 - val_loss: 0.0022 - val_accuracy: 0.9792\n",
            "Epoch 157/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0025 - accuracy: 0.9733 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 158/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0024 - accuracy: 0.9757 - val_loss: 0.0021 - val_accuracy: 0.9792\n",
            "Epoch 159/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0028 - accuracy: 0.9811 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "Epoch 160/160\n",
            "87/87 [==============================] - 0s 447us/step - loss: 0.0026 - accuracy: 0.9677 - val_loss: 0.0021 - val_accuracy: 0.9688\n",
            "3/3 [==============================] - 0s 600us/step - loss: 0.0021 - accuracy: 0.9688\n",
            "Loss = 0.002085859654471278, rmse = 0.96875\n",
            "Loss array:  [0.002609268995001912, 0.0022859082091599703, 0.0018555676797404885, 0.002085859654471278]\n",
            "####################### Iteration   4  #######################\n",
            "Epoch 1/160\n",
            "87/87 [==============================] - 0s 823us/step - loss: 0.1344 - accuracy: 0.6237 - val_loss: 0.0592 - val_accuracy: 0.5833\n",
            "Epoch 2/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0465 - accuracy: 0.6208 - val_loss: 0.0362 - val_accuracy: 0.7604\n",
            "Epoch 3/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0296 - accuracy: 0.8476 - val_loss: 0.0229 - val_accuracy: 0.8958\n",
            "Epoch 4/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0166 - accuracy: 0.9013 - val_loss: 0.0174 - val_accuracy: 0.9271\n",
            "Epoch 5/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0132 - accuracy: 0.9102 - val_loss: 0.0148 - val_accuracy: 0.9583\n",
            "Epoch 6/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0131 - accuracy: 0.9389 - val_loss: 0.0139 - val_accuracy: 0.9583\n",
            "Epoch 7/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0113 - accuracy: 0.9485 - val_loss: 0.0127 - val_accuracy: 0.9583\n",
            "Epoch 8/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0109 - accuracy: 0.9661 - val_loss: 0.0120 - val_accuracy: 0.9583\n",
            "Epoch 9/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0111 - accuracy: 0.9606 - val_loss: 0.0112 - val_accuracy: 0.9583\n",
            "Epoch 10/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0092 - accuracy: 0.9429 - val_loss: 0.0110 - val_accuracy: 0.9583\n",
            "Epoch 11/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0098 - accuracy: 0.9492 - val_loss: 0.0108 - val_accuracy: 0.9583\n",
            "Epoch 12/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0086 - accuracy: 0.9447 - val_loss: 0.0095 - val_accuracy: 0.9688\n",
            "Epoch 13/160\n",
            "87/87 [==============================] - 0s 388us/step - loss: 0.0089 - accuracy: 0.9631 - val_loss: 0.0094 - val_accuracy: 0.9688\n",
            "Epoch 14/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0084 - accuracy: 0.9488 - val_loss: 0.0088 - val_accuracy: 0.9688\n",
            "Epoch 15/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0076 - accuracy: 0.9455 - val_loss: 0.0085 - val_accuracy: 0.9688\n",
            "Epoch 16/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0077 - accuracy: 0.9506 - val_loss: 0.0082 - val_accuracy: 0.9688\n",
            "Epoch 17/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0071 - accuracy: 0.9666 - val_loss: 0.0083 - val_accuracy: 0.9688\n",
            "Epoch 18/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0075 - accuracy: 0.9624 - val_loss: 0.0086 - val_accuracy: 0.9688\n",
            "Epoch 19/160\n",
            "87/87 [==============================] - 0s 462us/step - loss: 0.0072 - accuracy: 0.9405 - val_loss: 0.0078 - val_accuracy: 0.9792\n",
            "Epoch 20/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0069 - accuracy: 0.9519 - val_loss: 0.0074 - val_accuracy: 0.9688\n",
            "Epoch 21/160\n",
            "87/87 [==============================] - 0s 387us/step - loss: 0.0063 - accuracy: 0.9607 - val_loss: 0.0075 - val_accuracy: 0.9688\n",
            "Epoch 22/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0063 - accuracy: 0.9586 - val_loss: 0.0071 - val_accuracy: 0.9792\n",
            "Epoch 23/160\n",
            "87/87 [==============================] - 0s 386us/step - loss: 0.0062 - accuracy: 0.9552 - val_loss: 0.0072 - val_accuracy: 0.9792\n",
            "Epoch 24/160\n",
            "87/87 [==============================] - 0s 457us/step - loss: 0.0058 - accuracy: 0.9679 - val_loss: 0.0064 - val_accuracy: 0.9688\n",
            "Epoch 25/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0055 - accuracy: 0.9574 - val_loss: 0.0066 - val_accuracy: 0.9792\n",
            "Epoch 26/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0053 - accuracy: 0.9719 - val_loss: 0.0068 - val_accuracy: 0.9792\n",
            "Epoch 27/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0051 - accuracy: 0.9572 - val_loss: 0.0067 - val_accuracy: 0.9792\n",
            "Epoch 28/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0055 - accuracy: 0.9564 - val_loss: 0.0061 - val_accuracy: 0.9792\n",
            "Epoch 29/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0052 - accuracy: 0.9524 - val_loss: 0.0061 - val_accuracy: 0.9792\n",
            "Epoch 30/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0051 - accuracy: 0.9739 - val_loss: 0.0061 - val_accuracy: 0.9792\n",
            "Epoch 31/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0049 - accuracy: 0.9681 - val_loss: 0.0059 - val_accuracy: 0.9792\n",
            "Epoch 32/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0047 - accuracy: 0.9629 - val_loss: 0.0063 - val_accuracy: 0.9792\n",
            "Epoch 33/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0045 - accuracy: 0.9648 - val_loss: 0.0060 - val_accuracy: 0.9792\n",
            "Epoch 34/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0047 - accuracy: 0.9746 - val_loss: 0.0058 - val_accuracy: 0.9792\n",
            "Epoch 35/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0042 - accuracy: 0.9719 - val_loss: 0.0060 - val_accuracy: 0.9792\n",
            "Epoch 36/160\n",
            "87/87 [==============================] - 0s 384us/step - loss: 0.0044 - accuracy: 0.9734 - val_loss: 0.0057 - val_accuracy: 0.9792\n",
            "Epoch 37/160\n",
            "87/87 [==============================] - 0s 454us/step - loss: 0.0040 - accuracy: 0.9596 - val_loss: 0.0064 - val_accuracy: 0.9583\n",
            "Epoch 38/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0040 - accuracy: 0.9671 - val_loss: 0.0057 - val_accuracy: 0.9792\n",
            "Epoch 39/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0042 - accuracy: 0.9677 - val_loss: 0.0056 - val_accuracy: 0.9792\n",
            "Epoch 40/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0038 - accuracy: 0.9735 - val_loss: 0.0060 - val_accuracy: 0.9792\n",
            "Epoch 41/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0039 - accuracy: 0.9527 - val_loss: 0.0057 - val_accuracy: 0.9792\n",
            "Epoch 42/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0042 - accuracy: 0.9641 - val_loss: 0.0057 - val_accuracy: 0.9792\n",
            "Epoch 43/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0041 - accuracy: 0.9669 - val_loss: 0.0057 - val_accuracy: 0.9688\n",
            "Epoch 44/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0038 - accuracy: 0.9690 - val_loss: 0.0056 - val_accuracy: 0.9792\n",
            "Epoch 45/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0035 - accuracy: 0.9668 - val_loss: 0.0062 - val_accuracy: 0.9583\n",
            "Epoch 46/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0037 - accuracy: 0.9726 - val_loss: 0.0056 - val_accuracy: 0.9792\n",
            "Epoch 47/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0036 - accuracy: 0.9616 - val_loss: 0.0063 - val_accuracy: 0.9583\n",
            "Epoch 48/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0033 - accuracy: 0.9762 - val_loss: 0.0058 - val_accuracy: 0.9792\n",
            "Epoch 49/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0034 - accuracy: 0.9701 - val_loss: 0.0056 - val_accuracy: 0.9792\n",
            "Epoch 50/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0037 - accuracy: 0.9810 - val_loss: 0.0057 - val_accuracy: 0.9792\n",
            "Epoch 51/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0034 - accuracy: 0.9551 - val_loss: 0.0057 - val_accuracy: 0.9792\n",
            "Epoch 52/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0035 - accuracy: 0.9688 - val_loss: 0.0059 - val_accuracy: 0.9792\n",
            "Epoch 53/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0036 - accuracy: 0.9620 - val_loss: 0.0059 - val_accuracy: 0.9792\n",
            "Epoch 54/160\n",
            "87/87 [==============================] - 0s 452us/step - loss: 0.0033 - accuracy: 0.9668 - val_loss: 0.0053 - val_accuracy: 0.9792\n",
            "Epoch 55/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0033 - accuracy: 0.9722 - val_loss: 0.0052 - val_accuracy: 0.9792\n",
            "Epoch 56/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0034 - accuracy: 0.9633 - val_loss: 0.0060 - val_accuracy: 0.9688\n",
            "Epoch 57/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0030 - accuracy: 0.9632 - val_loss: 0.0054 - val_accuracy: 0.9792\n",
            "Epoch 58/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0032 - accuracy: 0.9772 - val_loss: 0.0059 - val_accuracy: 0.9688\n",
            "Epoch 59/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0030 - accuracy: 0.9643 - val_loss: 0.0058 - val_accuracy: 0.9792\n",
            "Epoch 60/160\n",
            "87/87 [==============================] - 0s 439us/step - loss: 0.0032 - accuracy: 0.9505 - val_loss: 0.0058 - val_accuracy: 0.9792\n",
            "Epoch 61/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0032 - accuracy: 0.9629 - val_loss: 0.0053 - val_accuracy: 0.9792\n",
            "Epoch 62/160\n",
            "87/87 [==============================] - 0s 463us/step - loss: 0.0033 - accuracy: 0.9735 - val_loss: 0.0059 - val_accuracy: 0.9792\n",
            "Epoch 63/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0030 - accuracy: 0.9586 - val_loss: 0.0051 - val_accuracy: 0.9792\n",
            "Epoch 64/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0030 - accuracy: 0.9576 - val_loss: 0.0060 - val_accuracy: 0.9792\n",
            "Epoch 65/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0030 - accuracy: 0.9690 - val_loss: 0.0054 - val_accuracy: 0.9792\n",
            "Epoch 66/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0030 - accuracy: 0.9691 - val_loss: 0.0052 - val_accuracy: 0.9792\n",
            "Epoch 67/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0028 - accuracy: 0.9630 - val_loss: 0.0051 - val_accuracy: 0.9792\n",
            "Epoch 68/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0029 - accuracy: 0.9692 - val_loss: 0.0052 - val_accuracy: 0.9792\n",
            "Epoch 69/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0029 - accuracy: 0.9688 - val_loss: 0.0058 - val_accuracy: 0.9792\n",
            "Epoch 70/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0028 - accuracy: 0.9713 - val_loss: 0.0052 - val_accuracy: 0.9792\n",
            "Epoch 71/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0031 - accuracy: 0.9711 - val_loss: 0.0053 - val_accuracy: 0.9792\n",
            "Epoch 72/160\n",
            "87/87 [==============================] - 0s 496us/step - loss: 0.0034 - accuracy: 0.9643 - val_loss: 0.0058 - val_accuracy: 0.9792\n",
            "Epoch 73/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0029 - accuracy: 0.9675 - val_loss: 0.0053 - val_accuracy: 0.9792\n",
            "Epoch 74/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0031 - accuracy: 0.9688 - val_loss: 0.0058 - val_accuracy: 0.9792\n",
            "Epoch 75/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0025 - accuracy: 0.9686 - val_loss: 0.0056 - val_accuracy: 0.9792\n",
            "Epoch 76/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0031 - accuracy: 0.9767 - val_loss: 0.0067 - val_accuracy: 0.9271\n",
            "Epoch 77/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0031 - accuracy: 0.9714 - val_loss: 0.0056 - val_accuracy: 0.9583\n",
            "Epoch 78/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0029 - accuracy: 0.9722 - val_loss: 0.0054 - val_accuracy: 0.9792\n",
            "Epoch 79/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0027 - accuracy: 0.9689 - val_loss: 0.0051 - val_accuracy: 0.9792\n",
            "Epoch 80/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0028 - accuracy: 0.9763 - val_loss: 0.0060 - val_accuracy: 0.9479\n",
            "Epoch 81/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0028 - accuracy: 0.9774 - val_loss: 0.0055 - val_accuracy: 0.9792\n",
            "Epoch 82/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0025 - accuracy: 0.9702 - val_loss: 0.0067 - val_accuracy: 0.9375\n",
            "Epoch 83/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0029 - accuracy: 0.9734 - val_loss: 0.0052 - val_accuracy: 0.9792\n",
            "Epoch 84/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0026 - accuracy: 0.9768 - val_loss: 0.0053 - val_accuracy: 0.9792\n",
            "Epoch 85/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0029 - accuracy: 0.9724 - val_loss: 0.0053 - val_accuracy: 0.9792\n",
            "Epoch 86/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0023 - accuracy: 0.9721 - val_loss: 0.0051 - val_accuracy: 0.9792\n",
            "Epoch 87/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0024 - accuracy: 0.9747 - val_loss: 0.0054 - val_accuracy: 0.9792\n",
            "Epoch 88/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0026 - accuracy: 0.9568 - val_loss: 0.0054 - val_accuracy: 0.9792\n",
            "Epoch 89/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0026 - accuracy: 0.9755 - val_loss: 0.0055 - val_accuracy: 0.9792\n",
            "Epoch 90/160\n",
            "87/87 [==============================] - 0s 463us/step - loss: 0.0026 - accuracy: 0.9684 - val_loss: 0.0057 - val_accuracy: 0.9688\n",
            "Epoch 91/160\n",
            "87/87 [==============================] - 0s 457us/step - loss: 0.0025 - accuracy: 0.9676 - val_loss: 0.0053 - val_accuracy: 0.9792\n",
            "Epoch 92/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0026 - accuracy: 0.9659 - val_loss: 0.0052 - val_accuracy: 0.9792\n",
            "Epoch 93/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0026 - accuracy: 0.9710 - val_loss: 0.0052 - val_accuracy: 0.9792\n",
            "Epoch 94/160\n",
            "87/87 [==============================] - 0s 451us/step - loss: 0.0025 - accuracy: 0.9792 - val_loss: 0.0052 - val_accuracy: 0.9792\n",
            "Epoch 95/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0022 - accuracy: 0.9745 - val_loss: 0.0055 - val_accuracy: 0.9688\n",
            "Epoch 96/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0026 - accuracy: 0.9703 - val_loss: 0.0058 - val_accuracy: 0.9479\n",
            "Epoch 97/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0024 - accuracy: 0.9674 - val_loss: 0.0053 - val_accuracy: 0.9688\n",
            "Epoch 98/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0024 - accuracy: 0.9734 - val_loss: 0.0054 - val_accuracy: 0.9792\n",
            "Epoch 99/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0023 - accuracy: 0.9716 - val_loss: 0.0048 - val_accuracy: 0.9792\n",
            "Epoch 100/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0025 - accuracy: 0.9813 - val_loss: 0.0052 - val_accuracy: 0.9688\n",
            "Epoch 101/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0022 - accuracy: 0.9736 - val_loss: 0.0048 - val_accuracy: 0.9792\n",
            "Epoch 102/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0023 - accuracy: 0.9602 - val_loss: 0.0050 - val_accuracy: 0.9792\n",
            "Epoch 103/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0024 - accuracy: 0.9809 - val_loss: 0.0050 - val_accuracy: 0.9792\n",
            "Epoch 104/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0026 - accuracy: 0.9696 - val_loss: 0.0056 - val_accuracy: 0.9688\n",
            "Epoch 105/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0022 - accuracy: 0.9746 - val_loss: 0.0051 - val_accuracy: 0.9688\n",
            "Epoch 106/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0025 - accuracy: 0.9661 - val_loss: 0.0052 - val_accuracy: 0.9688\n",
            "Epoch 107/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0022 - accuracy: 0.9717 - val_loss: 0.0051 - val_accuracy: 0.9688\n",
            "Epoch 108/160\n",
            "87/87 [==============================] - 0s 484us/step - loss: 0.0025 - accuracy: 0.9645 - val_loss: 0.0053 - val_accuracy: 0.9688\n",
            "Epoch 109/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0021 - accuracy: 0.9640 - val_loss: 0.0054 - val_accuracy: 0.9688\n",
            "Epoch 110/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0022 - accuracy: 0.9778 - val_loss: 0.0053 - val_accuracy: 0.9688\n",
            "Epoch 111/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0025 - accuracy: 0.9729 - val_loss: 0.0053 - val_accuracy: 0.9688\n",
            "Epoch 112/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0021 - accuracy: 0.9823 - val_loss: 0.0057 - val_accuracy: 0.9688\n",
            "Epoch 113/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0024 - accuracy: 0.9715 - val_loss: 0.0057 - val_accuracy: 0.9583\n",
            "Epoch 114/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0023 - accuracy: 0.9769 - val_loss: 0.0057 - val_accuracy: 0.9583\n",
            "Epoch 115/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0024 - accuracy: 0.9728 - val_loss: 0.0051 - val_accuracy: 0.9688\n",
            "Epoch 116/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0023 - accuracy: 0.9651 - val_loss: 0.0048 - val_accuracy: 0.9792\n",
            "Epoch 117/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0025 - accuracy: 0.9714 - val_loss: 0.0056 - val_accuracy: 0.9583\n",
            "Epoch 118/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0022 - accuracy: 0.9734 - val_loss: 0.0057 - val_accuracy: 0.9583\n",
            "Epoch 119/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0022 - accuracy: 0.9674 - val_loss: 0.0051 - val_accuracy: 0.9688\n",
            "Epoch 120/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0023 - accuracy: 0.9768 - val_loss: 0.0050 - val_accuracy: 0.9688\n",
            "Epoch 121/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0024 - accuracy: 0.9732 - val_loss: 0.0057 - val_accuracy: 0.9583\n",
            "Epoch 122/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0023 - accuracy: 0.9635 - val_loss: 0.0061 - val_accuracy: 0.9583\n",
            "Epoch 123/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0025 - accuracy: 0.9695 - val_loss: 0.0050 - val_accuracy: 0.9792\n",
            "Epoch 124/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0024 - accuracy: 0.9768 - val_loss: 0.0050 - val_accuracy: 0.9688\n",
            "Epoch 125/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0021 - accuracy: 0.9695 - val_loss: 0.0052 - val_accuracy: 0.9688\n",
            "Epoch 126/160\n",
            "87/87 [==============================] - 0s 474us/step - loss: 0.0022 - accuracy: 0.9689 - val_loss: 0.0053 - val_accuracy: 0.9688\n",
            "Epoch 127/160\n",
            "87/87 [==============================] - 0s 456us/step - loss: 0.0022 - accuracy: 0.9824 - val_loss: 0.0055 - val_accuracy: 0.9583\n",
            "Epoch 128/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0021 - accuracy: 0.9839 - val_loss: 0.0051 - val_accuracy: 0.9792\n",
            "Epoch 129/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0023 - accuracy: 0.9731 - val_loss: 0.0057 - val_accuracy: 0.9688\n",
            "Epoch 130/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0020 - accuracy: 0.9691 - val_loss: 0.0055 - val_accuracy: 0.9688\n",
            "Epoch 131/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0020 - accuracy: 0.9650 - val_loss: 0.0050 - val_accuracy: 0.9688\n",
            "Epoch 132/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0020 - accuracy: 0.9713 - val_loss: 0.0056 - val_accuracy: 0.9583\n",
            "Epoch 133/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0020 - accuracy: 0.9783 - val_loss: 0.0055 - val_accuracy: 0.9688\n",
            "Epoch 134/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0020 - accuracy: 0.9738 - val_loss: 0.0052 - val_accuracy: 0.9688\n",
            "Epoch 135/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0021 - accuracy: 0.9755 - val_loss: 0.0053 - val_accuracy: 0.9688\n",
            "Epoch 136/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0022 - accuracy: 0.9750 - val_loss: 0.0059 - val_accuracy: 0.9583\n",
            "Epoch 137/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0019 - accuracy: 0.9781 - val_loss: 0.0051 - val_accuracy: 0.9688\n",
            "Epoch 138/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0023 - accuracy: 0.9729 - val_loss: 0.0049 - val_accuracy: 0.9688\n",
            "Epoch 139/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0019 - accuracy: 0.9789 - val_loss: 0.0051 - val_accuracy: 0.9792\n",
            "Epoch 140/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0022 - accuracy: 0.9722 - val_loss: 0.0055 - val_accuracy: 0.9688\n",
            "Epoch 141/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0021 - accuracy: 0.9785 - val_loss: 0.0052 - val_accuracy: 0.9688\n",
            "Epoch 142/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0021 - accuracy: 0.9750 - val_loss: 0.0059 - val_accuracy: 0.9583\n",
            "Epoch 143/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0024 - accuracy: 0.9791 - val_loss: 0.0072 - val_accuracy: 0.9271\n",
            "Epoch 144/160\n",
            "87/87 [==============================] - 0s 454us/step - loss: 0.0022 - accuracy: 0.9757 - val_loss: 0.0056 - val_accuracy: 0.9583\n",
            "Epoch 145/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0022 - accuracy: 0.9644 - val_loss: 0.0052 - val_accuracy: 0.9688\n",
            "Epoch 146/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0021 - accuracy: 0.9713 - val_loss: 0.0055 - val_accuracy: 0.9583\n",
            "Epoch 147/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0020 - accuracy: 0.9840 - val_loss: 0.0054 - val_accuracy: 0.9688\n",
            "Epoch 148/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0018 - accuracy: 0.9723 - val_loss: 0.0056 - val_accuracy: 0.9688\n",
            "Epoch 149/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0020 - accuracy: 0.9707 - val_loss: 0.0057 - val_accuracy: 0.9583\n",
            "Epoch 150/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0023 - accuracy: 0.9696 - val_loss: 0.0053 - val_accuracy: 0.9688\n",
            "Epoch 151/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0020 - accuracy: 0.9744 - val_loss: 0.0054 - val_accuracy: 0.9792\n",
            "Epoch 152/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0021 - accuracy: 0.9701 - val_loss: 0.0055 - val_accuracy: 0.9792\n",
            "Epoch 153/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0022 - accuracy: 0.9721 - val_loss: 0.0053 - val_accuracy: 0.9688\n",
            "Epoch 154/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0022 - accuracy: 0.9631 - val_loss: 0.0053 - val_accuracy: 0.9688\n",
            "Epoch 155/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0021 - accuracy: 0.9746 - val_loss: 0.0050 - val_accuracy: 0.9688\n",
            "Epoch 156/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0020 - accuracy: 0.9655 - val_loss: 0.0046 - val_accuracy: 0.9688\n",
            "Epoch 157/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0020 - accuracy: 0.9737 - val_loss: 0.0051 - val_accuracy: 0.9688\n",
            "Epoch 158/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0018 - accuracy: 0.9736 - val_loss: 0.0054 - val_accuracy: 0.9688\n",
            "Epoch 159/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0020 - accuracy: 0.9725 - val_loss: 0.0051 - val_accuracy: 0.9688\n",
            "Epoch 160/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0019 - accuracy: 0.9650 - val_loss: 0.0049 - val_accuracy: 0.9792\n",
            "3/3 [==============================] - 0s 574us/step - loss: 0.0049 - accuracy: 0.9792\n",
            "Loss = 0.004930993542075157, rmse = 0.9791666865348816\n",
            "Loss array:  [0.002609268995001912, 0.0022859082091599703, 0.0018555676797404885, 0.002085859654471278, 0.004930993542075157]\n",
            "####################### Iteration   5  #######################\n",
            "Epoch 1/160\n",
            "87/87 [==============================] - 0s 819us/step - loss: 0.3708 - accuracy: 0.6130 - val_loss: 0.1905 - val_accuracy: 0.6562\n",
            "Epoch 2/160\n",
            "87/87 [==============================] - 0s 446us/step - loss: 0.1490 - accuracy: 0.6011 - val_loss: 0.0698 - val_accuracy: 0.6562\n",
            "Epoch 3/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0590 - accuracy: 0.6124 - val_loss: 0.0385 - val_accuracy: 0.6979\n",
            "Epoch 4/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0310 - accuracy: 0.7156 - val_loss: 0.0252 - val_accuracy: 0.9167\n",
            "Epoch 5/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0202 - accuracy: 0.8777 - val_loss: 0.0195 - val_accuracy: 0.9583\n",
            "Epoch 6/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0169 - accuracy: 0.9260 - val_loss: 0.0172 - val_accuracy: 0.9792\n",
            "Epoch 7/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0142 - accuracy: 0.9504 - val_loss: 0.0159 - val_accuracy: 0.9792\n",
            "Epoch 8/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0137 - accuracy: 0.9596 - val_loss: 0.0149 - val_accuracy: 0.9792\n",
            "Epoch 9/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0133 - accuracy: 0.9606 - val_loss: 0.0141 - val_accuracy: 0.9792\n",
            "Epoch 10/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0112 - accuracy: 0.9535 - val_loss: 0.0135 - val_accuracy: 0.9792\n",
            "Epoch 11/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0111 - accuracy: 0.9506 - val_loss: 0.0129 - val_accuracy: 0.9792\n",
            "Epoch 12/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0108 - accuracy: 0.9549 - val_loss: 0.0123 - val_accuracy: 0.9792\n",
            "Epoch 13/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0110 - accuracy: 0.9561 - val_loss: 0.0117 - val_accuracy: 0.9792\n",
            "Epoch 14/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0094 - accuracy: 0.9517 - val_loss: 0.0114 - val_accuracy: 0.9792\n",
            "Epoch 15/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0092 - accuracy: 0.9456 - val_loss: 0.0109 - val_accuracy: 0.9792\n",
            "Epoch 16/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0091 - accuracy: 0.9480 - val_loss: 0.0104 - val_accuracy: 0.9792\n",
            "Epoch 17/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0079 - accuracy: 0.9623 - val_loss: 0.0102 - val_accuracy: 0.9792\n",
            "Epoch 18/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0084 - accuracy: 0.9635 - val_loss: 0.0100 - val_accuracy: 0.9896\n",
            "Epoch 19/160\n",
            "87/87 [==============================] - 0s 452us/step - loss: 0.0083 - accuracy: 0.9407 - val_loss: 0.0094 - val_accuracy: 0.9896\n",
            "Epoch 20/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0085 - accuracy: 0.9521 - val_loss: 0.0091 - val_accuracy: 0.9792\n",
            "Epoch 21/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0075 - accuracy: 0.9557 - val_loss: 0.0090 - val_accuracy: 0.9896\n",
            "Epoch 22/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0070 - accuracy: 0.9541 - val_loss: 0.0086 - val_accuracy: 0.9896\n",
            "Epoch 23/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0074 - accuracy: 0.9538 - val_loss: 0.0086 - val_accuracy: 0.9896\n",
            "Epoch 24/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0064 - accuracy: 0.9673 - val_loss: 0.0081 - val_accuracy: 0.9896\n",
            "Epoch 25/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0064 - accuracy: 0.9624 - val_loss: 0.0080 - val_accuracy: 0.9896\n",
            "Epoch 26/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0059 - accuracy: 0.9787 - val_loss: 0.0078 - val_accuracy: 0.9896\n",
            "Epoch 27/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0056 - accuracy: 0.9635 - val_loss: 0.0074 - val_accuracy: 0.9896\n",
            "Epoch 28/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0065 - accuracy: 0.9665 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 29/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0060 - accuracy: 0.9441 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 30/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0061 - accuracy: 0.9731 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 31/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0058 - accuracy: 0.9610 - val_loss: 0.0069 - val_accuracy: 0.9896\n",
            "Epoch 32/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0056 - accuracy: 0.9644 - val_loss: 0.0070 - val_accuracy: 0.9896\n",
            "Epoch 33/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0051 - accuracy: 0.9572 - val_loss: 0.0066 - val_accuracy: 0.9896\n",
            "Epoch 34/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0054 - accuracy: 0.9648 - val_loss: 0.0065 - val_accuracy: 0.9896\n",
            "Epoch 35/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0049 - accuracy: 0.9629 - val_loss: 0.0064 - val_accuracy: 0.9896\n",
            "Epoch 36/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0046 - accuracy: 0.9701 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 37/160\n",
            "87/87 [==============================] - 0s 465us/step - loss: 0.0049 - accuracy: 0.9624 - val_loss: 0.0064 - val_accuracy: 0.9896\n",
            "Epoch 38/160\n",
            "87/87 [==============================] - 0s 441us/step - loss: 0.0047 - accuracy: 0.9659 - val_loss: 0.0061 - val_accuracy: 0.9896\n",
            "Epoch 39/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0051 - accuracy: 0.9662 - val_loss: 0.0060 - val_accuracy: 0.9896\n",
            "Epoch 40/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0043 - accuracy: 0.9682 - val_loss: 0.0060 - val_accuracy: 0.9896\n",
            "Epoch 41/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0044 - accuracy: 0.9482 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 42/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0047 - accuracy: 0.9560 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 43/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0046 - accuracy: 0.9656 - val_loss: 0.0058 - val_accuracy: 0.9896\n",
            "Epoch 44/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0042 - accuracy: 0.9617 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 45/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0039 - accuracy: 0.9684 - val_loss: 0.0055 - val_accuracy: 0.9896\n",
            "Epoch 46/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0043 - accuracy: 0.9669 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 47/160\n",
            "87/87 [==============================] - 0s 440us/step - loss: 0.0040 - accuracy: 0.9561 - val_loss: 0.0056 - val_accuracy: 0.9896\n",
            "Epoch 48/160\n",
            "87/87 [==============================] - 0s 443us/step - loss: 0.0040 - accuracy: 0.9728 - val_loss: 0.0055 - val_accuracy: 0.9896\n",
            "Epoch 49/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0038 - accuracy: 0.9619 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 50/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0041 - accuracy: 0.9771 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 51/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0040 - accuracy: 0.9516 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 52/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0036 - accuracy: 0.9692 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 53/160\n",
            "87/87 [==============================] - 0s 466us/step - loss: 0.0038 - accuracy: 0.9663 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 54/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0036 - accuracy: 0.9591 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 55/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0038 - accuracy: 0.9725 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 56/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0040 - accuracy: 0.9571 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 57/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0033 - accuracy: 0.9589 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 58/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0036 - accuracy: 0.9638 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 59/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0033 - accuracy: 0.9642 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 60/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0033 - accuracy: 0.9547 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 61/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0033 - accuracy: 0.9630 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 62/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0034 - accuracy: 0.9682 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 63/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0033 - accuracy: 0.9618 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 64/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0032 - accuracy: 0.9629 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 65/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0033 - accuracy: 0.9700 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 66/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0032 - accuracy: 0.9649 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 67/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0030 - accuracy: 0.9663 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 68/160\n",
            "87/87 [==============================] - 0s 500us/step - loss: 0.0033 - accuracy: 0.9708 - val_loss: 0.0044 - val_accuracy: 0.9896\n",
            "Epoch 69/160\n",
            "87/87 [==============================] - 0s 447us/step - loss: 0.0029 - accuracy: 0.9637 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 70/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0030 - accuracy: 0.9731 - val_loss: 0.0047 - val_accuracy: 0.9896\n",
            "Epoch 71/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0034 - accuracy: 0.9713 - val_loss: 0.0046 - val_accuracy: 0.9896\n",
            "Epoch 72/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0035 - accuracy: 0.9659 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 73/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0033 - accuracy: 0.9694 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 74/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0031 - accuracy: 0.9542 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 75/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0027 - accuracy: 0.9704 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 76/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0033 - accuracy: 0.9671 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 77/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0031 - accuracy: 0.9662 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 78/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0030 - accuracy: 0.9698 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 79/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0029 - accuracy: 0.9640 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 80/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0027 - accuracy: 0.9654 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 81/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0030 - accuracy: 0.9717 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 82/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0029 - accuracy: 0.9661 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 83/160\n",
            "87/87 [==============================] - 0s 472us/step - loss: 0.0029 - accuracy: 0.9686 - val_loss: 0.0041 - val_accuracy: 0.9896\n",
            "Epoch 84/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0026 - accuracy: 0.9751 - val_loss: 0.0040 - val_accuracy: 0.9896\n",
            "Epoch 85/160\n",
            "87/87 [==============================] - 0s 467us/step - loss: 0.0028 - accuracy: 0.9730 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 86/160\n",
            "87/87 [==============================] - 0s 441us/step - loss: 0.0027 - accuracy: 0.9758 - val_loss: 0.0040 - val_accuracy: 0.9896\n",
            "Epoch 87/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0022 - accuracy: 0.9762 - val_loss: 0.0040 - val_accuracy: 0.9896\n",
            "Epoch 88/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0026 - accuracy: 0.9644 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 89/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0027 - accuracy: 0.9656 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 90/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0027 - accuracy: 0.9703 - val_loss: 0.0040 - val_accuracy: 0.9896\n",
            "Epoch 91/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0028 - accuracy: 0.9702 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 92/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0027 - accuracy: 0.9593 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 93/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0029 - accuracy: 0.9693 - val_loss: 0.0041 - val_accuracy: 0.9896\n",
            "Epoch 94/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0029 - accuracy: 0.9761 - val_loss: 0.0039 - val_accuracy: 0.9896\n",
            "Epoch 95/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0024 - accuracy: 0.9758 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 96/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0028 - accuracy: 0.9707 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 97/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0025 - accuracy: 0.9588 - val_loss: 0.0040 - val_accuracy: 0.9896\n",
            "Epoch 98/160\n",
            "87/87 [==============================] - 0s 480us/step - loss: 0.0024 - accuracy: 0.9752 - val_loss: 0.0042 - val_accuracy: 0.9896\n",
            "Epoch 99/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0027 - accuracy: 0.9708 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 100/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0025 - accuracy: 0.9721 - val_loss: 0.0039 - val_accuracy: 0.9896\n",
            "Epoch 101/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0022 - accuracy: 0.9773 - val_loss: 0.0042 - val_accuracy: 0.9896\n",
            "Epoch 102/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0024 - accuracy: 0.9654 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 103/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0024 - accuracy: 0.9788 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 104/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0025 - accuracy: 0.9652 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 105/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0026 - accuracy: 0.9707 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 106/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0025 - accuracy: 0.9569 - val_loss: 0.0039 - val_accuracy: 0.9896\n",
            "Epoch 107/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0026 - accuracy: 0.9687 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 108/160\n",
            "87/87 [==============================] - 0s 439us/step - loss: 0.0025 - accuracy: 0.9692 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 109/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0023 - accuracy: 0.9624 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 110/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0022 - accuracy: 0.9759 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 111/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0025 - accuracy: 0.9736 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 112/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0025 - accuracy: 0.9819 - val_loss: 0.0039 - val_accuracy: 0.9896\n",
            "Epoch 113/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0026 - accuracy: 0.9693 - val_loss: 0.0040 - val_accuracy: 0.9896\n",
            "Epoch 114/160\n",
            "87/87 [==============================] - 0s 446us/step - loss: 0.0025 - accuracy: 0.9741 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 115/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0026 - accuracy: 0.9735 - val_loss: 0.0037 - val_accuracy: 0.9896\n",
            "Epoch 116/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0024 - accuracy: 0.9706 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 117/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0027 - accuracy: 0.9757 - val_loss: 0.0038 - val_accuracy: 0.9896\n",
            "Epoch 118/160\n",
            "87/87 [==============================] - 0s 443us/step - loss: 0.0024 - accuracy: 0.9702 - val_loss: 0.0037 - val_accuracy: 0.9896\n",
            "Epoch 119/160\n",
            "87/87 [==============================] - 0s 468us/step - loss: 0.0024 - accuracy: 0.9664 - val_loss: 0.0037 - val_accuracy: 0.9896\n",
            "Epoch 120/160\n",
            "87/87 [==============================] - 0s 453us/step - loss: 0.0025 - accuracy: 0.9743 - val_loss: 0.0037 - val_accuracy: 0.9896\n",
            "Epoch 121/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0024 - accuracy: 0.9734 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 122/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0025 - accuracy: 0.9576 - val_loss: 0.0037 - val_accuracy: 0.9896\n",
            "Epoch 123/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0025 - accuracy: 0.9737 - val_loss: 0.0039 - val_accuracy: 0.9896\n",
            "Epoch 124/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0025 - accuracy: 0.9711 - val_loss: 0.0037 - val_accuracy: 0.9896\n",
            "Epoch 125/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0021 - accuracy: 0.9676 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 126/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0026 - accuracy: 0.9603 - val_loss: 0.0037 - val_accuracy: 0.9896\n",
            "Epoch 127/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0024 - accuracy: 0.9752 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 128/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0020 - accuracy: 0.9776 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 129/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0025 - accuracy: 0.9751 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 130/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0021 - accuracy: 0.9671 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 131/160\n",
            "87/87 [==============================] - 0s 439us/step - loss: 0.0022 - accuracy: 0.9719 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 132/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0021 - accuracy: 0.9658 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 133/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0023 - accuracy: 0.9709 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 134/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0022 - accuracy: 0.9707 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 135/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0023 - accuracy: 0.9678 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 136/160\n",
            "87/87 [==============================] - 0s 439us/step - loss: 0.0023 - accuracy: 0.9758 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 137/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0023 - accuracy: 0.9761 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 138/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0025 - accuracy: 0.9664 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 139/160\n",
            "87/87 [==============================] - 0s 458us/step - loss: 0.0022 - accuracy: 0.9723 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 140/160\n",
            "87/87 [==============================] - 0s 455us/step - loss: 0.0023 - accuracy: 0.9677 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 141/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0022 - accuracy: 0.9712 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 142/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0021 - accuracy: 0.9753 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 143/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0023 - accuracy: 0.9806 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 144/160\n",
            "87/87 [==============================] - 0s 441us/step - loss: 0.0023 - accuracy: 0.9774 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 145/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0026 - accuracy: 0.9736 - val_loss: 0.0034 - val_accuracy: 0.9896\n",
            "Epoch 146/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0023 - accuracy: 0.9675 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 147/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0025 - accuracy: 0.9848 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 148/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0020 - accuracy: 0.9723 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 149/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0021 - accuracy: 0.9677 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 150/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0022 - accuracy: 0.9681 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 151/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0021 - accuracy: 0.9684 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 152/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0021 - accuracy: 0.9818 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 153/160\n",
            "87/87 [==============================] - 0s 440us/step - loss: 0.0022 - accuracy: 0.9704 - val_loss: 0.0034 - val_accuracy: 0.9896\n",
            "Epoch 154/160\n",
            "87/87 [==============================] - 0s 451us/step - loss: 0.0023 - accuracy: 0.9701 - val_loss: 0.0034 - val_accuracy: 0.9896\n",
            "Epoch 155/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0020 - accuracy: 0.9763 - val_loss: 0.0036 - val_accuracy: 0.9896\n",
            "Epoch 156/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0021 - accuracy: 0.9590 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 157/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0020 - accuracy: 0.9745 - val_loss: 0.0034 - val_accuracy: 0.9896\n",
            "Epoch 158/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0020 - accuracy: 0.9755 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 159/160\n",
            "87/87 [==============================] - 0s 461us/step - loss: 0.0019 - accuracy: 0.9783 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "Epoch 160/160\n",
            "87/87 [==============================] - 0s 467us/step - loss: 0.0019 - accuracy: 0.9702 - val_loss: 0.0035 - val_accuracy: 0.9896\n",
            "3/3 [==============================] - 0s 654us/step - loss: 0.0035 - accuracy: 0.9896\n",
            "Loss = 0.003450318006798625, rmse = 0.9895833134651184\n",
            "Loss array:  [0.002609268995001912, 0.0022859082091599703, 0.0018555676797404885, 0.002085859654471278, 0.004930993542075157, 0.003450318006798625]\n",
            "####################### Iteration   6  #######################\n",
            "Epoch 1/160\n",
            "87/87 [==============================] - 0s 821us/step - loss: 0.3082 - accuracy: 0.4814 - val_loss: 0.1423 - val_accuracy: 0.6458\n",
            "Epoch 2/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.1123 - accuracy: 0.6040 - val_loss: 0.0412 - val_accuracy: 0.6667\n",
            "Epoch 3/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0411 - accuracy: 0.7777 - val_loss: 0.0215 - val_accuracy: 0.9479\n",
            "Epoch 4/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0216 - accuracy: 0.9090 - val_loss: 0.0153 - val_accuracy: 0.9375\n",
            "Epoch 5/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0157 - accuracy: 0.9259 - val_loss: 0.0135 - val_accuracy: 0.9479\n",
            "Epoch 6/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0153 - accuracy: 0.9288 - val_loss: 0.0126 - val_accuracy: 0.9479\n",
            "Epoch 7/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0143 - accuracy: 0.9322 - val_loss: 0.0119 - val_accuracy: 0.9479\n",
            "Epoch 8/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0135 - accuracy: 0.9522 - val_loss: 0.0115 - val_accuracy: 0.9479\n",
            "Epoch 9/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0131 - accuracy: 0.9552 - val_loss: 0.0112 - val_accuracy: 0.9479\n",
            "Epoch 10/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0111 - accuracy: 0.9463 - val_loss: 0.0104 - val_accuracy: 0.9375\n",
            "Epoch 11/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0108 - accuracy: 0.9428 - val_loss: 0.0099 - val_accuracy: 0.9375\n",
            "Epoch 12/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0102 - accuracy: 0.9446 - val_loss: 0.0100 - val_accuracy: 0.9479\n",
            "Epoch 13/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0104 - accuracy: 0.9557 - val_loss: 0.0089 - val_accuracy: 0.9375\n",
            "Epoch 14/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0092 - accuracy: 0.9594 - val_loss: 0.0091 - val_accuracy: 0.9479\n",
            "Epoch 15/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0092 - accuracy: 0.9473 - val_loss: 0.0084 - val_accuracy: 0.9479\n",
            "Epoch 16/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0089 - accuracy: 0.9558 - val_loss: 0.0082 - val_accuracy: 0.9479\n",
            "Epoch 17/160\n",
            "87/87 [==============================] - 0s 509us/step - loss: 0.0076 - accuracy: 0.9684 - val_loss: 0.0078 - val_accuracy: 0.9479\n",
            "Epoch 18/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0081 - accuracy: 0.9688 - val_loss: 0.0074 - val_accuracy: 0.9583\n",
            "Epoch 19/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0079 - accuracy: 0.9498 - val_loss: 0.0074 - val_accuracy: 0.9479\n",
            "Epoch 20/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0071 - val_accuracy: 0.9583\n",
            "Epoch 21/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0074 - accuracy: 0.9616 - val_loss: 0.0068 - val_accuracy: 0.9583\n",
            "Epoch 22/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0066 - accuracy: 0.9550 - val_loss: 0.0068 - val_accuracy: 0.9583\n",
            "Epoch 23/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0069 - accuracy: 0.9603 - val_loss: 0.0064 - val_accuracy: 0.9688\n",
            "Epoch 24/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0067 - accuracy: 0.9688 - val_loss: 0.0064 - val_accuracy: 0.9583\n",
            "Epoch 25/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0062 - accuracy: 0.9611 - val_loss: 0.0063 - val_accuracy: 0.9583\n",
            "Epoch 26/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0061 - accuracy: 0.9806 - val_loss: 0.0059 - val_accuracy: 0.9583\n",
            "Epoch 27/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0058 - accuracy: 0.9677 - val_loss: 0.0061 - val_accuracy: 0.9583\n",
            "Epoch 28/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0062 - accuracy: 0.9565 - val_loss: 0.0064 - val_accuracy: 0.9583\n",
            "Epoch 29/160\n",
            "87/87 [==============================] - 0s 453us/step - loss: 0.0060 - accuracy: 0.9614 - val_loss: 0.0059 - val_accuracy: 0.9583\n",
            "Epoch 30/160\n",
            "87/87 [==============================] - 0s 464us/step - loss: 0.0059 - accuracy: 0.9786 - val_loss: 0.0063 - val_accuracy: 0.9583\n",
            "Epoch 31/160\n",
            "87/87 [==============================] - 0s 563us/step - loss: 0.0058 - accuracy: 0.9645 - val_loss: 0.0054 - val_accuracy: 0.9792\n",
            "Epoch 32/160\n",
            "87/87 [==============================] - 0s 565us/step - loss: 0.0056 - accuracy: 0.9641 - val_loss: 0.0054 - val_accuracy: 0.9792\n",
            "Epoch 33/160\n",
            "87/87 [==============================] - 0s 469us/step - loss: 0.0052 - accuracy: 0.9601 - val_loss: 0.0053 - val_accuracy: 0.9792\n",
            "Epoch 34/160\n",
            "87/87 [==============================] - 0s 523us/step - loss: 0.0053 - accuracy: 0.9765 - val_loss: 0.0052 - val_accuracy: 0.9688\n",
            "Epoch 35/160\n",
            "87/87 [==============================] - 0s 448us/step - loss: 0.0050 - accuracy: 0.9717 - val_loss: 0.0051 - val_accuracy: 0.9792\n",
            "Epoch 36/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0049 - accuracy: 0.9772 - val_loss: 0.0051 - val_accuracy: 0.9688\n",
            "Epoch 37/160\n",
            "87/87 [==============================] - 0s 450us/step - loss: 0.0049 - accuracy: 0.9638 - val_loss: 0.0051 - val_accuracy: 0.9688\n",
            "Epoch 38/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0047 - accuracy: 0.9669 - val_loss: 0.0051 - val_accuracy: 0.9583\n",
            "Epoch 39/160\n",
            "87/87 [==============================] - 0s 476us/step - loss: 0.0049 - accuracy: 0.9636 - val_loss: 0.0049 - val_accuracy: 0.9792\n",
            "Epoch 40/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0044 - accuracy: 0.9756 - val_loss: 0.0048 - val_accuracy: 0.9792\n",
            "Epoch 41/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0045 - accuracy: 0.9635 - val_loss: 0.0050 - val_accuracy: 0.9792\n",
            "Epoch 42/160\n",
            "87/87 [==============================] - 0s 496us/step - loss: 0.0046 - accuracy: 0.9576 - val_loss: 0.0049 - val_accuracy: 0.9792\n",
            "Epoch 43/160\n",
            "87/87 [==============================] - 0s 511us/step - loss: 0.0047 - accuracy: 0.9609 - val_loss: 0.0047 - val_accuracy: 0.9792\n",
            "Epoch 44/160\n",
            "87/87 [==============================] - 0s 498us/step - loss: 0.0043 - accuracy: 0.9684 - val_loss: 0.0048 - val_accuracy: 0.9792\n",
            "Epoch 45/160\n",
            "87/87 [==============================] - 0s 463us/step - loss: 0.0040 - accuracy: 0.9686 - val_loss: 0.0047 - val_accuracy: 0.9792\n",
            "Epoch 46/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0044 - accuracy: 0.9666 - val_loss: 0.0046 - val_accuracy: 0.9792\n",
            "Epoch 47/160\n",
            "87/87 [==============================] - 0s 449us/step - loss: 0.0041 - accuracy: 0.9621 - val_loss: 0.0046 - val_accuracy: 0.9583\n",
            "Epoch 48/160\n",
            "87/87 [==============================] - 0s 447us/step - loss: 0.0042 - accuracy: 0.9710 - val_loss: 0.0045 - val_accuracy: 0.9792\n",
            "Epoch 49/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0040 - accuracy: 0.9676 - val_loss: 0.0046 - val_accuracy: 0.9792\n",
            "Epoch 50/160\n",
            "87/87 [==============================] - 0s 467us/step - loss: 0.0043 - accuracy: 0.9795 - val_loss: 0.0044 - val_accuracy: 0.9792\n",
            "Epoch 51/160\n",
            "87/87 [==============================] - 0s 449us/step - loss: 0.0042 - accuracy: 0.9546 - val_loss: 0.0045 - val_accuracy: 0.9792\n",
            "Epoch 52/160\n",
            "87/87 [==============================] - 0s 495us/step - loss: 0.0038 - accuracy: 0.9637 - val_loss: 0.0044 - val_accuracy: 0.9792\n",
            "Epoch 53/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0038 - accuracy: 0.9660 - val_loss: 0.0044 - val_accuracy: 0.9583\n",
            "Epoch 54/160\n",
            "87/87 [==============================] - 0s 508us/step - loss: 0.0038 - accuracy: 0.9661 - val_loss: 0.0043 - val_accuracy: 0.9792\n",
            "Epoch 55/160\n",
            "87/87 [==============================] - 0s 481us/step - loss: 0.0040 - accuracy: 0.9736 - val_loss: 0.0043 - val_accuracy: 0.9792\n",
            "Epoch 56/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0041 - accuracy: 0.9667 - val_loss: 0.0043 - val_accuracy: 0.9583\n",
            "Epoch 57/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0036 - accuracy: 0.9623 - val_loss: 0.0044 - val_accuracy: 0.9583\n",
            "Epoch 58/160\n",
            "87/87 [==============================] - 0s 452us/step - loss: 0.0038 - accuracy: 0.9732 - val_loss: 0.0042 - val_accuracy: 0.9688\n",
            "Epoch 59/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0036 - accuracy: 0.9644 - val_loss: 0.0044 - val_accuracy: 0.9688\n",
            "Epoch 60/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0037 - accuracy: 0.9532 - val_loss: 0.0041 - val_accuracy: 0.9583\n",
            "Epoch 61/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0036 - accuracy: 0.9671 - val_loss: 0.0041 - val_accuracy: 0.9792\n",
            "Epoch 62/160\n",
            "87/87 [==============================] - 0s 386us/step - loss: 0.0039 - accuracy: 0.9674 - val_loss: 0.0040 - val_accuracy: 0.9688\n",
            "Epoch 63/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0037 - accuracy: 0.9565 - val_loss: 0.0043 - val_accuracy: 0.9792\n",
            "Epoch 64/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0036 - accuracy: 0.9650 - val_loss: 0.0040 - val_accuracy: 0.9792\n",
            "Epoch 65/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0034 - accuracy: 0.9687 - val_loss: 0.0042 - val_accuracy: 0.9583\n",
            "Epoch 66/160\n",
            "87/87 [==============================] - 0s 482us/step - loss: 0.0035 - accuracy: 0.9683 - val_loss: 0.0039 - val_accuracy: 0.9688\n",
            "Epoch 67/160\n",
            "87/87 [==============================] - 0s 499us/step - loss: 0.0034 - accuracy: 0.9541 - val_loss: 0.0039 - val_accuracy: 0.9688\n",
            "Epoch 68/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0036 - accuracy: 0.9683 - val_loss: 0.0040 - val_accuracy: 0.9792\n",
            "Epoch 69/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0033 - accuracy: 0.9665 - val_loss: 0.0038 - val_accuracy: 0.9688\n",
            "Epoch 70/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0032 - accuracy: 0.9745 - val_loss: 0.0043 - val_accuracy: 0.9792\n",
            "Epoch 71/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0038 - accuracy: 0.9671 - val_loss: 0.0041 - val_accuracy: 0.9792\n",
            "Epoch 72/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0035 - accuracy: 0.9676 - val_loss: 0.0040 - val_accuracy: 0.9792\n",
            "Epoch 73/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0040 - accuracy: 0.9678 - val_loss: 0.0038 - val_accuracy: 0.9688\n",
            "Epoch 74/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0033 - accuracy: 0.9554 - val_loss: 0.0037 - val_accuracy: 0.9688\n",
            "Epoch 75/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0033 - accuracy: 0.9689 - val_loss: 0.0039 - val_accuracy: 0.9688\n",
            "Epoch 76/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0037 - accuracy: 0.9755 - val_loss: 0.0037 - val_accuracy: 0.9688\n",
            "Epoch 77/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0034 - accuracy: 0.9730 - val_loss: 0.0037 - val_accuracy: 0.9688\n",
            "Epoch 78/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0032 - accuracy: 0.9661 - val_loss: 0.0036 - val_accuracy: 0.9688\n",
            "Epoch 79/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0031 - accuracy: 0.9694 - val_loss: 0.0036 - val_accuracy: 0.9792\n",
            "Epoch 80/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0030 - accuracy: 0.9720 - val_loss: 0.0038 - val_accuracy: 0.9583\n",
            "Epoch 81/160\n",
            "87/87 [==============================] - 0s 456us/step - loss: 0.0032 - accuracy: 0.9780 - val_loss: 0.0036 - val_accuracy: 0.9792\n",
            "Epoch 82/160\n",
            "87/87 [==============================] - 0s 440us/step - loss: 0.0030 - accuracy: 0.9637 - val_loss: 0.0042 - val_accuracy: 0.9583\n",
            "Epoch 83/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0033 - accuracy: 0.9721 - val_loss: 0.0036 - val_accuracy: 0.9792\n",
            "Epoch 84/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0031 - accuracy: 0.9775 - val_loss: 0.0037 - val_accuracy: 0.9792\n",
            "Epoch 85/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0031 - accuracy: 0.9698 - val_loss: 0.0035 - val_accuracy: 0.9688\n",
            "Epoch 86/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0030 - accuracy: 0.9759 - val_loss: 0.0034 - val_accuracy: 0.9688\n",
            "Epoch 87/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0025 - accuracy: 0.9768 - val_loss: 0.0034 - val_accuracy: 0.9688\n",
            "Epoch 88/160\n",
            "87/87 [==============================] - 0s 381us/step - loss: 0.0028 - accuracy: 0.9685 - val_loss: 0.0035 - val_accuracy: 0.9792\n",
            "Epoch 89/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0030 - accuracy: 0.9646 - val_loss: 0.0036 - val_accuracy: 0.9583\n",
            "Epoch 90/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0033 - accuracy: 0.9689 - val_loss: 0.0034 - val_accuracy: 0.9688\n",
            "Epoch 91/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0031 - accuracy: 0.9698 - val_loss: 0.0034 - val_accuracy: 0.9688\n",
            "Epoch 92/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0031 - accuracy: 0.9608 - val_loss: 0.0034 - val_accuracy: 0.9688\n",
            "Epoch 93/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0033 - accuracy: 0.9714 - val_loss: 0.0034 - val_accuracy: 0.9792\n",
            "Epoch 94/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0030 - accuracy: 0.9794 - val_loss: 0.0036 - val_accuracy: 0.9792\n",
            "Epoch 95/160\n",
            "87/87 [==============================] - 0s 470us/step - loss: 0.0027 - accuracy: 0.9728 - val_loss: 0.0035 - val_accuracy: 0.9583\n",
            "Epoch 96/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0030 - accuracy: 0.9695 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 97/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0028 - accuracy: 0.9658 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 98/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0028 - accuracy: 0.9781 - val_loss: 0.0037 - val_accuracy: 0.9688\n",
            "Epoch 99/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0030 - accuracy: 0.9746 - val_loss: 0.0034 - val_accuracy: 0.9792\n",
            "Epoch 100/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0028 - accuracy: 0.9707 - val_loss: 0.0033 - val_accuracy: 0.9792\n",
            "Epoch 101/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0026 - accuracy: 0.9737 - val_loss: 0.0033 - val_accuracy: 0.9792\n",
            "Epoch 102/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0028 - accuracy: 0.9677 - val_loss: 0.0032 - val_accuracy: 0.9688\n",
            "Epoch 103/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0028 - accuracy: 0.9749 - val_loss: 0.0034 - val_accuracy: 0.9792\n",
            "Epoch 104/160\n",
            "87/87 [==============================] - 0s 441us/step - loss: 0.0028 - accuracy: 0.9734 - val_loss: 0.0033 - val_accuracy: 0.9583\n",
            "Epoch 105/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0027 - accuracy: 0.9786 - val_loss: 0.0032 - val_accuracy: 0.9688\n",
            "Epoch 106/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0031 - accuracy: 0.9562 - val_loss: 0.0032 - val_accuracy: 0.9688\n",
            "Epoch 107/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0029 - accuracy: 0.9700 - val_loss: 0.0032 - val_accuracy: 0.9792\n",
            "Epoch 108/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0028 - accuracy: 0.9675 - val_loss: 0.0031 - val_accuracy: 0.9688\n",
            "Epoch 109/160\n",
            "87/87 [==============================] - 0s 510us/step - loss: 0.0027 - accuracy: 0.9658 - val_loss: 0.0032 - val_accuracy: 0.9792\n",
            "Epoch 110/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0028 - accuracy: 0.9755 - val_loss: 0.0032 - val_accuracy: 0.9688\n",
            "Epoch 111/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0029 - accuracy: 0.9780 - val_loss: 0.0031 - val_accuracy: 0.9688\n",
            "Epoch 112/160\n",
            "87/87 [==============================] - 0s 468us/step - loss: 0.0027 - accuracy: 0.9711 - val_loss: 0.0032 - val_accuracy: 0.9792\n",
            "Epoch 113/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0028 - accuracy: 0.9747 - val_loss: 0.0035 - val_accuracy: 0.9688\n",
            "Epoch 114/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0026 - accuracy: 0.9790 - val_loss: 0.0031 - val_accuracy: 0.9688\n",
            "Epoch 115/160\n",
            "87/87 [==============================] - 0s 380us/step - loss: 0.0028 - accuracy: 0.9736 - val_loss: 0.0030 - val_accuracy: 0.9688\n",
            "Epoch 116/160\n",
            "87/87 [==============================] - 0s 388us/step - loss: 0.0027 - accuracy: 0.9687 - val_loss: 0.0033 - val_accuracy: 0.9792\n",
            "Epoch 117/160\n",
            "87/87 [==============================] - 0s 383us/step - loss: 0.0029 - accuracy: 0.9748 - val_loss: 0.0030 - val_accuracy: 0.9688\n",
            "Epoch 118/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0026 - accuracy: 0.9716 - val_loss: 0.0030 - val_accuracy: 0.9688\n",
            "Epoch 119/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0027 - accuracy: 0.9610 - val_loss: 0.0031 - val_accuracy: 0.9792\n",
            "Epoch 120/160\n",
            "87/87 [==============================] - 0s 379us/step - loss: 0.0026 - accuracy: 0.9811 - val_loss: 0.0030 - val_accuracy: 0.9792\n",
            "Epoch 121/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0026 - accuracy: 0.9718 - val_loss: 0.0034 - val_accuracy: 0.9688\n",
            "Epoch 122/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0028 - accuracy: 0.9619 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 123/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0027 - accuracy: 0.9674 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 124/160\n",
            "87/87 [==============================] - 0s 387us/step - loss: 0.0027 - accuracy: 0.9758 - val_loss: 0.0032 - val_accuracy: 0.9688\n",
            "Epoch 125/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0026 - accuracy: 0.9766 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 126/160\n",
            "87/87 [==============================] - 0s 378us/step - loss: 0.0026 - accuracy: 0.9664 - val_loss: 0.0031 - val_accuracy: 0.9688\n",
            "Epoch 127/160\n",
            "87/87 [==============================] - 0s 387us/step - loss: 0.0027 - accuracy: 0.9778 - val_loss: 0.0029 - val_accuracy: 0.9792\n",
            "Epoch 128/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0023 - accuracy: 0.9777 - val_loss: 0.0030 - val_accuracy: 0.9792\n",
            "Epoch 129/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0027 - accuracy: 0.9779 - val_loss: 0.0030 - val_accuracy: 0.9688\n",
            "Epoch 130/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0023 - accuracy: 0.9772 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 131/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0023 - accuracy: 0.9721 - val_loss: 0.0031 - val_accuracy: 0.9688\n",
            "Epoch 132/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0024 - accuracy: 0.9794 - val_loss: 0.0029 - val_accuracy: 0.9583\n",
            "Epoch 133/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0024 - accuracy: 0.9755 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 134/160\n",
            "87/87 [==============================] - 0s 461us/step - loss: 0.0024 - accuracy: 0.9767 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 135/160\n",
            "87/87 [==============================] - 0s 440us/step - loss: 0.0024 - accuracy: 0.9692 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 136/160\n",
            "87/87 [==============================] - 0s 455us/step - loss: 0.0024 - accuracy: 0.9748 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 137/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0025 - accuracy: 0.9773 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 138/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0026 - accuracy: 0.9633 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 139/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0024 - accuracy: 0.9754 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 140/160\n",
            "87/87 [==============================] - 0s 439us/step - loss: 0.0026 - accuracy: 0.9749 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 141/160\n",
            "87/87 [==============================] - 0s 440us/step - loss: 0.0024 - accuracy: 0.9778 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 142/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0023 - accuracy: 0.9778 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 143/160\n",
            "87/87 [==============================] - 0s 493us/step - loss: 0.0025 - accuracy: 0.9868 - val_loss: 0.0033 - val_accuracy: 0.9688\n",
            "Epoch 144/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0024 - accuracy: 0.9797 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 145/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0027 - accuracy: 0.9744 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 146/160\n",
            "87/87 [==============================] - 0s 461us/step - loss: 0.0025 - accuracy: 0.9676 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 147/160\n",
            "87/87 [==============================] - 0s 462us/step - loss: 0.0026 - accuracy: 0.9823 - val_loss: 0.0027 - val_accuracy: 0.9688\n",
            "Epoch 148/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0023 - accuracy: 0.9688 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 149/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0024 - accuracy: 0.9761 - val_loss: 0.0028 - val_accuracy: 0.9688\n",
            "Epoch 150/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0024 - accuracy: 0.9726 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 151/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0023 - accuracy: 0.9731 - val_loss: 0.0027 - val_accuracy: 0.9688\n",
            "Epoch 152/160\n",
            "87/87 [==============================] - 0s 381us/step - loss: 0.0023 - accuracy: 0.9771 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 153/160\n",
            "87/87 [==============================] - 0s 383us/step - loss: 0.0023 - accuracy: 0.9736 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 154/160\n",
            "87/87 [==============================] - 0s 376us/step - loss: 0.0025 - accuracy: 0.9665 - val_loss: 0.0028 - val_accuracy: 0.9792\n",
            "Epoch 155/160\n",
            "87/87 [==============================] - 0s 379us/step - loss: 0.0022 - accuracy: 0.9747 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 156/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0025 - accuracy: 0.9674 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 157/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0022 - accuracy: 0.9795 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "Epoch 158/160\n",
            "87/87 [==============================] - 0s 385us/step - loss: 0.0022 - accuracy: 0.9820 - val_loss: 0.0026 - val_accuracy: 0.9688\n",
            "Epoch 159/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0023 - accuracy: 0.9763 - val_loss: 0.0029 - val_accuracy: 0.9688\n",
            "Epoch 160/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0022 - accuracy: 0.9830 - val_loss: 0.0027 - val_accuracy: 0.9792\n",
            "3/3 [==============================] - 0s 540us/step - loss: 0.0027 - accuracy: 0.9792\n",
            "Loss = 0.002650673734024167, rmse = 0.9791666865348816\n",
            "Loss array:  [0.002609268995001912, 0.0022859082091599703, 0.0018555676797404885, 0.002085859654471278, 0.004930993542075157, 0.003450318006798625, 0.002650673734024167]\n",
            "####################### Iteration   7  #######################\n",
            "Epoch 1/160\n",
            "87/87 [==============================] - 0s 816us/step - loss: 0.3543 - accuracy: 0.6353 - val_loss: 0.1613 - val_accuracy: 0.6000\n",
            "Epoch 2/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.1282 - accuracy: 0.6326 - val_loss: 0.0479 - val_accuracy: 0.6737\n",
            "Epoch 3/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0396 - accuracy: 0.7400 - val_loss: 0.0247 - val_accuracy: 0.8421\n",
            "Epoch 4/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0206 - accuracy: 0.8656 - val_loss: 0.0168 - val_accuracy: 0.9263\n",
            "Epoch 5/160\n",
            "87/87 [==============================] - 0s 379us/step - loss: 0.0163 - accuracy: 0.9292 - val_loss: 0.0143 - val_accuracy: 0.9684\n",
            "Epoch 6/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0134 - accuracy: 0.9403 - val_loss: 0.0135 - val_accuracy: 0.9684\n",
            "Epoch 7/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0137 - accuracy: 0.9462 - val_loss: 0.0124 - val_accuracy: 0.9789\n",
            "Epoch 8/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0113 - accuracy: 0.9492 - val_loss: 0.0115 - val_accuracy: 0.9789\n",
            "Epoch 9/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0115 - accuracy: 0.9528 - val_loss: 0.0111 - val_accuracy: 0.9684\n",
            "Epoch 10/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0100 - accuracy: 0.9440 - val_loss: 0.0100 - val_accuracy: 0.9579\n",
            "Epoch 11/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0100 - accuracy: 0.9422 - val_loss: 0.0094 - val_accuracy: 0.9579\n",
            "Epoch 12/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0092 - accuracy: 0.9534 - val_loss: 0.0093 - val_accuracy: 0.9579\n",
            "Epoch 13/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0087 - accuracy: 0.9505 - val_loss: 0.0085 - val_accuracy: 0.9579\n",
            "Epoch 14/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0081 - accuracy: 0.9620 - val_loss: 0.0083 - val_accuracy: 0.9579\n",
            "Epoch 15/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0085 - accuracy: 0.9551 - val_loss: 0.0081 - val_accuracy: 0.9474\n",
            "Epoch 16/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0078 - accuracy: 0.9622 - val_loss: 0.0076 - val_accuracy: 0.9579\n",
            "Epoch 17/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0073 - accuracy: 0.9471 - val_loss: 0.0075 - val_accuracy: 0.9474\n",
            "Epoch 18/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0069 - accuracy: 0.9623 - val_loss: 0.0074 - val_accuracy: 0.9474\n",
            "Epoch 19/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0067 - accuracy: 0.9601 - val_loss: 0.0069 - val_accuracy: 0.9474\n",
            "Epoch 20/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0065 - accuracy: 0.9490 - val_loss: 0.0066 - val_accuracy: 0.9579\n",
            "Epoch 21/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0063 - accuracy: 0.9581 - val_loss: 0.0067 - val_accuracy: 0.9474\n",
            "Epoch 22/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0061 - accuracy: 0.9521 - val_loss: 0.0064 - val_accuracy: 0.9474\n",
            "Epoch 23/160\n",
            "87/87 [==============================] - 0s 384us/step - loss: 0.0062 - accuracy: 0.9501 - val_loss: 0.0062 - val_accuracy: 0.9474\n",
            "Epoch 24/160\n",
            "87/87 [==============================] - 0s 375us/step - loss: 0.0054 - accuracy: 0.9668 - val_loss: 0.0062 - val_accuracy: 0.9474\n",
            "Epoch 25/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0057 - accuracy: 0.9739 - val_loss: 0.0058 - val_accuracy: 0.9579\n",
            "Epoch 26/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0053 - accuracy: 0.9579 - val_loss: 0.0058 - val_accuracy: 0.9579\n",
            "Epoch 27/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0057 - accuracy: 0.9696 - val_loss: 0.0055 - val_accuracy: 0.9579\n",
            "Epoch 28/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0053 - accuracy: 0.9713 - val_loss: 0.0056 - val_accuracy: 0.9474\n",
            "Epoch 29/160\n",
            "87/87 [==============================] - 0s 388us/step - loss: 0.0053 - accuracy: 0.9536 - val_loss: 0.0054 - val_accuracy: 0.9579\n",
            "Epoch 30/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0052 - accuracy: 0.9767 - val_loss: 0.0052 - val_accuracy: 0.9579\n",
            "Epoch 31/160\n",
            "87/87 [==============================] - 0s 420us/step - loss: 0.0049 - accuracy: 0.9642 - val_loss: 0.0052 - val_accuracy: 0.9579\n",
            "Epoch 32/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0048 - accuracy: 0.9726 - val_loss: 0.0053 - val_accuracy: 0.9474\n",
            "Epoch 33/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0045 - accuracy: 0.9605 - val_loss: 0.0053 - val_accuracy: 0.9579\n",
            "Epoch 34/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0046 - accuracy: 0.9634 - val_loss: 0.0049 - val_accuracy: 0.9579\n",
            "Epoch 35/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0049 - accuracy: 0.9682 - val_loss: 0.0049 - val_accuracy: 0.9579\n",
            "Epoch 36/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0040 - accuracy: 0.9603 - val_loss: 0.0047 - val_accuracy: 0.9579\n",
            "Epoch 37/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0041 - accuracy: 0.9654 - val_loss: 0.0048 - val_accuracy: 0.9579\n",
            "Epoch 38/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0044 - accuracy: 0.9576 - val_loss: 0.0049 - val_accuracy: 0.9579\n",
            "Epoch 39/160\n",
            "87/87 [==============================] - 0s 376us/step - loss: 0.0045 - accuracy: 0.9554 - val_loss: 0.0050 - val_accuracy: 0.9474\n",
            "Epoch 40/160\n",
            "87/87 [==============================] - 0s 375us/step - loss: 0.0041 - accuracy: 0.9671 - val_loss: 0.0048 - val_accuracy: 0.9474\n",
            "Epoch 41/160\n",
            "87/87 [==============================] - 0s 377us/step - loss: 0.0041 - accuracy: 0.9718 - val_loss: 0.0047 - val_accuracy: 0.9579\n",
            "Epoch 42/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0045 - accuracy: 0.9599 - val_loss: 0.0047 - val_accuracy: 0.9579\n",
            "Epoch 43/160\n",
            "87/87 [==============================] - 0s 380us/step - loss: 0.0039 - accuracy: 0.9726 - val_loss: 0.0045 - val_accuracy: 0.9474\n",
            "Epoch 44/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0039 - accuracy: 0.9612 - val_loss: 0.0045 - val_accuracy: 0.9579\n",
            "Epoch 45/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0038 - accuracy: 0.9709 - val_loss: 0.0044 - val_accuracy: 0.9474\n",
            "Epoch 46/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0038 - accuracy: 0.9635 - val_loss: 0.0044 - val_accuracy: 0.9579\n",
            "Epoch 47/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0039 - accuracy: 0.9702 - val_loss: 0.0044 - val_accuracy: 0.9474\n",
            "Epoch 48/160\n",
            "87/87 [==============================] - 0s 452us/step - loss: 0.0033 - accuracy: 0.9749 - val_loss: 0.0042 - val_accuracy: 0.9579\n",
            "Epoch 49/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0035 - accuracy: 0.9581 - val_loss: 0.0049 - val_accuracy: 0.9579\n",
            "Epoch 50/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0036 - accuracy: 0.9702 - val_loss: 0.0044 - val_accuracy: 0.9474\n",
            "Epoch 51/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0038 - accuracy: 0.9701 - val_loss: 0.0043 - val_accuracy: 0.9474\n",
            "Epoch 52/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0037 - accuracy: 0.9593 - val_loss: 0.0043 - val_accuracy: 0.9474\n",
            "Epoch 53/160\n",
            "87/87 [==============================] - 0s 545us/step - loss: 0.0032 - accuracy: 0.9729 - val_loss: 0.0043 - val_accuracy: 0.9579\n",
            "Epoch 54/160\n",
            "87/87 [==============================] - 0s 459us/step - loss: 0.0036 - accuracy: 0.9670 - val_loss: 0.0042 - val_accuracy: 0.9474\n",
            "Epoch 55/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0033 - accuracy: 0.9694 - val_loss: 0.0041 - val_accuracy: 0.9474\n",
            "Epoch 56/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0032 - accuracy: 0.9714 - val_loss: 0.0041 - val_accuracy: 0.9474\n",
            "Epoch 57/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0035 - accuracy: 0.9566 - val_loss: 0.0041 - val_accuracy: 0.9474\n",
            "Epoch 58/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0034 - accuracy: 0.9631 - val_loss: 0.0041 - val_accuracy: 0.9474\n",
            "Epoch 59/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0033 - accuracy: 0.9727 - val_loss: 0.0042 - val_accuracy: 0.9368\n",
            "Epoch 60/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0031 - accuracy: 0.9708 - val_loss: 0.0040 - val_accuracy: 0.9474\n",
            "Epoch 61/160\n",
            "87/87 [==============================] - 0s 439us/step - loss: 0.0036 - accuracy: 0.9678 - val_loss: 0.0042 - val_accuracy: 0.9474\n",
            "Epoch 62/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0032 - accuracy: 0.9689 - val_loss: 0.0043 - val_accuracy: 0.9474\n",
            "Epoch 63/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0031 - accuracy: 0.9675 - val_loss: 0.0041 - val_accuracy: 0.9474\n",
            "Epoch 64/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0032 - accuracy: 0.9694 - val_loss: 0.0040 - val_accuracy: 0.9474\n",
            "Epoch 65/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0030 - accuracy: 0.9660 - val_loss: 0.0040 - val_accuracy: 0.9474\n",
            "Epoch 66/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0033 - accuracy: 0.9666 - val_loss: 0.0046 - val_accuracy: 0.9474\n",
            "Epoch 67/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0031 - accuracy: 0.9749 - val_loss: 0.0040 - val_accuracy: 0.9474\n",
            "Epoch 68/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0031 - accuracy: 0.9638 - val_loss: 0.0040 - val_accuracy: 0.9474\n",
            "Epoch 69/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0030 - accuracy: 0.9657 - val_loss: 0.0041 - val_accuracy: 0.9474\n",
            "Epoch 70/160\n",
            "87/87 [==============================] - 0s 439us/step - loss: 0.0028 - accuracy: 0.9707 - val_loss: 0.0039 - val_accuracy: 0.9474\n",
            "Epoch 71/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0029 - accuracy: 0.9642 - val_loss: 0.0040 - val_accuracy: 0.9474\n",
            "Epoch 72/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0029 - accuracy: 0.9624 - val_loss: 0.0040 - val_accuracy: 0.9474\n",
            "Epoch 73/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0032 - accuracy: 0.9667 - val_loss: 0.0042 - val_accuracy: 0.9474\n",
            "Epoch 74/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0030 - accuracy: 0.9697 - val_loss: 0.0039 - val_accuracy: 0.9474\n",
            "Epoch 75/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0027 - accuracy: 0.9587 - val_loss: 0.0038 - val_accuracy: 0.9474\n",
            "Epoch 76/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0029 - accuracy: 0.9735 - val_loss: 0.0042 - val_accuracy: 0.9579\n",
            "Epoch 77/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0028 - accuracy: 0.9637 - val_loss: 0.0040 - val_accuracy: 0.9474\n",
            "Epoch 78/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0027 - accuracy: 0.9720 - val_loss: 0.0039 - val_accuracy: 0.9474\n",
            "Epoch 79/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0028 - accuracy: 0.9693 - val_loss: 0.0038 - val_accuracy: 0.9474\n",
            "Epoch 80/160\n",
            "87/87 [==============================] - 0s 457us/step - loss: 0.0030 - accuracy: 0.9656 - val_loss: 0.0039 - val_accuracy: 0.9474\n",
            "Epoch 81/160\n",
            "87/87 [==============================] - 0s 447us/step - loss: 0.0027 - accuracy: 0.9645 - val_loss: 0.0038 - val_accuracy: 0.9474\n",
            "Epoch 82/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0025 - accuracy: 0.9673 - val_loss: 0.0038 - val_accuracy: 0.9474\n",
            "Epoch 83/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0027 - accuracy: 0.9619 - val_loss: 0.0038 - val_accuracy: 0.9474\n",
            "Epoch 84/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0027 - accuracy: 0.9785 - val_loss: 0.0038 - val_accuracy: 0.9474\n",
            "Epoch 85/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0030 - accuracy: 0.9764 - val_loss: 0.0038 - val_accuracy: 0.9474\n",
            "Epoch 86/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0026 - accuracy: 0.9676 - val_loss: 0.0037 - val_accuracy: 0.9474\n",
            "Epoch 87/160\n",
            "87/87 [==============================] - 0s 444us/step - loss: 0.0026 - accuracy: 0.9731 - val_loss: 0.0039 - val_accuracy: 0.9474\n",
            "Epoch 88/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0027 - accuracy: 0.9662 - val_loss: 0.0040 - val_accuracy: 0.9368\n",
            "Epoch 89/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0027 - accuracy: 0.9686 - val_loss: 0.0037 - val_accuracy: 0.9474\n",
            "Epoch 90/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0024 - accuracy: 0.9648 - val_loss: 0.0038 - val_accuracy: 0.9474\n",
            "Epoch 91/160\n",
            "87/87 [==============================] - 0s 459us/step - loss: 0.0026 - accuracy: 0.9693 - val_loss: 0.0040 - val_accuracy: 0.9579\n",
            "Epoch 92/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0027 - accuracy: 0.9634 - val_loss: 0.0041 - val_accuracy: 0.9474\n",
            "Epoch 93/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0025 - accuracy: 0.9645 - val_loss: 0.0035 - val_accuracy: 0.9368\n",
            "Epoch 94/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0024 - accuracy: 0.9714 - val_loss: 0.0038 - val_accuracy: 0.9474\n",
            "Epoch 95/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0024 - accuracy: 0.9779 - val_loss: 0.0037 - val_accuracy: 0.9579\n",
            "Epoch 96/160\n",
            "87/87 [==============================] - 0s 494us/step - loss: 0.0025 - accuracy: 0.9693 - val_loss: 0.0036 - val_accuracy: 0.9368\n",
            "Epoch 97/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0026 - accuracy: 0.9704 - val_loss: 0.0037 - val_accuracy: 0.9579\n",
            "Epoch 98/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0025 - accuracy: 0.9707 - val_loss: 0.0037 - val_accuracy: 0.9474\n",
            "Epoch 99/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0025 - accuracy: 0.9715 - val_loss: 0.0038 - val_accuracy: 0.9579\n",
            "Epoch 100/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0026 - accuracy: 0.9767 - val_loss: 0.0040 - val_accuracy: 0.9263\n",
            "Epoch 101/160\n",
            "87/87 [==============================] - 0s 462us/step - loss: 0.0027 - accuracy: 0.9803 - val_loss: 0.0039 - val_accuracy: 0.9579\n",
            "Epoch 102/160\n",
            "87/87 [==============================] - 0s 463us/step - loss: 0.0025 - accuracy: 0.9632 - val_loss: 0.0036 - val_accuracy: 0.9368\n",
            "Epoch 103/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0023 - accuracy: 0.9632 - val_loss: 0.0037 - val_accuracy: 0.9474\n",
            "Epoch 104/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0025 - accuracy: 0.9777 - val_loss: 0.0037 - val_accuracy: 0.9368\n",
            "Epoch 105/160\n",
            "87/87 [==============================] - 0s 457us/step - loss: 0.0023 - accuracy: 0.9643 - val_loss: 0.0038 - val_accuracy: 0.9474\n",
            "Epoch 106/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0025 - accuracy: 0.9750 - val_loss: 0.0037 - val_accuracy: 0.9579\n",
            "Epoch 107/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0025 - accuracy: 0.9696 - val_loss: 0.0035 - val_accuracy: 0.9579\n",
            "Epoch 108/160\n",
            "87/87 [==============================] - 0s 493us/step - loss: 0.0023 - accuracy: 0.9765 - val_loss: 0.0038 - val_accuracy: 0.9368\n",
            "Epoch 109/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0026 - accuracy: 0.9642 - val_loss: 0.0036 - val_accuracy: 0.9474\n",
            "Epoch 110/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0023 - accuracy: 0.9763 - val_loss: 0.0036 - val_accuracy: 0.9474\n",
            "Epoch 111/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0025 - accuracy: 0.9673 - val_loss: 0.0036 - val_accuracy: 0.9474\n",
            "Epoch 112/160\n",
            "87/87 [==============================] - 0s 458us/step - loss: 0.0025 - accuracy: 0.9683 - val_loss: 0.0035 - val_accuracy: 0.9579\n",
            "Epoch 113/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0021 - accuracy: 0.9768 - val_loss: 0.0036 - val_accuracy: 0.9474\n",
            "Epoch 114/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0023 - accuracy: 0.9673 - val_loss: 0.0036 - val_accuracy: 0.9579\n",
            "Epoch 115/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0021 - accuracy: 0.9714 - val_loss: 0.0035 - val_accuracy: 0.9579\n",
            "Epoch 116/160\n",
            "87/87 [==============================] - 0s 469us/step - loss: 0.0022 - accuracy: 0.9691 - val_loss: 0.0039 - val_accuracy: 0.9579\n",
            "Epoch 117/160\n",
            "87/87 [==============================] - 0s 460us/step - loss: 0.0023 - accuracy: 0.9748 - val_loss: 0.0036 - val_accuracy: 0.9579\n",
            "Epoch 118/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0022 - accuracy: 0.9722 - val_loss: 0.0035 - val_accuracy: 0.9474\n",
            "Epoch 119/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0025 - accuracy: 0.9685 - val_loss: 0.0035 - val_accuracy: 0.9579\n",
            "Epoch 120/160\n",
            "87/87 [==============================] - 0s 450us/step - loss: 0.0022 - accuracy: 0.9725 - val_loss: 0.0036 - val_accuracy: 0.9368\n",
            "Epoch 121/160\n",
            "87/87 [==============================] - 0s 451us/step - loss: 0.0022 - accuracy: 0.9656 - val_loss: 0.0034 - val_accuracy: 0.9579\n",
            "Epoch 122/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0023 - accuracy: 0.9697 - val_loss: 0.0036 - val_accuracy: 0.9368\n",
            "Epoch 123/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0022 - accuracy: 0.9671 - val_loss: 0.0035 - val_accuracy: 0.9579\n",
            "Epoch 124/160\n",
            "87/87 [==============================] - 0s 452us/step - loss: 0.0022 - accuracy: 0.9782 - val_loss: 0.0035 - val_accuracy: 0.9474\n",
            "Epoch 125/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0024 - accuracy: 0.9705 - val_loss: 0.0035 - val_accuracy: 0.9474\n",
            "Epoch 126/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0026 - accuracy: 0.9577 - val_loss: 0.0036 - val_accuracy: 0.9579\n",
            "Epoch 127/160\n",
            "87/87 [==============================] - 0s 509us/step - loss: 0.0021 - accuracy: 0.9716 - val_loss: 0.0035 - val_accuracy: 0.9579\n",
            "Epoch 128/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0022 - accuracy: 0.9715 - val_loss: 0.0034 - val_accuracy: 0.9579\n",
            "Epoch 129/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0019 - accuracy: 0.9663 - val_loss: 0.0035 - val_accuracy: 0.9579\n",
            "Epoch 130/160\n",
            "87/87 [==============================] - 0s 454us/step - loss: 0.0021 - accuracy: 0.9713 - val_loss: 0.0035 - val_accuracy: 0.9368\n",
            "Epoch 131/160\n",
            "87/87 [==============================] - 0s 441us/step - loss: 0.0023 - accuracy: 0.9674 - val_loss: 0.0035 - val_accuracy: 0.9579\n",
            "Epoch 132/160\n",
            "87/87 [==============================] - 0s 457us/step - loss: 0.0022 - accuracy: 0.9718 - val_loss: 0.0033 - val_accuracy: 0.9474\n",
            "Epoch 133/160\n",
            "87/87 [==============================] - 0s 487us/step - loss: 0.0019 - accuracy: 0.9823 - val_loss: 0.0033 - val_accuracy: 0.9474\n",
            "Epoch 134/160\n",
            "87/87 [==============================] - 0s 503us/step - loss: 0.0018 - accuracy: 0.9742 - val_loss: 0.0034 - val_accuracy: 0.9368\n",
            "Epoch 135/160\n",
            "87/87 [==============================] - 0s 484us/step - loss: 0.0021 - accuracy: 0.9777 - val_loss: 0.0034 - val_accuracy: 0.9368\n",
            "Epoch 136/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0020 - accuracy: 0.9738 - val_loss: 0.0033 - val_accuracy: 0.9579\n",
            "Epoch 137/160\n",
            "87/87 [==============================] - 0s 476us/step - loss: 0.0020 - accuracy: 0.9749 - val_loss: 0.0033 - val_accuracy: 0.9474\n",
            "Epoch 138/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0022 - accuracy: 0.9715 - val_loss: 0.0034 - val_accuracy: 0.9368\n",
            "Epoch 139/160\n",
            "87/87 [==============================] - 0s 484us/step - loss: 0.0022 - accuracy: 0.9685 - val_loss: 0.0034 - val_accuracy: 0.9579\n",
            "Epoch 140/160\n",
            "87/87 [==============================] - 0s 486us/step - loss: 0.0020 - accuracy: 0.9778 - val_loss: 0.0034 - val_accuracy: 0.9579\n",
            "Epoch 141/160\n",
            "87/87 [==============================] - 0s 467us/step - loss: 0.0020 - accuracy: 0.9615 - val_loss: 0.0035 - val_accuracy: 0.9474\n",
            "Epoch 142/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0022 - accuracy: 0.9630 - val_loss: 0.0034 - val_accuracy: 0.9368\n",
            "Epoch 143/160\n",
            "87/87 [==============================] - 0s 453us/step - loss: 0.0021 - accuracy: 0.9736 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 144/160\n",
            "87/87 [==============================] - 0s 463us/step - loss: 0.0018 - accuracy: 0.9701 - val_loss: 0.0036 - val_accuracy: 0.9368\n",
            "Epoch 145/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0021 - accuracy: 0.9779 - val_loss: 0.0033 - val_accuracy: 0.9579\n",
            "Epoch 146/160\n",
            "87/87 [==============================] - 0s 439us/step - loss: 0.0020 - accuracy: 0.9646 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 147/160\n",
            "87/87 [==============================] - 0s 448us/step - loss: 0.0021 - accuracy: 0.9797 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 148/160\n",
            "87/87 [==============================] - 0s 447us/step - loss: 0.0023 - accuracy: 0.9663 - val_loss: 0.0035 - val_accuracy: 0.9579\n",
            "Epoch 149/160\n",
            "87/87 [==============================] - 0s 460us/step - loss: 0.0019 - accuracy: 0.9616 - val_loss: 0.0033 - val_accuracy: 0.9474\n",
            "Epoch 150/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0020 - accuracy: 0.9804 - val_loss: 0.0036 - val_accuracy: 0.9368\n",
            "Epoch 151/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0021 - accuracy: 0.9684 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 152/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0020 - accuracy: 0.9708 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 153/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0019 - accuracy: 0.9815 - val_loss: 0.0034 - val_accuracy: 0.9579\n",
            "Epoch 154/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0022 - accuracy: 0.9760 - val_loss: 0.0035 - val_accuracy: 0.9579\n",
            "Epoch 155/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0020 - accuracy: 0.9757 - val_loss: 0.0036 - val_accuracy: 0.9579\n",
            "Epoch 156/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0023 - accuracy: 0.9696 - val_loss: 0.0033 - val_accuracy: 0.9474\n",
            "Epoch 157/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0018 - accuracy: 0.9687 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 158/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0020 - accuracy: 0.9673 - val_loss: 0.0034 - val_accuracy: 0.9579\n",
            "Epoch 159/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0021 - accuracy: 0.9639 - val_loss: 0.0034 - val_accuracy: 0.9579\n",
            "Epoch 160/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0021 - accuracy: 0.9619 - val_loss: 0.0034 - val_accuracy: 0.9579\n",
            "3/3 [==============================] - 0s 366us/step - loss: 0.0034 - accuracy: 0.9579\n",
            "Loss = 0.003421371802687645, rmse = 0.9578947424888611\n",
            "Loss array:  [0.002609268995001912, 0.0022859082091599703, 0.0018555676797404885, 0.002085859654471278, 0.004930993542075157, 0.003450318006798625, 0.002650673734024167, 0.003421371802687645]\n",
            "####################### Iteration   8  #######################\n",
            "Epoch 1/160\n",
            "87/87 [==============================] - 0s 813us/step - loss: 0.4674 - accuracy: 0.5461 - val_loss: 0.1988 - val_accuracy: 0.5053\n",
            "Epoch 2/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.1399 - accuracy: 0.6208 - val_loss: 0.0553 - val_accuracy: 0.7684\n",
            "Epoch 3/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0453 - accuracy: 0.8010 - val_loss: 0.0280 - val_accuracy: 0.7789\n",
            "Epoch 4/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0251 - accuracy: 0.8366 - val_loss: 0.0183 - val_accuracy: 0.8842\n",
            "Epoch 5/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0209 - accuracy: 0.9199 - val_loss: 0.0150 - val_accuracy: 0.9263\n",
            "Epoch 6/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0170 - accuracy: 0.9172 - val_loss: 0.0141 - val_accuracy: 0.9263\n",
            "Epoch 7/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0170 - accuracy: 0.9340 - val_loss: 0.0135 - val_accuracy: 0.9158\n",
            "Epoch 8/160\n",
            "87/87 [==============================] - 0s 454us/step - loss: 0.0153 - accuracy: 0.9353 - val_loss: 0.0131 - val_accuracy: 0.9158\n",
            "Epoch 9/160\n",
            "87/87 [==============================] - 0s 482us/step - loss: 0.0152 - accuracy: 0.9165 - val_loss: 0.0130 - val_accuracy: 0.9158\n",
            "Epoch 10/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0142 - accuracy: 0.9295 - val_loss: 0.0126 - val_accuracy: 0.9263\n",
            "Epoch 11/160\n",
            "87/87 [==============================] - 0s 484us/step - loss: 0.0145 - accuracy: 0.9432 - val_loss: 0.0125 - val_accuracy: 0.9263\n",
            "Epoch 12/160\n",
            "87/87 [==============================] - 0s 447us/step - loss: 0.0140 - accuracy: 0.9454 - val_loss: 0.0122 - val_accuracy: 0.9263\n",
            "Epoch 13/160\n",
            "87/87 [==============================] - 0s 447us/step - loss: 0.0129 - accuracy: 0.9369 - val_loss: 0.0119 - val_accuracy: 0.9263\n",
            "Epoch 14/160\n",
            "87/87 [==============================] - 0s 471us/step - loss: 0.0124 - accuracy: 0.9601 - val_loss: 0.0116 - val_accuracy: 0.9263\n",
            "Epoch 15/160\n",
            "87/87 [==============================] - 0s 487us/step - loss: 0.0129 - accuracy: 0.9603 - val_loss: 0.0114 - val_accuracy: 0.9263\n",
            "Epoch 16/160\n",
            "87/87 [==============================] - 0s 483us/step - loss: 0.0124 - accuracy: 0.9559 - val_loss: 0.0110 - val_accuracy: 0.9263\n",
            "Epoch 17/160\n",
            "87/87 [==============================] - 0s 444us/step - loss: 0.0117 - accuracy: 0.9489 - val_loss: 0.0107 - val_accuracy: 0.9263\n",
            "Epoch 18/160\n",
            "87/87 [==============================] - 0s 495us/step - loss: 0.0107 - accuracy: 0.9616 - val_loss: 0.0103 - val_accuracy: 0.9368\n",
            "Epoch 19/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0109 - accuracy: 0.9572 - val_loss: 0.0101 - val_accuracy: 0.9263\n",
            "Epoch 20/160\n",
            "87/87 [==============================] - 0s 446us/step - loss: 0.0108 - accuracy: 0.9522 - val_loss: 0.0098 - val_accuracy: 0.9158\n",
            "Epoch 21/160\n",
            "87/87 [==============================] - 0s 485us/step - loss: 0.0102 - accuracy: 0.9629 - val_loss: 0.0095 - val_accuracy: 0.9263\n",
            "Epoch 22/160\n",
            "87/87 [==============================] - 0s 506us/step - loss: 0.0100 - accuracy: 0.9529 - val_loss: 0.0092 - val_accuracy: 0.9158\n",
            "Epoch 23/160\n",
            "87/87 [==============================] - 0s 502us/step - loss: 0.0099 - accuracy: 0.9525 - val_loss: 0.0091 - val_accuracy: 0.8947\n",
            "Epoch 24/160\n",
            "87/87 [==============================] - 0s 482us/step - loss: 0.0087 - accuracy: 0.9639 - val_loss: 0.0088 - val_accuracy: 0.9263\n",
            "Epoch 25/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0091 - accuracy: 0.9663 - val_loss: 0.0085 - val_accuracy: 0.9263\n",
            "Epoch 26/160\n",
            "87/87 [==============================] - 0s 464us/step - loss: 0.0086 - accuracy: 0.9574 - val_loss: 0.0085 - val_accuracy: 0.8947\n",
            "Epoch 27/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0092 - accuracy: 0.9619 - val_loss: 0.0082 - val_accuracy: 0.9158\n",
            "Epoch 28/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0082 - accuracy: 0.9672 - val_loss: 0.0078 - val_accuracy: 0.9263\n",
            "Epoch 29/160\n",
            "87/87 [==============================] - 0s 451us/step - loss: 0.0083 - accuracy: 0.9622 - val_loss: 0.0076 - val_accuracy: 0.9263\n",
            "Epoch 30/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0078 - accuracy: 0.9677 - val_loss: 0.0074 - val_accuracy: 0.9158\n",
            "Epoch 31/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0078 - accuracy: 0.9689 - val_loss: 0.0072 - val_accuracy: 0.9368\n",
            "Epoch 32/160\n",
            "87/87 [==============================] - 0s 518us/step - loss: 0.0070 - accuracy: 0.9725 - val_loss: 0.0070 - val_accuracy: 0.9158\n",
            "Epoch 33/160\n",
            "87/87 [==============================] - 0s 460us/step - loss: 0.0068 - accuracy: 0.9692 - val_loss: 0.0067 - val_accuracy: 0.9158\n",
            "Epoch 34/160\n",
            "87/87 [==============================] - 0s 443us/step - loss: 0.0067 - accuracy: 0.9671 - val_loss: 0.0066 - val_accuracy: 0.9368\n",
            "Epoch 35/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0069 - accuracy: 0.9681 - val_loss: 0.0064 - val_accuracy: 0.9368\n",
            "Epoch 36/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0061 - accuracy: 0.9544 - val_loss: 0.0064 - val_accuracy: 0.9263\n",
            "Epoch 37/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0058 - accuracy: 0.9667 - val_loss: 0.0064 - val_accuracy: 0.9263\n",
            "Epoch 38/160\n",
            "87/87 [==============================] - 0s 522us/step - loss: 0.0062 - accuracy: 0.9686 - val_loss: 0.0063 - val_accuracy: 0.9368\n",
            "Epoch 39/160\n",
            "87/87 [==============================] - 0s 467us/step - loss: 0.0063 - accuracy: 0.9509 - val_loss: 0.0059 - val_accuracy: 0.9368\n",
            "Epoch 40/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0057 - accuracy: 0.9642 - val_loss: 0.0056 - val_accuracy: 0.9368\n",
            "Epoch 41/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0058 - accuracy: 0.9767 - val_loss: 0.0056 - val_accuracy: 0.9368\n",
            "Epoch 42/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0058 - accuracy: 0.9647 - val_loss: 0.0056 - val_accuracy: 0.9368\n",
            "Epoch 43/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0051 - accuracy: 0.9757 - val_loss: 0.0053 - val_accuracy: 0.9368\n",
            "Epoch 44/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0051 - accuracy: 0.9602 - val_loss: 0.0054 - val_accuracy: 0.9368\n",
            "Epoch 45/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0049 - accuracy: 0.9811 - val_loss: 0.0052 - val_accuracy: 0.9368\n",
            "Epoch 46/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0051 - accuracy: 0.9606 - val_loss: 0.0049 - val_accuracy: 0.9368\n",
            "Epoch 47/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0048 - accuracy: 0.9713 - val_loss: 0.0048 - val_accuracy: 0.9368\n",
            "Epoch 48/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0041 - accuracy: 0.9770 - val_loss: 0.0047 - val_accuracy: 0.9368\n",
            "Epoch 49/160\n",
            "87/87 [==============================] - 0s 515us/step - loss: 0.0046 - accuracy: 0.9691 - val_loss: 0.0059 - val_accuracy: 0.9368\n",
            "Epoch 50/160\n",
            "87/87 [==============================] - 0s 475us/step - loss: 0.0048 - accuracy: 0.9809 - val_loss: 0.0045 - val_accuracy: 0.9368\n",
            "Epoch 51/160\n",
            "87/87 [==============================] - 0s 435us/step - loss: 0.0048 - accuracy: 0.9807 - val_loss: 0.0046 - val_accuracy: 0.9368\n",
            "Epoch 52/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0044 - accuracy: 0.9708 - val_loss: 0.0044 - val_accuracy: 0.9368\n",
            "Epoch 53/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0038 - accuracy: 0.9785 - val_loss: 0.0048 - val_accuracy: 0.9368\n",
            "Epoch 54/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0046 - accuracy: 0.9733 - val_loss: 0.0042 - val_accuracy: 0.9368\n",
            "Epoch 55/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0038 - accuracy: 0.9829 - val_loss: 0.0043 - val_accuracy: 0.9263\n",
            "Epoch 56/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0039 - accuracy: 0.9782 - val_loss: 0.0046 - val_accuracy: 0.9368\n",
            "Epoch 57/160\n",
            "87/87 [==============================] - 0s 418us/step - loss: 0.0040 - accuracy: 0.9727 - val_loss: 0.0040 - val_accuracy: 0.9368\n",
            "Epoch 58/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0040 - accuracy: 0.9718 - val_loss: 0.0040 - val_accuracy: 0.9368\n",
            "Epoch 59/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0040 - accuracy: 0.9710 - val_loss: 0.0042 - val_accuracy: 0.9368\n",
            "Epoch 60/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0037 - accuracy: 0.9799 - val_loss: 0.0040 - val_accuracy: 0.9368\n",
            "Epoch 61/160\n",
            "87/87 [==============================] - 0s 492us/step - loss: 0.0041 - accuracy: 0.9737 - val_loss: 0.0039 - val_accuracy: 0.9368\n",
            "Epoch 62/160\n",
            "87/87 [==============================] - 0s 470us/step - loss: 0.0035 - accuracy: 0.9706 - val_loss: 0.0041 - val_accuracy: 0.9368\n",
            "Epoch 63/160\n",
            "87/87 [==============================] - 0s 459us/step - loss: 0.0035 - accuracy: 0.9729 - val_loss: 0.0041 - val_accuracy: 0.9368\n",
            "Epoch 64/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0036 - accuracy: 0.9734 - val_loss: 0.0037 - val_accuracy: 0.9368\n",
            "Epoch 65/160\n",
            "87/87 [==============================] - 0s 443us/step - loss: 0.0035 - accuracy: 0.9666 - val_loss: 0.0037 - val_accuracy: 0.9368\n",
            "Epoch 66/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0036 - accuracy: 0.9754 - val_loss: 0.0039 - val_accuracy: 0.9263\n",
            "Epoch 67/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0036 - accuracy: 0.9817 - val_loss: 0.0036 - val_accuracy: 0.9368\n",
            "Epoch 68/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0037 - accuracy: 0.9660 - val_loss: 0.0038 - val_accuracy: 0.9368\n",
            "Epoch 69/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0034 - accuracy: 0.9736 - val_loss: 0.0036 - val_accuracy: 0.9368\n",
            "Epoch 70/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0031 - accuracy: 0.9769 - val_loss: 0.0036 - val_accuracy: 0.9368\n",
            "Epoch 71/160\n",
            "87/87 [==============================] - 0s 447us/step - loss: 0.0031 - accuracy: 0.9684 - val_loss: 0.0036 - val_accuracy: 0.9368\n",
            "Epoch 72/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0032 - accuracy: 0.9716 - val_loss: 0.0035 - val_accuracy: 0.9368\n",
            "Epoch 73/160\n",
            "87/87 [==============================] - 0s 371us/step - loss: 0.0035 - accuracy: 0.9687 - val_loss: 0.0035 - val_accuracy: 0.9368\n",
            "Epoch 74/160\n",
            "87/87 [==============================] - 0s 381us/step - loss: 0.0032 - accuracy: 0.9798 - val_loss: 0.0035 - val_accuracy: 0.9368\n",
            "Epoch 75/160\n",
            "87/87 [==============================] - 0s 503us/step - loss: 0.0030 - accuracy: 0.9703 - val_loss: 0.0035 - val_accuracy: 0.9474\n",
            "Epoch 76/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0033 - accuracy: 0.9717 - val_loss: 0.0037 - val_accuracy: 0.9263\n",
            "Epoch 77/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0030 - accuracy: 0.9734 - val_loss: 0.0036 - val_accuracy: 0.9474\n",
            "Epoch 78/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0030 - accuracy: 0.9797 - val_loss: 0.0035 - val_accuracy: 0.9368\n",
            "Epoch 79/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0031 - accuracy: 0.9685 - val_loss: 0.0034 - val_accuracy: 0.9368\n",
            "Epoch 80/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0030 - accuracy: 0.9812 - val_loss: 0.0034 - val_accuracy: 0.9368\n",
            "Epoch 81/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0030 - accuracy: 0.9734 - val_loss: 0.0035 - val_accuracy: 0.9368\n",
            "Epoch 82/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0029 - accuracy: 0.9722 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 83/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0029 - accuracy: 0.9601 - val_loss: 0.0037 - val_accuracy: 0.9579\n",
            "Epoch 84/160\n",
            "87/87 [==============================] - 0s 437us/step - loss: 0.0030 - accuracy: 0.9824 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 85/160\n",
            "87/87 [==============================] - 0s 501us/step - loss: 0.0031 - accuracy: 0.9816 - val_loss: 0.0033 - val_accuracy: 0.9368\n",
            "Epoch 86/160\n",
            "87/87 [==============================] - 0s 471us/step - loss: 0.0028 - accuracy: 0.9714 - val_loss: 0.0034 - val_accuracy: 0.9368\n",
            "Epoch 87/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0030 - accuracy: 0.9767 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 88/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0031 - accuracy: 0.9731 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 89/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0029 - accuracy: 0.9727 - val_loss: 0.0033 - val_accuracy: 0.9474\n",
            "Epoch 90/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0027 - accuracy: 0.9664 - val_loss: 0.0032 - val_accuracy: 0.9474\n",
            "Epoch 91/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0029 - accuracy: 0.9692 - val_loss: 0.0034 - val_accuracy: 0.9368\n",
            "Epoch 92/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0032 - accuracy: 0.9688 - val_loss: 0.0033 - val_accuracy: 0.9368\n",
            "Epoch 93/160\n",
            "87/87 [==============================] - 0s 439us/step - loss: 0.0027 - accuracy: 0.9737 - val_loss: 0.0032 - val_accuracy: 0.9474\n",
            "Epoch 94/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0027 - accuracy: 0.9803 - val_loss: 0.0032 - val_accuracy: 0.9474\n",
            "Epoch 95/160\n",
            "87/87 [==============================] - 0s 450us/step - loss: 0.0028 - accuracy: 0.9834 - val_loss: 0.0032 - val_accuracy: 0.9474\n",
            "Epoch 96/160\n",
            "87/87 [==============================] - 0s 446us/step - loss: 0.0026 - accuracy: 0.9791 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 97/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0027 - accuracy: 0.9780 - val_loss: 0.0032 - val_accuracy: 0.9368\n",
            "Epoch 98/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0027 - accuracy: 0.9838 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 99/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0028 - accuracy: 0.9754 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 100/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0030 - accuracy: 0.9840 - val_loss: 0.0036 - val_accuracy: 0.9474\n",
            "Epoch 101/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0028 - accuracy: 0.9834 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 102/160\n",
            "87/87 [==============================] - 0s 466us/step - loss: 0.0027 - accuracy: 0.9726 - val_loss: 0.0032 - val_accuracy: 0.9474\n",
            "Epoch 103/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0027 - accuracy: 0.9774 - val_loss: 0.0032 - val_accuracy: 0.9474\n",
            "Epoch 104/160\n",
            "87/87 [==============================] - 0s 377us/step - loss: 0.0028 - accuracy: 0.9791 - val_loss: 0.0035 - val_accuracy: 0.9474\n",
            "Epoch 105/160\n",
            "87/87 [==============================] - 0s 485us/step - loss: 0.0026 - accuracy: 0.9701 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 106/160\n",
            "87/87 [==============================] - 0s 457us/step - loss: 0.0027 - accuracy: 0.9690 - val_loss: 0.0032 - val_accuracy: 0.9474\n",
            "Epoch 107/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0030 - accuracy: 0.9697 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 108/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0026 - accuracy: 0.9717 - val_loss: 0.0035 - val_accuracy: 0.9579\n",
            "Epoch 109/160\n",
            "87/87 [==============================] - 0s 451us/step - loss: 0.0029 - accuracy: 0.9787 - val_loss: 0.0032 - val_accuracy: 0.9579\n",
            "Epoch 110/160\n",
            "87/87 [==============================] - 0s 441us/step - loss: 0.0028 - accuracy: 0.9761 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 111/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0027 - accuracy: 0.9687 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 112/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0029 - accuracy: 0.9702 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 113/160\n",
            "87/87 [==============================] - 0s 470us/step - loss: 0.0024 - accuracy: 0.9750 - val_loss: 0.0036 - val_accuracy: 0.9579\n",
            "Epoch 114/160\n",
            "87/87 [==============================] - 0s 475us/step - loss: 0.0025 - accuracy: 0.9789 - val_loss: 0.0032 - val_accuracy: 0.9474\n",
            "Epoch 115/160\n",
            "87/87 [==============================] - 0s 461us/step - loss: 0.0025 - accuracy: 0.9779 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 116/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0026 - accuracy: 0.9777 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 117/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0026 - accuracy: 0.9774 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 118/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0024 - accuracy: 0.9721 - val_loss: 0.0030 - val_accuracy: 0.9474\n",
            "Epoch 119/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0028 - accuracy: 0.9671 - val_loss: 0.0031 - val_accuracy: 0.9579\n",
            "Epoch 120/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0024 - accuracy: 0.9789 - val_loss: 0.0034 - val_accuracy: 0.9474\n",
            "Epoch 121/160\n",
            "87/87 [==============================] - 0s 443us/step - loss: 0.0024 - accuracy: 0.9779 - val_loss: 0.0031 - val_accuracy: 0.9579\n",
            "Epoch 122/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0024 - accuracy: 0.9715 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 123/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0025 - accuracy: 0.9738 - val_loss: 0.0030 - val_accuracy: 0.9474\n",
            "Epoch 124/160\n",
            "87/87 [==============================] - 0s 433us/step - loss: 0.0026 - accuracy: 0.9808 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 125/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0027 - accuracy: 0.9781 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 126/160\n",
            "87/87 [==============================] - 0s 454us/step - loss: 0.0028 - accuracy: 0.9623 - val_loss: 0.0031 - val_accuracy: 0.9579\n",
            "Epoch 127/160\n",
            "87/87 [==============================] - 0s 521us/step - loss: 0.0024 - accuracy: 0.9791 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 128/160\n",
            "87/87 [==============================] - 0s 504us/step - loss: 0.0026 - accuracy: 0.9729 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 129/160\n",
            "87/87 [==============================] - 0s 450us/step - loss: 0.0023 - accuracy: 0.9680 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 130/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0025 - accuracy: 0.9828 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 131/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0025 - accuracy: 0.9706 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 132/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0024 - accuracy: 0.9791 - val_loss: 0.0029 - val_accuracy: 0.9579\n",
            "Epoch 133/160\n",
            "87/87 [==============================] - 0s 454us/step - loss: 0.0023 - accuracy: 0.9847 - val_loss: 0.0032 - val_accuracy: 0.9474\n",
            "Epoch 134/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0023 - accuracy: 0.9865 - val_loss: 0.0031 - val_accuracy: 0.9579\n",
            "Epoch 135/160\n",
            "87/87 [==============================] - 0s 503us/step - loss: 0.0023 - accuracy: 0.9821 - val_loss: 0.0030 - val_accuracy: 0.9474\n",
            "Epoch 136/160\n",
            "87/87 [==============================] - 0s 482us/step - loss: 0.0023 - accuracy: 0.9836 - val_loss: 0.0029 - val_accuracy: 0.9579\n",
            "Epoch 137/160\n",
            "87/87 [==============================] - 0s 449us/step - loss: 0.0022 - accuracy: 0.9895 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 138/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0028 - accuracy: 0.9726 - val_loss: 0.0031 - val_accuracy: 0.9579\n",
            "Epoch 139/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0025 - accuracy: 0.9747 - val_loss: 0.0029 - val_accuracy: 0.9579\n",
            "Epoch 140/160\n",
            "87/87 [==============================] - 0s 414us/step - loss: 0.0023 - accuracy: 0.9872 - val_loss: 0.0029 - val_accuracy: 0.9579\n",
            "Epoch 141/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0024 - accuracy: 0.9743 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 142/160\n",
            "87/87 [==============================] - 0s 468us/step - loss: 0.0026 - accuracy: 0.9646 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 143/160\n",
            "87/87 [==============================] - 0s 440us/step - loss: 0.0023 - accuracy: 0.9878 - val_loss: 0.0030 - val_accuracy: 0.9474\n",
            "Epoch 144/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0022 - accuracy: 0.9836 - val_loss: 0.0031 - val_accuracy: 0.9579\n",
            "Epoch 145/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0025 - accuracy: 0.9823 - val_loss: 0.0028 - val_accuracy: 0.9579\n",
            "Epoch 146/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0024 - accuracy: 0.9729 - val_loss: 0.0028 - val_accuracy: 0.9579\n",
            "Epoch 147/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0024 - accuracy: 0.9871 - val_loss: 0.0030 - val_accuracy: 0.9474\n",
            "Epoch 148/160\n",
            "87/87 [==============================] - 0s 460us/step - loss: 0.0024 - accuracy: 0.9768 - val_loss: 0.0031 - val_accuracy: 0.9474\n",
            "Epoch 149/160\n",
            "87/87 [==============================] - 0s 466us/step - loss: 0.0022 - accuracy: 0.9692 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 150/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0024 - accuracy: 0.9860 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 151/160\n",
            "87/87 [==============================] - 0s 505us/step - loss: 0.0023 - accuracy: 0.9774 - val_loss: 0.0031 - val_accuracy: 0.9579\n",
            "Epoch 152/160\n",
            "87/87 [==============================] - 0s 466us/step - loss: 0.0023 - accuracy: 0.9766 - val_loss: 0.0029 - val_accuracy: 0.9579\n",
            "Epoch 153/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0023 - accuracy: 0.9855 - val_loss: 0.0028 - val_accuracy: 0.9579\n",
            "Epoch 154/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0024 - accuracy: 0.9849 - val_loss: 0.0030 - val_accuracy: 0.9474\n",
            "Epoch 155/160\n",
            "87/87 [==============================] - 0s 448us/step - loss: 0.0024 - accuracy: 0.9719 - val_loss: 0.0033 - val_accuracy: 0.9474\n",
            "Epoch 156/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0028 - accuracy: 0.9790 - val_loss: 0.0030 - val_accuracy: 0.9579\n",
            "Epoch 157/160\n",
            "87/87 [==============================] - 0s 457us/step - loss: 0.0020 - accuracy: 0.9796 - val_loss: 0.0028 - val_accuracy: 0.9579\n",
            "Epoch 158/160\n",
            "87/87 [==============================] - 0s 401us/step - loss: 0.0021 - accuracy: 0.9803 - val_loss: 0.0028 - val_accuracy: 0.9579\n",
            "Epoch 159/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0024 - accuracy: 0.9747 - val_loss: 0.0028 - val_accuracy: 0.9579\n",
            "Epoch 160/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0023 - accuracy: 0.9786 - val_loss: 0.0028 - val_accuracy: 0.9579\n",
            "3/3 [==============================] - 0s 344us/step - loss: 0.0028 - accuracy: 0.9579\n",
            "Loss = 0.0027937048580497503, rmse = 0.9578947424888611\n",
            "Loss array:  [0.002609268995001912, 0.0022859082091599703, 0.0018555676797404885, 0.002085859654471278, 0.004930993542075157, 0.003450318006798625, 0.002650673734024167, 0.003421371802687645, 0.0027937048580497503]\n",
            "####################### Iteration   9  #######################\n",
            "Epoch 1/160\n",
            "87/87 [==============================] - 0s 952us/step - loss: 0.3356 - accuracy: 0.5433 - val_loss: 0.0996 - val_accuracy: 0.6737\n",
            "Epoch 2/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0756 - accuracy: 0.6208 - val_loss: 0.0512 - val_accuracy: 0.6842\n",
            "Epoch 3/160\n",
            "87/87 [==============================] - 0s 486us/step - loss: 0.0425 - accuracy: 0.7583 - val_loss: 0.0358 - val_accuracy: 0.8316\n",
            "Epoch 4/160\n",
            "87/87 [==============================] - 0s 445us/step - loss: 0.0274 - accuracy: 0.8864 - val_loss: 0.0269 - val_accuracy: 0.9053\n",
            "Epoch 5/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0211 - accuracy: 0.9086 - val_loss: 0.0220 - val_accuracy: 0.9368\n",
            "Epoch 6/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0163 - accuracy: 0.8995 - val_loss: 0.0194 - val_accuracy: 0.9579\n",
            "Epoch 7/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0155 - accuracy: 0.9214 - val_loss: 0.0177 - val_accuracy: 0.9684\n",
            "Epoch 8/160\n",
            "87/87 [==============================] - 0s 495us/step - loss: 0.0137 - accuracy: 0.9257 - val_loss: 0.0165 - val_accuracy: 0.9684\n",
            "Epoch 9/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0124 - accuracy: 0.9335 - val_loss: 0.0155 - val_accuracy: 0.9789\n",
            "Epoch 10/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0121 - accuracy: 0.9236 - val_loss: 0.0148 - val_accuracy: 0.9789\n",
            "Epoch 11/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0123 - accuracy: 0.9324 - val_loss: 0.0141 - val_accuracy: 0.9789\n",
            "Epoch 12/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0114 - accuracy: 0.9377 - val_loss: 0.0136 - val_accuracy: 0.9684\n",
            "Epoch 13/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0107 - accuracy: 0.9292 - val_loss: 0.0130 - val_accuracy: 0.9684\n",
            "Epoch 14/160\n",
            "87/87 [==============================] - 0s 443us/step - loss: 0.0102 - accuracy: 0.9510 - val_loss: 0.0125 - val_accuracy: 0.9684\n",
            "Epoch 15/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0107 - accuracy: 0.9456 - val_loss: 0.0119 - val_accuracy: 0.9684\n",
            "Epoch 16/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0101 - accuracy: 0.9526 - val_loss: 0.0114 - val_accuracy: 0.9684\n",
            "Epoch 17/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0098 - accuracy: 0.9367 - val_loss: 0.0111 - val_accuracy: 0.9684\n",
            "Epoch 18/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0089 - accuracy: 0.9512 - val_loss: 0.0107 - val_accuracy: 0.9684\n",
            "Epoch 19/160\n",
            "87/87 [==============================] - 0s 416us/step - loss: 0.0090 - accuracy: 0.9564 - val_loss: 0.0102 - val_accuracy: 0.9684\n",
            "Epoch 20/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0089 - accuracy: 0.9365 - val_loss: 0.0099 - val_accuracy: 0.9684\n",
            "Epoch 21/160\n",
            "87/87 [==============================] - 0s 372us/step - loss: 0.0088 - accuracy: 0.9592 - val_loss: 0.0100 - val_accuracy: 0.9684\n",
            "Epoch 22/160\n",
            "87/87 [==============================] - 0s 388us/step - loss: 0.0087 - accuracy: 0.9483 - val_loss: 0.0094 - val_accuracy: 0.9684\n",
            "Epoch 23/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0082 - accuracy: 0.9376 - val_loss: 0.0091 - val_accuracy: 0.9684\n",
            "Epoch 24/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0072 - accuracy: 0.9523 - val_loss: 0.0090 - val_accuracy: 0.9684\n",
            "Epoch 25/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0078 - accuracy: 0.9642 - val_loss: 0.0086 - val_accuracy: 0.9684\n",
            "Epoch 26/160\n",
            "87/87 [==============================] - 0s 451us/step - loss: 0.0072 - accuracy: 0.9582 - val_loss: 0.0085 - val_accuracy: 0.9684\n",
            "Epoch 27/160\n",
            "87/87 [==============================] - 0s 434us/step - loss: 0.0079 - accuracy: 0.9511 - val_loss: 0.0082 - val_accuracy: 0.9684\n",
            "Epoch 28/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0070 - accuracy: 0.9581 - val_loss: 0.0081 - val_accuracy: 0.9684\n",
            "Epoch 29/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0074 - accuracy: 0.9550 - val_loss: 0.0079 - val_accuracy: 0.9684\n",
            "Epoch 30/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0070 - accuracy: 0.9638 - val_loss: 0.0076 - val_accuracy: 0.9684\n",
            "Epoch 31/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0068 - accuracy: 0.9550 - val_loss: 0.0074 - val_accuracy: 0.9684\n",
            "Epoch 32/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0064 - accuracy: 0.9646 - val_loss: 0.0074 - val_accuracy: 0.9684\n",
            "Epoch 33/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0062 - accuracy: 0.9539 - val_loss: 0.0073 - val_accuracy: 0.9684\n",
            "Epoch 34/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0063 - accuracy: 0.9528 - val_loss: 0.0070 - val_accuracy: 0.9684\n",
            "Epoch 35/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0063 - accuracy: 0.9660 - val_loss: 0.0069 - val_accuracy: 0.9684\n",
            "Epoch 36/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0054 - accuracy: 0.9637 - val_loss: 0.0066 - val_accuracy: 0.9684\n",
            "Epoch 37/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0053 - accuracy: 0.9637 - val_loss: 0.0065 - val_accuracy: 0.9684\n",
            "Epoch 38/160\n",
            "87/87 [==============================] - 0s 438us/step - loss: 0.0057 - accuracy: 0.9623 - val_loss: 0.0063 - val_accuracy: 0.9684\n",
            "Epoch 39/160\n",
            "87/87 [==============================] - 0s 453us/step - loss: 0.0057 - accuracy: 0.9504 - val_loss: 0.0064 - val_accuracy: 0.9684\n",
            "Epoch 40/160\n",
            "87/87 [==============================] - 0s 457us/step - loss: 0.0055 - accuracy: 0.9598 - val_loss: 0.0061 - val_accuracy: 0.9684\n",
            "Epoch 41/160\n",
            "87/87 [==============================] - 0s 422us/step - loss: 0.0056 - accuracy: 0.9561 - val_loss: 0.0059 - val_accuracy: 0.9684\n",
            "Epoch 42/160\n",
            "87/87 [==============================] - 0s 427us/step - loss: 0.0057 - accuracy: 0.9507 - val_loss: 0.0060 - val_accuracy: 0.9684\n",
            "Epoch 43/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0050 - accuracy: 0.9679 - val_loss: 0.0058 - val_accuracy: 0.9684\n",
            "Epoch 44/160\n",
            "87/87 [==============================] - 0s 417us/step - loss: 0.0049 - accuracy: 0.9629 - val_loss: 0.0057 - val_accuracy: 0.9684\n",
            "Epoch 45/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0047 - accuracy: 0.9615 - val_loss: 0.0055 - val_accuracy: 0.9684\n",
            "Epoch 46/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0052 - accuracy: 0.9505 - val_loss: 0.0055 - val_accuracy: 0.9684\n",
            "Epoch 47/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0051 - accuracy: 0.9574 - val_loss: 0.0054 - val_accuracy: 0.9684\n",
            "Epoch 48/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0042 - accuracy: 0.9623 - val_loss: 0.0053 - val_accuracy: 0.9684\n",
            "Epoch 49/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0046 - accuracy: 0.9367 - val_loss: 0.0061 - val_accuracy: 0.9684\n",
            "Epoch 50/160\n",
            "87/87 [==============================] - 0s 500us/step - loss: 0.0045 - accuracy: 0.9706 - val_loss: 0.0052 - val_accuracy: 0.9684\n",
            "Epoch 51/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0048 - accuracy: 0.9662 - val_loss: 0.0051 - val_accuracy: 0.9684\n",
            "Epoch 52/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0044 - accuracy: 0.9554 - val_loss: 0.0050 - val_accuracy: 0.9684\n",
            "Epoch 53/160\n",
            "87/87 [==============================] - 0s 385us/step - loss: 0.0041 - accuracy: 0.9746 - val_loss: 0.0051 - val_accuracy: 0.9684\n",
            "Epoch 54/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0049 - accuracy: 0.9614 - val_loss: 0.0049 - val_accuracy: 0.9684\n",
            "Epoch 55/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0039 - accuracy: 0.9687 - val_loss: 0.0048 - val_accuracy: 0.9684\n",
            "Epoch 56/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0041 - accuracy: 0.9604 - val_loss: 0.0048 - val_accuracy: 0.9684\n",
            "Epoch 57/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0043 - accuracy: 0.9563 - val_loss: 0.0047 - val_accuracy: 0.9684\n",
            "Epoch 58/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0043 - accuracy: 0.9502 - val_loss: 0.0047 - val_accuracy: 0.9684\n",
            "Epoch 59/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0042 - accuracy: 0.9524 - val_loss: 0.0045 - val_accuracy: 0.9684\n",
            "Epoch 60/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0041 - accuracy: 0.9614 - val_loss: 0.0044 - val_accuracy: 0.9684\n",
            "Epoch 61/160\n",
            "87/87 [==============================] - 0s 392us/step - loss: 0.0040 - accuracy: 0.9721 - val_loss: 0.0044 - val_accuracy: 0.9684\n",
            "Epoch 62/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0039 - accuracy: 0.9589 - val_loss: 0.0043 - val_accuracy: 0.9684\n",
            "Epoch 63/160\n",
            "87/87 [==============================] - 0s 511us/step - loss: 0.0035 - accuracy: 0.9638 - val_loss: 0.0048 - val_accuracy: 0.9684\n",
            "Epoch 64/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0041 - accuracy: 0.9556 - val_loss: 0.0042 - val_accuracy: 0.9684\n",
            "Epoch 65/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0037 - accuracy: 0.9666 - val_loss: 0.0043 - val_accuracy: 0.9684\n",
            "Epoch 66/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0039 - accuracy: 0.9653 - val_loss: 0.0041 - val_accuracy: 0.9684\n",
            "Epoch 67/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0039 - accuracy: 0.9692 - val_loss: 0.0041 - val_accuracy: 0.9684\n",
            "Epoch 68/160\n",
            "87/87 [==============================] - 0s 394us/step - loss: 0.0039 - accuracy: 0.9593 - val_loss: 0.0043 - val_accuracy: 0.9684\n",
            "Epoch 69/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0038 - accuracy: 0.9619 - val_loss: 0.0041 - val_accuracy: 0.9684\n",
            "Epoch 70/160\n",
            "87/87 [==============================] - 0s 382us/step - loss: 0.0035 - accuracy: 0.9632 - val_loss: 0.0040 - val_accuracy: 0.9684\n",
            "Epoch 71/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0037 - accuracy: 0.9525 - val_loss: 0.0039 - val_accuracy: 0.9684\n",
            "Epoch 72/160\n",
            "87/87 [==============================] - 0s 413us/step - loss: 0.0034 - accuracy: 0.9690 - val_loss: 0.0038 - val_accuracy: 0.9684\n",
            "Epoch 73/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0038 - accuracy: 0.9517 - val_loss: 0.0039 - val_accuracy: 0.9684\n",
            "Epoch 74/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0032 - accuracy: 0.9656 - val_loss: 0.0037 - val_accuracy: 0.9684\n",
            "Epoch 75/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0032 - accuracy: 0.9709 - val_loss: 0.0038 - val_accuracy: 0.9684\n",
            "Epoch 76/160\n",
            "87/87 [==============================] - 0s 432us/step - loss: 0.0035 - accuracy: 0.9683 - val_loss: 0.0038 - val_accuracy: 0.9684\n",
            "Epoch 77/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0033 - accuracy: 0.9724 - val_loss: 0.0038 - val_accuracy: 0.9684\n",
            "Epoch 78/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0033 - accuracy: 0.9709 - val_loss: 0.0036 - val_accuracy: 0.9684\n",
            "Epoch 79/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0034 - accuracy: 0.9625 - val_loss: 0.0035 - val_accuracy: 0.9684\n",
            "Epoch 80/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0033 - accuracy: 0.9618 - val_loss: 0.0037 - val_accuracy: 0.9684\n",
            "Epoch 81/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0034 - accuracy: 0.9646 - val_loss: 0.0036 - val_accuracy: 0.9684\n",
            "Epoch 82/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0032 - accuracy: 0.9634 - val_loss: 0.0035 - val_accuracy: 0.9684\n",
            "Epoch 83/160\n",
            "87/87 [==============================] - 0s 397us/step - loss: 0.0034 - accuracy: 0.9573 - val_loss: 0.0037 - val_accuracy: 0.9684\n",
            "Epoch 84/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0033 - accuracy: 0.9736 - val_loss: 0.0034 - val_accuracy: 0.9684\n",
            "Epoch 85/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0032 - accuracy: 0.9782 - val_loss: 0.0033 - val_accuracy: 0.9684\n",
            "Epoch 86/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0030 - accuracy: 0.9646 - val_loss: 0.0034 - val_accuracy: 0.9684\n",
            "Epoch 87/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0033 - accuracy: 0.9696 - val_loss: 0.0034 - val_accuracy: 0.9684\n",
            "Epoch 88/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0033 - accuracy: 0.9707 - val_loss: 0.0033 - val_accuracy: 0.9684\n",
            "Epoch 89/160\n",
            "87/87 [==============================] - 0s 486us/step - loss: 0.0032 - accuracy: 0.9600 - val_loss: 0.0034 - val_accuracy: 0.9684\n",
            "Epoch 90/160\n",
            "87/87 [==============================] - 0s 425us/step - loss: 0.0029 - accuracy: 0.9657 - val_loss: 0.0034 - val_accuracy: 0.9684\n",
            "Epoch 91/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0029 - accuracy: 0.9605 - val_loss: 0.0035 - val_accuracy: 0.9684\n",
            "Epoch 92/160\n",
            "87/87 [==============================] - 0s 412us/step - loss: 0.0035 - accuracy: 0.9574 - val_loss: 0.0034 - val_accuracy: 0.9684\n",
            "Epoch 93/160\n",
            "87/87 [==============================] - 0s 403us/step - loss: 0.0030 - accuracy: 0.9651 - val_loss: 0.0033 - val_accuracy: 0.9684\n",
            "Epoch 94/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0029 - accuracy: 0.9742 - val_loss: 0.0032 - val_accuracy: 0.9684\n",
            "Epoch 95/160\n",
            "87/87 [==============================] - 0s 395us/step - loss: 0.0031 - accuracy: 0.9746 - val_loss: 0.0032 - val_accuracy: 0.9684\n",
            "Epoch 96/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0030 - accuracy: 0.9559 - val_loss: 0.0032 - val_accuracy: 0.9684\n",
            "Epoch 97/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0029 - accuracy: 0.9692 - val_loss: 0.0033 - val_accuracy: 0.9684\n",
            "Epoch 98/160\n",
            "87/87 [==============================] - 0s 423us/step - loss: 0.0029 - accuracy: 0.9749 - val_loss: 0.0033 - val_accuracy: 0.9684\n",
            "Epoch 99/160\n",
            "87/87 [==============================] - 0s 411us/step - loss: 0.0030 - accuracy: 0.9624 - val_loss: 0.0032 - val_accuracy: 0.9684\n",
            "Epoch 100/160\n",
            "87/87 [==============================] - 0s 419us/step - loss: 0.0033 - accuracy: 0.9735 - val_loss: 0.0032 - val_accuracy: 0.9684\n",
            "Epoch 101/160\n",
            "87/87 [==============================] - 0s 388us/step - loss: 0.0029 - accuracy: 0.9670 - val_loss: 0.0032 - val_accuracy: 0.9684\n",
            "Epoch 102/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0030 - accuracy: 0.9619 - val_loss: 0.0034 - val_accuracy: 0.9684\n",
            "Epoch 103/160\n",
            "87/87 [==============================] - 0s 428us/step - loss: 0.0029 - accuracy: 0.9545 - val_loss: 0.0032 - val_accuracy: 0.9684\n",
            "Epoch 104/160\n",
            "87/87 [==============================] - 0s 398us/step - loss: 0.0031 - accuracy: 0.9700 - val_loss: 0.0035 - val_accuracy: 0.9684\n",
            "Epoch 105/160\n",
            "87/87 [==============================] - 0s 385us/step - loss: 0.0027 - accuracy: 0.9594 - val_loss: 0.0032 - val_accuracy: 0.9684\n",
            "Epoch 106/160\n",
            "87/87 [==============================] - 0s 386us/step - loss: 0.0029 - accuracy: 0.9569 - val_loss: 0.0030 - val_accuracy: 0.9684\n",
            "Epoch 107/160\n",
            "87/87 [==============================] - 0s 382us/step - loss: 0.0029 - accuracy: 0.9630 - val_loss: 0.0031 - val_accuracy: 0.9684\n",
            "Epoch 108/160\n",
            "87/87 [==============================] - 0s 393us/step - loss: 0.0026 - accuracy: 0.9675 - val_loss: 0.0031 - val_accuracy: 0.9684\n",
            "Epoch 109/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0033 - accuracy: 0.9618 - val_loss: 0.0032 - val_accuracy: 0.9684\n",
            "Epoch 110/160\n",
            "87/87 [==============================] - 0s 426us/step - loss: 0.0029 - accuracy: 0.9673 - val_loss: 0.0030 - val_accuracy: 0.9684\n",
            "Epoch 111/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0029 - accuracy: 0.9613 - val_loss: 0.0032 - val_accuracy: 0.9684\n",
            "Epoch 112/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0030 - accuracy: 0.9596 - val_loss: 0.0030 - val_accuracy: 0.9684\n",
            "Epoch 113/160\n",
            "87/87 [==============================] - 0s 424us/step - loss: 0.0027 - accuracy: 0.9695 - val_loss: 0.0033 - val_accuracy: 0.9684\n",
            "Epoch 114/160\n",
            "87/87 [==============================] - 0s 452us/step - loss: 0.0026 - accuracy: 0.9668 - val_loss: 0.0033 - val_accuracy: 0.9684\n",
            "Epoch 115/160\n",
            "87/87 [==============================] - 0s 430us/step - loss: 0.0028 - accuracy: 0.9656 - val_loss: 0.0031 - val_accuracy: 0.9684\n",
            "Epoch 116/160\n",
            "87/87 [==============================] - 0s 387us/step - loss: 0.0028 - accuracy: 0.9652 - val_loss: 0.0030 - val_accuracy: 0.9684\n",
            "Epoch 117/160\n",
            "87/87 [==============================] - 0s 383us/step - loss: 0.0029 - accuracy: 0.9674 - val_loss: 0.0031 - val_accuracy: 0.9684\n",
            "Epoch 118/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0026 - accuracy: 0.9597 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 119/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0030 - accuracy: 0.9619 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 120/160\n",
            "87/87 [==============================] - 0s 391us/step - loss: 0.0026 - accuracy: 0.9734 - val_loss: 0.0033 - val_accuracy: 0.9684\n",
            "Epoch 121/160\n",
            "87/87 [==============================] - 0s 382us/step - loss: 0.0026 - accuracy: 0.9708 - val_loss: 0.0031 - val_accuracy: 0.9684\n",
            "Epoch 122/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0026 - accuracy: 0.9638 - val_loss: 0.0032 - val_accuracy: 0.9684\n",
            "Epoch 123/160\n",
            "87/87 [==============================] - 0s 415us/step - loss: 0.0026 - accuracy: 0.9734 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 124/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0027 - accuracy: 0.9705 - val_loss: 0.0030 - val_accuracy: 0.9684\n",
            "Epoch 125/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0029 - accuracy: 0.9610 - val_loss: 0.0031 - val_accuracy: 0.9684\n",
            "Epoch 126/160\n",
            "87/87 [==============================] - 0s 512us/step - loss: 0.0028 - accuracy: 0.9491 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 127/160\n",
            "87/87 [==============================] - 0s 421us/step - loss: 0.0027 - accuracy: 0.9684 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 128/160\n",
            "87/87 [==============================] - 0s 379us/step - loss: 0.0028 - accuracy: 0.9709 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 129/160\n",
            "87/87 [==============================] - 0s 386us/step - loss: 0.0025 - accuracy: 0.9559 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 130/160\n",
            "87/87 [==============================] - 0s 429us/step - loss: 0.0026 - accuracy: 0.9731 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 131/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0026 - accuracy: 0.9597 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 132/160\n",
            "87/87 [==============================] - 0s 389us/step - loss: 0.0026 - accuracy: 0.9689 - val_loss: 0.0030 - val_accuracy: 0.9684\n",
            "Epoch 133/160\n",
            "87/87 [==============================] - 0s 381us/step - loss: 0.0025 - accuracy: 0.9763 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 134/160\n",
            "87/87 [==============================] - 0s 376us/step - loss: 0.0025 - accuracy: 0.9710 - val_loss: 0.0030 - val_accuracy: 0.9684\n",
            "Epoch 135/160\n",
            "87/87 [==============================] - 0s 376us/step - loss: 0.0024 - accuracy: 0.9766 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 136/160\n",
            "87/87 [==============================] - 0s 390us/step - loss: 0.0024 - accuracy: 0.9743 - val_loss: 0.0030 - val_accuracy: 0.9684\n",
            "Epoch 137/160\n",
            "87/87 [==============================] - 0s 402us/step - loss: 0.0025 - accuracy: 0.9715 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 138/160\n",
            "87/87 [==============================] - 0s 454us/step - loss: 0.0028 - accuracy: 0.9674 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 139/160\n",
            "87/87 [==============================] - 0s 431us/step - loss: 0.0027 - accuracy: 0.9655 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 140/160\n",
            "87/87 [==============================] - 0s 400us/step - loss: 0.0026 - accuracy: 0.9721 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 141/160\n",
            "87/87 [==============================] - 0s 387us/step - loss: 0.0027 - accuracy: 0.9532 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 142/160\n",
            "87/87 [==============================] - 0s 380us/step - loss: 0.0027 - accuracy: 0.9593 - val_loss: 0.0030 - val_accuracy: 0.9684\n",
            "Epoch 143/160\n",
            "87/87 [==============================] - 0s 385us/step - loss: 0.0025 - accuracy: 0.9746 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 144/160\n",
            "87/87 [==============================] - 0s 386us/step - loss: 0.0023 - accuracy: 0.9785 - val_loss: 0.0034 - val_accuracy: 0.9684\n",
            "Epoch 145/160\n",
            "87/87 [==============================] - 0s 385us/step - loss: 0.0027 - accuracy: 0.9756 - val_loss: 0.0027 - val_accuracy: 0.9684\n",
            "Epoch 146/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0025 - accuracy: 0.9597 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 147/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0026 - accuracy: 0.9717 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 148/160\n",
            "87/87 [==============================] - 0s 481us/step - loss: 0.0025 - accuracy: 0.9566 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 149/160\n",
            "87/87 [==============================] - 0s 442us/step - loss: 0.0021 - accuracy: 0.9549 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 150/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0024 - accuracy: 0.9764 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 151/160\n",
            "87/87 [==============================] - 0s 405us/step - loss: 0.0024 - accuracy: 0.9725 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 152/160\n",
            "87/87 [==============================] - 0s 399us/step - loss: 0.0025 - accuracy: 0.9751 - val_loss: 0.0030 - val_accuracy: 0.9684\n",
            "Epoch 153/160\n",
            "87/87 [==============================] - 0s 396us/step - loss: 0.0024 - accuracy: 0.9750 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 154/160\n",
            "87/87 [==============================] - 0s 408us/step - loss: 0.0025 - accuracy: 0.9746 - val_loss: 0.0027 - val_accuracy: 0.9684\n",
            "Epoch 155/160\n",
            "87/87 [==============================] - 0s 409us/step - loss: 0.0024 - accuracy: 0.9702 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 156/160\n",
            "87/87 [==============================] - 0s 410us/step - loss: 0.0026 - accuracy: 0.9628 - val_loss: 0.0029 - val_accuracy: 0.9684\n",
            "Epoch 157/160\n",
            "87/87 [==============================] - 0s 407us/step - loss: 0.0023 - accuracy: 0.9713 - val_loss: 0.0027 - val_accuracy: 0.9684\n",
            "Epoch 158/160\n",
            "87/87 [==============================] - 0s 404us/step - loss: 0.0022 - accuracy: 0.9752 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 159/160\n",
            "87/87 [==============================] - 0s 406us/step - loss: 0.0026 - accuracy: 0.9627 - val_loss: 0.0028 - val_accuracy: 0.9684\n",
            "Epoch 160/160\n",
            "87/87 [==============================] - 0s 436us/step - loss: 0.0023 - accuracy: 0.9703 - val_loss: 0.0027 - val_accuracy: 0.9684\n",
            "3/3 [==============================] - 0s 392us/step - loss: 0.0027 - accuracy: 0.9684\n",
            "Loss = 0.0027115645352751017, rmse = 0.9684210419654846\n",
            "Loss array:  [0.002609268995001912, 0.0022859082091599703, 0.0018555676797404885, 0.002085859654471278, 0.004930993542075157, 0.003450318006798625, 0.002650673734024167, 0.003421371802687645, 0.0027937048580497503, 0.0027115645352751017]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "NUM_EPOCHS = 181 # 180\n",
        "BATCH_SIZE = 10\n",
        "K_FOLD_SPLITS = 10\n",
        "\n",
        "\n",
        "# Define the cross-validation process to be used inside cross_val_Score evaluation\n",
        "cv = KFold(n_splits=K_FOLD_SPLITS)\n",
        "\n",
        "# Handling for accommodating multiple targets\n",
        "Y1 = y_train_norm[:,0]\n",
        "Y2 = y_train_norm[:,1]\n",
        "targets = (Y1, Y2)\n",
        "\n",
        "X = X_train_norm\n",
        "\n",
        "i = 0\n",
        "arr_loss = list()\n",
        "arr_rmse = list()\n",
        "min_loss = 1000000\n",
        "best_model = None\n",
        "history = None\n",
        "history_best_model = None\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_indices, test_indices in cv.split(X_train):\n",
        "  print('####################### Iteration  ', i, ' #######################')\n",
        "  trainX, valX = np.array(X[train_indices]), np.array(X[test_indices])\n",
        "  trainY = np.vstack((Y1[train_indices], Y2[train_indices])).T\n",
        "  valY = np.vstack((Y1[test_indices], Y2[test_indices])).T\n",
        "\n",
        "  model = my_model()\n",
        "  history = model.fit(trainX, trainY,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            validation_data = (valX, valY)\n",
        "  )\n",
        "\n",
        "\n",
        "  #testing on validation set process\n",
        "  loss, rmse = model.evaluate(x = valX, y = valY, verbose=1)\n",
        "  print(f\"Loss = {loss}, rmse = {rmse}\" )\n",
        "\n",
        "  if loss < min_loss:\n",
        "    best_model = model\n",
        "    history_best_model = history\n",
        "    min_loss = loss\n",
        "\n",
        "  arr_loss.append(loss)\n",
        "  arr_rmse.append(rmse)\n",
        "  print('Loss array: ', arr_loss)\n",
        "  i+=1\n",
        "\n",
        "# Saving the best model within the k folds\n",
        "best_model.save(FILENAME_BEST_MODEL)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results\n",
        "- Plot of k-cross validation performance\n",
        "- Scatter Plot of prediction results against true values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 623,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "xKSkPnO4ETWD",
        "outputId": "564ee694-d414-4d21-bbd9-f838e7249dd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loss across k folds\n",
        "plot_line(arr_loss, \"Loss across k-folds\", \"Value of k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 624,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training and Validation Loss\n",
        "plot_loss_curve(history_best_model, NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 625,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the test dataset\n",
        "X_test_norm = scaler_input.transform(X_test)\n",
        "y_test_norm = scaler_output.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 626,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-erJ0l_Yu4P",
        "outputId": "9cff94b2-e4ca-491b-8459-aeaa1eff7606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time: 0.0219 seconds\n",
            "Maxval here is:  35.763466\n",
            "Maxval here is:  0.8844\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAFFCAYAAAAHJJ51AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXiU5dX48e/MJJnsG9kXSIBAEgIYEhCIyFJAQBGXKq3VCqgt5Qcu1KVotaC+rlXxrUq1lUURS11QREXhVUACiCTsSVhCIGSFkI3sk5n5/ZHMkMnMJJPJSnI+18Ulmbmf57mfJxAP95z7HIVer9cjhBBCCCFEL6Hs7gkIIYQQQgjRkSTAFUIIIYQQvYoEuEIIIYQQoleRAFcIIYQQQvQqEuAKIYQQQoheRQJcIYQQQgjRq0iAK4QQQgghehUJcIUQQgghRK8iAa4QQgghhOhVJMAVQoh2mDdvHgqFgrVr15q8vnz5chQKBcuXL++WeV2NFAoFCoWiu6chhOgFJMAVQvQaERERxiCp6S93d3dGjBjBsmXLuHTpUndP0y5r1641uy+1Wk1AQADDhw/n3nvvZf369dTU1HT3VDvc2rVrWb58OWfPnu3uqQghrhIO3T0BIYToaFFRUQQEBACg0+nIz8/n6NGjHD16lA8//JDdu3cTERHRvZO0k1qtJjExEQC9Xk9ZWRlnz57l2LFjfPDBByxdupRVq1Zx++23d/NM227o0KEWX1+7di07d+5k0qRJV+33TQjRtWQFVwjR6zz55JPs3r2b3bt3s2fPHrKyskhNTSUkJITc3Fwef/zx7p6i3YKCgoz3lpyczLFjxygtLWXPnj3cfPPNXLx4kV//+te8++673T3VNsvIyCAjI6O7pyGE6AUkwBVC9Anx8fE89dRTAGzfvr2bZ9OxVCoV48aN48svv+TJJ58EYMmSJZw6daqbZyaEEN1DAlwhRJ8xYMAAAOrq6szeM+TvWsvznDRpEgqFgh07drR7HseOHSM4OBiFQsHzzz/f7vM19dxzzxEfH49Go+G1116zOCYnJ4cHH3yQIUOG4OLigre3N5MnT+bTTz+1OL7pvWdkZHDHHXfg5+eHi4sLCQkJ/Pe//7V4XGVlJc8++ywjRozAzc0NZ2dnwsPDmTRpEi+99BIajcZkfPNNZjt27EChULBz504AJk+ebJKDvHbtWrZu3YpCoWDEiBFWn0ldXR39+vVDoVBw/PjxFp+fEKJ3kABXCNFnHDhwAIDo6Ohum8P+/fuZOHEihYWFvPnmm/z1r3/t0PMrlUr+8Ic/APD111+bvb9z507i4uL4xz/+QU5ODlFRUXh6erJjxw7uuOMOHn30UavnTklJYfTo0Xz33XdERETg4eFBamoqc+fOZf369SZj6+vrmTp1Kn/72984fvw44eHhDB8+HJ1Ox08//cSyZcuorKxs8V68vLxISkrC09MTgLi4OJKSkoy/AgMDmT59OuHh4Rw9epTU1FSL5/nqq68oLi4mMTGRYcOGtXhNIUTvIAGuEKJX0+l05OXlsWrVKl5++WUUCgXLli3rlrns2LGDqVOnUlZWxurVq3nwwQc75TrXXXcd0LBSW1BQYHw9Ly+P2267jfLycl544QVKSko4cuQI2dnZJCcnExoaymuvvcaWLVssnnfZsmXMmzePCxcucODAAQoLC3niiScAeOKJJ9BqtcaxX375Jfv27WPkyJGcO3eOjIwMfvnlF3JzcykoKGDlypU4OTm1eB/x8fHs3r2b+Ph4AP7xj38Y8493797NzJkzUSqV/P73vwdg3bp1Fs9jeH3evHk2PD0hRG8gAa4QoteZP3++8WNslUpFaGgoixYtIi4ujq1bt3ZLhYGvv/6amTNnUltby8aNGzs12AoPDzf+/sKFC8bfv/baaxQXF/Pwww+zbNky1Gq18b3x48fzz3/+E4A33njD4nljY2N58803cXZ2BhpSCp577jmCgoLIy8vjyJEjxrGG/N8FCxYQFhZmch5/f38eeughXF1d23mnGK+hUCjYsGGDWdrDxYsX+fbbb3FycuK3v/1th1xPCNHzSYArhOh1oqKiTD7KHjp0KGq1mpSUFN555x1KSkq6dD4bN27k1ltvRalUsnnz5k4PsN3c3Iy/v3z5svH3n3/+OQD333+/xeNmzJiBk5MTe/bsob6+3uz9BQsWoFSa/m/D0dGRkSNHAnDmzBnj64Yg++uvv6aqqsrOO7HNwIEDuf766ykqKuKbb74xee+jjz6ivr6em2++GV9f306dhxCi55A6uEKIXufJJ580WyEtLS3loYce4oMPPmD69Ons37+/S7pmffHFFzz33HN4eHiwZcsWY/pAZ6qoqDD+3pC/WlFRYdxAZ8jRtaampoZLly4RGBho8vqgQYMsjjfUHG563VtuuYWIiAi+//57QkJCmDFjBhMmTGDSpEmdkge7YMECdu7cybp165gzZ47xdUlPEKJvkhVcIUSf4O3tzXvvvUdoaCgHDhzgyy+/7JLrZmVlodPp8PX1JTIyskuumZ2dbfy9IfgsKyszvpacnGz1l6HCRHV1tdl5m64MN2VY1dXr9SZjf/rpJ+bPn49Op2Pjxo0sXryYuLg4hg0bZjXP116//vWv8fT0ZMuWLcZudUeOHOHQoUMEBQUxY8aMDr2eEKJnkwBXCNFnqNVqRo0aBTRUM2jKsJrbNEhrqrUd/9Y8+OCD3HHHHWRlZfGrX/2KwsJCu87TFrt37wagf//+xlVYd3d34/t1dXXo9foWf3VEx7CwsDBWr15NcXEx+/bt46WXXiIxMZG0tDRuueUWfv7553Zfw8DV1ZW5c+ei0Wj4+OOPgSurt3fffTcqlarDriWE6PkkwBVC9Ck6nQ6A4uJik9cNq5MXL160eFxmZqZd11OpVGzYsIE5c+Zw4sQJfvWrX1FUVGTXuWyh0+l47733ALjxxhuNr3t5eRESEgLQ5bVgHRwcuPbaa3niiSf45Zdf+M1vfoNWq2X16tU2HW9rKsmCBQuAhta+9fX1fPTRR4CkJwjRF0mAK4ToM2pqajh48CDQsDGpKcPXv/zyi9lxn332Wbs2pjk4OPDf//6XWbNmcfz4caZOndppG92efvppDh8+jKOjI3/+859N3rvtttsAWLlyZadc21Zjx44FGsqW2cLFxQWwnDbR/LyxsbGkpKTw97//ncLCQql9K0QfJQGuEKJPKCkp4YEHHiAvLw8nJyfuvPNOk/dnzpwJwCuvvGLS4vaXX37hwQcfxNHRsV3Xd3Jy4rPPPmPatGkcPnyY6dOnm+TFtodOp2Pv3r3MmTOHF154AYBVq1aZbQp74okn8PX1Zd26dSxdupTS0lKT94uLi1m9enWHdFd74403WLlypVlKRnZ2Nv/+978BjOkirTH848PQ0awl8+fPBxoCfZDVWyH6KglwhRC9zgsvvMB1111n/BUTE0NwcDDr16/HwcGBd9991yzHdP78+QwbNozs7GxiY2MZPnw4Q4cOZcyYMVx//fWMHz++3fNydnbmiy++YOLEiRw4cICZM2eaVB6wRUFBgfG+kpKSGD58ON7e3owfP57Nmzfj7+/P559/zn333Wd2bFhYGJs3b8bPz4833niDgIAARowYwdixYxk0aBB+fn7cd999HDt2rN33eu7cOR555BGCgoKIjIzk2muvJSYmhoEDB3Ls2DHi4uJYunSpTeeaO3cuAC+//DJDhw5l4sSJTJo0ia1bt5qN/f3vf4+joyP19fVS+1aIPkzKhAkhep1Tp06ZrMKq1WpCQ0OZOHEiDz30kLFua1POzs788MMPPPnkk3z11VecOnWKyMhI/v73v/PII48wZcqUDpmbq6srW7ZsYcaMGSQnJ3PjjTfy7bff2tz0oLa2luTkZKChBq2XlxcDBgxg1KhRTJs2jTvuuMOkgUNzSUlJpKWl8eabb7JlyxYyMzPRarWEhoYyY8YMZs+ebUxlaI+FCxfi4+PDDz/8QGZmJocOHcLHx4fRo0fzu9/9jvvuu8+YetCaCRMmsGHDBlauXMnx48c5efIkYHl1NiAggJkzZ7J582apfStEH6bQW9syLIQQQlyFxo4dy88//8yWLVtMNtoJIfoOCXCFEEL0GsePHycuLo7g4GDOnz8v5cGE6KMkB1cIIUSvoNVqeeqpp4CGbm0S3ArRd8kKrhBCiKva1q1beemllzhz5gznz58nMDCQ9PR0fHx8untqQohuIiu4QgghrmoFBQXs3LmT4uJiJk+ezPfffy/BrRB9nKzgCiGEEEKIXkVWcIUQQgghRK8idXBp6AKUl5eHh4eHzT3PhRBCCCFE19Hr9Vy+fJmQkBCUypbXaCXApaEfenh4eHdPQwghhBBCtOL8+fOEhYW1OEYCXMDDwwNoeGCenp7dPJvupdFo+P7775k+fTqOjo7dPZ0+RZ5995Fn3z3kuXcfefbdR569/crLywkPDzfGbS2RABeMaQmenp4S4Go0uLq64unpKX/xupg8++4jz757yHPvPvLsu488+/azJZ1UNpkJIYQQQoheRQJcIYQQQgjRq0iAK4QQQgghepUel4O7a9cuXn31VVJSUsjPz2fTpk3ccsstLR6zc+dOli5dyvHjxwkJCeHxxx9n4cKFHTovvV5PfX09Wq22Q8/b02g0GhwcHKipqenR96pSqXBwcJCybkIIIYQw0+MC3MrKSkaOHMn8+fO5/fbbWx2flZXFrFmzeOCBB1i/fj3JycksWrQIf39/m463RV1dHfn5+VRVVXXI+XoyvV5PUFAQ58+f7/HBo6urK8HBwTg5OXX3VIQQQgjRg/S4AHfmzJnMnDnT5vH//Oc/6d+/PytXrgQgJiaGAwcO8Pe//71DAlydTkdWVhYqlYqQkBCcnJx6fODXHjqdjoqKCtzd3Vstotxd9Ho9dXV1XLx4kaysLKKionrsXIUQQgjR9XpcgNtWe/fuZfr06Sav3XDDDbz//vtoNBqLJThqa2upra01fl1eXg40fDyv0WjMxmq1WkJDQ3F1de2EO+hZDMGjWq3u0YG8Wq1GpVKRnZ1NVVUVarW6u6fUboY/e83/DIrOJ8++e8hz7z7y7LuPPHv7teWZXfUBbkFBAYGBgSavBQYGUl9fT1FREcHBwWbHvPjii6xYscLs9e+//94siHVwcCAoKIiqqirq6+s7dvI92OXLl7t7Cq2qq6ujurqanTt39qrvzbZt27p7Cn2WPPvuIc+9+8iz7z7y7NuuLamiV32AC+YFf/V6vcXXDZYtW8bSpUuNXxs6Y0yfPt2s0UNNTQ3nz5/H3d0dZ2fnDp55z2Po8+zh4dGjV3Ch4Xvj4uLC9ddf3yu+NxqNhm3btjFt2jQp/t3F5Nl3D3nu3UeeffeRZ28/wyfutrjqA9ygoCAKCgpMXrtw4QIODg7069fP4jFqtdriR9qOjo5mf9i0Wi0KhQKlUtkn8jx1Oh2A8Z57MqVSiUKhsPh9u5r1tvu5msiz7x7y3LuPPPvuI8/edpdrNPz3QA7/+r9jNh9z1Qe448aN46uvvjJ57fvvvycxMVH+4Nhg0qRJXHPNNcZNel11zvfee4/nnnuO3NxcXn/9dUpLS/niiy84dOhQh81DCCGEEFcXvV7PnsxLrEnOYnv6BZP3dLU1Np+nxwW4FRUVnD592vh1VlYWhw4dwtfXl/79+7Ns2TJyc3P54IMPAFi4cCFvvfUWS5cu5YEHHmDv3r28//77fPzxx911Cz3GvHnzjIFjT1JeXs7ixYt5/fXXuf322/Hy8kKn07FkyRLjmJ46dyGEEEJ0nIKyGj7cd5Y1yWepquu4+vs9LsA9cOAAkydPNn5tyJW99957Wbt2Lfn5+WRnZxvfj4yM5JtvvuGRRx7h7bffJiQkhP/93//tsBq4ouNlZ2ej0Wi48cYbTTYBuru7d+OshBBCCNGZNFod3x4rYE1yFgezS2065lfRAcxPiiRpcD8uX76Ml40fOPe4AHfSpEnGTWKWrF271uy1iRMnkpqa2omzMqXX66nWdE+XLxdHld2bvyorK/nTn/7E559/joeHB48++qjZmLq6Op555hk+++wzSktLiYuL4+WXX2bSpEkAXLp0icWLF/PTTz9RXFzMoEGDePLJJ/ntb39r0xzWrl3L/PnzARg4cCDQsEq/du1aY4rC8uXLWbduHXBlo+CPP/5onIMQQggher6ThZdZk5zFx/vP2zQ+1NuFBddFckdiGJ7O7Usz7XEB7tWgWqMl9pnvuuXaac/egKuTfd+2xx57jB9//JFNmzYRFBTEk08+SUpKCtdcc41xzIIFC8jMzGTDhg2EhYWxadMmZsyYwdGjR4mKiqKmpoaEhASeeOIJPD09+frrr7nnnnsYOHAg1157batzmDt3LuHh4UydOpX9+/cTHh6Ov7+/yZhHH32U9PR0ysvLWbNmDQC+vr523bMQQgghOl9lbT2fpuSwOjmLc5dsK+d1R0IY85IiGBbi1eHzkQC3j6ioqOD999/ngw8+YNq0aQCsW7eOsLAw45jMzEz+85//cPz4cYYOHYpSqeTRRx9l69atrFmzhhdeeIHQ0FCTld8lS5awdetWPvnkE5sCXBcXF2N1C39/f4KCgszGuLu74+LiQm1trcX3hRBCCNF99Ho9P2cVsyY5i++OF9p0zPBQLxZcF8Gs4cGoHVSdPEMJcO3i4qgi7dkbuu3a9sjMzKSuro5x48YZX/P19WXo0KHGr1NTU9Hr9YwePdrk2NraWmNQqtVqeemll9i4cSO5ubnGrnBubm52zUsIIYQQPduFyzWs35fNmuQsLte03ljJSaVkflIE94wbQJhP93SBlQDXDgqFwu40ge7SUl6zgU6nQ6VS8eOPP+Ll5WVSB9ewAey1117jjTfeYOXKlQwfPhw3Nzcefvhh6urqOm3uQgghhOga9Vod36cVsiY5i1/Olth0zMQh/sxPiuD6KH+Uyp7RJOrqitKE3QYPHoyjoyP79u2jf//+AJSUlHDy5EkmTpwIQHx8PFqtlosXL5KQkGCx0cNPP/3EnDlzuPvuu4GGoPjUqVPExMR06HydnJzQartnI58QQgjRV5y+UMHaPVms35fd+mAgyNOZBddFMDexP16uPbffgAS4fYS7uzv33Xcfjz32GP369SMwMJCnnnrKJIgdMmQId911F3/605947bXXSEhIoKioiB9++IHhw4cza9YsBg8ezGeffcaePXvw8fHh9ddfp6CgoMMD3IiICL777jtOnDhBv3798PLyksYdQgghRDtU1dXzeWouq5OzOHOx0qZjbosPZX5SJMPDOn4jWGeSALcPefXVV6moqODmm2/Gw8ODP//5z5SVlZmMWb16Nc888wyPPfYYubm59OvXj3HjxjFr1iwAnn76abKysrjhhhtwdXXlD3/4A7fccovZedrrgQceYMeOHSQmJlJRUSFlwoQQQog20Ov1pJwrYU3yWb4+mm/TMTHBnixIimD2yBCc7dzz01Mo9LYkZ/Zy5eXleHl5UVZWhqenp8l7NTU1ZGVlERkZibOzczfNsOvodDrKy8vx9PS0mKLQk/S2741Go+Gbb75h1qxZslrdxeTZdw957t1Hnn336axnX1RRy4afGzaClVRpWh2vVMD8pEjuHRdB/37dsxGsrVqK15qTFVwhhBBCiK5QXw8HD+JSaFtpLWu0Oj3b0xs2gu07U2zTMROi/JifFMGkIQE9ZiNYZ5IAVwghhBCiM5SUwL59sGdPw6+ff8axspIBd9wBjV09bZFVVMm6PWdZu+esTeP93NUsuC6C347uj4+bk52Tv7pJgCuEEEII0V56PZw6dSWYTU6GtDTzYZ6eKFuoElSj0fLFwYaNYCcLK2y69M0jQ5ifFEF8fx+7p9/bSIArhBBCCNFWVVVw4MCVgHbPHrh0yXxcVBSMH2/8VR8VRdrWrUQ0vn0wu2Ej2ObDeTZddmigB/OTIrglPvSq3wjWmSTAFUIIIUSfodXp2Z9VzIXLNQR4ODMm0heVLTmpubmmwWxqakNObVNqNYwe3RDMJiXBuHHg7298u7iyjo9+yuK9Ayoe2vu9TfOdNz6CeeMjiPCTjqFtIQGuEEIIIfqErcfyWfFVGvllNcbXvF0cmZ8UyeIpg68EuvX1cPiwaUCbbaERQnBwQyBrWKGNjwenhpxXnU7PjycusPrLfSSfbr6yazmgHjewH/OTIvhVTKBtQbewSgJcIYQQQvR6W4/l86f1qTSvjVparWH1VymcWruRR1yLGHT6CPz8c0MKQlNKJYwceWV1dvx46N8fFA2B6PniKtZ+f5rVyVnYUoDVx9WRBUmR/Pba/vi5qzvmJoWRBLhCCCGE6NW0Oj0rvkprCG71egYV5zAqN52E3AwSctOJunTe/CBv74YUA8Pq7Jgx4O4ONGwE23w4jzVf7CY9v9ymOdw4PJgF10UwPNidb7/9llmzpksN4k4kAa4QQgghOpS1PNfmrycM8CHlXEnb82HboqqKjC+2c+vWz4xBrU/NZbNhmb6hpIbEcDpqOI8/ex+q2JiGVVugsLyGg2dLOHj+PO/uPNPqJQf5u7HgukhujQ/F1ck01NJoWm/CINpPAlzRZZYvX86qVau4cOECmzZt4osvvqC0tJQvvviiu6cmhBB9klan50DmJQrKayiuqMXXzYkAT2fQQ1FlrV1Bp6U812AvZ24eGczmw/kmrysVoGvycX6wlzN/mx3LjLhg+28qJ6ehRJchd/bQIYbV1zOsyZAaBycOBw8hJTSalNAYUkOiKXH1ujKPMjc0u89y6HwpB7NLyGsyZ0vuGTuAe8dHMDjA3f55iw4lAW4vNm/ePNatW2f82tfXl9GjR/PKK68wYsSIDrnG8uXL+eKLLzh06FCL49LT01mxYgWbNm1i7Nix+Pj4MHnyZJp2ip40aRLXXHMNK1eu7JC5CSGEaNB85TQ+zAOAG1bu4lxJbYvHWgs6tTo9+85cYm/mJUDPuIF+FFfVseTjg2bnyC+r4d1dWWav65rlqhaU1fCn9amsunuUbUGuRmO+Gey8ebpBXWAQ33sPJjU0hpTQaNICB6JRWU8PWP7VcZOvlQoYEuhBfH8fhod64evmyNSYQBxUPbulfV8mAW4vN2PGDNasWQNAQUEBf/3rX7npppvItrQbtBNlZmYCMGfOHBSNCflqtSTVCyFEZ7O0ohro7sCTw6GgvAZrO/oNCspqWLg+lUemRhHh50aAhzMllbUs23SUsuorZbLe+jGz3XM1xLsrvkpjWmyQycqxVqcnNfU02j17CEs/RGj6QRT790N1telJVCq45hqT2rOq0DD+55UfTZ5BS7xcHBkT6Ut8f2/iw30YEeaFm1pCpquJfLfsodeb767sKq6uxh2btlCr1QQFBQEQFBTEE088wfXXX8/Fixfxb6zNl5uby9KlS/n+++9RKpVce+21vPXWWwwcOBCAHTt28Pjjj3P8+HEcHR0ZNmwYGzZs4Mcff2TFihUAxqB1zZo1zJs3z2QOy5cvN45TNuYz6fV65s2bZ0xRmDdvHjt37mTnzp28+eabAGRlZREREWHfcxJCCNFi5QBbGY59Y/upDptXa/LLanhr+wkeCtfDnj3kfL2d+t17GH3RwuKMj4/5ZjA3N+q1Ok4WVjSkGfx81OwZWOPvoWbvX6bI6uxVTgJce1RVGXdSdrmKCnCzr9hzRUUFH330EYMHD6Zfv34AVFVVMXnyZCZMmMCuXbtQKpUsX76cWbNmceTIEZRKJbfccgsPPPAAH3/8MXV1dezfvx+FQsHcuXM5duwYW7duZfv27QB4eXmZXffRRx8lIiKC+fPnk5+fb3Fub775JidPniQuLo5nn30WwBiACyGEaDuTygFXAZe6GkYWnCQhJ52E3HRGvZkBNQ2tasOajDvtG9aQNxsaQ0poDI8+OJsZI0K5cLmGg9mlHPrpPAezSziSU0ZVnXlL3OZ5vwaGpaPn5gyT4LYXkAC3l9uyZQvujcF4ZWUlwcHBbNmyxbiS+p///AelUsm///1vFAoFOp2Ot99+m4iICHbs2EFiYiJlZWXcdNNNDBo0CICYmBjj+d3d3XFwcDCuElvi7u6Ot7c3gNVxXl5eODk54erq2uK5hBBC2GZ/VrHNH8l3Ob2ekMsXSchJZ1ReQ6mu2MIzOOh1JsOqHdWkhw1lb+DQxqA2mlIXT5MxD39yhH7fnCC3tFmqAuCudmBkuBfx4T7E9/dmZLg3Pq5OvPXDKdYknzVZyQ7qiA1uoseQANcerq4NK6ndde02mDx5MqtWrQKguLiYd955h5kzZ7J//34GDBhASkoKp0+fxsPDw+S4mpoaMjMzmT59OvPmzeOGG25g2rRpTJ06lTvvvJPgYPkBIIQQPZVWpyf59MXunoaRg7ae2AtnSMxJbyzVlU5wRfPuXpDn4UdK48psSmgM6QGR1KtaDlVqNDpyS6tRKGBIgEdD3mx/b+L7+zDI391iBYiHpg5h8ZQo+1r2iquCBLj2UCjsThPoam5ubgwePNj4dUJCAl5eXvzrX//i+eefR6fTkZCQwEcffQSATqejoqICd3d3AgMDgYa82gcffJCtW7eyceNG/vrXv7Jt2zbGjh3bLfckhBDCOkubyrqaT1WZcWU2ITeDEfmncKk3rdZQr1ByPHAQqY2lulJCY8j3tC817f9NHsTCiYPwcLa9cYJKqWDcoH52XU/0fBLg9jEKhQKlUkl1467TUaNGsXHjRgICAvD09ESn01FeXo6np6cxjQEgPj6e+Ph4li1bxrhx49iwYQNjx47FyckJrdY8x8keHXkuIYToi6xtKutMCr2OQZdySMhNb1ihzUtnUHGu2bgSZw9SQqONubNHgqKodnLukDlcN9i/TcGt6P0kwO3lamtrKSgoAKCkpIS33nqLiooKZs+eDcDvfvc7Xn31VebMmcOzzz5LSEgIGRkZfPfddzz++ONoNBree+89br75ZkJCQjhx4gQnT57k97//PQARERFkZWVx6NAhwsLC8PDwsLv8V0REBD///DNnz57F3d0dX19fkyBbCCGEdV21qcy1rpqR+ScbV2fTGZWbgVdtpdm4U/3CG1dmG4LaM76h6BVt/5nu7KCgpt7yXSloyJ0dE+nb5sYQmQUAACAASURBVPOK3k0C3F5u69atxnxZDw8PoqOj+eSTT5g0aRIArq6u7Nq1iyeeeILbbruNy5cvExwczNSpU/H09KS6upqMjAzWrVvHpUuXCA4OZvHixfzxj38E4Pbbb+fzzz9n8uTJlJaWWiwTZqtHH32Ue++9l9jYWKqrq6VMmBCiVzM0X8gvrebg+RL0QGQ/N+4ZF4GTg9Jqu1trOmVTmV5PaPnFxkC2IaCNuZBlthmsylHNoeChxoD2YEg0ZS4eVk7aNgsnDuLN/zvdMJ0mrxuexN9mx0rurDAjAW4vtnbtWtauXdvquKCgIGPHs+YpCp6enmzatMnqsWq1mk8//bTVa9xyyy0mXcsM82tqyJAh7N27t9VzCSFET9I8EE0Y4EPKuZIWA9OW8mT/55t0pkT7k5pdSnHllV3+wV7OPH1jDD5uapNzQ0Nw++0xy2UY28JRq2FY4RmTgDaoothsXI6nvzHVICU0hgz/iFY3g9nDx9WRJb8aQnSwp9nzkqoHoiUS4AohhBB2shSoNq+z2rzVbWt5sjo9bE83r4CQX1bDog2mbXC9XRvyTkurbG/c0JRPZRlx5080phukMaLgNM71dSZjNEoVxwMHkhIa21CqKySaAk8/u67XVi/eNhyVUsGMuGCmxQZJ1QNhMwlwhRBC9Dlt/fjfEmuBavMmAgVlNfxpfSqr7h7FtNgg/vK57V21WtOWwFah1xFVlE1Cbgaj89L41doM5uTlmY0rdvFsthlsMDWOHbMZzFY+ro68eNtwk9VZqXog2qJHBrjvvPMOr776Kvn5+QwbNoyVK1cyYcIEq+M/+ugjXnnlFU6dOoWXlxczZszg73//u7FblxBCCGFgadW1+Spra9qyoUtPQ77oiq/SyMgvt3u1ta3caquabAbLYFReBp4WNoOd7NeflNBoUsIaVmizfELa1BK+w+arVjFvXATjB/sxdmA/WZ0V7dLjAtyNGzfy8MMP884775CUlMS7777LzJkzSUtLo3///mbjd+/eze9//3veeOMNZs+eTW5uLgsXLuT+++9vMXdUCCFE32Nt1bXpKqstQW5bN3TpaUgx+NdPWW2bsM0X0BNWVmgMZhNy04m+eBZVs81glY7OHAoZwuGwGOInR7GkYhhF6o7ZDNZer94+klkjJJ9WdIweF+C+/vrr3Hfffdx///0ArFy5ku+++45Vq1bx4osvmo3ft28fERERPPjggwBERkbyxz/+kVdeecXqNWpra6mtvVJwury8HACNRoNGY/ov6/r6evR6PVqtFp3O9AdFb2TYCKbX63v8/Wq1WvR6PfX19Wbft6uR4R56w71cbeTZd4/2PnetTk/KuRKKKmrxc1eTMMCnxVU/rU7PC1uO4aSyXnLqxa+PM2GQL4fOl7Z43v87nofaynlaUq+tR61q82FmHOs1xBZmEp+TwaicNOJzMgioLDEbl+MVwMHQaFLDYkkNjeZkQAQahQqlAkLUUGTl0SvQo1CAkobFXAWdv6jr5azsE38H5eeN/dryzBT65lvbu1FdXR2urq588skn3HrrrcbXH3roIQ4dOsTOnTvNjtmzZw+TJ09m06ZNzJw5kwsXLnDnnXcSExPDP//5T4vXWb58OStWrDB7fcOGDbg2a4WrUCgIDg4mKCjIrJ2t6F6XL1+moKCA/Px8swoNQgjRm6hLS/HJyMA3IwPfEyfwPn0aVbP/2escHCgdOJDi6GiKo6MpHDyUE2o/zlXA2csKzlUoKNeYR6muDnoi3PUMcNcT4QH93fW49rjlLyGgqqqKu+66i7KyMjw9PVsc26MC3Ly8PEJDQ0lOTmb8+PHG11944QXWrVvHiRMnLB736aefMn/+fGpqaqivr+fmm2/m008/xdHRclcTSyu44eHhFBUVWXxghYWFlJeX4+/vj6urK4puyE3qKnq9nsrKStzc3Hrsfer1eqqqqrh48SKenp7GlsJXO41Gw7Zt25g2bZrVP7uic8iz7x72Pvft6YU8svGQWZqB4SfWG3OvYWpMoNkxD288ZNc8m5538tAAbli5i4LyzmuDq9RpGVx0nvicdOJzMxiVk86AEvMSYMUunhwMi+FgWEOr26NBg6lxUKMD9HpDzdjmP8f1KAAHJcwdqGPTWQUancLq6qyro4rnb4njle9OUFhe06lNJFbfO7pPNGyQnzf2Ky8vx8/Pz6YAt0f+G615YKXX660GW2lpaTz44IM888wz3HDDDeTn5/PYY4+xcOFC3n//fYvHqNVqi922HB0dLf5hCw0NRaVSUVRUZMfdXF30ej3V1dW4uLj02ADXwMfHh6CgoB4/z7ay9udQdD559t2jLc9dq9Pz7NcnqNFa/nuvAJ79+gTT40KNaQWGY2qtHGMLw3k9XZ05V1KLeeBoP/faKq7JO2HsDHZN3gk866pMxuhQcNKvf5Pas9GctbQZrNUIVIEeUCr0jPbX80mWkjqd9XtZPW80SVF+qBwc+NP6VNsuYXK1hvHero6UVWksHmvoRjZ2cECf2lgmP2/ari3Pq0cFuH5+fqhUKmNrWYMLFy5YXaV78cUXSUpK4rHHHgNgxIgRuLm5MWHCBJ5//nljF6/2MKQpBAQE9PqcGY1Gw65du7j++ut79F88R0dHVKoOSGQTQlxVWtvcZdjMtT+r2FhSqiM6fBnOuzfzUrvOg15PeONmsMScNBJy0xl68RzKZqFfhZMLh4KHGBspHAoZSrmzu12XXDx5MFGB7hRdruW5r9NtOsYYdDY+wxlxway6e5TV5hTWGJoxAPxpfaox4G16HZBuZKLj9agA18nJiYSEBLZt22aSg7tt2zbmzJlj8ZiqqiocHExvwxD4dHT2hUql6vVBlUqlor6+Hmdn5x4d4Aoh+qYLl20LrpqOs/UY27Tt/yvDfBxRHz3SsDqb17BC619ZajYu2yvQGMymhsZwwn8AWmXH/P8mabAf4wb148tDuW06rnnQ2bTZwva0AjYeOE9FrdbkGB9XR+aNjyTCz9WsvrClAFm6kYnO0qMCXIClS5dyzz33kJiYyLhx43jvvffIzs5m4cKFACxbtozc3Fw++OADAGbPns0DDzzAqlWrjCkKDz/8MGPGjCEkJKQ7b0UIIUQHC/CwreFA03G2HmOLcQP9+Cw11+oqpn9FCaPy0knIaQhm4wpPo9bWm4ypUzpwLGjQlYA2JJoLHh1ft92wCmvIa7X1Ofi6OfLCrcMtBp2GZgvjBvXjyRtj2Zd5ib1nioCG11uqXyvdyERX6nEB7ty5c7l06RLPPvss+fn5xMXF8c033zBgwAAA8vPzyc7ONo6fN28ely9f5q233uLPf/4z3t7eTJkyhZdffrm7bkEIIUSjtnQMs2XsmEhfgr2cKSizvOGpeVCn1enR6fR4uzhSWm09xSzYyxm9Xk9hea3VNVpDW9ybRgTzr5+yUOq0DC0619BEoTF/dkBpgdlxRa5exmA2JTSGY0GDqXVwsjqXjtR0Fbbps7Omn5sTe5f9CicHZavnVikVJEX5kRRle9te6UYmukqPC3ABFi1axKJFiyy+t3btWrPXlixZwpIlSzp5VkIIIdqiLR3DbB2rUir42+xYm/I5LZ3TmpbyRA20JaX886+rSMxJ58PcdK7JP4FHXbXJGB0KTvgPIDW0obLBgdBYsr2DOqyIrJuTiso6besDgT9cH9nis2vK8PX/3BpnU3ArRE/XIwNcIYQQVzdrHcPyy2pYuD6Vd+6KZ1qMP9BQwmvRhsM2dxeztuGpaT6ntetb80tWMVNjg3j7rnie+zqd/NJqBpTmGysbjMrNsLgZ7LKTCwdDoo0B7aGQoVxWu9l41db5uDpy17X9UdCQHjF2UD+2pRWwfHNaq6XKNh/O5/EZMWZ5tKvuHsWLXx8HrrTtlVxY0dtIgCuEEKJDaXV6VnyV1mJwufjjg/xj7kgAXvo2w+JYPQ0ri8s3H8fD2ZGiilpj6kJL+Zy2XL+59TtPcnjj10y6dJpNtdn4Hk7Bqdi8NOQ57yDjRrCU0GhO+A1A10GbwSwpqdJw3WB/k4/1Z8QF4+bowD1r9rd4bH5ZDWuTs/DzUJs8nxlxwUyK6sd3W7/lldtHEODlJrmwoteRAFcIIUSHsqUsl04PSz85xCtjaFyJtBxc6YGC8lp+9++fja81TV2wlM9py/X9K4qNq7MJuenEFWTipDPdDFarcuBoUFRjQBtNakgMF919WjxvZ9iWVmByn1uP5fOXz47adGzTsmBNn5shmJ01PFgq5oheSQJcIYToY5pu5vJzV4MeiiprO2xXe8eW5TJnLXXB2vVVOi1DL54jITetMaDNILys0Oy4i27eDRvBQmI4HjGMlH6RXbYZrCWrk88aV63bmnrRVNPn9quhtm8ME+JqJAGuEEL0Ia1tvLK2CawtOrIslyWG1IUVX6UxLTbIJCDX6vSU511k4pkUY2WDa/JP4m5lM9iBsFhjdYPzXoEdthmsIxnudUp0YJtTL5pq+twmRU3ouAkK0QNJgCuEEL1Y09Xas0VVrNx+ssUAybDK9/Zd8fi4qU3yWwGznFdLrxnKUdna8crNUUWtVtem+zJ2LDtziXG6Ytizh/NbtlP3UzK/u3COe5rdZbmTK4dChpp0BqtQu7Z4DbVK2eZ5WWIoL1ZaZV8nTMO9frj3bId1ZEs5V9Ku8wjR00mAK4QQvVRbymQZGMLCxR8fRNckRnRTq3BQKiirvpKn6q52QKfXU9WkbFWwlzNP3xjDb0b3543tJ226ZqVGi7Uc3ObUmlpGFJwiITejobrBu6egtBiA8CbjznoHkxIaTUrjCu2pfuFt3gy2aPIgVm4/BbTevyzIU81vx/Qnws/NYtoHmP5DoKSyoW1uW74354qr2jT/lhRV1HbYuYToiSTAFUKIXuibI3ks2nDQ7uN1zSK6ylrz2qsVtfVmr+WX1bTrus0FXi4yBrMJuekMK8zEUWc6F71azZGgwewNHEpq44awIjf7N4MZmkUsnhLF0CAPi/V5n74xxmyFu7Xc5eYb4m6IC2Z/VjHJpy/y1o+Zrc5rgG/LK85t4eeuxrxGhBC9hwS4QgjRy3xzJJ/FH3dckNlVVDot0ReyjBvBEnLTCCu/aDbugpsPBxpTDRyuS2KnWygZJa1//P/H6wfy8NQhHDpfyra0AlYnn221WURntpc1dPUaE+nLZ6m5rXZnu2dcBP/endXiuEBPNaCgsLzlcyUM8OG7dAsDhOglJMAVQoheZOuxfBZtSO3uadjEs7qCgAPHeXjHSUbmZHBN/glcNaYfnWsVSjL8IxpzZxuaKeQ03QxWB9TZltsaG+KJi5OKcYP6GQPLlppFGHR2e1lbu7M5OShbHbf85mGA5Y5szYN3IXozCXCFEKKXMDQ46JH0egYW5zZ2BWtYoR1yKRuAcU2GlTu5ctDY5jaGw8FDqGxhM9iMuCCiAtz5xw+nW51C8+oOnbk621a2dGdry7jWxmg09m14E+JqIQGuEEJ0sqaVDDoziLKlwUFXcdbUMDL/lDGgHZV3At/qcrNx5UHBbPOP4UBILCmh0Zzy649eobTpGsFezrx91ygAPk3JafXeSyrrzF7r7NXZtrA14LZlXE8K3oXoDhLgCiFEJ7JUycCWTUr2BMWd3WChJUHlRcaNYKPy0hlWeMZsM1itypHDwVGkhsZwIDSW1NChFLt623U9BaYftT99Y0yrm9ue+zqNG+KCenSQZ2vAbcu4nhS8C9HVJMAVQohOYq3rlKVKA00bLFgLiltrwNDZDRYMHLT1xBg3g6UzKjeD0Mvmm8EK3X05EBpDauOGsOOBA9GoTNvCKhqfjr5ZmbB37hqFj5sT3x3P57PUXC7XXKnYYOlZ+LipW513flkN+7OKJegTog+QAFcIITqBIR/W1q5ThgYLf7g+kvd2ZVkMiheuT+W+pAimxgZZXNFNGOCDr5sTxRY+im8Pr+rLjMq7UqprZP5Ji5vB0gMiGzeCNdSezfX0t9oZzNlRyQNJEYRVnuSZVBWGKmTNg9dxg/rx9E3DWl3NtnX1ujtXuYUQXUcCXCGE6ARtzYc1BLT/+sk8uG3q/eSzvJ98Fm8XR+YnRbJ4ymBUSoVx1be9wa1Cr2vYDJaTbgxoBxfnmI0rU7uR2rgZLKVxM1iVk4vN16nR6Bg70JeidFh972iKquqtBq+2fNRu6+p1V61yCyG6lwS4QgjRCexdKWzeYMGa0moNb2w/yZo9WcxNDLO46msLl7oaRhacZJShM1huBj41l83GZfqGGoPZlNAYMvuF2bwZzBpDN60xkb44Ojq2MrplhvbArdWSNXQVE0L0bhLgCiFEJ+iqlcLSKg3v7sqyeXxw+UXjymxCbjqxhWdw0OtMxtQ4OHE4eIix7mxqSDQlrl4dPfUO7aZlay3ZnrzBTAjRcSTAFUKIFthb4mtMpC/ero6UVnVfvVEHbT2xF84YO4ONyk0n5LJ5SFng7suB0FhSwhpWZ9MDIs02g3WkzuqmZWuNWCFE7ycBrhBCWGFvNYPu4l1dzqjcDBJz00jIzWBE/ilc6k03g9UrlKQFDjSuzKaExZDnYX0zWEfr7NVUqf8qhAAJcIUQwiJrJb4M1Q5W3T2qxSB3f1Zxp67eKvQ6Bl3KaZJukMEgC5vBSp3djXmzqaHRHA4aQrWT5fSJm4YHseVoQafNGbqmm5bUfxVCSIArhBDNtFTiS0/DKuSKr9KYFmu9aUBHl6NyratmZP4pRuWmk5ibxqjcDLxqK83GnfYNM9kMdqZfqM2bwaYNCyLUx6VNOb22WDx5EFGBHrKaKoToMhLgCiH6FEs5tc21VuJLT+tNA9q1yUyvJ7RxM9ioxhXamAtZZpvBqh3UHA6O4kBYQ93ZgyFDKXXxtPuyAR7OzJkVyqkLFfyQYd64wV5Jg/1lRVUI0aUkwBVC9BnWcmqfuXGoybiOaBpQUlmLUmFb2S9HrYbYwjMk5GaQkJtGQm46QRXFZuNyPfxNas+mB0RSr7L+YzzIU80zN8WybNNRyqrrrY6DhudgCPYfmDDI5gC3pXuU0lxCiO4iAa4QolczrNhuTyvg/eSzZu8XlNXwyMZDvDzmymvtbRqw9Vg+/2/DQat1aX2ryprUnU1nZMEpnOtNGzRolCqOBw4kNeRK/my+p3+rc3r6xhj8PNQm6QBKpYKF61NbPK7ppq/WasoaKIAHJjR0XgMpzSWE6DkkwBVC9FqWVmybaxqUaXV6HGlf04Dm+bsKvY7BReeNG8ESctMYWJJndlyJswcpodGkGjuDRVHjeCWADvdxwbWyjqo6rcX7MMxpXlKkWUA5Iy6Yf949ir98doTSZiu5Pq6OvHjbcJMNcy3VlLV0XHx/HynNJYToUSTAFUL0StaqIFhiGJNyroSkIYHtahpw4Og5Ig/v49eG2rN5GXha2Ax2sl9/k4D2jG+oxVJd/dyc+NvsWG6+JtR4T03nbMuc4Er5rH2Zl9h7pghoqDQwdmA/i8dYqynb0CI4gsVToozHSWkuIURPIwGuEKLXaakKQksMrWPBxqYBej2cO4dudzIXvvsR5wM/M/pkGht0ppvBqhzVHAoe2pg7G83BkGjKXDwAcFQpGBnmzdQBPsSHezM8zIvzxdUWA8X2NjJQKRUkRfmRFOVn0/OwFrgCFoPZ9mwks7ehhhBCWCIBrhDiqtc8ONLp9S2mJVjj5642+bppgFdQXkNpcTmROaeI2PBv9CcOo9i7B/LzUQJBTY7L8QwwBrMpoTFkBESiVapMzj0/KYLbR4UxNMgDR5VpGa8wH1fjPW05kmcS8HX1amnzwLUzml9sTy/k2a9PXDUNNYQQPZ8EuEKIq5qlgMvbxb42s2aNGS5cQLV3L4Fffo/LD7uIyTmBWms6pmEz2KArzRRCoinwtL5CasiV/euN1tMJWgsiu6uRQXubX1jzyMZD1GhNn0V7zymE6Nt6ZID7zjvv8Oqrr5Kfn8+wYcNYuXIlEyZMsDq+traWZ599lvXr11NQUEBYWBhPPfUUCxYs6MJZCyG6mrWAq7Tajg5ZOh3vvv0FEcFVDDt3HPbsgdOnARjYZNglF09j3mxKaDRHgqKodVRbPmcztuTKWrun/G4O+Dqi+YWlcxqO76hzCiEE9MAAd+PGjTz88MO88847JCUl8e677zJz5kzS0tLo37+/xWPuvPNOCgsLef/99xk8eDAXLlygvr7lmo9CiKubvXm2Bm61VVyTf5KE3HRG56UzdmUGc6qqzMad8OvfWKYrhgOhMZz1CbG4GcwWreXKtnZPemDZ50e7JeDriOYXzaWcK2nxfXvOKYQQ0AMD3Ndff5377ruP+++/H4CVK1fy3XffsWrVKl588UWz8Vu3bmXnzp2cOXMGX9+GzQ8RERFdOWUhRDdoLeAyodcTXlbYWKqr4dfQi+dQNesMVunozMGQocaA9mDIUMqd3ds1z8WTBxMV6G5Trqwt91RSpeGtH07x0NQh7ZpXW3VE84vmmm7q66hzCiEE9LAAt66ujpSUFP7yl7+YvD59+nT27Nlj8ZjNmzeTmJjIK6+8wocffoibmxs333wzzz33HC4uLhaPqa2tpbb2yg/W8vJyADQaDRqNHR9t9iKG++/rz6E7yLNvWMFMOVdCUUUtfu5qEgb4WA0IL5RVolZZXut0rNcwrCCT+Nx04nPSic/JIKDSfLXwvFeAMW82JSyWDP8ItEoVKgXo0aMEHBV6FNi9aMu4SG9j5QGdth6d5TK2rd5TUxv2ZvHHCRFduorr5+pg09z8XB1s/jPs66KiGFArWz5vW84pbCM/b7qPPHv7teWZKfR6vb2f8HW4vLw8QkNDSU5OZvz48cbXX3jhBdatW8eJEyfMjpkxYwY7duxg6tSpPPPMMxQVFbFo0SKmTJnC6tWrLV5n+fLlrFixwuz1DRs24Orq2nE3JIToEurSUnwzMvDJyMA3IwPv06dRNUtT0igdOBpkuhnsgkc/nFV6BrjrGeAOER4Nv3e3b4+aEEKITlRVVcVdd91FWVkZnp6eLY7tUSu4BopmSyV6vd7sNQOdTodCoeCjjz7Cy8sLaEhz+PWvf83bb79tcRV32bJlLF261Ph1eXk54eHhTJ8+vdUH1ttpNBq2bdvGtGnTcHSU/8t3pa589raulLZlRbUtY5vbnl7IIxsPWc09XTB+AEunRzdeSMvPW35i30dbGHz6KPG5GQwoyTc7psjVq3EzWDQHQmM5FjSYWgdH42qsYXVWp4f8KlgUq+PpA0pqdUqzc7WV4a7fmHsNU2MCbT5Oq9Mz8ZUfKa1pfZXildtHMGt41242M3yfwHKjibber+HP/DMHlNTqFB1yTmEb+VnffeTZ28/wibstelSA6+fnh0qloqCgwOT1CxcuEBho+QdccHAwoaGhxuAWICYmBr1eT05ODlFRUWbHqNVq1GrzXc+Ojo7yh62RPIvu09nP3tY6pm2pd9rW2qhN69b6uatZsSXDrEyUgXttFcc++IKzW0qJyjxK/Z69XFdZwXVNxuhQcMJ/AKmNdWdTQmM45x1sMa9AT0N/BsN/4cqwWp2CWivzaM4w6g/XR7L5cH6H1HB1BO4aN5A3tp9sdWyAl1uX/x2dOSIMhVLV4XVwX7ojXurgdhP5Wd995Nm3XVueV48KcJ2cnEhISGDbtm3ceuutxte3bdvGnDlzLB6TlJTEJ598QkVFBe7uDZtBTp48iVKpJCwsrEvmLcTVwtY6pm2pd9rW2qiWgmEjvZ7+pQVmm8GUTc7uAFQ4uXAweKhxhfZgaDSX1W7GMV4uDtw1PIgfMi5SUH4l394QNAHW52CjphURHp8RY7XxQls7dC2eMpg1yWcorbZcCcZQR9eQ19vVOqPRxNSYQKbHhUonMyFEh+lRAS7A0qVLueeee0hMTGTcuHG89957ZGdns3DhQqAhvSA3N5cPPvgAgLvuuovnnnuO+fPns2LFCoqKinjsscdYsGCB1U1mQvRGrQVSWp2e5ZuPt1pzdEp0oM31Tmn8va11TJsHw+r6OoYVZJKYm0ZCbjqjcjPwryo1O9c57yBjZYOU0GhO+A1A16wzWFPv/C6BpMF+LT6TpkGan6sDRen7rJ6vqcWTB5E02N/kXNYaL9jT9WtbWoHVHW221NHtCp3RaKK7mlcIIXqnHhfgzp07l0uXLvHss8+Sn59PXFwc33zzDQMGDAAgPz+f7Oxs43h3d3e2bdvGkiVLSExMpF+/ftx55508//zz3XULQnQ5WwKpt344bbKa2Zyh5uiHe8/aXO+Uxt/bMnZMpC//2LCb6ScOGVdn4wpPo9aarlTWqhw4Fjj4ymaw0Bguuvu0+gyaMpSfailoavqeRqPhm3QI8nQmu6TWYsBuWDl9ZNpQgFZXG+3p+mXtGAMvV0deum24fGwvhBCtaFOAq1QqrW72aolCoWhT44VFixaxaNEii++tXbvW7LXo6Gi2bdvW5nkJ0RvYEkjpdNiU1wlwrti82YElrdUmVeq0DC06R0JOOmEPvo/mSCpf55wzG3fR1ZuUsBhSQhoC2uNBg6h1cLJpDtYEeDjbddxfZkazaMNhFFjeRPW32bFsSyto9R8T9nT9sqVxhYujyrhyLoQQwro2BbjXX3+9XQGuEKJz2BJIPfHZES7X2P4PzAG+tpXKax5EetRWEp+bQUJuBqNy04nPP4F7XbXJGMNmsBRjq9sYsr2D7C8y20x781OnxgSy6u5RZgFsUJPcXVtWZe3p+mVLkwfp6iWEELZpU4C7Y8eOTpqGEMIetgRSZVY2K1kS7OXMPeMi+MePpymtslyqSgEEeaoZoy1GkZzMyh8+JTrrGEOKsk02gwFcdnLhYMiVygaHQoZSoe6YWtMtrbK2Jz/V2iYqgOte/sGmVVl7un7Zekzy6SLZiCWEEK3ocTm4QgjbdXQL07/NjuWHjEKz4FatqWV44enG3NkMri86heqpSwDc0mTcWe9gUkKjGzeDxXDSrz+jIv2YOTyYBSig0gAAIABJREFUh8O8WLwhlcpyyzmubfHI1CH855dsi6usHZGfail3d2/mJZtXZW1NkWg6ztZj3vrxtPH3UkpLCCEskwBX9AltLdV0tbA319SSR6ZGMS02iKSX/g//imLjRrDEnHSGFWbipGu+GcyRI0FRxoD2YGg0F92ubAYL8FDzzpxhJsHX8puH8af1qWarr7YypCAsnjKYxVMGd+n3tC2rsjeNCCHYy5mCspoWN6w1TaUYE+nb4jGWtLRhTQgh+rIOCXD37t3L9u3bycvLo7bWfJe2QqHg/fff74hLCdFm9pRq6qmaB+oJA3zaHBQ1p9JpGVORw5KMLE6+8Gc+Sf2F8LJCs3EX3bw5EBprDGhrho8kbmAA8f19eCTcm0H+7qScK2kx4JwRF2wxx9XH1RE9WE2LAMspCF2Zi9qWVVmVUsHfZsdaDOatpVK0dIw11jasCSFEX9euALe+vp7f/va3fP7558Z2unr9lR/Lhq8lwBXdxZ5STT2VtUD95pHBvLcry+bzeNZUEJ93goScNBLy0rkm7yRumoZzNjbDRatQkuEf0Zg725BDm+MVaNwM9tJtw/nNmP5m524t4NTq9Hi5OPH4DUMprqzD111NkOeVlUxD8H62qIqP92dTUG6agvCb0f2prtPy/k9nTI7tisAuYYAPvm6OFFe2kJvcZFXWWjDfUiqFtWNaYmnDmhBC9HXtCnBfe+01PvvsMxYsWMCiRYtITEzk4YcfZu7cuezatYuXXnqJqVOn8vLLL3fUfIWwmT2lmnqqlgL193Zlcf+ECN7ffRZd8wF6PZEleY1NFBo7gxVl01y5kysHm7S5PRw8pMXNYAP6uVl9r6V7sLaSbmlFtmkKwtmiSj7en22x1JmlEl0dnbpgmHtLwS2Yr8ra0/Wr+TGnCi/z1o+Zrc6xo/OxhRDiatauAPejjz4iLi6Of//738bXvL29ufbaa7n22muZNWsWY8aMYcqUKfzxj39s92SFaAt7SjX1RLYE6p+l5qLTN2wGG1FwioTcDBJy0xiVm0G/6nKz47J8gkkJjTWu0J7y649eobRpPsF2lOGyZyXdsNFr67F8Vm4/ZfUj+/wm5wDzFrztTUdprfkCtLwqa0+HrqbH7M28ZFOA25H52EIIcbVrV4B7+vRp7r//fuPXCoUCjebKCsewYcOYPXs2q1atkgBXdDl7SjX1RC0F6oGXixqD2YbV2WGFmTjqtCZjalWOHA6OMlY2SA2J5pKbt93zaWsZrvaspNvS/MBg2edHKbGQw9uedBRbrt/PzYmdj03GycG2fyC0VWubz9pb+1cIIXqjdgW4Tk5OuLpe+RjT3d2dCxcumIwZMGAAX331VXsuI4Rd7CnV1BMZAnCVTkv0hSxjqa6E3DTCyi+aj3fz4UBoDClhDSu0xwMHolE5dshcHpka1eYgsT0r6bY0PzCcw1Jwa3jP3nQUW65/qbKOlHMlnfYpgD0b1oQQoq9rV4AbHh7O+fPnjV9HR0eza9cu48YygH379uHrKysLoutd9StfxcWwbx8jN29jw7c/cE3+CVw1plVKtAol6QGRJrVnczwDzDqDGe711vgQ3tlxxq7pBHs5s3hKVJuPa89KeketrtubjtJTPgWwZ8OaEEL0Ze0KcCdOnMiXX35pDGjnzp3Lo48+yk033cSsWbPYvXs3u3fvZsGCBR01XyFsdlWtfOn1cOIEYdv/j8r/fo5y7x48sxoK+kc0/gIoU7uR2mwzWJWTC/7uTiyfPYzNHx9s8V69XJzaHOC291m1ZyW9o1fX2xqI9qRPAezZsCaEEH1VuwLcBQsWoNVqycnJITw8nCVLlrBjxw62bNnCt99+C8CYMWN46aWXOmSyQrRVj135qqqCX36hesdPVO7YhVvqL7iUl5LQbFimbyipITGkRw7jJ/8hnPYLN9kMpmj89dwtccyIC0alUrR4r1qdvsVSV5a091m1ZyXdcKytJbNa09ZAtKd9CmDPhjUhhOiL2hXgjho1ilWrVhm/dnR0ZPPmzRw4cIDMzEwGDBjAmDFjUCo7Z/OFELboEStfOTnU795N6fadkLwHn1NpqLT1uAAujUNqHJw4EjSYQ/2HUTJyNOoJ4xkaN5Dr+ntzm4czb/1wmjXJWZRWXwlOmwefrd2rSqng+TlxLNpwsMXp+ro58vRNwzqkzmx7VtKbHtvSRi8F4OXqSFmVpkMD0avqUwAhhBBGndKqNzExkcTExM44tRB26dKVL40GDh+m7P92NqzOpuzH62IBDoBfk2EF7r4cCI3l3NCRaK4di+/4RC7nnWD+bTNwdVYbx1mqH+vt4sj8pAgWT4kyC65au9dZI0L4Y04p71ppDqEAXrh1eIeubrdnJb215geGMmBApwSiPfZTACGEEFZ1SIBbV1fH9u3bycjIoLKykqeffhqAmpoaysvL8fPzk1Vc0XtdukTtT8lc2rYD/Z49+KUdRl1Xgxfg1TikvnEz2NH+wyiJH436+usYnBDDdf19uMnVCQCNRsM335zAUXXl74q1Gqxl1RpWbj/F0CAPuwKsZbNiGRnmw1+/PEZxZZ3x9c5sYdyelfSmxxaUVZt1QTOco7MC0R7xKYAQQgibtTvA3bx5M3/4wx+4ePGicbOZIcA9cuQI48aN48MPP+Suu+5q92SF6HY6HfqMDC5+/yOVP/6EW8p+AnKzUAMhTYaVqd1I/f/t3XtYFOf5PvB7WY4Ci2cEOXpChEQDKHLyiFC1tulVr/itjYcEbfipSZRqitVEtElsjUk1TTAmlVirMdqorYnGSKNRFFFBNCqLIqLgCiKEo0RY4P39Ydi6Liq7uAwM9+e6/GPffWf2macbezv7zoybLwoGD0PdiJHoMTYcTw/ui//rYQ+LFoYicz+JbdLTLoj2b9vQ1poz6S3Z1pxBlOtfiYg6jlYF3OPHj2Pq1KlwcXHB+vXrkZaWhu3bt+veHzFiBAYMGIBdu3Yx4FLHdOcOqlNSUfzNYeDECfS+cAYOdyrR+4Fpud3dcNHLD+XPDIf1qHB4hwYg2KMbxlqb/p9YWzyJTY6hTY7HRERExmlVwH3zzTfRtWtXpKeno1evXigtLTWYExgYiFOnTrXmY4jaTH3eNRR+fQh3vrt3dtb1WjYcGhvhcN+cHy1t8L3rIGh8h0EbPBLdxo2C/9D+mOJkq7v/85PQXu7BSkRE1NG0KuCmpaVh6tSp6NWr10PnuLu7Y+/eva35GJKphkYh7ZpGrRalx06i+JvDEKmp6H3hDHqWFcP9gWmFDj2g7vcUKoYNh/XocHiMDUWAR3cEK827rrw93YOViIioI2lVwK2trYWTk9Mj51RUVPACMzLQ3J0BzHmBEwDcLbyFgn3f6s7OuudeRA9tLe7/MbteYYFsl/7Q+D4D7YiR6D5hDAaP8MM4e2uz1PQo7e0erERERB1FqwJuv379kJ6e/sg5J06cwODBg1vzMSQzD7szQFHFXfy/rWew4fmAVodc0dAATVrmvbWzqanoff4M3Irz8eCDZsttHXCp31MoHxYE61Hh8IgahSGezvBvB1fH8x6sREREpmlVwP31r3+NN998E1u2bMHMmTMN3l+7di0uXLiANWvWtOZjSEbMdWeAittluPb1d6g5fBT2GSfhlXMebner4fbAvKu9PKDxfQb1wSPRNXIMBkUEINiu7c/OthTvwUpERGS8VgXcJUuWYNeuXXjhhRewdetW3L177/+AX3vtNZw4cQKpqakYNmwYFixY8ESKpY7vSdwZoL6+AXln1Lj1zSEg9d6dDfpprmCoaNSbV2Nlg1yvIffWzo4KQ99J4+Dt3Rf9nuCFYG2B92AlIiIyTqsCroODA1JSUrBgwQLs3LkTDQ0NAO6duVUoFHjuueeQmJgIGxubx+yJOgtT7gxQXFKJq/89jjuHjsA+4xS8c77HwKpSg+UGRV1731s7GzwS3SPHwGtcCJ6yk8d3j7e+IiIiarlWP+ihW7du2LZtG95//32cPn0aP/zwA1QqFYYPHw5nZ+cnUSPJSEuu+O9eU4Hqnbtx8I0M9D5/BoNvXMLI+jq9OVoLJfI9BqF82HBYR4TBbfJ49PHpjz7mKpyIiIg6jCfyqF4A6NGjB372s58ZjOfl5WHlypXYvHnzk/oo6sAevDOAQjRiQEkBgjRqBGrUCNCo0a/spsF2FfZOuvvOdo8cA9fICPR3sG/7AyAiIqJ274kF3Afl5+fjT3/6E7Zs2YL6+noGXELlXS0uqjX4bXUOao8fQ6AmGwE3s6GqvWMwV+PqjfJhw2ETEQaXyePh5D8ETh1s7SwRERFJw6SAe+zYMbz++uvIyMiApaUlIiIisGbNGvj4+KCmpgbLly9HYmIi6urq4OrqiqVLlz7puqmda2gUyLlVicsnL6D68FE4ZJxC/5zvMeL2NYQ8cDHYHStbnHUdhIue/hjw7ASMnfUL9O3eHX0lqp2IiIg6NqMDbkZGBiIjI1FX9781kV9++SVOnz6No0eP4tlnn0VWVhZcXV3xhz/8Ab/73e94kVkncLuqFudyb6HwcCqQegLOFzIw9IYav6j+wWBuaU8XlA8LglVEOEqeCsQN9wHo1c0BMbwzABERET0BRgfcNWvWoK6uDqtXr0ZMTAwA4KOPPsIbb7yBiIgI3L59G8uXL8cf//hH2Nqa9gjRxMREvPPOOygsLISfnx/WrVuHiIiIx253/PhxjB49Gv7+/jh79qxJn02PV1vfgKyblVCfu4Lq747BPuMkBuaeR0RhDmwatHpz6y2UKB7oB21wCLpGjobTuFHo0bev7ulhHgAC2vwIiIiISM6MDrjHjx/HuHHj8Ic//EE3tnz5cnz77bc4evQo3nnnHcTFxZlc0I4dO7Bw4UIkJiYiLCwMGzduxMSJE5GVlQUPD4+HbldRUYGZM2di/PjxuHXrlsmfT/qEELhR9iPO5JXgZmoGRGoqXC5mYtiNLEwvKzSYX+3Y7aengoWhx4SxsBwxHK52dhJUTkRERJ2V0QG3uLgYv/3tbw3Ghw8fjqNHj2LWrFmtKui9995DTEwM5syZAwBYt24dvvnmG2zYsAGrV69+6HYvvfQSpk+fDqVSiX//+9+tqqEzq66tx+UKBW5+/T1qjqXBPuMUhlw9j7E3L0FVV2Mwv9RrIOqCQ9A1chTsRo+Cw4ABcODFYERERCQhowNufX097O0Nb8/UNNajh+k3o6+rq0NGRgbi4+P1xqOiopCamvrQ7T799FPk5uZi69atePPNNx/7ObW1taitrdW9rqysBABotVpotdqHbSY7jY0Cubfv4GxBGfIzsqA4cQKu6rOYrFHD5/Z1KB+4GKzW1g4VTwXAMjwUjmMjgJEjoeraVfe+FgDq69v2IGSk6bvXmb6D7QV7Lw32XTrsvXTYe9MZ0zOz3SbMFCUlJWhoaDB4QISzszOKioqa3SYnJwfx8fFISUmBpWXLDmf16tVYuXKlwfjBgwfRpUsX4wvvIKq1wLVqBTQ/1MMqJxcuOdkYWpCNSI0ave+UGcwv7dEbtwcNRo3/YFT4DkaVpyeEUnnvzcZG4BH/6CDTJScnS11Cp8XeS4N9lw57Lx323ng1NYa/JD+MSQF369atSEtL0xu7cuUKAGDSpEkG8xUKBfbt29fi/Sse+IlbCGEwBgANDQ2YPn06Vq5ciUGDBrV4/0uXLtVbJ1xZWQl3d3dERUVBpVK1eD/tWV19I9RFVTh3owK5F3KB1DR4Xj6HaI0aTxXlwKZB/0xrg6UlKoc8DWXISGQ7OeCp3/0OKg8PyKMbHYNWq0VycjImTJgAKysrqcvpVNh7abDv0mHvpcPem67pF/eWMCngXrlyRRdoH3TgwAGDsebCaXN69uwJpVJpcLa2uLi42cf+VlVVIT09HZmZmViwYAEAoLGxEUIIWFpa4uDBgxg3bpzBdjY2Ns3euszKyqpDftmEENCU/4jM/HKcu1aK0lNn4HjmNIYVZCFSo0ZMueHZ77vdeqBuxEjYjx0FZXgYlIGB6GZrC61Wi8L9+/GMh0eH7IUcdNTvoRyw99Jg36XD3kuHvTeeMf0yOuDm5eUZu0mLWVtbIzAwEMnJyfjVr36lG09OTsYvf/lLg/kqlQrnz5/XG0tMTMShQ4fwxRdfwNvb22y1SulObT2+v1GBzIIyXMq+gYa0NAy48j0CNNl49WY2HOt+1JsvFArcGTgYVhHhsBkVDoSGwrZ/f9jyYjAiIiKSIaMDrqenpznq0ImLi8OMGTMQFBSEkJAQfPzxx8jPz0dsbCyAe8sLNBoNtmzZAgsLC/j7++tt37t3b9ja2hqMd1SNjQJXS6pxJr8cmdfLUJR5Ed3OpSPghhpjNWrE3r4OCwi9bbRd7FE/fARsR0dAERYGRXAwHJycJDoCIiIiorbVri4yA4Bp06ahtLQUq1atQmFhIfz9/bF//35dsC4sLER+fr7EVZpP2Z06nC0oR2Z+GS5cvQXtqXT45l1AoEaNOE02etWUG2xz18MLVuFhUIaHAaGhsPL3h1XTxWBEREREnUy7C7gAMG/ePMybN6/Z9zZv3vzIbRMSEpCQkPDkizIDbUMj1IWVPwXacly/cAW9LmQiSJOFMRo1FhTlwrpR/2KwRitr1D/zDKwjwoGwMCAkBLZ9+kh0BERERETtT7sMuHIkhEBhxV1k5pfjbEEZzl0rRW3mOTyVn4VAjRqLNGp4VBg+ga2+Zy9YhIfBIuze2VmLgABYm/gIZCIiIqLOgAHXTGrq6nH+RgUyC8pxNr8cOZcL0PfS9wjUZGO0JguvFl6GQzMXgzX6+UMZce9CMISGwtLbG+DFYEREREQtxoD7BDQ2CuSV3kFm/r21s5nXy1CbfQnDCtQI1KixUKPGoJJ8g4vBGh1VUISMhOKnMKsIDoZSJvfhJSIiIpIKA64JymvqdOtmMwvKoc4tguf1bATdUGOMRo04jRo9fjS8GXFjv/6wCAu9t3Y2NBQWQ4YAvBiMiIiI6IliwH0MbUMjLhVV3Tsz+9Nyg+q8fARq1D+tnc2G3y3Di8GEjQ0UQUG6pQYICYFFMw+rICIiIqIniwH3AUUVd/XC7MWCUnhpchGoUWO0JhtxGjXcKosNthN9+kDx05lZhIZC8cwzQDNPSyMiIiIi82LAvc/4d79DbcWPCNBkI0Cjxqs31Rh28zLstXf15gkLCyiefvp/Z2dDQ6Hw8uLFYERERETtAAPufTb+bT4Cym4YjAuVCoqQEN3aWcWIEYCjowQVEhEREdHjMODeZ0BTuB04UP/s7JAhgIWFtMURERERUYsw4N5v+3Zg/HigVy+pKyEiIiIiEzHg3m/SJID3oSUiIiLq0Pi7OxERERHJCgMuEREREckKAy4RERERyQoDLhERERHJCgMuEREREckKAy4RERERyQoDLhERERHJCgMuEREREckKAy4RERERyQoDLhERERHJCgMuEREREckKAy4RERERyQoDLhERERHJCgMuEREREckKAy4RERERyQoDLhERERHJCgMuEREREckKAy4RERERyQoDLhERERHJSrsMuImJifD29oatrS0CAwORkpLy0Lm7d+/GhAkT0KtXL6hUKoSEhOCbb75pw2qJiIiIqD1pdwF3x44dWLhwIZYtW4bMzExERERg4sSJyM/Pb3b+0aNHMWHCBOzfvx8ZGRkYO3YspkyZgszMzDaunIiIiIjag3YXcN977z3ExMRgzpw58PX1xbp16+Du7o4NGzY0O3/dunV47bXXMHz4cAwcOBBvv/02Bg4ciC+//LKNKyciIiKi9sBS6gLuV1dXh4yMDMTHx+uNR0VFITU1tUX7aGxsRFVVFbp37/7QObW1taitrdW9rqysBABotVpotVoTKpePpuPv7H2QAnsvHfZeGuy7dNh76bD3pjOmZ+0q4JaUlKChoQHOzs56487OzigqKmrRPt59913cuXMHzz333EPnrF69GitXrjQYP3jwILp06WJc0TKVnJwsdQmdFnsvHfZeGuy7dNh76bD3xqupqWnx3HYVcJsoFAq910IIg7HmbN++HQkJCfjPf/6D3r17P3Te0qVLERcXp3tdWVkJd3d3REVFQaVSmV64DGi1WiQnJ2PChAmwsrKSupxOhb2XDnsvDfZdOuy9dNh70zX94t4S7Srg9uzZE0ql0uBsbXFxscFZ3Qft2LEDMTEx+Ne//oXIyMhHzrWxsYGNjY3BuJWVFb9sP2EvpMPeS4e9lwb7Lh32XjrsvfGM6Ve7usjM2toagYGBBqftk5OTERoa+tDttm/fjtmzZ+Ozzz7D5MmTzV0mEREREbVj7eoMLgDExcVhxowZCAoKQkhICD7++GPk5+cjNjYWwL3lBRqNBlu2bAFwL9zOnDkT69evx8iRI3Vnf+3s7ODk5CTZcRARERGRNNpdwJ02bRpKS0uxatUqFBYWwt/fH/v374enpycAoLCwUO+euBs3bkR9fT3mz5+P+fPn68ZnzZqFzZs3t3X5RERERCSxdhdwAWDevHmYN29es+89GFq/++478xdERERERB1Gu1qDS0RERETUWgy4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCvtMuAmJibC29sbtra2CAwMREpKyiPnHzlyBIGBgbC1tUW/fv3w0UcftVGlRERERNTetLuAu2PHDixcuBDLli1DZmYmIiIiMHHiROTn5zc7Py8vD5MmTUJERAQyMzPxxz/+Ea+88gp27drVxpUTERERUXvQ7gLue++9h5iYGMyZMwe+vr5Yt24d3N3dsWHDhmbnf/TRR/Dw8MC6devg6+uLOXPm4MUXX8TatWvbuHIiIiIiag8spS7gfnV1dcjIyEB8fLzeeFRUFFJTU5vd5sSJE4iKitIbi46OxqZNm6DVamFlZWWwTW1tLWpra3WvKysrAQBarRZarba1h9GhNR1/Z++DFNh76bD30mDfpcPeS4e9N50xPWtXAbekpAQNDQ1wdnbWG3d2dkZRUVGz2xQVFTU7v76+HiUlJXBxcTHYZvXq1Vi5cqXB+MGDB9GlS5dWHIF8JCcnS11Cp8XeS4e9lwb7Lh32XjrsvfFqampaPLddBdwmCoVC77UQwmDscfObG2+ydOlSxMXF6V5XVlbC3d0dUVFRUKlUppYtC1qtFsnJyZgwYUKzZ7/JfNh76bD30mDfpcPeS4e9N13TL+4t0a4Cbs+ePaFUKg3O1hYXFxucpW3Sp0+fZudbWlqiR48ezW5jY2MDGxsbg3ErKyt+2X7CXkiHvZcOey8N9l067L102HvjGdOvdnWRmbW1NQIDAw1O2ycnJyM0NLTZbUJCQgzmHzx4EEFBQfziEBEREXVC7SrgAkBcXBz+/ve/IykpCWq1GosWLUJ+fj5iY2MB3FteMHPmTN382NhYXL9+HXFxcVCr1UhKSsKmTZuwePFiqQ6BiIiIiCTUrpYoAMC0adNQWlqKVatWobCwEP7+/ti/fz88PT0BAIWFhXr3xPX29sb+/fuxaNEifPjhh3B1dcX777+PX//611IdAhERERFJqN0FXACYN28e5s2b1+x7mzdvNhgbPXo0zpw5Y+aqiIiIiKgjaHdLFIiIiIiIWoMBl4iIiIhkhQGXiIiIiGSFAZeIiIiIZIUBl4iIiIhkhQGXiIiIiGSFAZeIiIiIZKVd3ge3rQkhAACVlZUSVyI9rVaLmpoaVFZW8lHHbYy9lw57Lw32XTrsvXTYe9M15bSm3PYoDLgAqqqqAADu7u4SV0JEREREj1JVVQUnJ6dHzlGIlsRgmWtsbMTNmzfh6OgIhUIhdTmSqqyshLu7OwoKCqBSqaQup1Nh76XD3kuDfZcOey8d9t50QghUVVXB1dUVFhaPXmXLM7gALCws4ObmJnUZ7YpKpeJ/eBJh76XD3kuDfZcOey8d9t40jztz24QXmRERERGRrDDgEhEREZGsKBMSEhKkLoLaF6VSiTFjxsDSkitY2hp7Lx32Xhrsu3TYe+mw9+bHi8yIiIiISFa4RIGIiIiIZIUBl4iIiIhkhQGXiIiIiGSFAZeIiIiIZIUBtxNKTEyEt7c3bG1tERgYiJSUlBZtd/z4cVhaWmLYsGFmrlC+jOn9d999B4VCYfAnOzu7DSuWB2O/87W1tVi2bBk8PT1hY2OD/v37IykpqY2qlRdjej979uxmv/N+fn5tWLF8GPu937ZtG4YOHYouXbrAxcUFL7zwAkpLS9uoWvkwtu8ffvghfH19YWdnBx8fH2zZsqWNKpU5QZ3K559/LqysrMQnn3wisrKyxKuvvirs7e3F9evXH7ldeXm56Nevn4iKihJDhw5to2rlxdjeHz58WAAQly5dEoWFhbo/9fX1bVx5x2bKd/4Xv/iFCA4OFsnJySIvL0+cPHlSHD9+vA2rlgdje19eXq73XS8oKBDdu3cXK1asaNvCZcDY3qekpAgLCwuxfv16cfXqVZGSkiL8/PzEs88+28aVd2zG9j0xMVE4OjqKzz//XOTm5ort27cLBwcHsXfv3jauXH4YcDuZESNGiNjYWL2xwYMHi/j4+EduN23aNLF8+XKxYsUKBlwTGdv7poBbVlbWFuXJlrF9//rrr4WTk5MoLS1ti/JkzdS/b5rs2bNHKBQKce3aNXOUJ2vG9v6dd94R/fr10xt7//33hZubm9lqlCNj+x4SEiIWL16sN/bqq6+KsLAws9XYWXCJQidSV1eHjIytLLPNAAAOKklEQVQMREVF6Y1HRUUhNTX1odt9+umnyM3NxYoVK8xdomyZ2nsAeOaZZ+Di4oLx48fj8OHD5ixTdkzp+969exEUFIQ1a9agb9++GDRoEBYvXowff/yxLUqWjdZ855ts2rQJkZGR8PT0NEeJsmVK70NDQ3Hjxg3s378fQgjcunULX3zxBSZPntwWJcuCKX2vra2Fra2t3pidnR1OnToFrVZrtlo7AwbcTqSkpAQNDQ1wdnbWG3d2dkZRUVGz2+Tk5CA+Ph7btm3jE1dawZTeu7i44OOPP8auXbuwe/du+Pj4YPz48Th69GhblCwLpvT96tWrOHbsGC5cuIA9e/Zg3bp1+OKLLzB//vy2KFk2TOn9/QoLC/H1119jzpw55ipRtkzpfWhoKLZt24Zp06bB2toaffr0QdeuXfG3v/2tLUqWBVP6Hh0djb///e/IyMiAEALp6elISkqCVqtFSUlJW5QtW0wsnZBCodB7LYQwGAOAhoYGTJ8+HStXrsSgQYPaqjxZa2nvAcDHxwc+Pj661yEhISgoKMDatWsxatQos9YpN8b0vbGxEQqFAtu2bYOTkxMA4L333sPUqVPx4Ycfws7Ozuz1yokxvb/f5s2b0bVrVzz77LPmKk32jOl9VlYWXnnlFbzxxhuIjo5GYWEhlixZgtjYWGzatKktypUNY/r++uuvo6ioCCNHjoQQAs7Ozpg9ezbWrFkDpVLZFuXKFs/gdiI9e/aEUqk0+JdkcXGxwb84AaCqqgrp6elYsGABLC0tYWlpiVWrVuHcuXOwtLTEoUOH2qr0Ds/Y3j/MyJEjkZOT86TLky1T+u7i4oK+ffvqwi0A+Pr6QgiBGzdumLVeOWnNd14IgaSkJMyYMQPW1tbmLFOWTOn96tWrERYWhiVLluDpp59GdHQ0EhMTkZSUhMLCwrYou8Mzpe92dnZISkpCTU0Nrl27hvz8fHh5ecHR0RE9e/Zsi7JliwG3E7G2tkZgYCCSk5P1xpOTkxEaGmowX6VS4fz58zh79qzuT2xsLHx8fHD27FkEBwe3VekdnrG9f5jMzEy4uLg86fJky5S+h4WF4ebNm6iurtaNXb58GRYWFnBzczNrvXLSmu/8kSNHcOXKFcTExJizRNkypfc1NTWwsNCPBE1nEIUQ5ilUZlrznbeysoKbmxuUSiU+//xz/PznPzf434OMJM21bSSVpluYbNq0SWRlZYmFCxcKe3t73VXK8fHxYsaMGQ/dnndRMJ2xvf/rX/8q9uzZIy5fviwuXLgg4uPjBQCxa9cuqQ6hQzK271VVVcLNzU1MnTpVXLx4URw5ckQMHDhQzJkzR6pD6LBM/fvm+eefF8HBwW1drqwY2/tPP/1UWFpaisTERJGbmyuOHTsmgoKCxIgRI6Q6hA7J2L5funRJ/POf/xSXL18WJ0+eFNOmTRPdu3cXeXl5Eh2BfHANbiczbdo0lJaWYtWqVSgsLIS/vz/279+vu0q5sLAQ+fn5ElcpT8b2vq6uDosXL4ZGo4GdnR38/Pywb98+TJo0SapD6JCM7buDgwOSk5Px8ssvIygoCD169MBzzz2HN998U6pD6LBM+fumoqICu3btwvr166UoWTaM7f3s2bNRVVWFDz74AL///e/RtWtXjBs3Dn/5y1+kOoQOydi+NzQ04N1338WlS5dgZWWFsWPHIjU1FV5eXhIdgXwohOBvD0REREQkH1zgQURERESywoBLRERERLLCgEtEREREssKAS0RERESywoBLRERERLLCgEtEREREssKAS0RERESywoBLRERERLLCgEtE1M5t3rwZCoUCmzdv1htXKBQYM2aMWT7z2rVrUCgUmD17tln2T0RkTgy4REQ/aQp19/+xtraGu7s7pk+fju+//17qEp8oLy8vPhKUiGTJUuoCiIjam/79++P5558HAFRXVyMtLQ3bt2/H7t27cejQIYSGhkpc4T1qtRpdunQxy7779u0LtVoNJycns+yfiMicGHCJiB4wYMAAJCQk6I0tX74cb731FpYtW4bDhw9LU9gDBg8ebLZ9W1lZmXX/RETmxCUKREQt8PLLLwMATp8+DQCYPXs2FAoFrl69ir/+9a/w8/ODjY2N3ppVIQSSkpIQFhYGlUqFLl26ICgoCElJSc1+xg8//IDY2Fg4OzujS5cuGD58OPbs2fPQmh62Breurg7r16/HiBEj4OjoCAcHBwwZMgRxcXEoKyvTLcW4fv06rl+/rrckoynYP2oNbn5+PmJiYtC3b19YW1vDzc0NMTExKCgoMJg7ZswYKBQK1NfX409/+hO8vb1hY2ODQYMGITEx0WD+3bt38e6772Lo0KFwcnKCg4MD+vfvj9/85jc4f/78Q3tBRHQ/nsElImoBhULR7PjLL7+MtLQ0TJ48GT//+c/h7OwM4F64ff755/HZZ59h0KBBmD59OqytrZGcnIyYmBhkZWVh7dq1uv3U1NRgzJgxOH/+PEJCQjB69GgUFBRg2rRpiIqKanGdd+/eRXR0NI4ePYqBAwfihRdegI2NDXJycvDRRx9h5syZ8PLywooVK7Bu3ToAwMKFC3XbP+6itZycHISHh6O4uBhTpkyBn58fLl68iKSkJHz11Vc4fvw4BgwYYLDdb37zG5w8eRITJ06EUqnEzp07MX/+fFhZWWHu3Lm6ebNmzcLOnTvx9NNP62rPz8/H4cOHER0djaeeeqrFvSCiTkwQEZEQQoi8vDwBQERHRxu8t2zZMgFAjBkzRgghxKxZswQA4ebmJq5fv24w/+OPPxYARExMjNBqtbrx2tpaMWXKFAFApKen68ZXrFghAIi5c+fq7eebb74RAAQA8emnn+q9B0CMHj1ab2zJkiUCgJgxY4aor6/Xe6+8vFxUVVXpXnt6egpPT89H9mLWrFl64+PGjRMAxMaNG/XGN27cKACI8ePH642PHj1aABDBwcGioqJCN56dnS0sLS2Fj4+PXn0KhUIEBQUZ1F5fXy/KysqarZWI6EFcokBE9IArV64gISEBCQkJWLx4McLDw/HWW2/B1tYWb7/9tt7cJUuWwMPDw2AfH3zwAezt7fHBBx/A0vJ/P5ZZW1vjrbfeAgBs375dN75lyxZYW1tj1apVevuJiorC+PHjW1R3Q0MDNm7cCCcnJ6xfvx5KpVLv/aaf/E1VUFCAQ4cOYciQIXpnXQFg7ty58PX1xbffftvsUoXVq1dDpVLpXvv4+CAsLAyXLl1CVVUVgHtnyYUQsLGxMahdqVSia9euJtdORJ0LlygQET0gNzcXK1euBHDvYitnZ2dMnz4d8fHxBj+RjxgxwmD7mpoanD9/Hq6urvjzn/9s8L5WqwUAZGdnAwCqqqqQl5eHIUOGoE+fPgbzIyIi8O233z627uzsbFRWViIyMhLdunV7/IEaKTMzEwAwevRogyUbCoUCo0aNglqtxrlz5+Du7q73fkBAgMH+3NzcAADl5eVwdHSESqXCz372Mxw4cAABAQGYOnUqIiIiEBwcDGtr6yd+PEQkXwy4REQPiI6OxoEDB1o0t2nN7f3KysoghIBGo9EF5ebcuXMHAFBRUQEA6N27d4s/oznl5eUA7t3iyxwqKysfWU9TOG86nvs1d7uxpjPbDQ0NurEvvvgCb7/9NrZv345ly5YBABwdHfHiiy/i7bffNttt0YhIXrhEgYioFZq7+Kzpp/jAwEAIIR76p+l2Y03zi4uLm/2MW7dutaiWpp/wNRqN0cfREk11PqyepvH7lyIYy97eHm+99RauXr2Kq1evYtOmTRg8eDDWr1+PRYsWmbxfIupcGHCJiJ4wR0dH+Pr6Qq1W686qPopKpYK3tzeuXLmCoqIig/dTUlJa9Lk+Pj5QqVQ4ffo0ysrKHjtfqVTqnT19nGHDhgEAjh49CiGE3ntCCF2dTfNay9vbGy+++CKOHDkCBwcH7N2794nsl4jkjwGXiMgMXnnlFdTU1GDu3Lm6pQj3y8vLw7Vr13SvZ8yYgbq6Orzxxht68w4ePNii9bfAvZ/8X3rpJVRUVODVV181CK8VFRWorq7Wve7evTtKSkpw9+7dFu3fw8MDY8eO1d0W7H5JSUm4ePEixo0bZ7D+tqVu376NU6dOGYyXlZWhtrYWdnZ2Ju2XiDofrsElIjKDl156CWlpafjHP/6B48ePIzIyEq6urrh16xays7Nx8uRJfPbZZ/Dy8gIAvPbaa9i9ezc++eQTXLx4EaNGjUJBQQF27tyJyZMnY9++fS363FWrViEtLQ3//Oc/kZaWhokTJ8LGxgZXr17FgQMHcOzYMd0Z1nHjxiE9PR1TpkxBREQErK2tER4ejvDw8Ifuf8OGDQgPD8fcuXPx5ZdfYsiQIcjKysLevXvRq1cvbNiwweSeaTQaBAcHw8/PDwEBAejbty9KS0vxn//8B1qtFq+99prJ+yaizoUBl4jIDBQKBTZv3oxJkybhk08+wVdffYXq6mr07t0bAwcOxNq1axEZGambb29vjyNHjmDp0qXYs2cPzpw5Az8/P+zYsQMVFRUtDri2trZITk7GBx98gK1bt+KTTz6BUqmEh4cHYmNjdYEaAF5//XWUlZXhq6++wqFDh9DY2IgVK1Y8MuD6+PggPT0dK1euxIEDB7Bv3z706tULs2fPxooVK+Dp6Wlyz7y8vJCQkIBDhw7hv//9L0pLS9GzZ08EBARg0aJFRj3wgog6N4V4cCEVEREREVEHxjW4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCsMuEREREQkKwy4RERERCQrDLhEREREJCsMuEREREQkK/8fTc7Cces20u4AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "Y_pred_normalized = best_model.predict(X_test_norm)\n",
        "end_time = time.time()\n",
        "Y_pred_normalized_entire = best_model.predict(dataset_x_norm)\n",
        "# Calculate elapsed time in seconds\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Elapsed time:\", round(elapsed_time, 3), \"seconds\")\n",
        "\n",
        "\n",
        "Y_pred = scaler_output.inverse_transform(Y_pred_normalized)\n",
        "Y_pred_entire = scaler_output.inverse_transform(Y_pred_normalized_entire)\n",
        "Y_actual = np.array(y_test)\n",
        "Y_actual_entire = np.array(df_targets)\n",
        "# Moisture Content\n",
        "scatter_plot(trueValues=Y_actual[:,0], \n",
        "             predictions=Y_pred[:,0], \n",
        "             title=\"Moisture Content\")\n",
        "a, b = np.polyfit(Y_pred[:, 0], Y_actual[:, 0], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,0]), max(Y_actual[:,0])), 1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_MC.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)\n",
        "\n",
        "# Bulk Density\n",
        "scatter_plot(trueValues=Y_actual[:,1], \n",
        "             predictions=Y_pred[:,1], \n",
        "             title=\"Bulk Density\")\n",
        "plt.xlim([min(min(Y_pred[:,1]), min(Y_actual[:,1]))-0.1, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1])\n",
        "a, b = np.polyfit(Y_pred[:, 1], Y_actual[:, 1], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,1]), max(Y_actual[:,1]))+0.1, 0.1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "plt.savefig('../Poster/Results/obj_3_BD.svg', dpi=300,\n",
        "                bbox_inches='tight',\n",
        "                transparent=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Error analysis\n",
        "- R squared calculation\n",
        "- Mean accuracy error"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### R squared calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 627,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9789\n",
            "0.9127\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# MOISTURE CONTENT\n",
        "#   - R-squared\n",
        "# mc_r2_score = r2_score(Y_actual[:, 0], Y_pred[:, 0])\n",
        "mc_r2_score = calculate_r_squared(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"{:#.4g}\".format(mc_r2_score))\n",
        "\n",
        "# BULK DENSITY\n",
        "#   - R-squared\n",
        "# bd_r2_score = r2_score(Y_actual[:, 1], Y_pred[:, 1])\n",
        "bd_r2_score = calculate_r_squared(y_true=Y_actual[:, 1], y_pred=Y_pred[:, 1])\n",
        "print(\"{:#.4g}\".format(bd_r2_score))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 628,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE_MC:  1.199\n",
            "RMSE_BD:  0.03352\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sigfig import round\n",
        "\n",
        "#MC\n",
        "rmse_mc = np.sqrt(mean_squared_error(Y_actual[:, 0], Y_pred[:, 0]))\n",
        "print('RMSE_MC: ', \"{0:.4g}\".format(rmse_mc))\n",
        "\n",
        "#BD\n",
        "rmse_bd = np.sqrt(mean_squared_error(Y_actual[:, 1], Y_pred[:, 1]))\n",
        "print('RMSE_BD: ', \"{0:.4g}\".format(rmse_bd))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will compare with the results from Trabelsi's paper. This is single moisture prediction \n",
        "\n",
        "R^2 : 0.993\\\n",
        "Mean Squared Error: 0.028\\\n",
        "Mean absolute Error: 0.135\\\n",
        "Min. Absolute Error: 0.004\\\n",
        "Max Absolute Error: 0.441"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 629,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9745\n",
            "Mean Squared Error:  1.438\n",
            "Mean Absolute Error:  0.8743\n",
            "Min Absolute Error:  0.012550773620604971\n",
            "Max Absolute Error:  4.931872177124021\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,max_error, r2_score\n",
        "from sigfig import round\n",
        "\n",
        "mc_r2_score = r2_score(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual[:, 0], Y_pred[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual[:, 0], Y_pred[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual[:,0])):\n",
        "    sum = Y_actual[:,0][i] - Y_pred[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 630,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9795\n",
            "Mean Squared Error:  1.065\n",
            "Mean Absolute Error:  0.7733\n",
            "Min Absolute Error:  0.0019256591796867895\n",
            "Max Absolute Error:  4.931872177124021\n"
          ]
        }
      ],
      "source": [
        "mc_r2_score = r2_score(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual_entire[:, 0], Y_pred_entire[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual_entire[:,0])):\n",
        "    sum = Y_actual_entire[:,0][i] - Y_pred_entire[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
