{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of different values in the 'Variety' column:\n",
      "GA PRICHARD    123\n",
      "NE 3292 C      122\n",
      "NE 3001        118\n",
      "GA COOK        104\n",
      "GA WOODRUFF    104\n",
      "Name: Variety, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('../Datasets/processed/Soybeans.csv')\n",
    "\n",
    "# Check if the 'Variety' column exists in the DataFrame\n",
    "if 'Variety' in df.columns:\n",
    "    # Count the occurrences of each unique value in the 'Variety' column\n",
    "    variety_counts = df['Variety'].value_counts()\n",
    "\n",
    "    # Print the counts\n",
    "    print(\"Counts of different values in the 'Variety' column:\")\n",
    "    print(variety_counts)\n",
    "else:\n",
    "    print(\"'Variety' column not found in the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to newWheatData.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeenat/anaconda3/envs/venv_ml/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "GRAIN_TYPE = \"Wheat\"  # Assuming you have defined GRAIN_TYPE somewhere\n",
    "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
    "\n",
    "# Read in csv format\n",
    "df = pd.read_csv(URL)\n",
    "\n",
    "# Filter rows where the \"Variety\" column is \"KANSAS\"\n",
    "if 'Variety' in df.columns and 'Phase' in df.columns and 'Attn' in df.columns:\n",
    "    df_kansas = df[df['Variety'].str.upper() == 'KANSAS']  # This also makes the comparison case-insensitive\n",
    "\n",
    "    # Calculate the \"Phase/Attn\" column\n",
    "    # It's good practice to handle division by zero or invalid data\n",
    "    df_kansas['Phase/Attn'] = df_kansas['Phase'] / df_kansas['Attn'].replace({0: None})\n",
    "\n",
    "    # Save the filtered and modified DataFrame to a new CSV file\n",
    "    df_kansas.to_csv('newWheatData.csv', index=False)\n",
    "    print('Filtered data saved to newWheatData.csv')\n",
    "else:\n",
    "    missing_columns = []\n",
    "    if 'Variety' not in df.columns:\n",
    "        missing_columns.append('Variety')\n",
    "    if 'Phase' not in df.columns:\n",
    "        missing_columns.append('Phase')\n",
    "    if 'Attn' not in df.columns:\n",
    "        missing_columns.append('Attn')\n",
    "    print(f\"Missing column(s) in the DataFrame: {', '.join(missing_columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum and Maximum values for each variety:\n",
      "                  Unnamed: 0      Freq       d(cm)          M%        Density  \\\n",
      "                         min  max  min   max   min  max    min    max     min   \n",
      "Variety                                                                         \n",
      "KANSAS                     0  177  5.0  18.0   4.4  8.9  11.30  20.43  0.6692   \n",
      "NEBRASKA OVERLAND        342  507  5.0  18.0   4.4  8.9  11.61  21.63  0.6531   \n",
      "NEBRASKA SETTLER         178  341  5.0  18.0   4.4  8.9  12.18  21.36  0.6736   \n",
      "OKLAHOMA                 508  685  5.0  18.0   4.4  8.9  10.26  24.41  0.6254   \n",
      "SOUTH DAKOTA             686  805  5.0  16.0   4.4  8.9  13.68  20.90  0.6873   \n",
      "\n",
      "                             Attn             Phase          Phase_Corr  \\\n",
      "                      max     min      max      min      max        min   \n",
      "Variety                                                                   \n",
      "KANSAS             0.8420  8.0242  29.8970 -179.335  179.046  -1102.044   \n",
      "NEBRASKA OVERLAND  0.8383  8.1565  29.8970 -179.224  179.048  -1152.760   \n",
      "NEBRASKA SETTLER   0.8985  8.0023  29.6297 -173.092  178.108  -1274.435   \n",
      "OKLAHOMA           0.9205  8.2010  29.8970 -179.116  178.017  -1223.394   \n",
      "SOUTH DAKOTA       0.9278  8.1565  29.8970 -178.403  172.233  -1079.128   \n",
      "\n",
      "                           Permittivity_real        Permittivity_imaginary  \\\n",
      "                       max               min    max                    min   \n",
      "Variety                                                                      \n",
      "KANSAS            -264.103             2.340  3.587                  0.220   \n",
      "NEBRASKA OVERLAND -245.944             2.441  3.634                  0.246   \n",
      "NEBRASKA SETTLER  -255.090             2.604  4.038                  0.296   \n",
      "OKLAHOMA          -235.044             2.473  3.953                  0.230   \n",
      "SOUTH DAKOTA      -251.837             2.736  3.885                  0.378   \n",
      "\n",
      "                          \n",
      "                     max  \n",
      "Variety                   \n",
      "KANSAS             0.793  \n",
      "NEBRASKA OVERLAND  0.868  \n",
      "NEBRASKA SETTLER   0.987  \n",
      "OKLAHOMA           0.947  \n",
      "SOUTH DAKOTA       0.902  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "GRAIN_TYPE = \"Wheat\"  # Assuming you have defined GRAIN_TYPE somewhere\n",
    "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
    "# Read in csv format\n",
    "df = pd.read_csv(URL)\n",
    "\n",
    "# Check if the 'Variety' column exists in the DataFrame\n",
    "if 'Variety' in df.columns:\n",
    "    # Group the DataFrame by 'Variety' and then calculate min and max for each numeric column\n",
    "    grouped = df.groupby('Variety').agg(['min', 'max'])\n",
    "\n",
    "    # Print the result\n",
    "    print(\"Minimum and Maximum values for each variety:\")\n",
    "    print(grouped)\n",
    "else:\n",
    "    print(\"'Variety' column not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety                      Count            Freq           d(cm)              M%         Density            Attn           Phase      Phase_Corr Permittivity_real Permittivity_imaginary\n",
      "KANSAS                       178.0         11.253           7.080          15.856           0.767          18.213          -4.896        -619.727           2.778           0.461\n",
      "NEBRASKA OVERLAND            166.0         10.614           7.156          16.402           0.771          18.767          -1.886        -622.127           2.882           0.507\n",
      "NEBRASKA SETTLER             164.0         10.409           7.186          16.400           0.820          19.278          -5.802        -651.168           3.034           0.542\n",
      "OKLAHOMA                     178.0         11.674           7.102          15.353           0.813          16.930          -2.117        -663.465           2.816           0.425\n",
      "SOUTH DAKOTA                 120.0          9.700           6.857          17.344           0.819          19.217          -9.989        -600.989           3.128           0.598\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "GRAIN_TYPE = \"Wheat\"  # Assuming you have defined GRAIN_TYPE somewhere\n",
    "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
    "df = pd.read_csv(URL)\n",
    "\n",
    "# Columns for which you want to calculate the average\n",
    "columns_to_average = [\n",
    "    'Freq', 'd(cm)', 'M%', 'Density', 'Attn', 'Phase', \n",
    "    'Phase_Corr', 'Permittivity_real', 'Permittivity_imaginary'\n",
    "]\n",
    "\n",
    "# Group by 'Variety', calculate the mean for the specified columns, and count for each group\n",
    "aggregation = {col: 'mean' for col in columns_to_average}\n",
    "aggregation['Variety'] = 'size'\n",
    "grouped = df.groupby('Variety').agg(aggregation)\n",
    "\n",
    "# Rename the 'Variety' column to 'Count'\n",
    "grouped.rename(columns={'Variety': 'Count'}, inplace=True)\n",
    "\n",
    "# Find the longest variety name for formatting\n",
    "max_variety_length = max(len(str(variety)) for variety in grouped.index)\n",
    "\n",
    "# Prepare the header\n",
    "header_names = [\"Variety\", \"Count\"] + columns_to_average\n",
    "header_str = f\"{header_names[0]: <{max_variety_length}}  \" + ' '.join([f\"{name: >15}\" for name in header_names[1:]])\n",
    "print(header_str)\n",
    "\n",
    "# Print the results\n",
    "for variety, row in grouped.iterrows():\n",
    "    # Format variety names to have equal distance from the first number\n",
    "    variety_str = f\"{variety: <{max_variety_length}}  \"\n",
    "    # Get count and average values, ensure correct formatting\n",
    "    count_str = f\"{row['Count']: >15}\"\n",
    "    avg_values_str = ' '.join([f\"{value: >15.3f}\" for value in row[columns_to_average]])\n",
    "    print(variety_str + count_str + avg_values_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will create a csv file with the column type, that will have the average moisture content and act as the category. And the column Phase / Attn which will have well exactly what the name says\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "GRAIN_TYPE = \"Wheat\"  # Assuming you have defined GRAIN_TYPE somewhere\n",
    "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
    "df = pd.read_csv(URL)\n",
    "# Calculate the mean M% for each variety\n",
    "mean_m_per_variety = df.groupby('Variety')['M%'].mean().reset_index()\n",
    "mean_m_per_variety.rename(columns={'M%': 'Type'}, inplace=True)\n",
    "\n",
    "# Merge the mean M% back into the original DataFrame\n",
    "df_with_type = pd.merge(df, mean_m_per_variety, how='left', on='Variety')\n",
    "# Add a new column 'Phase/Attn' representing phase divided by attn\n",
    "df_with_type['Phase/Attn'] = df_with_type['Phase'] / df_with_type['Attn']\n",
    "\n",
    "# Handle potential division by zero or NaN values, if necessary\n",
    "df_with_type['Phase/Attn'] = df_with_type['Phase/Attn'].replace([float('inf'), -float('inf')], pd.NA)\n",
    "# Export the updated DataFrame to a new CSV file\n",
    "df_with_type.to_csv('../Datasets/processed/' + GRAIN_TYPE + 'Added_Type.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
