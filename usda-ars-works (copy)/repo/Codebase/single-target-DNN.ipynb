{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {},
      "outputs": [],
      "source": [
        "GRAIN_TYPE = 'WheatAdded_Type'\n",
        "# GRAIN_TYPE = 'Oats'\n",
        "# GRAIN_TYPE = 'Barley'\n",
        "# GRAIN_TYPE = 'Sorghum'\n",
        "# GRAIN_TYPE = 'Soybeans'\n",
        "#GRAIN_TYPE = 'Corn'\n",
        "\n",
        "FILENAME_BEST_MODEL = 'Best models/target_1/model_Moisture_Content/' + GRAIN_TYPE + '_t1_dnn_mc.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNGoIGbc0kw_",
        "outputId": "279cc9c8-32fd-4f89-e56b-83a0a31081dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ]
        }
      ],
      "source": [
        "#Import libraries\n",
        "import requests\n",
        "import pydot\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Data visualization\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Machine Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Activation, BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "print(tf.__version__)\n",
        "np.random.seed(39)\n",
        "random.seed(39)\n",
        "tf.random.set_seed(39)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {
        "id": "nxHO_qH0Zi5J"
      },
      "outputs": [],
      "source": [
        "def calculate_r_squared(y_true, y_pred):\n",
        "   corr_matrix = np.corrcoef(y_true, y_pred)\n",
        "   corr = corr_matrix[0,1]\n",
        "   R_sq = corr**2\n",
        "   return R_sq\n",
        "\n",
        "def plot_loss_curve(history, epoch_size):\n",
        "    loss_train = history.history['loss']\n",
        "    loss_val = history.history['val_loss']\n",
        "    epochs = range(0,epoch_size)\n",
        "    \n",
        "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "    \n",
        "    plt.title('Training and Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_line(metric, title, xlabel):\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.title(title, fontsize = 16)\n",
        "    plt.plot(metric)\n",
        "    plt.xlabel(xlabel, fontsize = 14)\n",
        "    plt.grid()\n",
        "    plt.legend(loc= \"best\")\n",
        "    plt.show()\n",
        "\n",
        "def scatter_plot(trueValues, predictions, title):\n",
        "  plt.figure(figsize=(8,3))\n",
        "  ax = plt.axes()\n",
        "  maxVal = max( max(trueValues), max(predictions) )\n",
        "\n",
        "  ax.scatter(trueValues, predictions)\n",
        "  ax.plot([0, 1, maxVal], [0, 1, maxVal], label=\"Ideal fit\")\n",
        "  print('Maxval here is: ', maxVal)\n",
        "  plt.title(title, fontsize = 16)\n",
        "  plt.xlabel(\"Predictions\", fontsize = 14)\n",
        "  plt.ylabel(\"Real\", fontsize = 14)\n",
        "  plt.grid()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G7t0SXuDz64P"
      },
      "source": [
        "# 1. Load the Dataset\n",
        "We are going to use one dataset from UCI Machine Learning Repository. You can download the Energy Efficient Dataset using the following link. You can use pandas to download and open the data set which is in excel format or load from your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "s3pvA5g-zdgv",
        "outputId": "7a7208f1-6b68-4eba-ad1d-9108d0df66ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From USDA:  ../Datasets/processed/WheatAdded_Type.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Variety</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>8.8258</td>\n",
              "      <td>-55.973</td>\n",
              "      <td>-415.973</td>\n",
              "      <td>2.416</td>\n",
              "      <td>0.243</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-6.341975</td>\n",
              "      <td>62.3</td>\n",
              "      <td>61.7806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>10.2572</td>\n",
              "      <td>-114.289</td>\n",
              "      <td>-474.289</td>\n",
              "      <td>2.412</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-11.142320</td>\n",
              "      <td>71.2</td>\n",
              "      <td>82.0576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>11.5679</td>\n",
              "      <td>-168.171</td>\n",
              "      <td>-528.171</td>\n",
              "      <td>2.395</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-14.537729</td>\n",
              "      <td>80.1</td>\n",
              "      <td>104.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>12.8795</td>\n",
              "      <td>134.849</td>\n",
              "      <td>-585.151</td>\n",
              "      <td>2.390</td>\n",
              "      <td>0.246</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>10.470049</td>\n",
              "      <td>89.0</td>\n",
              "      <td>128.7950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>KANSAS</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>13.7649</td>\n",
              "      <td>83.502</td>\n",
              "      <td>-636.498</td>\n",
              "      <td>2.371</td>\n",
              "      <td>0.238</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>6.066299</td>\n",
              "      <td>97.9</td>\n",
              "      <td>151.4139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 Variety  Freq  d(cm)    M%  Density     Attn    Phase  \\\n",
              "0           0  KANSAS   7.0    8.9  11.3   0.7356   8.8258  -55.973   \n",
              "1           1  KANSAS   8.0    8.9  11.3   0.7356  10.2572 -114.289   \n",
              "2           2  KANSAS   9.0    8.9  11.3   0.7356  11.5679 -168.171   \n",
              "3           3  KANSAS  10.0    8.9  11.3   0.7356  12.8795  134.849   \n",
              "4           4  KANSAS  11.0    8.9  11.3   0.7356  13.7649   83.502   \n",
              "\n",
              "   Phase_Corr  Permittivity_real  Permittivity_imaginary       Type  \\\n",
              "0    -415.973              2.416                   0.243  15.855506   \n",
              "1    -474.289              2.412                   0.246  15.855506   \n",
              "2    -528.171              2.395                   0.246  15.855506   \n",
              "3    -585.151              2.390                   0.246  15.855506   \n",
              "4    -636.498              2.371                   0.238  15.855506   \n",
              "\n",
              "   Phase/Attn  Freq*d(cm)  Freq*Attn  \n",
              "0   -6.341975        62.3    61.7806  \n",
              "1  -11.142320        71.2    82.0576  \n",
              "2  -14.537729        80.1   104.1111  \n",
              "3   10.470049        89.0   128.7950  \n",
              "4    6.066299        97.9   151.4139  "
            ]
          },
          "execution_count": 348,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#url dataset\n",
        "URL = \"../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
        "\n",
        "#read in excel format\n",
        "df = pd.read_csv(URL)\n",
        "#df = df[df['Variety'] == 'SOUTH DAKOTA']\n",
        "print(\"From USDA: \", URL)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUzjHHV2stm"
      },
      "source": [
        "# 2. Overview of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Xohz7dGh2sXH",
        "outputId": "7d018cd8-018a-45d3-b1b7-ba9fc14aa5e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Freq</th>\n",
              "      <th>d(cm)</th>\n",
              "      <th>M%</th>\n",
              "      <th>Density</th>\n",
              "      <th>Attn</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Phase_Corr</th>\n",
              "      <th>Permittivity_real</th>\n",
              "      <th>Permittivity_imaginary</th>\n",
              "      <th>Type</th>\n",
              "      <th>Phase/Attn</th>\n",
              "      <th>Freq*d(cm)</th>\n",
              "      <th>Freq*Attn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>806.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>402.500000</td>\n",
              "      <td>10.811414</td>\n",
              "      <td>7.088834</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>0.796298</td>\n",
              "      <td>18.410033</td>\n",
              "      <td>-4.604663</td>\n",
              "      <td>-633.488065</td>\n",
              "      <td>2.912112</td>\n",
              "      <td>0.499187</td>\n",
              "      <td>16.189541</td>\n",
              "      <td>-0.377074</td>\n",
              "      <td>77.159677</td>\n",
              "      <td>215.799030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>232.816451</td>\n",
              "      <td>3.530055</td>\n",
              "      <td>1.554604</td>\n",
              "      <td>3.794772</td>\n",
              "      <td>0.067384</td>\n",
              "      <td>5.946835</td>\n",
              "      <td>101.951444</td>\n",
              "      <td>219.510760</td>\n",
              "      <td>0.305758</td>\n",
              "      <td>0.186739</td>\n",
              "      <td>0.629743</td>\n",
              "      <td>6.071761</td>\n",
              "      <td>32.552200</td>\n",
              "      <td>124.108325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>10.260000</td>\n",
              "      <td>0.625400</td>\n",
              "      <td>8.002300</td>\n",
              "      <td>-179.335000</td>\n",
              "      <td>-1274.435000</td>\n",
              "      <td>2.340000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>15.352809</td>\n",
              "      <td>-17.418676</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>40.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>201.250000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>13.680000</td>\n",
              "      <td>0.745400</td>\n",
              "      <td>13.524700</td>\n",
              "      <td>-88.842000</td>\n",
              "      <td>-793.405750</td>\n",
              "      <td>2.688500</td>\n",
              "      <td>0.337000</td>\n",
              "      <td>15.855506</td>\n",
              "      <td>-5.077754</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>107.817375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>402.500000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>16.225000</td>\n",
              "      <td>0.801300</td>\n",
              "      <td>18.131600</td>\n",
              "      <td>-9.838500</td>\n",
              "      <td>-602.380500</td>\n",
              "      <td>2.861500</td>\n",
              "      <td>0.470500</td>\n",
              "      <td>16.400366</td>\n",
              "      <td>-0.589378</td>\n",
              "      <td>71.200000</td>\n",
              "      <td>195.600450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>603.750000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>18.810000</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>23.098000</td>\n",
              "      <td>80.957250</td>\n",
              "      <td>-456.055750</td>\n",
              "      <td>3.109750</td>\n",
              "      <td>0.639000</td>\n",
              "      <td>16.401988</td>\n",
              "      <td>4.300734</td>\n",
              "      <td>100.100000</td>\n",
              "      <td>310.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>805.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>24.410000</td>\n",
              "      <td>0.927800</td>\n",
              "      <td>29.897000</td>\n",
              "      <td>179.048000</td>\n",
              "      <td>-235.044000</td>\n",
              "      <td>4.038000</td>\n",
              "      <td>0.987000</td>\n",
              "      <td>17.344167</td>\n",
              "      <td>14.827701</td>\n",
              "      <td>160.200000</td>\n",
              "      <td>538.146000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0        Freq       d(cm)          M%     Density        Attn  \\\n",
              "count  806.000000  806.000000  806.000000  806.000000  806.000000  806.000000   \n",
              "mean   402.500000   10.811414    7.088834   16.189541    0.796298   18.410033   \n",
              "std    232.816451    3.530055    1.554604    3.794772    0.067384    5.946835   \n",
              "min      0.000000    5.000000    4.400000   10.260000    0.625400    8.002300   \n",
              "25%    201.250000    8.000000    6.500000   13.680000    0.745400   13.524700   \n",
              "50%    402.500000   11.000000    7.700000   16.225000    0.801300   18.131600   \n",
              "75%    603.750000   13.000000    7.700000   18.810000    0.842000   23.098000   \n",
              "max    805.000000   18.000000    8.900000   24.410000    0.927800   29.897000   \n",
              "\n",
              "            Phase   Phase_Corr  Permittivity_real  Permittivity_imaginary  \\\n",
              "count  806.000000   806.000000         806.000000              806.000000   \n",
              "mean    -4.604663  -633.488065           2.912112                0.499187   \n",
              "std    101.951444   219.510760           0.305758                0.186739   \n",
              "min   -179.335000 -1274.435000           2.340000                0.220000   \n",
              "25%    -88.842000  -793.405750           2.688500                0.337000   \n",
              "50%     -9.838500  -602.380500           2.861500                0.470500   \n",
              "75%     80.957250  -456.055750           3.109750                0.639000   \n",
              "max    179.048000  -235.044000           4.038000                0.987000   \n",
              "\n",
              "             Type  Phase/Attn  Freq*d(cm)   Freq*Attn  \n",
              "count  806.000000  806.000000  806.000000  806.000000  \n",
              "mean    16.189541   -0.377074   77.159677  215.799030  \n",
              "std      0.629743    6.071761   32.552200  124.108325  \n",
              "min     15.352809  -17.418676   22.000000   40.011500  \n",
              "25%     15.855506   -5.077754   52.800000  107.817375  \n",
              "50%     16.400366   -0.589378   71.200000  195.600450  \n",
              "75%     16.401988    4.300734  100.100000  310.863000  \n",
              "max     17.344167   14.827701  160.200000  538.146000  "
            ]
          },
          "execution_count": 349,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data summary\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmFqsYQyGnM",
        "outputId": "54445a7f-a2c8-452a-9651-42dbbe682d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(806, 15)"
            ]
          },
          "execution_count": 350,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimension of the dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fep-GIv4yUuf",
        "outputId": "c46072fa-aa7f-4549-9a1d-4c5b05d11112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unnamed: 0                0\n",
              "Variety                   0\n",
              "Freq                      0\n",
              "d(cm)                     0\n",
              "M%                        0\n",
              "Density                   0\n",
              "Attn                      0\n",
              "Phase                     0\n",
              "Phase_Corr                0\n",
              "Permittivity_real         0\n",
              "Permittivity_imaginary    0\n",
              "Type                      0\n",
              "Phase/Attn                0\n",
              "Freq*d(cm)                0\n",
              "Freq*Attn                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 351,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check info about missing values in dataframe\n",
        "df.isnull().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_TKP9VymuK"
      },
      "source": [
        "# Exploratory Data Analysis\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz1g9T3FzhF0"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "\n",
        "1.   Convert dataframe to numpy array for flexibility.\n",
        "2. Split our data into training and testing datasets and store the target values in different variables.\n",
        "3.   Normalize the features by applying some operations in the data sets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {
        "id": "T0juhagf1M2I"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy array\n",
        "df_features = df[['Freq', \n",
        "                    'd(cm)', \n",
        "                    #'Attn', \n",
        "                    #'Phase', \n",
        "                    'Phase_Corr', \n",
        "                    'Permittivity_real', \n",
        "                    'Permittivity_imaginary',\n",
        "                    'Type',\n",
        "                    #'Density'\n",
        "            ]]\n",
        "\n",
        "# df_targets = df[['M%', 'Density']]\n",
        "df_targets = df[['M%']]\n",
        "\n",
        "dataset_x = df_features.to_numpy()\n",
        "dataset_y = df_targets.to_numpy()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting dataset to test and train+validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform train-test split on RAW DATA\n",
        "X_trainVal, X_test, y_trainVal, y_test = train_test_split(dataset_x, dataset_y, \n",
        "                                                    test_size=0.2\n",
        "                                                    ,random_state=42\n",
        "                                                    )\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainVal, y_trainVal, \n",
        "                                                    test_size=0.15 #validation split\n",
        "                                                    ,random_state=42\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Normalizing the data set\n",
        "scaler_input = MinMaxScaler()\n",
        "scaler_output = MinMaxScaler()\n",
        "\n",
        "# Normalize Train set\n",
        "X_train_norm = scaler_input.fit_transform(X_train)\n",
        "y_train_norm = scaler_output.fit_transform(y_train)\n",
        "\n",
        "# Normalize Validation set\n",
        "X_val_norm = scaler_input.fit_transform(X_val)\n",
        "y_val_norm = scaler_output.fit_transform(y_val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKfjwMP0Tzn"
      },
      "source": [
        "# K-cross Validation\n",
        "* Input features: 7\n",
        "* Output targets: 2\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {
        "id": "l31WJZ7Z0ONb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_148 (Dense)            (None, 89)                623       \n",
            "_________________________________________________________________\n",
            "dense_149 (Dense)            (None, 89)                8010      \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 89)                8010      \n",
            "_________________________________________________________________\n",
            "dense_151 (Dense)            (None, 1)                 90        \n",
            "=================================================================\n",
            "Total params: 16,733\n",
            "Trainable params: 16,733\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import layers, Sequential, regularizers\n",
        "\n",
        "# Define the model-building function\n",
        "def my_model():\n",
        "  \n",
        "  my_model = Sequential([   \n",
        "    layers.Dense(89, input_shape=(6,), activation='relu', \n",
        "                #  kernel_regularizer=regularizers.l2(0.01)\n",
        "                 ),\n",
        "      # layers.BatchNormalization(),  # Batch normalization layer\n",
        "      # layers.Dropout(0.2),\n",
        "\n",
        "      layers.Dense(89, activation='relu', \n",
        "                  #  kernel_regularizer=regularizers.l2(0.01)\n",
        "                   ),\n",
        "\n",
        "      layers.Dense(89, activation='relu', \n",
        "                  #  kernel_regularizer=regularizers.l2(0.01)\n",
        "                   ),\n",
        "      \n",
        "      # layers.BatchNormalization(),  # Batch normalization layer\n",
        "      # layers.Dropout(0.5),\n",
        "      \n",
        "      layers.Dense(1, activation='sigmoid')  # Output layer with 2 neurons for the two regression targets\n",
        "  ])\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.0009) # 0.00051 for good density results\n",
        "  my_model.compile(\n",
        "      optimizer = opt,\n",
        "      loss = 'mse',\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "\n",
        "  return my_model\n",
        "\n",
        "plot_model(my_model(), show_shapes=True, show_layer_names=True)\n",
        "my_model().summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running model with KCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 356,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khCKKB74hFVT",
        "outputId": "37e79cdf-4183-4559-f560-fceb2fc0c630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/170\n",
            "Epoch 1/170\n",
            "Epoch 1/170\n",
            "Epoch 1/170\n",
            "Epoch 1/170\n",
            " 1/62 [..............................] - ETA: 37s - loss: 0.1162 - accuracy: 0.0000e+00WARNING:tensorflow:5 out of the last 52628 calls to <function Model.make_train_function.<locals>.train_function at 0x7f8d086e55f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "62/62 [==============================] - 1s 6ms/step - loss: 0.0565 - accuracy: 0.0866 - val_loss: 0.0107 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 1s 6ms/step - loss: 0.0499 - accuracy: 0.0944 - val_loss: 0.0053 - val_accuracy: 0.0545\n",
            "Epoch 2/170\n",
            "Epoch 2/170\n",
            "62/62 [==============================] - 1s 6ms/step - loss: 0.0397 - accuracy: 0.0776 - val_loss: 0.0057 - val_accuracy: 0.1455\n",
            "Epoch 2/170\n",
            "62/62 [==============================] - 1s 7ms/step - loss: 0.0558 - accuracy: 0.0703 - val_loss: 0.0086 - val_accuracy: 0.1273\n",
            "62/62 [==============================] - 1s 7ms/step - loss: 0.0509 - accuracy: 0.0896 - val_loss: 0.0081 - val_accuracy: 0.0727\n",
            "Epoch 2/170\n",
            "Epoch 2/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.0755 - val_loss: 0.0035 - val_accuracy: 0.0545\n",
            "Epoch 3/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.0821 - val_loss: 0.0055 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.0865 - val_loss: 0.0029 - val_accuracy: 0.1455\n",
            "Epoch 3/170\n",
            "Epoch 3/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.0903 - val_loss: 0.0044 - val_accuracy: 0.0727\n",
            "Epoch 3/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.0830 - val_loss: 0.0068 - val_accuracy: 0.1273\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0019 - accuracy: 0.0000e+00Epoch 3/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.0873 - val_loss: 0.0028 - val_accuracy: 0.1455\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.0975 - val_loss: 0.0024 - val_accuracy: 0.0545\n",
            "Epoch 4/170Epoch 4/170\n",
            "\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.0886 - val_loss: 0.0058 - val_accuracy: 0.0909\n",
            "Epoch 4/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.0874 - val_loss: 0.0046 - val_accuracy: 0.0727\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.0807 - val_loss: 0.0063 - val_accuracy: 0.1273\n",
            "Epoch 4/170\n",
            "Epoch 4/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.0769 - val_loss: 0.0025 - val_accuracy: 0.1455\n",
            "Epoch 5/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.0815 - val_loss: 0.0025 - val_accuracy: 0.0545\n",
            "Epoch 5/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.0748 - val_loss: 0.0046 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0023 - accuracy: 0.0000e+00Epoch 5/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.0788 - val_loss: 0.0048 - val_accuracy: 0.1273\n",
            "Epoch 5/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.0782 - val_loss: 0.0031 - val_accuracy: 0.0727\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0021 - accuracy: 0.0000e+00Epoch 5/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.0839 - val_loss: 0.0025 - val_accuracy: 0.1455\n",
            "Epoch 6/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.0853 - val_loss: 0.0037 - val_accuracy: 0.0545\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0053 - accuracy: 0.0000e+00Epoch 6/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.0795 - val_loss: 0.0040 - val_accuracy: 0.0909\n",
            "Epoch 6/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.0718 - val_loss: 0.0041 - val_accuracy: 0.1273\n",
            "Epoch 6/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.0836 - val_loss: 0.0029 - val_accuracy: 0.0727\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0027 - accuracy: 0.0000e+00Epoch 6/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.0906 - val_loss: 0.0022 - val_accuracy: 0.1455\n",
            "Epoch 7/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.0905 - val_loss: 0.0027 - val_accuracy: 0.0545\n",
            "Epoch 7/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.0925 - val_loss: 0.0033 - val_accuracy: 0.0909\n",
            "Epoch 7/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.0896 - val_loss: 0.0033 - val_accuracy: 0.1273\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.1031 - val_loss: 0.0026 - val_accuracy: 0.0727\n",
            "Epoch 7/170\n",
            "Epoch 7/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.0832 - val_loss: 0.0020 - val_accuracy: 0.1455\n",
            "Epoch 8/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.0901 - val_loss: 0.0020 - val_accuracy: 0.0545\n",
            "Epoch 8/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0845 - val_loss: 0.0031 - val_accuracy: 0.0909\n",
            "Epoch 8/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0812 - val_loss: 0.0034 - val_accuracy: 0.1273\n",
            "Epoch 8/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.0794 - val_loss: 0.0029 - val_accuracy: 0.0727\n",
            "Epoch 8/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.0611 - val_loss: 0.0022 - val_accuracy: 0.1455\n",
            "Epoch 9/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0652 - val_loss: 0.0022 - val_accuracy: 0.0545\n",
            "Epoch 9/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.0617 - val_loss: 0.0031 - val_accuracy: 0.0909\n",
            "Epoch 9/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.0550 - val_loss: 0.0024 - val_accuracy: 0.1273\n",
            "Epoch 9/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.0630 - val_loss: 0.0034 - val_accuracy: 0.0727\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0023 - accuracy: 0.2500Epoch 9/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.0844 - val_loss: 0.0016 - val_accuracy: 0.1455\n",
            "Epoch 10/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.1024 - val_loss: 0.0016 - val_accuracy: 0.0545\n",
            "Epoch 10/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.0948 - val_loss: 0.0027 - val_accuracy: 0.0909\n",
            "Epoch 10/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.0879 - val_loss: 0.0024 - val_accuracy: 0.1273\n",
            "Epoch 10/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0952 - val_loss: 0.0020 - val_accuracy: 0.0727\n",
            "Epoch 10/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.0880 - val_loss: 0.0016 - val_accuracy: 0.1455\n",
            "52/62 [========================>.....] - ETA: 0s - loss: 0.0022 - accuracy: 0.1054Epoch 11/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.0905 - val_loss: 0.0018 - val_accuracy: 0.0545\n",
            "Epoch 11/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.0864 - val_loss: 0.0025 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.0946 - val_loss: 0.0025 - val_accuracy: 0.1273\n",
            "Epoch 11/170\n",
            "Epoch 11/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.1023 - val_loss: 0.0019 - val_accuracy: 0.0727\n",
            "Epoch 11/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0649 - val_loss: 0.0014 - val_accuracy: 0.1455\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 0.0016 - accuracy: 0.0743Epoch 12/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.0840 - val_loss: 0.0016 - val_accuracy: 0.0545\n",
            "Epoch 12/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0607 - val_loss: 0.0019 - val_accuracy: 0.1273\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0749 - val_loss: 0.0020 - val_accuracy: 0.0909\n",
            "Epoch 12/170\n",
            "Epoch 12/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0730 - val_loss: 0.0017 - val_accuracy: 0.0727\n",
            "Epoch 12/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0968 - val_loss: 0.0016 - val_accuracy: 0.1455\n",
            "Epoch 13/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0959 - val_loss: 0.0018 - val_accuracy: 0.0545\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 0.0017 - accuracy: 0.1031Epoch 13/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.1012 - val_loss: 0.0017 - val_accuracy: 0.1273\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.1015 - val_loss: 0.0016 - val_accuracy: 0.0909\n",
            "Epoch 13/170\n",
            "Epoch 13/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.1034 - val_loss: 0.0017 - val_accuracy: 0.0727\n",
            "Epoch 13/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0765 - val_loss: 0.0013 - val_accuracy: 0.1455\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 0.0013 - accuracy: 0.08Epoch 14/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0870 - val_loss: 0.0020 - val_accuracy: 0.0545\n",
            "Epoch 14/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0845 - val_loss: 0.0016 - val_accuracy: 0.1273\n",
            "Epoch 14/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0810 - val_loss: 0.0014 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0012 - accuracy: 0.1250Epoch 14/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0800 - val_loss: 0.0017 - val_accuracy: 0.0727\n",
            "Epoch 14/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0539 - val_loss: 0.0015 - val_accuracy: 0.1455\n",
            "Epoch 15/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0787 - val_loss: 0.0011 - val_accuracy: 0.0545\n",
            " 1/62 [..............................] - ETA: 0s - loss: 5.8068e-04 - accuracy: 0.0000e+Epoch 15/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0687 - val_loss: 0.0018 - val_accuracy: 0.1273\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0725 - val_loss: 0.0013 - val_accuracy: 0.0909\n",
            "Epoch 15/170\n",
            "Epoch 15/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0751 - val_loss: 0.0016 - val_accuracy: 0.0727\n",
            " 1/62 [..............................] - ETA: 0s - loss: 3.5082e-04 - accuracy: 0.0000e+00Epoch 15/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0823 - val_loss: 0.0013 - val_accuracy: 0.0545\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0682 - val_loss: 0.0015 - val_accuracy: 0.1455\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 0.0012 - accuracy: 0.0681Epoch 16/170\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 0.0013 - accuracy: 0.0649Epoch 16/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0720 - val_loss: 0.0017 - val_accuracy: 0.0727\n",
            "Epoch 16/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0664 - val_loss: 0.0022 - val_accuracy: 0.1273\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0696 - val_loss: 0.0012 - val_accuracy: 0.0909\n",
            "19/62 [========>.....................] - ETA: 0s - loss: 0.0012 - accuracy: 0.070508Epoch 16/170\n",
            "Epoch 16/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.0416e-04 - accuracy: 0.0844 - val_loss: 0.0012 - val_accuracy: 0.1455\n",
            "Epoch 17/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0799 - val_loss: 0.0011 - val_accuracy: 0.0545\n",
            "Epoch 17/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0810 - val_loss: 0.0016 - val_accuracy: 0.0727\n",
            "Epoch 17/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0794 - val_loss: 0.0012 - val_accuracy: 0.0909\n",
            "21/62 [=========>....................] - ETA: 0s - loss: 0.0011 - accuracy: 0.0672    Epoch 17/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0824 - val_loss: 0.0012 - val_accuracy: 0.1273\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0011 - accuracy: 0.0000e+00Epoch 17/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0733 - val_loss: 0.0012 - val_accuracy: 0.1455\n",
            "Epoch 18/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0659 - val_loss: 0.0012 - val_accuracy: 0.0545\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 0.0015 - accuracy: 0.064512Epoch 18/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0657 - val_loss: 0.0014 - val_accuracy: 0.0727\n",
            "Epoch 18/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.8932e-04 - accuracy: 0.0609 - val_loss: 0.0010 - val_accuracy: 0.0909\n",
            "19/62 [========>.....................] - ETA: 0s - loss: 8.6372e-04 - accuracy: 0.0928Epoch 18/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0698 - val_loss: 0.0012 - val_accuracy: 0.1273\n",
            "Epoch 18/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.6329e-04 - accuracy: 0.0850 - val_loss: 0.0013 - val_accuracy: 0.1455\n",
            "Epoch 19/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0895 - val_loss: 0.0014 - val_accuracy: 0.0545\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0011 - accuracy: 0.1250Epoch 19/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0905 - val_loss: 0.0015 - val_accuracy: 0.0727\n",
            "Epoch 19/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0875 - val_loss: 0.0011 - val_accuracy: 0.0909\n",
            "Epoch 19/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0771 - val_loss: 0.0013 - val_accuracy: 0.1273\n",
            "20/62 [========>.....................] - ETA: 0s - loss: 0.0011 - accuracy: 0.0773Epoch 19/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0713 - val_loss: 8.8563e-04 - val_accuracy: 0.1455\n",
            "Epoch 20/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0830 - val_loss: 0.0014 - val_accuracy: 0.0545\n",
            "Epoch 20/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0882 - val_loss: 0.0027 - val_accuracy: 0.0727\n",
            "Epoch 20/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.0760e-04 - accuracy: 0.0825 - val_loss: 0.0017 - val_accuracy: 0.0909\n",
            "Epoch 20/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0688 - val_loss: 0.0029 - val_accuracy: 0.1273\n",
            "Epoch 20/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.4412e-04 - accuracy: 0.0788 - val_loss: 8.5703e-04 - val_accuracy: 0.1455\n",
            "Epoch 21/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.5068e-04 - accuracy: 0.1078 - val_loss: 0.0015 - val_accuracy: 0.0545\n",
            "Epoch 21/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.1032 - val_loss: 0.0014 - val_accuracy: 0.0727\n",
            "Epoch 21/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.2628e-04 - accuracy: 0.1008 - val_loss: 9.3042e-04 - val_accuracy: 0.0909\n",
            "Epoch 21/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0917 - val_loss: 0.0022 - val_accuracy: 0.1273\n",
            "Epoch 21/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0564 - val_loss: 9.5190e-04 - val_accuracy: 0.1455\n",
            "Epoch 22/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0825 - val_loss: 0.0012 - val_accuracy: 0.0545\n",
            " 1/62 [..............................] - ETA: 0s - loss: 4.2560e-04 - accuracy: 0.0000e+Epoch 22/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0697 - val_loss: 0.0010 - val_accuracy: 0.0727\n",
            "Epoch 22/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.7550e-04 - accuracy: 0.0749 - val_loss: 8.3368e-04 - val_accuracy: 0.0909\n",
            "Epoch 22/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0573 - val_loss: 0.0010 - val_accuracy: 0.1273\n",
            "Epoch 22/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.8818e-04 - accuracy: 0.0509 - val_loss: 0.0010 - val_accuracy: 0.1455\n",
            "Epoch 23/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0724 - val_loss: 6.5385e-04 - val_accuracy: 0.0545\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.7584e-04 - accuracy: 0.0000e+00Epoch 23/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.0169e-04 - accuracy: 0.0692 - val_loss: 0.0014 - val_accuracy: 0.0727\n",
            "Epoch 23/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.7449e-04 - accuracy: 0.0673 - val_loss: 6.2891e-04 - val_accuracy: 0.0909\n",
            "Epoch 23/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.1507e-04 - accuracy: 0.0621 - val_loss: 9.5375e-04 - val_accuracy: 0.1273\n",
            "Epoch 23/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.9101e-04 - accuracy: 0.1008 - val_loss: 8.1454e-04 - val_accuracy: 0.0545\n",
            "Epoch 24/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.2953e-04 - accuracy: 0.0746 - val_loss: 9.2857e-04 - val_accuracy: 0.1455\n",
            "60/62 [============================>.] - ETA: 0s - loss: 6.8274e-04 - accuracy: 0.0749Epoch 24/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.8172e-04 - accuracy: 0.0962 - val_loss: 0.0011 - val_accuracy: 0.0727\n",
            "Epoch 24/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.3023e-04 - accuracy: 0.0970 - val_loss: 8.0146e-04 - val_accuracy: 0.0909\n",
            "Epoch 24/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.8673e-04 - accuracy: 0.0751 - val_loss: 0.0020 - val_accuracy: 0.1273\n",
            "Epoch 24/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.5406e-04 - accuracy: 0.0844 - val_loss: 6.4824e-04 - val_accuracy: 0.0545\n",
            "Epoch 25/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.9164e-04 - accuracy: 0.0949 - val_loss: 6.6841e-04 - val_accuracy: 0.1455\n",
            "Epoch 25/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.1395e-04 - accuracy: 0.0900 - val_loss: 5.0487e-04 - val_accuracy: 0.0909\n",
            "Epoch 25/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.1299e-04 - accuracy: 0.0927 - val_loss: 0.0017 - val_accuracy: 0.0727\n",
            " 1/62 [..............................] - ETA: 0s - loss: 6.5665e-04 - accuracy: 0.2500Epoch 25/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.8709e-04 - accuracy: 0.0920 - val_loss: 0.0012 - val_accuracy: 0.1273\n",
            "18/62 [=======>......................] - ETA: 0s - loss: 6.7714e-04 - accuracy: 0.1277Epoch 25/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.8193e-04 - accuracy: 0.0987 - val_loss: 5.9558e-04 - val_accuracy: 0.0545\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 8.2915e-04 - accuracy: 0.0954Epoch 26/1\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.4158e-04 - accuracy: 0.0568 - val_loss: 0.0017 - val_accuracy: 0.1455\n",
            "Epoch 26/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.1837e-04 - accuracy: 0.0995 - val_loss: 7.1911e-04 - val_accuracy: 0.0909\n",
            "Epoch 26/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.2740e-04 - accuracy: 0.0948 - val_loss: 0.0012 - val_accuracy: 0.0727\n",
            "Epoch 26/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.0346e-04 - accuracy: 0.0725 - val_loss: 9.1968e-04 - val_accuracy: 0.1273\n",
            "Epoch 26/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.5606e-04 - accuracy: 0.0772 - val_loss: 6.4427e-04 - val_accuracy: 0.0545\n",
            "Epoch 27/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.1452e-04 - accuracy: 0.0885 - val_loss: 0.0011 - val_accuracy: 0.1455\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 7.5664e-04 - accuracy: 0.0809Epoch 27/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.5310e-04 - accuracy: 0.0730 - val_loss: 5.1287e-04 - val_accuracy: 0.0909\n",
            "Epoch 27/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.5479e-04 - accuracy: 0.0794 - val_loss: 9.7573e-04 - val_accuracy: 0.0727\n",
            "Epoch 27/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.5907e-04 - accuracy: 0.0808 - val_loss: 0.0013 - val_accuracy: 0.1273\n",
            "Epoch 27/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.7291e-04 - accuracy: 0.0994 - val_loss: 5.9668e-04 - val_accuracy: 0.0545\n",
            "Epoch 28/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 7.4843e-04 - accuracy: 0.0929 - val_loss: 6.7275e-04 - val_accuracy: 0.1455\n",
            "Epoch 28/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 5.2897e-04 - accuracy: 0.0966 - val_loss: 4.9965e-04 - val_accuracy: 0.0909\n",
            "18/62 [=======>......................] - ETA: 0s - loss: 5.9566e-04 - accuracy: 0.1046Epoch 28/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 8.5868e-04 - accuracy: 0.0950 - val_loss: 9.7637e-04 - val_accuracy: 0.0727\n",
            "Epoch 28/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 9.5034e-04 - accuracy: 0.0956 - val_loss: 6.0019e-04 - val_accuracy: 0.1273\n",
            "Epoch 28/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.6671e-04 - accuracy: 0.0880 - val_loss: 7.5282e-04 - val_accuracy: 0.0545\n",
            "Epoch 29/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.3528e-04 - accuracy: 0.0664 - val_loss: 8.3553e-04 - val_accuracy: 0.1455\n",
            "Epoch 29/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.3793e-04 - accuracy: 0.0858 - val_loss: 5.1964e-04 - val_accuracy: 0.0909\n",
            "19/62 [========>.....................] - ETA: 0s - loss: 7.8806e-04 - accuracy: 0.0420Epoch 29/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.9597e-04 - accuracy: 0.0905 - val_loss: 7.7683e-04 - val_accuracy: 0.0727\n",
            "Epoch 29/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.3506e-04 - accuracy: 0.0740 - val_loss: 5.5271e-04 - val_accuracy: 0.1273\n",
            "Epoch 29/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.4650e-04 - accuracy: 0.0601 - val_loss: 6.0091e-04 - val_accuracy: 0.0545\n",
            "Epoch 30/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.4993e-04 - accuracy: 0.0578 - val_loss: 4.5239e-04 - val_accuracy: 0.0909\n",
            "Epoch 30/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.4925e-04 - accuracy: 0.0607 - val_loss: 8.5128e-04 - val_accuracy: 0.1455\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.7657e-04 - accuracy: 0.0606 - val_loss: 0.0015 - val_accuracy: 0.0727\n",
            " 1/62 [..............................] - ETA: 0s - loss: 4.7988e-04 - accuracy: 0.0000e+00\n",
            "Epoch 30/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.1766e-04 - accuracy: 0.0525 - val_loss: 6.5174e-04 - val_accuracy: 0.1273\n",
            "Epoch 30/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.5635e-04 - accuracy: 0.0778 - val_loss: 5.1210e-04 - val_accuracy: 0.0545\n",
            "Epoch 31/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.1202e-04 - accuracy: 0.0663 - val_loss: 5.8136e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.8122e-04 - accuracy: 0.0596 - val_loss: 9.6450e-04 - val_accuracy: 0.1455\n",
            "Epoch 31/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.4210e-04 - accuracy: 0.0670 - val_loss: 9.3454e-04 - val_accuracy: 0.0727\n",
            " 1/62 [..............................] - ETA: 0s - loss: 9.2018e-04 - accuracy: 0.0000e+00Epoch 31/170\n",
            "Epoch 31/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.3210e-04 - accuracy: 0.0595 - val_loss: 6.1611e-04 - val_accuracy: 0.1273\n",
            "Epoch 31/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.3679e-04 - accuracy: 0.0778 - val_loss: 5.4123e-04 - val_accuracy: 0.0545\n",
            "Epoch 32/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.7975e-04 - accuracy: 0.0825 - val_loss: 7.6846e-04 - val_accuracy: 0.0727\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.5640e-04 - accuracy: 0.0748 - val_loss: 6.4226e-04 - val_accuracy: 0.0909\n",
            "Epoch 32/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.2470e-04 - accuracy: 0.0758 - val_loss: 5.7123e-04 - val_accuracy: 0.1455\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.6793e-04 - accuracy: 0.0000e+00Epoch 32/170\n",
            "Epoch 32/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.1799e-04 - accuracy: 0.0769 - val_loss: 5.0572e-04 - val_accuracy: 0.1273\n",
            "Epoch 32/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.2450e-04 - accuracy: 0.0975 - val_loss: 6.9189e-04 - val_accuracy: 0.0545\n",
            "Epoch 33/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.9041e-04 - accuracy: 0.0999 - val_loss: 6.7051e-04 - val_accuracy: 0.0727\n",
            "Epoch 33/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.8388e-04 - accuracy: 0.1002 - val_loss: 3.8266e-04 - val_accuracy: 0.0909\n",
            "Epoch 33/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.9714e-04 - accuracy: 0.0864 - val_loss: 5.1721e-04 - val_accuracy: 0.1455\n",
            "Epoch 33/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.0438e-04 - accuracy: 0.0895 - val_loss: 4.0908e-04 - val_accuracy: 0.1273\n",
            "Epoch 33/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.6135e-04 - accuracy: 0.1001 - val_loss: 5.9359e-04 - val_accuracy: 0.0545\n",
            "39/62 [=================>............] - ETA: 0s - loss: 3.4649e-04 - accuracy: 0.0837Epoch 34/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.6666e-04 - accuracy: 0.0910 - val_loss: 8.6052e-04 - val_accuracy: 0.0727\n",
            "Epoch 34/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.9464e-04 - accuracy: 0.0932 - val_loss: 3.7122e-04 - val_accuracy: 0.0909\n",
            "Epoch 34/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.7630e-04 - accuracy: 0.0898 - val_loss: 4.9145e-04 - val_accuracy: 0.1455\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.8085e-04 - accuracy: 0.0820 - val_loss: 4.1902e-04 - val_accuracy: 0.1273\n",
            "Epoch 34/170\n",
            "Epoch 34/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.1862e-04 - accuracy: 0.0832 - val_loss: 5.0199e-04 - val_accuracy: 0.0545\n",
            "Epoch 35/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.4373e-04 - accuracy: 0.0875 - val_loss: 8.7263e-04 - val_accuracy: 0.0727\n",
            "Epoch 35/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.4601e-04 - accuracy: 0.0860 - val_loss: 3.9580e-04 - val_accuracy: 0.0909\n",
            "Epoch 35/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.6057e-04 - accuracy: 0.0802 - val_loss: 5.1300e-04 - val_accuracy: 0.1455\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.2810e-04 - accuracy: 0.0801 - val_loss: 7.0626e-04 - val_accuracy: 0.1273\n",
            "Epoch 35/170\n",
            "Epoch 35/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.4302e-04 - accuracy: 0.0862 - val_loss: 4.0050e-04 - val_accuracy: 0.0545\n",
            "Epoch 36/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 5.5840e-04 - accuracy: 0.0827 - val_loss: 5.8211e-04 - val_accuracy: 0.0727\n",
            "Epoch 36/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 4.0318e-04 - accuracy: 0.0805 - val_loss: 6.9243e-04 - val_accuracy: 0.1455\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 5.1629e-04 - accuracy: 0.0810 - val_loss: 5.3978e-04 - val_accuracy: 0.0909\n",
            "Epoch 36/170Epoch 36/170\n",
            "\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 3.7951e-04 - accuracy: 0.0836 - val_loss: 3.4501e-04 - val_accuracy: 0.1273\n",
            "37/62 [================>.............] - ETA: 0s - loss: 4.5613e-04 - accuracy: 0.0848Epoch 36/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.5862e-04 - accuracy: 0.0873 - val_loss: 4.0207e-04 - val_accuracy: 0.0545\n",
            "37/62 [================>.............] - ETA: 0s - loss: 3.3958e-04 - accuracy: 0.0792Epoch 37/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.8233e-04 - accuracy: 0.0887 - val_loss: 4.9801e-04 - val_accuracy: 0.0727\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 3.3990e-04 - accuracy: 0.0846Epoch 37/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.6107e-04 - accuracy: 0.0793 - val_loss: 3.7387e-04 - val_accuracy: 0.0909\n",
            "Epoch 37/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.5353e-04 - accuracy: 0.0781 - val_loss: 4.7566e-04 - val_accuracy: 0.1455\n",
            "Epoch 37/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.4426e-04 - accuracy: 0.0842 - val_loss: 4.2533e-04 - val_accuracy: 0.1273\n",
            "Epoch 37/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.9010e-04 - accuracy: 0.0724 - val_loss: 3.9047e-04 - val_accuracy: 0.0545\n",
            "Epoch 38/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.6005e-04 - accuracy: 0.0683 - val_loss: 5.1715e-04 - val_accuracy: 0.0727\n",
            "Epoch 38/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.9598e-04 - accuracy: 0.0680 - val_loss: 5.4035e-04 - val_accuracy: 0.0909\n",
            "Epoch 38/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.3962e-04 - accuracy: 0.0621 - val_loss: 4.4736e-04 - val_accuracy: 0.1455\n",
            "Epoch 38/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.0255e-04 - accuracy: 0.0613 - val_loss: 5.2239e-04 - val_accuracy: 0.1273\n",
            "Epoch 38/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.7355e-04 - accuracy: 0.0834 - val_loss: 3.8689e-04 - val_accuracy: 0.0545\n",
            "Epoch 39/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.7783e-04 - accuracy: 0.0775 - val_loss: 6.0692e-04 - val_accuracy: 0.0727\n",
            "20/62 [========>.....................] - ETA: 0s - loss: 3.3774e-04 - accuracy: 0.1303Epoch 39/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.2512e-04 - accuracy: 0.0747 - val_loss: 2.7679e-04 - val_accuracy: 0.0909\n",
            "Epoch 39/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.8936e-04 - accuracy: 0.0618 - val_loss: 4.7470e-04 - val_accuracy: 0.1455\n",
            "Epoch 39/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.0550e-04 - accuracy: 0.0639 - val_loss: 8.2941e-04 - val_accuracy: 0.1273\n",
            "Epoch 39/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.5275e-04 - accuracy: 0.1170 - val_loss: 3.8160e-04 - val_accuracy: 0.0545\n",
            "Epoch 40/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.1121e-04 - accuracy: 0.1156 - val_loss: 4.3730e-04 - val_accuracy: 0.0727\n",
            "Epoch 40/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.5392e-04 - accuracy: 0.1139 - val_loss: 3.4566e-04 - val_accuracy: 0.0909\n",
            "Epoch 40/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.7508e-04 - accuracy: 0.0985 - val_loss: 4.5613e-04 - val_accuracy: 0.1455\n",
            "Epoch 40/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.4655e-04 - accuracy: 0.1061 - val_loss: 5.1050e-04 - val_accuracy: 0.1273\n",
            "Epoch 40/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.7525e-04 - accuracy: 0.0830 - val_loss: 5.5143e-04 - val_accuracy: 0.0545\n",
            "41/62 [==================>...........] - ETA: 0s - loss: 2.1169e-04 - accuracy: 0.0854\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.4982e-04 - accuracy: 0.0870 - val_loss: 7.4500e-04 - val_accuracy: 0.0727\n",
            "Epoch 41/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1544e-04 - accuracy: 0.0822 - val_loss: 6.4307e-04 - val_accuracy: 0.0909\n",
            "Epoch 41/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3716e-04 - accuracy: 0.0828 - val_loss: 4.7605e-04 - val_accuracy: 0.1455\n",
            "Epoch 41/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4422e-04 - accuracy: 0.0738 - val_loss: 7.2976e-04 - val_accuracy: 0.1273\n",
            "Epoch 41/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.3074e-04 - accuracy: 0.0802 - val_loss: 3.0630e-04 - val_accuracy: 0.0545\n",
            "Epoch 42/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.5775e-04 - accuracy: 0.0781 - val_loss: 4.6505e-04 - val_accuracy: 0.0727\n",
            "61/62 [============================>.] - ETA: 0s - loss: 3.6131e-04 - accuracy: 0.0672\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.5011e-04 - accuracy: 0.0716 - val_loss: 3.5945e-04 - val_accuracy: 0.0909\n",
            "Epoch 42/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.6177e-04 - accuracy: 0.0675 - val_loss: 3.2496e-04 - val_accuracy: 0.1455\n",
            "Epoch 42/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.6785e-04 - accuracy: 0.0732 - val_loss: 3.6397e-04 - val_accuracy: 0.1273\n",
            "Epoch 42/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.5947e-04 - accuracy: 0.0803 - val_loss: 3.8847e-04 - val_accuracy: 0.0545\n",
            "Epoch 43/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.2578e-04 - accuracy: 0.0854 - val_loss: 3.8755e-04 - val_accuracy: 0.0727\n",
            "Epoch 43/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 4.0703e-04 - accuracy: 0.0859 - val_loss: 3.0898e-04 - val_accuracy: 0.1455\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.8170e-04 - accuracy: 0.0803 - val_loss: 3.2915e-04 - val_accuracy: 0.0909\n",
            "Epoch 43/170\n",
            "Epoch 43/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 4.6709e-04 - accuracy: 0.0791 - val_loss: 3.5263e-04 - val_accuracy: 0.1273\n",
            " 1/62 [..............................] - ETA: 0s - loss: 9.6380e-05 - accuracy: 0.1250Epoch 43/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.8312e-04 - accuracy: 0.0806 - val_loss: 2.7678e-04 - val_accuracy: 0.0545\n",
            "Epoch 44/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.5084e-04 - accuracy: 0.0701 - val_loss: 3.8856e-04 - val_accuracy: 0.0727\n",
            "Epoch 44/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8678e-04 - accuracy: 0.0723 - val_loss: 3.7734e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2996e-04 - accuracy: 0.0696 - val_loss: 3.3428e-04 - val_accuracy: 0.1455\n",
            "37/62 [================>.............] - ETA: 0s - loss: 3.0694e-04 - accuracy: 0.1029Epoch 44/170\n",
            "Epoch 44/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0613e-04 - accuracy: 0.0696 - val_loss: 2.9139e-04 - val_accuracy: 0.1273\n",
            " 1/62 [..............................] - ETA: 0s - loss: 6.0528e-05 - accuracy: 0.0000e+00Epoch 44/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.0554e-04 - accuracy: 0.0969 - val_loss: 3.1146e-04 - val_accuracy: 0.0545\n",
            "Epoch 45/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1562e-04 - accuracy: 0.0932 - val_loss: 4.0102e-04 - val_accuracy: 0.0727\n",
            "21/62 [=========>....................] - ETA: 0s - loss: 3.9251e-04 - accuracy: 0.0363    Epoch 45/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7840e-04 - accuracy: 0.0890 - val_loss: 2.5283e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3703e-04 - accuracy: 0.0817 - val_loss: 3.6687e-04 - val_accuracy: 0.1455\n",
            "Epoch 45/170\n",
            "Epoch 45/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9499e-04 - accuracy: 0.0804 - val_loss: 2.5605e-04 - val_accuracy: 0.1273\n",
            "39/62 [=================>............] - ETA: 0s - loss: 4.0134e-04 - accuracy: 0.0501e+00Epoch 45/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.8523e-04 - accuracy: 0.0622 - val_loss: 3.4116e-04 - val_accuracy: 0.0545\n",
            "Epoch 46/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3925e-04 - accuracy: 0.0698 - val_loss: 3.3693e-04 - val_accuracy: 0.0727\n",
            "Epoch 46/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.7053e-04 - accuracy: 0.0599 - val_loss: 3.6605e-04 - val_accuracy: 0.0909\n",
            "Epoch 46/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.7589e-04 - accuracy: 0.0673 - val_loss: 3.2648e-04 - val_accuracy: 0.1273\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.6982e-04 - accuracy: 0.0651 - val_loss: 3.7014e-04 - val_accuracy: 0.1455\n",
            "Epoch 46/170Epoch 46/170\n",
            "\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.7045e-04 - accuracy: 0.0929 - val_loss: 2.5697e-04 - val_accuracy: 0.0545\n",
            "Epoch 47/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.5778e-04 - accuracy: 0.0952 - val_loss: 8.9148e-04 - val_accuracy: 0.0727\n",
            "Epoch 47/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3341e-04 - accuracy: 0.0903 - val_loss: 3.4057e-04 - val_accuracy: 0.0909\n",
            "Epoch 47/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.0280e-04 - accuracy: 0.0858 - val_loss: 4.0478e-04 - val_accuracy: 0.1455\n",
            "44/62 [====================>.........] - ETA: 0s - loss: 3.1567e-04 - accuracy: 0.0968Epoch 47/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2978e-04 - accuracy: 0.0871 - val_loss: 2.7951e-04 - val_accuracy: 0.1273\n",
            "Epoch 47/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.2196e-04 - accuracy: 0.0939 - val_loss: 2.9826e-04 - val_accuracy: 0.0545\n",
            "Epoch 48/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.1230e-04 - accuracy: 0.1006 - val_loss: 3.5352e-04 - val_accuracy: 0.0727\n",
            "Epoch 48/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2815e-04 - accuracy: 0.0956 - val_loss: 4.3730e-04 - val_accuracy: 0.1455\n",
            "Epoch 48/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1893e-04 - accuracy: 0.0912 - val_loss: 3.1584e-04 - val_accuracy: 0.0909\n",
            "Epoch 48/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3071e-04 - accuracy: 0.0942 - val_loss: 2.6788e-04 - val_accuracy: 0.1273\n",
            "Epoch 48/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.8274e-04 - accuracy: 0.0750 - val_loss: 4.5812e-04 - val_accuracy: 0.0545\n",
            "42/62 [===================>..........] - ETA: 0s - loss: 2.7404e-04 - accuracy: 0.0708  Epoch 49/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.7714e-04 - accuracy: 0.0750 - val_loss: 3.1357e-04 - val_accuracy: 0.0727\n",
            "Epoch 49/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4530e-04 - accuracy: 0.0779 - val_loss: 3.8490e-04 - val_accuracy: 0.1455\n",
            "Epoch 49/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.8177e-04 - accuracy: 0.0713 - val_loss: 2.7113e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2249e-04 - accuracy: 0.0738 - val_loss: 4.0326e-04 - val_accuracy: 0.1273\n",
            "Epoch 49/170\n",
            "Epoch 49/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.5880e-04 - accuracy: 0.0852 - val_loss: 3.0704e-04 - val_accuracy: 0.0545\n",
            "22/62 [=========>....................] - ETA: 0s - loss: 1.8966e-04 - accuracy: 0.07Epoch 50/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 3.0328e-04 - accuracy: 0.0842 - val_loss: 4.4651e-04 - val_accuracy: 0.0727\n",
            "Epoch 50/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.7180e-04 - accuracy: 0.0648 - val_loss: 3.3317e-04 - val_accuracy: 0.1455\n",
            "Epoch 50/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.7173e-04 - accuracy: 0.0829 - val_loss: 4.1290e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.5897e-04 - accuracy: 0.0631 - val_loss: 2.8701e-04 - val_accuracy: 0.1273\n",
            "Epoch 50/170\n",
            "Epoch 50/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.7486e-04 - accuracy: 0.0990 - val_loss: 2.6052e-04 - val_accuracy: 0.0545\n",
            "Epoch 51/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0964e-04 - accuracy: 0.0947 - val_loss: 2.9023e-04 - val_accuracy: 0.0727\n",
            "Epoch 51/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0624e-04 - accuracy: 0.0817 - val_loss: 4.1299e-04 - val_accuracy: 0.1455\n",
            "Epoch 51/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.7150e-04 - accuracy: 0.0954 - val_loss: 2.8001e-04 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.9901e-04 - accuracy: 0.1250Epoch 51/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1362e-04 - accuracy: 0.0894 - val_loss: 2.2516e-04 - val_accuracy: 0.1273\n",
            "Epoch 51/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.0746e-04 - accuracy: 0.0794 - val_loss: 3.1901e-04 - val_accuracy: 0.0545\n",
            "Epoch 52/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.5477e-04 - accuracy: 0.0693 - val_loss: 3.7417e-04 - val_accuracy: 0.0727\n",
            "Epoch 52/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.7203e-04 - accuracy: 0.0696 - val_loss: 4.3594e-04 - val_accuracy: 0.1455\n",
            "Epoch 52/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.9295e-04 - accuracy: 0.0708 - val_loss: 5.1289e-04 - val_accuracy: 0.0909\n",
            "Epoch 52/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8717e-04 - accuracy: 0.0737 - val_loss: 2.2469e-04 - val_accuracy: 0.1273\n",
            "23/62 [==========>...................] - ETA: 0s - loss: 2.6120e-04 - accuracy: 0.1058\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.3028e-04 - accuracy: 0.1054 - val_loss: 3.0819e-04 - val_accuracy: 0.0545\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 2.5404e-04 - accuracy: 0.1152Epoch 53/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4102e-04 - accuracy: 0.0955 - val_loss: 6.1523e-04 - val_accuracy: 0.0727\n",
            "Epoch 53/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7636e-04 - accuracy: 0.0973 - val_loss: 4.2937e-04 - val_accuracy: 0.1455\n",
            "Epoch 53/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4739e-04 - accuracy: 0.0985 - val_loss: 3.2775e-04 - val_accuracy: 0.0909\n",
            "Epoch 53/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0636e-04 - accuracy: 0.0890 - val_loss: 5.0688e-04 - val_accuracy: 0.1273\n",
            "Epoch 53/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.9595e-04 - accuracy: 0.1113 - val_loss: 4.9055e-04 - val_accuracy: 0.0545\n",
            "24/62 [==========>...................] - ETA: 0s - loss: 2.9046e-04 - accuracy: 0.0631Epoch 54/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.9901e-04 - accuracy: 0.0978 - val_loss: 2.3845e-04 - val_accuracy: 0.0727\n",
            "Epoch 54/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.7488e-04 - accuracy: 0.1007 - val_loss: 3.5370e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.5162e-04 - accuracy: 0.0696 - val_loss: 4.0095e-04 - val_accuracy: 0.1455\n",
            "Epoch 54/170\n",
            "Epoch 54/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.1042e-04 - accuracy: 0.0690 - val_loss: 2.1389e-04 - val_accuracy: 0.1273\n",
            "Epoch 54/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.8571e-04 - accuracy: 0.0750 - val_loss: 5.9438e-04 - val_accuracy: 0.0545\n",
            "Epoch 55/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6869e-04 - accuracy: 0.0827 - val_loss: 4.4815e-04 - val_accuracy: 0.0727\n",
            "Epoch 55/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3154e-04 - accuracy: 0.0801 - val_loss: 3.3176e-04 - val_accuracy: 0.1455\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9450e-04 - accuracy: 0.0724 - val_loss: 3.5846e-04 - val_accuracy: 0.0909\n",
            "19/62 [========>.....................] - ETA: 0s - loss: 3.0431e-04 - accuracy: 0.0795    Epoch 55/170\n",
            "Epoch 55/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6669e-04 - accuracy: 0.0834 - val_loss: 3.7218e-04 - val_accuracy: 0.1273\n",
            "Epoch 55/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.7184e-04 - accuracy: 0.0850 - val_loss: 3.5042e-04 - val_accuracy: 0.0545\n",
            "Epoch 56/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.0270e-04 - accuracy: 0.0793 - val_loss: 5.1718e-04 - val_accuracy: 0.0727\n",
            "Epoch 56/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 1.8908e-04 - accuracy: 0.0772 - val_loss: 3.9525e-04 - val_accuracy: 0.0909\n",
            "46/62 [=====================>........] - ETA: 0s - loss: 3.6312e-04 - accuracy: 0.0714\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.2771e-04 - accuracy: 0.0787 - val_loss: 3.1803e-04 - val_accuracy: 0.1455\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.6839e-04 - accuracy: 0.0000e+00Epoch 56/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 3.7660e-04 - accuracy: 0.0799 - val_loss: 2.9972e-04 - val_accuracy: 0.1273\n",
            "Epoch 56/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 3.5141e-04 - accuracy: 0.0768 - val_loss: 2.1014e-04 - val_accuracy: 0.0545\n",
            "Epoch 57/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.5790e-04 - accuracy: 0.0790 - val_loss: 2.5900e-04 - val_accuracy: 0.0727\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 1.8937e-04 - accuracy: 0.0756Epoch 57/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1965e-04 - accuracy: 0.0789 - val_loss: 4.2415e-04 - val_accuracy: 0.1455\n",
            "Epoch 57/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9044e-04 - accuracy: 0.0772 - val_loss: 3.6174e-04 - val_accuracy: 0.0909\n",
            "Epoch 57/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.9141e-04 - accuracy: 0.0686 - val_loss: 2.2609e-04 - val_accuracy: 0.1273\n",
            "Epoch 57/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.7050e-04 - accuracy: 0.0857 - val_loss: 2.9191e-04 - val_accuracy: 0.0545\n",
            "Epoch 58/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8388e-04 - accuracy: 0.0889 - val_loss: 3.0152e-04 - val_accuracy: 0.0727\n",
            "Epoch 58/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.6761e-04 - accuracy: 0.0729 - val_loss: 2.5000e-04 - val_accuracy: 0.1455\n",
            "Epoch 58/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7290e-04 - accuracy: 0.0859 - val_loss: 2.6332e-04 - val_accuracy: 0.0909\n",
            "Epoch 58/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9213e-04 - accuracy: 0.0764 - val_loss: 4.2065e-04 - val_accuracy: 0.1273\n",
            "Epoch 58/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.6757e-04 - accuracy: 0.0696 - val_loss: 2.6062e-04 - val_accuracy: 0.0545\n",
            "Epoch 59/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4964e-04 - accuracy: 0.0807 - val_loss: 2.6557e-04 - val_accuracy: 0.0727\n",
            "Epoch 59/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3858e-04 - accuracy: 0.0729 - val_loss: 4.3658e-04 - val_accuracy: 0.1455\n",
            "20/62 [========>.....................] - ETA: 0s - loss: 1.7228e-04 - accuracy: 0.0961Epoch 59/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1870e-04 - accuracy: 0.0717 - val_loss: 2.6371e-04 - val_accuracy: 0.0909\n",
            "Epoch 59/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.5598e-04 - accuracy: 0.0637 - val_loss: 2.7305e-04 - val_accuracy: 0.1273\n",
            "Epoch 59/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0958e-04 - accuracy: 0.0945 - val_loss: 2.1976e-04 - val_accuracy: 0.0545\n",
            "Epoch 60/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7302e-04 - accuracy: 0.0833 - val_loss: 3.5806e-04 - val_accuracy: 0.0727\n",
            "Epoch 60/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0861e-04 - accuracy: 0.0779 - val_loss: 3.1448e-04 - val_accuracy: 0.1455\n",
            "23/62 [==========>...................] - ETA: 0s - loss: 2.4898e-04 - accuracy: 0.1658Epoch 60/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4936e-04 - accuracy: 0.0884 - val_loss: 2.5475e-04 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.3480e-04 - accuracy: 0.3750Epoch 60/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6676e-04 - accuracy: 0.0771 - val_loss: 2.2380e-04 - val_accuracy: 0.1273\n",
            "Epoch 60/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.7794e-04 - accuracy: 0.1046 - val_loss: 2.9429e-04 - val_accuracy: 0.0545\n",
            "Epoch 61/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2735e-04 - accuracy: 0.1198 - val_loss: 2.2613e-04 - val_accuracy: 0.0727\n",
            "21/62 [=========>....................] - ETA: 0s - loss: 1.6174e-04 - accuracy: 0.0734    Epoch 61/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 1.6568e-04 - accuracy: 0.1091 - val_loss: 2.2503e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.4837e-04 - accuracy: 0.1046 - val_loss: 5.6186e-04 - val_accuracy: 0.1455\n",
            "Epoch 61/170\n",
            "Epoch 61/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.4662e-04 - accuracy: 0.1101 - val_loss: 5.4106e-04 - val_accuracy: 0.1273\n",
            "Epoch 61/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 1.7900e-04 - accuracy: 0.0779 - val_loss: 4.6315e-04 - val_accuracy: 0.0545\n",
            "Epoch 62/170\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 3.7652e-04 - accuracy: 0.0682 - val_loss: 6.0398e-04 - val_accuracy: 0.0727\n",
            "Epoch 62/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3692e-04 - accuracy: 0.0682 - val_loss: 2.4858e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.7682e-04 - accuracy: 0.0713 - val_loss: 5.9211e-04 - val_accuracy: 0.1455\n",
            "Epoch 62/170Epoch 62/170\n",
            "\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.5710e-04 - accuracy: 0.0683 - val_loss: 6.2725e-04 - val_accuracy: 0.1273\n",
            "Epoch 62/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.6941e-04 - accuracy: 0.0662 - val_loss: 3.1086e-04 - val_accuracy: 0.0545\n",
            "Epoch 63/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.2333e-04 - accuracy: 0.0628 - val_loss: 2.4694e-04 - val_accuracy: 0.0727\n",
            "Epoch 63/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7187e-04 - accuracy: 0.0687 - val_loss: 2.4413e-04 - val_accuracy: 0.0909\n",
            "Epoch 63/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.7232e-04 - accuracy: 0.0663 - val_loss: 2.5496e-04 - val_accuracy: 0.1455\n",
            "Epoch 63/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.0191e-04 - accuracy: 0.0639 - val_loss: 2.1524e-04 - val_accuracy: 0.1273\n",
            "Epoch 63/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.6199e-04 - accuracy: 0.0905 - val_loss: 4.0886e-04 - val_accuracy: 0.0545\n",
            "Epoch 64/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8520e-04 - accuracy: 0.0933 - val_loss: 3.1886e-04 - val_accuracy: 0.0727\n",
            "Epoch 64/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3589e-04 - accuracy: 0.0922 - val_loss: 2.3873e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2204e-04 - accuracy: 0.0876 - val_loss: 4.8442e-04 - val_accuracy: 0.1455\n",
            "Epoch 64/170\n",
            "Epoch 64/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8272e-04 - accuracy: 0.0906 - val_loss: 3.3896e-04 - val_accuracy: 0.1273\n",
            "Epoch 64/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0209e-04 - accuracy: 0.0995 - val_loss: 2.2286e-04 - val_accuracy: 0.0545\n",
            "20/62 [========>.....................] - ETA: 0s - loss: 1.5876e-04 - accuracy: 0.0974Epoch 65/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8651e-04 - accuracy: 0.0943 - val_loss: 3.4823e-04 - val_accuracy: 0.0727\n",
            "Epoch 65/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4366e-04 - accuracy: 0.0989 - val_loss: 2.7782e-04 - val_accuracy: 0.0909\n",
            "Epoch 65/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8786e-04 - accuracy: 0.0848 - val_loss: 2.1420e-04 - val_accuracy: 0.1455\n",
            "Epoch 65/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7642e-04 - accuracy: 0.0858 - val_loss: 1.9765e-04 - val_accuracy: 0.1273\n",
            "Epoch 65/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9190e-04 - accuracy: 0.0691 - val_loss: 2.6266e-04 - val_accuracy: 0.0545\n",
            "Epoch 66/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9292e-04 - accuracy: 0.0641 - val_loss: 4.2005e-04 - val_accuracy: 0.0727\n",
            "Epoch 66/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6958e-04 - accuracy: 0.0650 - val_loss: 2.6527e-04 - val_accuracy: 0.0909\n",
            "Epoch 66/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.1389e-04 - accuracy: 0.0716 - val_loss: 5.9858e-04 - val_accuracy: 0.1455\n",
            "Epoch 66/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4089e-04 - accuracy: 0.0680 - val_loss: 3.9066e-04 - val_accuracy: 0.1273\n",
            "Epoch 66/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3423e-04 - accuracy: 0.0851 - val_loss: 2.1955e-04 - val_accuracy: 0.0545\n",
            "Epoch 67/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7671e-04 - accuracy: 0.0786 - val_loss: 2.7163e-04 - val_accuracy: 0.0727\n",
            "Epoch 67/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5940e-04 - accuracy: 0.0788 - val_loss: 2.0990e-04 - val_accuracy: 0.0909\n",
            "Epoch 67/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.3688e-04 - accuracy: 0.0735 - val_loss: 2.9180e-04 - val_accuracy: 0.1455\n",
            "Epoch 67/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1918e-04 - accuracy: 0.0712 - val_loss: 1.9707e-04 - val_accuracy: 0.1273\n",
            "Epoch 67/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2064e-04 - accuracy: 0.1013 - val_loss: 2.3260e-04 - val_accuracy: 0.0545\n",
            "Epoch 68/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6059e-04 - accuracy: 0.1001 - val_loss: 3.2303e-04 - val_accuracy: 0.0727\n",
            "Epoch 68/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8265e-04 - accuracy: 0.0919 - val_loss: 2.8565e-04 - val_accuracy: 0.0909\n",
            "Epoch 68/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6404e-04 - accuracy: 0.0875 - val_loss: 2.7516e-04 - val_accuracy: 0.1455\n",
            "Epoch 68/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4331e-04 - accuracy: 0.0943 - val_loss: 2.3958e-04 - val_accuracy: 0.1273\n",
            "Epoch 68/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7267e-04 - accuracy: 0.0850 - val_loss: 2.3016e-04 - val_accuracy: 0.0545\n",
            "Epoch 69/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.3848e-04 - accuracy: 0.0853 - val_loss: 6.5381e-04 - val_accuracy: 0.0727\n",
            "Epoch 69/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5523e-04 - accuracy: 0.0825 - val_loss: 2.1857e-04 - val_accuracy: 0.0909\n",
            "Epoch 69/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.8615e-04 - accuracy: 0.0946 - val_loss: 2.6138e-04 - val_accuracy: 0.1455\n",
            "Epoch 69/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0611e-04 - accuracy: 0.0925 - val_loss: 2.0767e-04 - val_accuracy: 0.1273\n",
            "Epoch 69/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.3261e-04 - accuracy: 0.0814 - val_loss: 2.2649e-04 - val_accuracy: 0.0545\n",
            "29/62 [=============>................] - ETA: 0s - loss: 1.0861e-04 - accuracy: 0.0615    Epoch 70/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.9654e-04 - accuracy: 0.0669 - val_loss: 2.4907e-04 - val_accuracy: 0.0727\n",
            "Epoch 70/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0525e-04 - accuracy: 0.0725 - val_loss: 2.8147e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8390e-04 - accuracy: 0.0749 - val_loss: 2.1759e-04 - val_accuracy: 0.1455\n",
            "Epoch 70/170\n",
            "Epoch 70/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0832e-04 - accuracy: 0.0653 - val_loss: 2.0440e-04 - val_accuracy: 0.1273\n",
            "Epoch 70/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6594e-04 - accuracy: 0.0738 - val_loss: 2.2144e-04 - val_accuracy: 0.0545\n",
            "Epoch 71/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3751e-04 - accuracy: 0.0534 - val_loss: 2.1806e-04 - val_accuracy: 0.0727\n",
            "Epoch 71/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6434e-04 - accuracy: 0.0528 - val_loss: 2.4986e-04 - val_accuracy: 0.1455\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.8355e-05 - accuracy: 0.0552 - val_loss: 2.8607e-04 - val_accuracy: 0.0909\n",
            "Epoch 71/170\n",
            "Epoch 71/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3441e-04 - accuracy: 0.0430 - val_loss: 1.7371e-04 - val_accuracy: 0.1273\n",
            "Epoch 71/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7746e-04 - accuracy: 0.0814 - val_loss: 2.3053e-04 - val_accuracy: 0.0545\n",
            "Epoch 72/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0913e-04 - accuracy: 0.0851 - val_loss: 4.3074e-04 - val_accuracy: 0.0727\n",
            "Epoch 72/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4731e-04 - accuracy: 0.0815 - val_loss: 2.5680e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6382e-04 - accuracy: 0.0907 - val_loss: 2.0861e-04 - val_accuracy: 0.1455\n",
            "\n",
            "Epoch 72/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7271e-04 - accuracy: 0.0862 - val_loss: 2.7328e-04 - val_accuracy: 0.1273\n",
            "Epoch 72/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9787e-04 - accuracy: 0.0881 - val_loss: 4.2185e-04 - val_accuracy: 0.0545\n",
            "Epoch 73/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8134e-04 - accuracy: 0.0763 - val_loss: 2.5252e-04 - val_accuracy: 0.0727\n",
            "Epoch 73/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1409e-04 - accuracy: 0.0733 - val_loss: 3.8541e-04 - val_accuracy: 0.0909\n",
            "Epoch 73/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8980e-04 - accuracy: 0.0692 - val_loss: 2.6512e-04 - val_accuracy: 0.1455\n",
            " 1/62 [..............................] - ETA: 0s - loss: 4.2277e-04 - accuracy: 0.0000e+00Epoch 73/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4876e-04 - accuracy: 0.0651 - val_loss: 2.3515e-04 - val_accuracy: 0.1273\n",
            "Epoch 73/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.6613e-04 - accuracy: 0.0896 - val_loss: 3.4322e-04 - val_accuracy: 0.0545\n",
            "Epoch 74/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4408e-04 - accuracy: 0.0931 - val_loss: 4.2897e-04 - val_accuracy: 0.0727\n",
            "Epoch 74/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6114e-04 - accuracy: 0.0860 - val_loss: 1.9678e-04 - val_accuracy: 0.0909\n",
            "Epoch 74/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5561e-04 - accuracy: 0.0837 - val_loss: 5.7240e-04 - val_accuracy: 0.1455\n",
            "Epoch 74/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1629e-04 - accuracy: 0.0796 - val_loss: 2.3049e-04 - val_accuracy: 0.1273\n",
            "Epoch 74/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8706e-04 - accuracy: 0.0812 - val_loss: 2.1801e-04 - val_accuracy: 0.0545\n",
            "Epoch 75/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2876e-04 - accuracy: 0.0690 - val_loss: 2.3293e-04 - val_accuracy: 0.0727\n",
            "Epoch 75/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5011e-04 - accuracy: 0.0753 - val_loss: 1.5968e-04 - val_accuracy: 0.0909\n",
            "Epoch 75/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9548e-04 - accuracy: 0.0626 - val_loss: 3.2832e-04 - val_accuracy: 0.1455\n",
            "Epoch 75/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2650e-04 - accuracy: 0.0603 - val_loss: 2.2407e-04 - val_accuracy: 0.1273\n",
            "Epoch 75/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6166e-04 - accuracy: 0.0723 - val_loss: 1.6349e-04 - val_accuracy: 0.0545\n",
            "Epoch 76/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5571e-04 - accuracy: 0.0725 - val_loss: 2.4991e-04 - val_accuracy: 0.0727\n",
            "Epoch 76/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0372e-04 - accuracy: 0.0710 - val_loss: 2.7530e-04 - val_accuracy: 0.0909\n",
            "Epoch 76/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6379e-04 - accuracy: 0.0599 - val_loss: 3.8445e-04 - val_accuracy: 0.1455\n",
            "Epoch 76/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5014e-04 - accuracy: 0.0681 - val_loss: 1.7043e-04 - val_accuracy: 0.1273\n",
            "Epoch 76/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4335e-04 - accuracy: 0.0868 - val_loss: 1.7699e-04 - val_accuracy: 0.0545\n",
            "Epoch 77/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6098e-04 - accuracy: 0.0856 - val_loss: 2.7255e-04 - val_accuracy: 0.0727\n",
            "Epoch 77/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2735e-04 - accuracy: 0.0817 - val_loss: 2.3374e-04 - val_accuracy: 0.0909\n",
            "Epoch 77/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4869e-04 - accuracy: 0.0794 - val_loss: 3.4518e-04 - val_accuracy: 0.1455\n",
            "Epoch 77/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1614e-04 - accuracy: 0.0793 - val_loss: 1.4761e-04 - val_accuracy: 0.1273\n",
            "Epoch 77/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1416e-04 - accuracy: 0.0889 - val_loss: 3.8092e-04 - val_accuracy: 0.0545\n",
            "Epoch 78/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5557e-04 - accuracy: 0.0977 - val_loss: 3.8826e-04 - val_accuracy: 0.0727\n",
            "Epoch 78/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.2349e-04 - accuracy: 0.0814 - val_loss: 9.0099e-04 - val_accuracy: 0.0909\n",
            "Epoch 78/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.8824e-04 - accuracy: 0.0658 - val_loss: 4.7561e-04 - val_accuracy: 0.1455\n",
            "Epoch 78/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1951e-04 - accuracy: 0.0808 - val_loss: 2.6980e-04 - val_accuracy: 0.1273\n",
            "Epoch 78/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.9967e-04 - accuracy: 0.1029 - val_loss: 1.8742e-04 - val_accuracy: 0.0545\n",
            "Epoch 79/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5193e-04 - accuracy: 0.0893 - val_loss: 2.0395e-04 - val_accuracy: 0.0727\n",
            "Epoch 79/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.0316e-04 - accuracy: 0.0904 - val_loss: 1.7043e-04 - val_accuracy: 0.0909\n",
            "Epoch 79/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0571e-04 - accuracy: 0.0838 - val_loss: 2.4253e-04 - val_accuracy: 0.1455\n",
            "Epoch 79/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4027e-04 - accuracy: 0.0890 - val_loss: 1.7860e-04 - val_accuracy: 0.1273\n",
            "Epoch 79/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0598e-04 - accuracy: 0.0674 - val_loss: 2.2776e-04 - val_accuracy: 0.0545\n",
            "Epoch 80/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3674e-04 - accuracy: 0.0669 - val_loss: 3.2376e-04 - val_accuracy: 0.0727\n",
            "Epoch 80/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5143e-04 - accuracy: 0.0587 - val_loss: 2.1512e-04 - val_accuracy: 0.0909\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 1.5254e-04 - accuracy: 0.0610Epoch 80/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5263e-04 - accuracy: 0.0623 - val_loss: 2.6917e-04 - val_accuracy: 0.1455\n",
            "Epoch 80/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2605e-04 - accuracy: 0.0624 - val_loss: 2.1161e-04 - val_accuracy: 0.1273\n",
            "Epoch 80/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7608e-04 - accuracy: 0.0838 - val_loss: 1.6639e-04 - val_accuracy: 0.0545\n",
            "Epoch 81/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5949e-04 - accuracy: 0.0806 - val_loss: 2.4853e-04 - val_accuracy: 0.0727\n",
            "Epoch 81/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1216e-04 - accuracy: 0.0755 - val_loss: 1.8657e-04 - val_accuracy: 0.0909\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 1.4743e-04 - accuracy: 0.0765Epoch 81/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4869e-04 - accuracy: 0.0768 - val_loss: 2.6690e-04 - val_accuracy: 0.1455\n",
            "Epoch 81/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5625e-04 - accuracy: 0.0795 - val_loss: 1.6536e-04 - val_accuracy: 0.1273\n",
            "Epoch 81/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6613e-04 - accuracy: 0.1071 - val_loss: 3.1516e-04 - val_accuracy: 0.0545\n",
            "Epoch 82/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2322e-04 - accuracy: 0.0973 - val_loss: 3.4033e-04 - val_accuracy: 0.0727\n",
            "Epoch 82/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0761e-04 - accuracy: 0.1009 - val_loss: 2.4042e-04 - val_accuracy: 0.0909\n",
            "Epoch 82/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1827e-04 - accuracy: 0.0838 - val_loss: 1.8876e-04 - val_accuracy: 0.1455\n",
            "Epoch 82/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9050e-04 - accuracy: 0.0850 - val_loss: 1.9133e-04 - val_accuracy: 0.1273\n",
            "Epoch 82/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4177e-04 - accuracy: 0.0893 - val_loss: 2.8644e-04 - val_accuracy: 0.0545\n",
            "48/62 [======================>.......] - ETA: 0s - loss: 3.4857e-04 - accuracy: 0.0904Epoch 83/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.4003e-04 - accuracy: 0.0897 - val_loss: 1.4508e-04 - val_accuracy: 0.0727\n",
            "Epoch 83/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2957e-04 - accuracy: 0.0835 - val_loss: 2.5191e-04 - val_accuracy: 0.0909\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 1.3521e-04 - accuracy: 0.0802Epoch 83/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3629e-04 - accuracy: 0.0799 - val_loss: 2.2937e-04 - val_accuracy: 0.1455\n",
            "Epoch 83/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4228e-04 - accuracy: 0.0761 - val_loss: 2.5501e-04 - val_accuracy: 0.1273\n",
            "Epoch 83/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4784e-04 - accuracy: 0.0914 - val_loss: 1.4522e-04 - val_accuracy: 0.0545\n",
            "Epoch 84/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5130e-04 - accuracy: 0.1034 - val_loss: 2.8593e-04 - val_accuracy: 0.0727\n",
            "Epoch 84/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4594e-04 - accuracy: 0.0915 - val_loss: 2.8597e-04 - val_accuracy: 0.0909\n",
            "Epoch 84/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6393e-04 - accuracy: 0.0852 - val_loss: 5.9448e-04 - val_accuracy: 0.1455\n",
            "Epoch 84/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4262e-04 - accuracy: 0.0609 - val_loss: 1.7988e-04 - val_accuracy: 0.0545\n",
            " 1/62 [..............................] - ETA: 0s - loss: 5.3772e-04 - accuracy: 0.0000e+00Epoch 85/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5673e-04 - accuracy: 0.0904 - val_loss: 3.2182e-04 - val_accuracy: 0.1273\n",
            "Epoch 84/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0585e-04 - accuracy: 0.0541 - val_loss: 1.8420e-04 - val_accuracy: 0.0727\n",
            "Epoch 85/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7961e-04 - accuracy: 0.0614 - val_loss: 1.9975e-04 - val_accuracy: 0.0909\n",
            "Epoch 85/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.9203e-04 - accuracy: 0.0610 - val_loss: 5.5479e-04 - val_accuracy: 0.1455\n",
            "Epoch 85/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4692e-04 - accuracy: 0.0956 - val_loss: 1.5808e-04 - val_accuracy: 0.0545\n",
            " 1/62 [..............................] - ETA: 0s - loss: 3.3387e-04 - accuracy: 0.3750Epoch 86/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4778e-04 - accuracy: 0.0553 - val_loss: 1.4837e-04 - val_accuracy: 0.1273\n",
            "Epoch 85/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1248e-04 - accuracy: 0.0838 - val_loss: 1.6527e-04 - val_accuracy: 0.0727\n",
            "Epoch 86/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1916e-04 - accuracy: 0.0846 - val_loss: 1.9379e-04 - val_accuracy: 0.0909\n",
            "Epoch 86/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5445e-04 - accuracy: 0.0834 - val_loss: 2.0522e-04 - val_accuracy: 0.0545\n",
            "Epoch 87/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1345e-04 - accuracy: 0.0879 - val_loss: 2.0070e-04 - val_accuracy: 0.1455\n",
            "Epoch 86/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.8905e-05 - accuracy: 0.0771 - val_loss: 2.3705e-04 - val_accuracy: 0.1273\n",
            "Epoch 86/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2361e-04 - accuracy: 0.0809 - val_loss: 7.4023e-04 - val_accuracy: 0.0727\n",
            "Epoch 87/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.5790e-05 - accuracy: 0.0792 - val_loss: 1.8729e-04 - val_accuracy: 0.0909\n",
            "Epoch 87/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.0775e-04 - accuracy: 0.1022 - val_loss: 2.5294e-04 - val_accuracy: 0.0545\n",
            "Epoch 88/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2430e-04 - accuracy: 0.0863 - val_loss: 2.2841e-04 - val_accuracy: 0.1455\n",
            "Epoch 87/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5883e-04 - accuracy: 0.0831 - val_loss: 1.8294e-04 - val_accuracy: 0.1273\n",
            "Epoch 87/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.3479e-04 - accuracy: 0.0884 - val_loss: 5.7813e-04 - val_accuracy: 0.0727\n",
            "Epoch 88/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.2230e-05 - accuracy: 0.0904 - val_loss: 2.4371e-04 - val_accuracy: 0.0909\n",
            "Epoch 88/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4592e-04 - accuracy: 0.1002 - val_loss: 1.6801e-04 - val_accuracy: 0.0545\n",
            "Epoch 89/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0657e-04 - accuracy: 0.0813 - val_loss: 2.1311e-04 - val_accuracy: 0.1455\n",
            "Epoch 88/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.1706e-05 - accuracy: 0.0795 - val_loss: 1.6859e-04 - val_accuracy: 0.1273\n",
            "Epoch 88/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9357e-04 - accuracy: 0.1004 - val_loss: 2.3300e-04 - val_accuracy: 0.0727\n",
            "Epoch 89/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.4750e-05 - accuracy: 0.0980 - val_loss: 2.0003e-04 - val_accuracy: 0.0909\n",
            "Epoch 89/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4495e-04 - accuracy: 0.0919 - val_loss: 1.9084e-04 - val_accuracy: 0.0545\n",
            "Epoch 90/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2447e-04 - accuracy: 0.0890 - val_loss: 2.2424e-04 - val_accuracy: 0.1455\n",
            "Epoch 89/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.4947e-05 - accuracy: 0.0989 - val_loss: 1.9884e-04 - val_accuracy: 0.1273\n",
            "Epoch 89/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1507e-04 - accuracy: 0.0817 - val_loss: 1.9864e-04 - val_accuracy: 0.0727\n",
            "Epoch 90/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.6784e-05 - accuracy: 0.0772 - val_loss: 1.6574e-04 - val_accuracy: 0.0909\n",
            "Epoch 90/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8088e-04 - accuracy: 0.1017 - val_loss: 5.2362e-04 - val_accuracy: 0.0545\n",
            "Epoch 91/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7380e-04 - accuracy: 0.0597 - val_loss: 2.1642e-04 - val_accuracy: 0.1455\n",
            "Epoch 90/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0593e-04 - accuracy: 0.0575 - val_loss: 2.1345e-04 - val_accuracy: 0.1273\n",
            "Epoch 90/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2867e-04 - accuracy: 0.0981 - val_loss: 4.5072e-04 - val_accuracy: 0.0727\n",
            "Epoch 91/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.5308e-05 - accuracy: 0.1029 - val_loss: 4.3578e-04 - val_accuracy: 0.0909\n",
            "Epoch 91/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2956e-04 - accuracy: 0.0877 - val_loss: 2.1830e-04 - val_accuracy: 0.0545\n",
            "Epoch 92/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0069e-04 - accuracy: 0.1055 - val_loss: 4.8268e-04 - val_accuracy: 0.1455\n",
            "Epoch 91/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5816e-04 - accuracy: 0.0976 - val_loss: 2.6862e-04 - val_accuracy: 0.1273\n",
            "Epoch 91/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7776e-04 - accuracy: 0.0969 - val_loss: 3.0743e-04 - val_accuracy: 0.0727\n",
            "Epoch 92/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1622e-04 - accuracy: 0.0926 - val_loss: 1.6540e-04 - val_accuracy: 0.0909\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 3.6641e-04 - accuracy: 0.0841Epoch 92/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7095e-04 - accuracy: 0.0849 - val_loss: 1.8849e-04 - val_accuracy: 0.0545\n",
            "Epoch 93/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6254e-04 - accuracy: 0.0983 - val_loss: 1.3323e-04 - val_accuracy: 0.1273\n",
            "Epoch 92/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.5620e-04 - accuracy: 0.0832 - val_loss: 2.2713e-04 - val_accuracy: 0.1455\n",
            "Epoch 92/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1996e-04 - accuracy: 0.0867 - val_loss: 1.8969e-04 - val_accuracy: 0.0727\n",
            "Epoch 93/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0678e-04 - accuracy: 0.0853 - val_loss: 1.7699e-04 - val_accuracy: 0.0909\n",
            "Epoch 93/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8637e-04 - accuracy: 0.0817 - val_loss: 2.1499e-04 - val_accuracy: 0.0545\n",
            "Epoch 94/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3437e-04 - accuracy: 0.0740 - val_loss: 2.4289e-04 - val_accuracy: 0.1273\n",
            "Epoch 93/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4156e-04 - accuracy: 0.0768 - val_loss: 2.4357e-04 - val_accuracy: 0.1455\n",
            "Epoch 93/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0444e-04 - accuracy: 0.0794 - val_loss: 2.6354e-04 - val_accuracy: 0.0727\n",
            "Epoch 94/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.1120e-05 - accuracy: 0.0789 - val_loss: 1.8122e-04 - val_accuracy: 0.0909\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.6315e-04 - accuracy: 0.0758Epoch 94/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6341e-04 - accuracy: 0.0763 - val_loss: 1.6596e-04 - val_accuracy: 0.0545\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 1.0235e-04 - accuracy: 0.0733Epoch 95/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0311e-04 - accuracy: 0.0737 - val_loss: 2.8591e-04 - val_accuracy: 0.1273\n",
            "Epoch 94/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1335e-04 - accuracy: 0.0694 - val_loss: 2.3127e-04 - val_accuracy: 0.1455\n",
            "29/62 [=============>................] - ETA: 0s - loss: 8.1627e-05 - accuracy: 0.0599    Epoch 94/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0528e-04 - accuracy: 0.0707 - val_loss: 2.2044e-04 - val_accuracy: 0.0727\n",
            "46/62 [=====================>........] - ETA: 0s - loss: 8.2730e-05 - accuracy: 0.0680Epoch 95/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.5338e-05 - accuracy: 0.0729 - val_loss: 2.1375e-04 - val_accuracy: 0.0909\n",
            "Epoch 95/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5169e-04 - accuracy: 0.0844 - val_loss: 2.3778e-04 - val_accuracy: 0.0545\n",
            "Epoch 96/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0345e-04 - accuracy: 0.0652 - val_loss: 2.3260e-04 - val_accuracy: 0.1273\n",
            "Epoch 95/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2223e-04 - accuracy: 0.0539 - val_loss: 2.4785e-04 - val_accuracy: 0.1455\n",
            "Epoch 95/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5755e-04 - accuracy: 0.0840 - val_loss: 2.2954e-04 - val_accuracy: 0.0727\n",
            "Epoch 96/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.9556e-05 - accuracy: 0.0790 - val_loss: 2.3195e-04 - val_accuracy: 0.0909\n",
            "Epoch 96/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5890e-04 - accuracy: 0.0656 - val_loss: 2.6523e-04 - val_accuracy: 0.0545\n",
            "Epoch 97/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9622e-04 - accuracy: 0.0753 - val_loss: 3.2533e-04 - val_accuracy: 0.1455\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5569e-04 - accuracy: 0.0832 - val_loss: 2.2586e-04 - val_accuracy: 0.1273\n",
            "Epoch 96/170\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.6428e-04 - accuracy: 0.1250Epoch 96/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1220e-04 - accuracy: 0.0660 - val_loss: 3.2319e-04 - val_accuracy: 0.0727\n",
            "Epoch 97/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2743e-04 - accuracy: 0.0614 - val_loss: 2.4635e-04 - val_accuracy: 0.0909\n",
            "27/62 [============>.................] - ETA: 0s - loss: 1.1289e-04 - accuracy: 0.0704    Epoch 97/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1477e-04 - accuracy: 0.0880 - val_loss: 2.4670e-04 - val_accuracy: 0.0545\n",
            "Epoch 98/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1409e-04 - accuracy: 0.0678 - val_loss: 6.1735e-04 - val_accuracy: 0.1455\n",
            "Epoch 97/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1893e-04 - accuracy: 0.0666 - val_loss: 7.8978e-04 - val_accuracy: 0.1273\n",
            "Epoch 97/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1898e-04 - accuracy: 0.0816 - val_loss: 3.1736e-04 - val_accuracy: 0.0727\n",
            "Epoch 98/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1572e-04 - accuracy: 0.0758 - val_loss: 2.1159e-04 - val_accuracy: 0.0909\n",
            "29/62 [=============>................] - ETA: 0s - loss: 1.3860e-04 - accuracy: 0.0874Epoch 98/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9659e-04 - accuracy: 0.0878 - val_loss: 2.1408e-04 - val_accuracy: 0.0545\n",
            "Epoch 99/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.0375e-04 - accuracy: 0.0723 - val_loss: 1.9858e-04 - val_accuracy: 0.1455\n",
            "Epoch 98/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.2383e-04 - accuracy: 0.0766 - val_loss: 2.8826e-04 - val_accuracy: 0.1273\n",
            "Epoch 98/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2358e-04 - accuracy: 0.0872 - val_loss: 1.7343e-04 - val_accuracy: 0.0727\n",
            "22/62 [=========>....................] - ETA: 0s - loss: 1.1720e-04 - accuracy: 0.0810\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3785e-04 - accuracy: 0.0897 - val_loss: 1.4565e-04 - val_accuracy: 0.0909\n",
            "38/62 [=================>............] - ETA: 0s - loss: 2.7817e-04 - accuracy: 0.0777Epoch 99/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1862e-04 - accuracy: 0.0769 - val_loss: 1.6512e-04 - val_accuracy: 0.0545\n",
            "Epoch 100/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1756e-04 - accuracy: 0.0857 - val_loss: 1.7633e-04 - val_accuracy: 0.1455\n",
            "Epoch 99/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.6908e-04 - accuracy: 0.0780 - val_loss: 2.0725e-04 - val_accuracy: 0.1273\n",
            "Epoch 99/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1112e-04 - accuracy: 0.0749 - val_loss: 1.6753e-04 - val_accuracy: 0.0727\n",
            "Epoch 100/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.5830e-05 - accuracy: 0.0739 - val_loss: 1.6306e-04 - val_accuracy: 0.0909\n",
            "Epoch 100/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4486e-04 - accuracy: 0.0869 - val_loss: 4.1834e-04 - val_accuracy: 0.0545\n",
            "Epoch 101/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0490e-04 - accuracy: 0.0816 - val_loss: 2.2663e-04 - val_accuracy: 0.1455\n",
            "Epoch 100/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2587e-04 - accuracy: 0.0802 - val_loss: 2.7113e-04 - val_accuracy: 0.1273\n",
            "Epoch 100/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5791e-04 - accuracy: 0.0800 - val_loss: 1.8286e-04 - val_accuracy: 0.0727\n",
            "Epoch 101/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1492e-04 - accuracy: 0.0806 - val_loss: 5.3068e-04 - val_accuracy: 0.0909\n",
            "Epoch 101/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.1077e-04 - accuracy: 0.1027 - val_loss: 1.7830e-04 - val_accuracy: 0.0545\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 1.3614e-04 - accuracy: 0.0856Epoch 102/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3672e-04 - accuracy: 0.0851 - val_loss: 2.0912e-04 - val_accuracy: 0.1455\n",
            "Epoch 101/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1188e-04 - accuracy: 0.0838 - val_loss: 2.6970e-04 - val_accuracy: 0.1273\n",
            "Epoch 101/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1208e-04 - accuracy: 0.0987 - val_loss: 2.4790e-04 - val_accuracy: 0.0727\n",
            "24/62 [==========>...................] - ETA: 0s - loss: 1.6480e-04 - accuracy: 0.0537    Epoch 102/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4779e-04 - accuracy: 0.0988 - val_loss: 2.9779e-04 - val_accuracy: 0.0909\n",
            "Epoch 102/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4815e-04 - accuracy: 0.0717 - val_loss: 1.5662e-04 - val_accuracy: 0.0545\n",
            "Epoch 103/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2585e-04 - accuracy: 0.1027 - val_loss: 3.1053e-04 - val_accuracy: 0.1455\n",
            "Epoch 102/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2739e-04 - accuracy: 0.0978 - val_loss: 2.0456e-04 - val_accuracy: 0.1273\n",
            "Epoch 102/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3553e-04 - accuracy: 0.0738 - val_loss: 2.8021e-04 - val_accuracy: 0.0727\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.1028e-04 - accuracy: 0.0000e+00Epoch 103/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0126e-04 - accuracy: 0.0717 - val_loss: 2.6489e-04 - val_accuracy: 0.0909\n",
            "36/62 [================>.............] - ETA: 0s - loss: 1.3862e-04 - accuracy: 0.0628Epoch 103/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2544e-04 - accuracy: 0.0920 - val_loss: 2.4082e-04 - val_accuracy: 0.0545\n",
            "Epoch 104/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0518e-04 - accuracy: 0.0852 - val_loss: 2.4308e-04 - val_accuracy: 0.1455\n",
            "Epoch 103/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1903e-04 - accuracy: 0.0820 - val_loss: 1.9186e-04 - val_accuracy: 0.0727\n",
            "Epoch 104/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4333e-04 - accuracy: 0.0700 - val_loss: 2.3638e-04 - val_accuracy: 0.1273\n",
            "Epoch 103/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0044e-04 - accuracy: 0.0788 - val_loss: 4.3766e-04 - val_accuracy: 0.0909\n",
            "Epoch 104/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6471e-04 - accuracy: 0.0991 - val_loss: 2.2599e-04 - val_accuracy: 0.0545\n",
            "Epoch 105/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5097e-04 - accuracy: 0.0791 - val_loss: 1.9712e-04 - val_accuracy: 0.1455\n",
            "Epoch 104/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.8976e-05 - accuracy: 0.0803 - val_loss: 2.6555e-04 - val_accuracy: 0.0727\n",
            "Epoch 105/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1665e-04 - accuracy: 0.0768 - val_loss: 2.1171e-04 - val_accuracy: 0.1273\n",
            "Epoch 104/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6064e-04 - accuracy: 0.0818 - val_loss: 3.6001e-04 - val_accuracy: 0.0909\n",
            "Epoch 105/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5592e-04 - accuracy: 0.0648 - val_loss: 1.9507e-04 - val_accuracy: 0.0545\n",
            "Epoch 106/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5322e-04 - accuracy: 0.0876 - val_loss: 1.7226e-04 - val_accuracy: 0.1455\n",
            "Epoch 105/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3662e-04 - accuracy: 0.0593 - val_loss: 1.8508e-04 - val_accuracy: 0.0727\n",
            "Epoch 106/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.1909e-05 - accuracy: 0.0758 - val_loss: 2.0319e-04 - val_accuracy: 0.1273\n",
            "Epoch 105/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0325e-04 - accuracy: 0.0573 - val_loss: 1.3711e-04 - val_accuracy: 0.0909\n",
            "Epoch 106/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0979e-04 - accuracy: 0.0944 - val_loss: 2.7644e-04 - val_accuracy: 0.0545\n",
            "Epoch 107/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.0850e-05 - accuracy: 0.0594 - val_loss: 3.0519e-04 - val_accuracy: 0.1455\n",
            "28/62 [============>.................] - ETA: 0s - loss: 9.1975e-05 - accuracy: 0.1108Epoch 106/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.6016e-05 - accuracy: 0.0962 - val_loss: 2.1002e-04 - val_accuracy: 0.0727\n",
            "Epoch 107/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.7884e-05 - accuracy: 0.0584 - val_loss: 1.4437e-04 - val_accuracy: 0.1273\n",
            "Epoch 106/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.7396e-05 - accuracy: 0.0901 - val_loss: 2.2837e-04 - val_accuracy: 0.0909\n",
            "Epoch 107/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.1428e-04 - accuracy: 0.0976 - val_loss: 2.1568e-04 - val_accuracy: 0.0545\n",
            "Epoch 108/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2422e-04 - accuracy: 0.0773 - val_loss: 2.4869e-04 - val_accuracy: 0.1455\n",
            "Epoch 107/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.5802e-04 - accuracy: 0.0915 - val_loss: 5.5118e-04 - val_accuracy: 0.0727\n",
            "Epoch 108/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.8876e-05 - accuracy: 0.0815 - val_loss: 2.2985e-04 - val_accuracy: 0.1273\n",
            "Epoch 107/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1863e-04 - accuracy: 0.0873 - val_loss: 1.8346e-04 - val_accuracy: 0.0909\n",
            "Epoch 108/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0984e-04 - accuracy: 0.1015 - val_loss: 2.4882e-04 - val_accuracy: 0.0545\n",
            "53/62 [========================>.....] - ETA: 0s - loss: 2.1398e-04 - accuracy: 0.0788\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1988e-04 - accuracy: 0.0784 - val_loss: 2.3695e-04 - val_accuracy: 0.1455\n",
            "Epoch 108/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2690e-04 - accuracy: 0.0930 - val_loss: 1.7823e-04 - val_accuracy: 0.0727\n",
            "Epoch 109/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9507e-04 - accuracy: 0.0824 - val_loss: 2.9941e-04 - val_accuracy: 0.1273\n",
            "Epoch 108/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4967e-04 - accuracy: 0.0933 - val_loss: 1.8996e-04 - val_accuracy: 0.0909\n",
            "Epoch 109/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9490e-04 - accuracy: 0.1015 - val_loss: 4.5878e-04 - val_accuracy: 0.0545\n",
            "Epoch 110/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0558e-04 - accuracy: 0.0914 - val_loss: 1.7577e-04 - val_accuracy: 0.1455\n",
            "Epoch 109/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.9122e-05 - accuracy: 0.1032 - val_loss: 1.7796e-04 - val_accuracy: 0.0727\n",
            "Epoch 110/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0755e-04 - accuracy: 0.0918 - val_loss: 1.4491e-04 - val_accuracy: 0.1273\n",
            "Epoch 109/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5573e-04 - accuracy: 0.0993 - val_loss: 2.9263e-04 - val_accuracy: 0.0909\n",
            "Epoch 110/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1957e-04 - accuracy: 0.0728 - val_loss: 1.6820e-04 - val_accuracy: 0.0545\n",
            "Epoch 111/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3707e-04 - accuracy: 0.0975 - val_loss: 1.9257e-04 - val_accuracy: 0.1455\n",
            "Epoch 110/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0200e-04 - accuracy: 0.0768 - val_loss: 1.6484e-04 - val_accuracy: 0.0727\n",
            "Epoch 111/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.6534e-05 - accuracy: 0.0912 - val_loss: 1.7020e-04 - val_accuracy: 0.1273\n",
            "Epoch 110/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7713e-04 - accuracy: 0.0776 - val_loss: 2.1109e-04 - val_accuracy: 0.0909\n",
            "41/62 [==================>...........] - ETA: 0s - loss: 1.4627e-04 - accuracy: 0.0758Epoch 111/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0547e-04 - accuracy: 0.0910 - val_loss: 1.3710e-04 - val_accuracy: 0.0545\n",
            "Epoch 112/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4754e-04 - accuracy: 0.0775 - val_loss: 2.1436e-04 - val_accuracy: 0.1455\n",
            "Epoch 111/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2480e-04 - accuracy: 0.1012 - val_loss: 4.8004e-04 - val_accuracy: 0.0727\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.9985e-04 - accuracy: 0.1250Epoch 112/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.1703e-05 - accuracy: 0.0687 - val_loss: 1.7914e-04 - val_accuracy: 0.1273\n",
            "Epoch 111/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.9166e-05 - accuracy: 0.0921 - val_loss: 1.4850e-04 - val_accuracy: 0.0909\n",
            "23/62 [==========>...................] - ETA: 0s - loss: 8.8753e-05 - accuracy: 0.1173Epoch 112/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.8909e-05 - accuracy: 0.0846 - val_loss: 1.5321e-04 - val_accuracy: 0.0545\n",
            "Epoch 113/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9905e-04 - accuracy: 0.0812 - val_loss: 2.3063e-04 - val_accuracy: 0.1455\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3818e-04 - accuracy: 0.0899 - val_loss: 3.2379e-04 - val_accuracy: 0.0727\n",
            "Epoch 112/170\n",
            "Epoch 113/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.4544e-05 - accuracy: 0.0974 - val_loss: 1.6278e-04 - val_accuracy: 0.1273\n",
            "Epoch 112/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.7298e-05 - accuracy: 0.0776 - val_loss: 1.9873e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2729e-04 - accuracy: 0.0723 - val_loss: 1.8835e-04 - val_accuracy: 0.0545\n",
            "Epoch 113/170\n",
            " 1/62 [..............................] - ETA: 0s - loss: 9.1068e-05 - accuracy: 0.0000e+00Epoch 114/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3284e-04 - accuracy: 0.0835 - val_loss: 4.2636e-04 - val_accuracy: 0.0727\n",
            "Epoch 114/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.3731e-05 - accuracy: 0.0861 - val_loss: 2.5254e-04 - val_accuracy: 0.1455\n",
            "Epoch 113/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.9257e-05 - accuracy: 0.0919 - val_loss: 1.8852e-04 - val_accuracy: 0.1273\n",
            "Epoch 113/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0865e-04 - accuracy: 0.0899 - val_loss: 1.7105e-04 - val_accuracy: 0.0545\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.1606e-05 - accuracy: 0.0777 - val_loss: 1.9026e-04 - val_accuracy: 0.0909\n",
            "Epoch 115/170\n",
            " 1/62 [..............................] - ETA: 0s - loss: 8.3260e-05 - accuracy: 0.0000e+00Epoch 114/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3466e-04 - accuracy: 0.0953 - val_loss: 1.5590e-04 - val_accuracy: 0.0727\n",
            "27/62 [============>.................] - ETA: 0s - loss: 1.0031e-04 - accuracy: 0.0829    Epoch 115/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3819e-04 - accuracy: 0.0738 - val_loss: 1.8406e-04 - val_accuracy: 0.1455\n",
            "Epoch 114/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.8389e-05 - accuracy: 0.0851 - val_loss: 1.6995e-04 - val_accuracy: 0.1273\n",
            "Epoch 114/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0690e-04 - accuracy: 0.0868 - val_loss: 1.7959e-04 - val_accuracy: 0.0545\n",
            "Epoch 116/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0071e-04 - accuracy: 0.0867 - val_loss: 1.7656e-04 - val_accuracy: 0.0909\n",
            "Epoch 115/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.9909e-05 - accuracy: 0.0864 - val_loss: 2.8709e-04 - val_accuracy: 0.0727\n",
            "30/62 [=============>................] - ETA: 0s - loss: 1.2471e-04 - accuracy: 0.1028Epoch 116/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.9497e-05 - accuracy: 0.0815 - val_loss: 2.1444e-04 - val_accuracy: 0.1455\n",
            "Epoch 115/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.4745e-05 - accuracy: 0.0932 - val_loss: 1.8261e-04 - val_accuracy: 0.1273\n",
            "Epoch 115/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2490e-04 - accuracy: 0.0954 - val_loss: 1.4671e-04 - val_accuracy: 0.0545\n",
            "Epoch 117/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4956e-05 - accuracy: 0.0857 - val_loss: 1.6305e-04 - val_accuracy: 0.0909\n",
            "Epoch 116/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1283e-04 - accuracy: 0.0861 - val_loss: 1.7474e-04 - val_accuracy: 0.0727\n",
            "Epoch 117/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.0016e-05 - accuracy: 0.0877 - val_loss: 1.6567e-04 - val_accuracy: 0.1273\n",
            "Epoch 116/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1106e-04 - accuracy: 0.0895 - val_loss: 1.8895e-04 - val_accuracy: 0.1455\n",
            "Epoch 116/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9388e-04 - accuracy: 0.0809 - val_loss: 1.8976e-04 - val_accuracy: 0.0545\n",
            "Epoch 118/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.9133e-05 - accuracy: 0.0867 - val_loss: 1.3413e-04 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.1091e-04 - accuracy: 0.1250Epoch 117/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1179e-04 - accuracy: 0.0728 - val_loss: 1.5315e-04 - val_accuracy: 0.0727\n",
            "Epoch 118/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.1779e-05 - accuracy: 0.0781 - val_loss: 1.4638e-04 - val_accuracy: 0.1273\n",
            "Epoch 117/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0874e-04 - accuracy: 0.0659 - val_loss: 2.3787e-04 - val_accuracy: 0.1455\n",
            "Epoch 117/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5514e-04 - accuracy: 0.0940 - val_loss: 1.5637e-04 - val_accuracy: 0.0545\n",
            "Epoch 119/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0655e-04 - accuracy: 0.0674 - val_loss: 1.9614e-04 - val_accuracy: 0.0909\n",
            "Epoch 118/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4797e-04 - accuracy: 0.0874 - val_loss: 1.8587e-04 - val_accuracy: 0.0727\n",
            "Epoch 119/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0940e-04 - accuracy: 0.0638 - val_loss: 1.7761e-04 - val_accuracy: 0.1273\n",
            "Epoch 118/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0166e-04 - accuracy: 0.0629 - val_loss: 2.0229e-04 - val_accuracy: 0.1455\n",
            "24/62 [==========>...................] - ETA: 0s - loss: 7.3950e-05 - accuracy: 0.0708    Epoch 118/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1588e-04 - accuracy: 0.0877 - val_loss: 1.4996e-04 - val_accuracy: 0.0545\n",
            "29/62 [=============>................] - ETA: 0s - loss: 1.6143e-04 - accuracy: 0.0744    Epoch 120/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.7525e-05 - accuracy: 0.0871 - val_loss: 1.2134e-04 - val_accuracy: 0.0909\n",
            "Epoch 119/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.9614e-05 - accuracy: 0.0824 - val_loss: 2.5625e-04 - val_accuracy: 0.0727\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 4.7658e-04 - accuracy: 0.0864Epoch 120/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.8721e-04 - accuracy: 0.0856 - val_loss: 6.2205e-04 - val_accuracy: 0.1273\n",
            "Epoch 119/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9466e-04 - accuracy: 0.0772 - val_loss: 1.7052e-04 - val_accuracy: 0.1455\n",
            "22/62 [=========>....................] - ETA: 0s - loss: 8.3119e-05 - accuracy: 0.1002Epoch 119/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.7466e-05 - accuracy: 0.0970 - val_loss: 1.3968e-04 - val_accuracy: 0.0545\n",
            "Epoch 121/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4432e-04 - accuracy: 0.0793 - val_loss: 2.3933e-04 - val_accuracy: 0.0909\n",
            "Epoch 120/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.7221e-05 - accuracy: 0.0884 - val_loss: 1.7618e-04 - val_accuracy: 0.0727\n",
            "Epoch 121/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.7773e-04 - accuracy: 0.0718 - val_loss: 2.4787e-04 - val_accuracy: 0.1273\n",
            "Epoch 120/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5286e-04 - accuracy: 0.0732 - val_loss: 3.4071e-04 - val_accuracy: 0.1455\n",
            "Epoch 120/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0520e-04 - accuracy: 0.0855 - val_loss: 2.2908e-04 - val_accuracy: 0.0545\n",
            "Epoch 122/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.6735e-05 - accuracy: 0.0834 - val_loss: 1.7086e-04 - val_accuracy: 0.0909\n",
            "Epoch 121/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.1871e-05 - accuracy: 0.0831 - val_loss: 1.5470e-04 - val_accuracy: 0.0727\n",
            "18/62 [=======>......................] - ETA: 0s - loss: 1.3951e-04 - accuracy: 0.0894    Epoch 122/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6448e-04 - accuracy: 0.0830 - val_loss: 1.7921e-04 - val_accuracy: 0.1273\n",
            "Epoch 121/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0175e-04 - accuracy: 0.0740 - val_loss: 2.5759e-04 - val_accuracy: 0.1455\n",
            "Epoch 121/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6416e-04 - accuracy: 0.0907 - val_loss: 2.6536e-04 - val_accuracy: 0.0545\n",
            "Epoch 123/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1090e-04 - accuracy: 0.0775 - val_loss: 1.8202e-04 - val_accuracy: 0.0909\n",
            "Epoch 122/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.0154e-05 - accuracy: 0.0876 - val_loss: 1.2357e-04 - val_accuracy: 0.0727\n",
            "Epoch 123/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0119e-04 - accuracy: 0.0795 - val_loss: 1.6120e-04 - val_accuracy: 0.1273\n",
            "Epoch 122/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4861e-04 - accuracy: 0.0700 - val_loss: 3.2026e-04 - val_accuracy: 0.1455\n",
            "29/62 [=============>................] - ETA: 0s - loss: 7.7595e-05 - accuracy: 0.0883    Epoch 122/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0519e-04 - accuracy: 0.0822 - val_loss: 1.5193e-04 - val_accuracy: 0.0545\n",
            "Epoch 124/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.0462e-05 - accuracy: 0.0875 - val_loss: 1.4109e-04 - val_accuracy: 0.0909\n",
            "Epoch 123/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.7927e-05 - accuracy: 0.0794 - val_loss: 1.5224e-04 - val_accuracy: 0.0727\n",
            "52/62 [========================>.....] - ETA: 0s - loss: 1.5349e-04 - accuracy: 0.0855Epoch 124/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1042e-04 - accuracy: 0.0847 - val_loss: 2.4300e-04 - val_accuracy: 0.1273\n",
            "Epoch 123/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5746e-04 - accuracy: 0.0839 - val_loss: 2.7603e-04 - val_accuracy: 0.1455\n",
            "Epoch 123/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3338e-04 - accuracy: 0.0879 - val_loss: 1.5691e-04 - val_accuracy: 0.0545\n",
            "Epoch 125/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4695e-05 - accuracy: 0.0743 - val_loss: 1.5779e-04 - val_accuracy: 0.0909\n",
            "Epoch 124/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.9170e-05 - accuracy: 0.0895 - val_loss: 1.3042e-04 - val_accuracy: 0.0727\n",
            "Epoch 125/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1006e-04 - accuracy: 0.0711 - val_loss: 1.4581e-04 - val_accuracy: 0.1273\n",
            "Epoch 124/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6399e-04 - accuracy: 0.0787 - val_loss: 1.6681e-04 - val_accuracy: 0.1455\n",
            "Epoch 124/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1683e-04 - accuracy: 0.0889 - val_loss: 1.6521e-04 - val_accuracy: 0.0545\n",
            "Epoch 126/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3681e-04 - accuracy: 0.0895 - val_loss: 2.0130e-04 - val_accuracy: 0.0909\n",
            "Epoch 125/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.6380e-05 - accuracy: 0.0858 - val_loss: 1.4472e-04 - val_accuracy: 0.0727\n",
            "Epoch 126/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.3586e-05 - accuracy: 0.0902 - val_loss: 1.5386e-04 - val_accuracy: 0.1273\n",
            "Epoch 125/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.1030e-05 - accuracy: 0.0867 - val_loss: 1.7830e-04 - val_accuracy: 0.1455\n",
            "Epoch 125/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.1492e-05 - accuracy: 0.0859 - val_loss: 2.1821e-04 - val_accuracy: 0.0545\n",
            "Epoch 127/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.0533e-05 - accuracy: 0.0872 - val_loss: 1.2117e-04 - val_accuracy: 0.0909\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 1.1259e-04 - accuracy: 0.0671Epoch 126/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1610e-04 - accuracy: 0.0696 - val_loss: 1.7665e-04 - val_accuracy: 0.0727\n",
            "53/62 [========================>.....] - ETA: 0s - loss: 1.2327e-04 - accuracy: 0.0918Epoch 127/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.1075e-05 - accuracy: 0.0742 - val_loss: 1.8010e-04 - val_accuracy: 0.1273\n",
            "Epoch 126/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2032e-04 - accuracy: 0.0895 - val_loss: 1.7885e-04 - val_accuracy: 0.1455\n",
            "Epoch 126/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.8088e-05 - accuracy: 0.0949 - val_loss: 3.6472e-04 - val_accuracy: 0.0545\n",
            "Epoch 128/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.4920e-05 - accuracy: 0.0734 - val_loss: 1.0507e-04 - val_accuracy: 0.0909\n",
            "Epoch 127/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2983e-04 - accuracy: 0.0896 - val_loss: 3.6821e-04 - val_accuracy: 0.0727\n",
            "Epoch 128/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.3925e-05 - accuracy: 0.0654 - val_loss: 1.5069e-04 - val_accuracy: 0.1273\n",
            "Epoch 127/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4252e-04 - accuracy: 0.0630 - val_loss: 2.2592e-04 - val_accuracy: 0.1455\n",
            "Epoch 127/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9223e-04 - accuracy: 0.0811 - val_loss: 1.7638e-04 - val_accuracy: 0.0545\n",
            "Epoch 129/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.5800e-05 - accuracy: 0.0889 - val_loss: 1.3752e-04 - val_accuracy: 0.0909\n",
            "Epoch 128/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.9284e-04 - accuracy: 0.0868 - val_loss: 1.8956e-04 - val_accuracy: 0.0727\n",
            "28/62 [============>.................] - ETA: 0s - loss: 1.7401e-04 - accuracy: 0.1158Epoch 129/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.6766e-05 - accuracy: 0.0818 - val_loss: 1.3211e-04 - val_accuracy: 0.1273\n",
            "Epoch 128/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3877e-04 - accuracy: 0.0720 - val_loss: 1.6216e-04 - val_accuracy: 0.1455\n",
            "Epoch 128/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0908e-04 - accuracy: 0.1023 - val_loss: 2.6588e-04 - val_accuracy: 0.0545\n",
            "Epoch 130/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.3023e-05 - accuracy: 0.0767 - val_loss: 1.2339e-04 - val_accuracy: 0.0909\n",
            "Epoch 129/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4872e-04 - accuracy: 0.0870 - val_loss: 2.0149e-04 - val_accuracy: 0.0727\n",
            "Epoch 130/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.6329e-05 - accuracy: 0.0821 - val_loss: 1.5424e-04 - val_accuracy: 0.1273\n",
            "Epoch 129/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.7586e-05 - accuracy: 0.0766 - val_loss: 2.4883e-04 - val_accuracy: 0.1455\n",
            "Epoch 129/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.2494e-04 - accuracy: 0.1240 - val_loss: 2.3670e-04 - val_accuracy: 0.0545\n",
            "Epoch 131/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.3252e-05 - accuracy: 0.0994 - val_loss: 1.6453e-04 - val_accuracy: 0.0909\n",
            "Epoch 130/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0104e-04 - accuracy: 0.1262 - val_loss: 1.1712e-04 - val_accuracy: 0.0727\n",
            "Epoch 131/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.9790e-05 - accuracy: 0.0908 - val_loss: 1.3712e-04 - val_accuracy: 0.1273\n",
            "16/62 [======>.......................] - ETA: 0s - loss: 5.1691e-05 - accuracy: 0.0679Epoch 130/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0462e-04 - accuracy: 0.1034 - val_loss: 2.1287e-04 - val_accuracy: 0.1455\n",
            "Epoch 130/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2918e-04 - accuracy: 0.0789 - val_loss: 2.4221e-04 - val_accuracy: 0.0545\n",
            "Epoch 132/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6887e-04 - accuracy: 0.1268 - val_loss: 1.7200e-04 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.1389e-04 - accuracy: 0.0000e+00Epoch 131/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.1145e-05 - accuracy: 0.0795 - val_loss: 1.2813e-04 - val_accuracy: 0.0727\n",
            "Epoch 132/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.2163e-05 - accuracy: 0.1122 - val_loss: 1.8614e-04 - val_accuracy: 0.1273\n",
            "23/62 [==========>...................] - ETA: 0s - loss: 6.5194e-05 - accuracy: 0.0718    Epoch 131/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2413e-04 - accuracy: 0.1122 - val_loss: 1.7260e-04 - val_accuracy: 0.1455\n",
            "Epoch 131/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0268e-04 - accuracy: 0.0814 - val_loss: 1.4208e-04 - val_accuracy: 0.0545\n",
            "Epoch 133/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4108e-05 - accuracy: 0.0797 - val_loss: 1.9231e-04 - val_accuracy: 0.0909\n",
            "Epoch 132/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.9850e-05 - accuracy: 0.0779 - val_loss: 1.6079e-04 - val_accuracy: 0.0727\n",
            "Epoch 133/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.9256e-05 - accuracy: 0.0751 - val_loss: 1.5117e-04 - val_accuracy: 0.1273\n",
            "Epoch 132/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3941e-04 - accuracy: 0.0645 - val_loss: 3.3974e-04 - val_accuracy: 0.1455\n",
            "Epoch 132/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.1555e-05 - accuracy: 0.1122 - val_loss: 1.4067e-04 - val_accuracy: 0.0545\n",
            "Epoch 134/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.1863e-05 - accuracy: 0.0735 - val_loss: 1.2096e-04 - val_accuracy: 0.0909\n",
            "Epoch 133/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.0034e-05 - accuracy: 0.1015 - val_loss: 1.4708e-04 - val_accuracy: 0.0727\n",
            "Epoch 134/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.7473e-05 - accuracy: 0.0739 - val_loss: 1.4243e-04 - val_accuracy: 0.1273\n",
            "Epoch 133/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4001e-04 - accuracy: 0.0737 - val_loss: 2.4589e-04 - val_accuracy: 0.1455\n",
            "Epoch 133/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.9321e-05 - accuracy: 0.0740 - val_loss: 1.6440e-04 - val_accuracy: 0.0545\n",
            "Epoch 135/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.3868e-05 - accuracy: 0.0999 - val_loss: 1.4304e-04 - val_accuracy: 0.0909\n",
            "Epoch 134/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.3450e-05 - accuracy: 0.0720 - val_loss: 3.1114e-04 - val_accuracy: 0.0727\n",
            "Epoch 135/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.3094e-05 - accuracy: 0.0920 - val_loss: 1.2076e-04 - val_accuracy: 0.1273\n",
            "Epoch 134/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2323e-04 - accuracy: 0.0714 - val_loss: 3.1215e-04 - val_accuracy: 0.1455\n",
            "Epoch 134/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.6046e-05 - accuracy: 0.1067 - val_loss: 1.5119e-04 - val_accuracy: 0.0545\n",
            "Epoch 136/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.6725e-05 - accuracy: 0.0713 - val_loss: 2.1697e-04 - val_accuracy: 0.0909\n",
            "Epoch 135/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5488e-04 - accuracy: 0.0873 - val_loss: 2.4942e-04 - val_accuracy: 0.0727\n",
            "Epoch 136/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.0056e-05 - accuracy: 0.0681 - val_loss: 2.3103e-04 - val_accuracy: 0.1273\n",
            "Epoch 135/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0433e-04 - accuracy: 0.0646 - val_loss: 2.6780e-04 - val_accuracy: 0.1455\n",
            "Epoch 135/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.3444e-05 - accuracy: 0.1074 - val_loss: 1.3882e-04 - val_accuracy: 0.0545\n",
            "28/62 [============>.................] - ETA: 0s - loss: 1.8712e-04 - accuracy: 0.0601    Epoch 137/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5433e-04 - accuracy: 0.0946 - val_loss: 1.4111e-04 - val_accuracy: 0.0909\n",
            "Epoch 136/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4293e-04 - accuracy: 0.0974 - val_loss: 1.3072e-04 - val_accuracy: 0.0727\n",
            "Epoch 137/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.9429e-05 - accuracy: 0.0732 - val_loss: 2.6135e-04 - val_accuracy: 0.1273\n",
            "Epoch 136/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9065e-04 - accuracy: 0.0661 - val_loss: 1.7018e-04 - val_accuracy: 0.1455\n",
            "Epoch 136/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.4543e-05 - accuracy: 0.0829 - val_loss: 1.6229e-04 - val_accuracy: 0.0545\n",
            "Epoch 138/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0700e-04 - accuracy: 0.1049 - val_loss: 1.8103e-04 - val_accuracy: 0.0909\n",
            "Epoch 137/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.8600e-05 - accuracy: 0.0791 - val_loss: 1.3473e-04 - val_accuracy: 0.0727\n",
            "Epoch 138/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.5175e-05 - accuracy: 0.0898 - val_loss: 1.6141e-04 - val_accuracy: 0.1273\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1413e-04 - accuracy: 0.0861 - val_loss: 2.1485e-04 - val_accuracy: 0.1455\n",
            "28/62 [============>.................] - ETA: 0s - loss: 7.6802e-05 - accuracy: 0.0696    Epoch 137/170Epoch 137/170\n",
            "\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.9562e-05 - accuracy: 0.0864 - val_loss: 1.7771e-04 - val_accuracy: 0.0545\n",
            "Epoch 139/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.3970e-05 - accuracy: 0.0768 - val_loss: 1.1460e-04 - val_accuracy: 0.0909\n",
            "Epoch 138/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.2991e-05 - accuracy: 0.0892 - val_loss: 1.7256e-04 - val_accuracy: 0.0727\n",
            "Epoch 139/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.2670e-05 - accuracy: 0.0725 - val_loss: 1.3369e-04 - val_accuracy: 0.1273\n",
            "Epoch 138/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3985e-04 - accuracy: 0.0846 - val_loss: 2.5903e-04 - val_accuracy: 0.1455\n",
            "Epoch 138/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0302e-04 - accuracy: 0.0810 - val_loss: 2.1332e-04 - val_accuracy: 0.0545\n",
            "55/62 [=========================>....] - ETA: 0s - loss: 7.2045e-05 - accuracy: 0.0818Epoch 140/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.3310e-05 - accuracy: 0.0862 - val_loss: 1.6914e-04 - val_accuracy: 0.0909\n",
            "Epoch 139/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4107e-05 - accuracy: 0.0821 - val_loss: 2.7117e-04 - val_accuracy: 0.0727\n",
            "Epoch 140/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.2295e-05 - accuracy: 0.0865 - val_loss: 1.6117e-04 - val_accuracy: 0.1273\n",
            "Epoch 139/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3939e-04 - accuracy: 0.0887 - val_loss: 1.6220e-04 - val_accuracy: 0.1455\n",
            "Epoch 139/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.3884e-05 - accuracy: 0.0858 - val_loss: 1.5003e-04 - val_accuracy: 0.0545\n",
            "Epoch 141/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.3156e-05 - accuracy: 0.0831 - val_loss: 1.5061e-04 - val_accuracy: 0.0909\n",
            "Epoch 140/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7541e-04 - accuracy: 0.0793 - val_loss: 1.3126e-04 - val_accuracy: 0.0727\n",
            "Epoch 141/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.9840e-05 - accuracy: 0.0802 - val_loss: 5.8422e-04 - val_accuracy: 0.1273\n",
            "Epoch 140/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.5601e-05 - accuracy: 0.0670 - val_loss: 1.7617e-04 - val_accuracy: 0.1455\n",
            "Epoch 140/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.3627e-05 - accuracy: 0.0946 - val_loss: 2.0433e-04 - val_accuracy: 0.0545\n",
            "29/62 [=============>................] - ETA: 0s - loss: 1.4250e-04 - accuracy: 0.1020Epoch 142/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.0347e-05 - accuracy: 0.0764 - val_loss: 1.1069e-04 - val_accuracy: 0.0909\n",
            "Epoch 141/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.8501e-05 - accuracy: 0.0922 - val_loss: 1.3736e-04 - val_accuracy: 0.0727\n",
            "Epoch 142/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9829e-04 - accuracy: 0.0823 - val_loss: 1.7369e-04 - val_accuracy: 0.1273\n",
            "Epoch 141/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2104e-04 - accuracy: 0.0895 - val_loss: 1.7176e-04 - val_accuracy: 0.1455\n",
            "Epoch 141/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5311e-04 - accuracy: 0.1022 - val_loss: 2.0051e-04 - val_accuracy: 0.0545\n",
            "Epoch 143/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.3557e-05 - accuracy: 0.0912 - val_loss: 1.9804e-04 - val_accuracy: 0.0909\n",
            "Epoch 142/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.9661e-05 - accuracy: 0.0894 - val_loss: 1.6243e-04 - val_accuracy: 0.0727\n",
            "Epoch 143/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0053e-04 - accuracy: 0.0729 - val_loss: 2.1872e-04 - val_accuracy: 0.1273\n",
            "Epoch 142/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.0353e-05 - accuracy: 0.0658 - val_loss: 2.6587e-04 - val_accuracy: 0.1455\n",
            "Epoch 142/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2871e-04 - accuracy: 0.0700 - val_loss: 1.5527e-04 - val_accuracy: 0.0545\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 1.3438e-04 - accuracy: 0.0984Epoch 144/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7771e-04 - accuracy: 0.0975 - val_loss: 3.6613e-04 - val_accuracy: 0.0909\n",
            "Epoch 143/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.7923e-05 - accuracy: 0.0736 - val_loss: 1.1148e-04 - val_accuracy: 0.0727\n",
            "52/62 [========================>.....] - ETA: 0s - loss: 6.6062e-05 - accuracy: 0.0922Epoch 144/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.5686e-05 - accuracy: 0.0899 - val_loss: 1.2125e-04 - val_accuracy: 0.1273\n",
            "Epoch 143/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6654e-04 - accuracy: 0.0816 - val_loss: 1.5668e-04 - val_accuracy: 0.1455\n",
            "Epoch 143/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.6381e-05 - accuracy: 0.0730 - val_loss: 1.3408e-04 - val_accuracy: 0.0545\n",
            "27/62 [============>.................] - ETA: 0s - loss: 1.1744e-04 - accuracy: 0.0384    \n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4556e-04 - accuracy: 0.0691 - val_loss: 1.4463e-04 - val_accuracy: 0.0909\n",
            "Epoch 144/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.3393e-05 - accuracy: 0.0657 - val_loss: 1.6051e-04 - val_accuracy: 0.0727\n",
            "Epoch 145/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.5991e-05 - accuracy: 0.0656 - val_loss: 1.5835e-04 - val_accuracy: 0.1273\n",
            "28/62 [============>.................] - ETA: 0s - loss: 1.2175e-04 - accuracy: 0.0464    Epoch 144/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1459e-04 - accuracy: 0.0599 - val_loss: 1.7702e-04 - val_accuracy: 0.1455\n",
            "Epoch 144/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.1826e-05 - accuracy: 0.0917 - val_loss: 1.8705e-04 - val_accuracy: 0.0545\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 6.7782e-05 - accuracy: 0.0805Epoch 146/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0510e-04 - accuracy: 0.0660 - val_loss: 1.4006e-04 - val_accuracy: 0.0909\n",
            "Epoch 145/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.7754e-05 - accuracy: 0.0811 - val_loss: 1.7910e-04 - val_accuracy: 0.0727\n",
            "Epoch 146/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.6341e-05 - accuracy: 0.0590 - val_loss: 1.5929e-04 - val_accuracy: 0.1273\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 9.7556e-05 - accuracy: 0.0811    Epoch 145/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.4849e-05 - accuracy: 0.0555 - val_loss: 1.9231e-04 - val_accuracy: 0.1455\n",
            "40/62 [==================>...........] - ETA: 0s - loss: 1.0825e-04 - accuracy: 0.0777Epoch 145/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.7618e-05 - accuracy: 0.0726 - val_loss: 1.2894e-04 - val_accuracy: 0.0545\n",
            "38/62 [=================>............] - ETA: 0s - loss: 5.5333e-05 - accuracy: 0.0730Epoch 147/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1632e-04 - accuracy: 0.0799 - val_loss: 1.5360e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - ETA: 0s - loss: 6.6469e-05 - accuracy: 0.0666Epoch 146/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.6719e-05 - accuracy: 0.0669 - val_loss: 1.8110e-04 - val_accuracy: 0.0727\n",
            "Epoch 147/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.7152e-05 - accuracy: 0.0748 - val_loss: 1.6702e-04 - val_accuracy: 0.1273\n",
            "Epoch 146/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.7622e-05 - accuracy: 0.0732 - val_loss: 1.8841e-04 - val_accuracy: 0.1455\n",
            "Epoch 146/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.8620e-05 - accuracy: 0.0780 - val_loss: 2.3305e-04 - val_accuracy: 0.0545\n",
            "Epoch 148/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0255e-04 - accuracy: 0.0645 - val_loss: 1.3839e-04 - val_accuracy: 0.0909\n",
            "Epoch 147/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.7720e-05 - accuracy: 0.0633 - val_loss: 1.1823e-04 - val_accuracy: 0.0727\n",
            "52/62 [========================>.....] - ETA: 0s - loss: 5.1571e-05 - accuracy: 0.0552Epoch 148/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.2579e-05 - accuracy: 0.0595 - val_loss: 1.1655e-04 - val_accuracy: 0.1273\n",
            "Epoch 147/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1557e-04 - accuracy: 0.0600 - val_loss: 1.6276e-04 - val_accuracy: 0.1455\n",
            "Epoch 147/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5171e-04 - accuracy: 0.0789 - val_loss: 1.6849e-04 - val_accuracy: 0.0545\n",
            "Epoch 149/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.8130e-05 - accuracy: 0.0691 - val_loss: 1.4358e-04 - val_accuracy: 0.0909\n",
            "Epoch 148/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.0906e-05 - accuracy: 0.0810 - val_loss: 1.3860e-04 - val_accuracy: 0.0727\n",
            "44/62 [====================>.........] - ETA: 0s - loss: 1.0076e-04 - accuracy: 0.0624Epoch 149/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.9010e-05 - accuracy: 0.0675 - val_loss: 1.6389e-04 - val_accuracy: 0.1273\n",
            "37/62 [================>.............] - ETA: 0s - loss: 6.2930e-05 - accuracy: 0.0699Epoch 148/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.9610e-05 - accuracy: 0.0665 - val_loss: 1.3734e-04 - val_accuracy: 0.1455\n",
            "Epoch 148/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2926e-04 - accuracy: 0.1093 - val_loss: 3.3599e-04 - val_accuracy: 0.0545\n",
            "Epoch 150/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.3391e-05 - accuracy: 0.0742 - val_loss: 2.4249e-04 - val_accuracy: 0.0909\n",
            "Epoch 149/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0137e-04 - accuracy: 0.1010 - val_loss: 2.7713e-04 - val_accuracy: 0.0727\n",
            "Epoch 150/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.1292e-05 - accuracy: 0.0763 - val_loss: 1.7597e-04 - val_accuracy: 0.1273\n",
            "Epoch 149/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.8898e-05 - accuracy: 0.0717 - val_loss: 1.3305e-04 - val_accuracy: 0.1455\n",
            "Epoch 149/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1556e-04 - accuracy: 0.0720 - val_loss: 1.2952e-04 - val_accuracy: 0.0545\n",
            "52/62 [========================>.....] - ETA: 0s - loss: 8.8738e-05 - accuracy: 0.1124Epoch 151/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.8507e-05 - accuracy: 0.1074 - val_loss: 1.6795e-04 - val_accuracy: 0.0909\n",
            "Epoch 150/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1409e-04 - accuracy: 0.0825 - val_loss: 4.2249e-04 - val_accuracy: 0.0727\n",
            "Epoch 151/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.5477e-05 - accuracy: 0.0903 - val_loss: 1.5607e-04 - val_accuracy: 0.1455\n",
            "Epoch 150/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.8335e-05 - accuracy: 0.0861 - val_loss: 1.2302e-04 - val_accuracy: 0.1273 loss: 4.2996e-04 - accuracy: 0.0627  \n",
            "Epoch 150/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1267e-04 - accuracy: 0.0701 - val_loss: 1.2914e-04 - val_accuracy: 0.0545\n",
            "Epoch 152/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.4594e-05 - accuracy: 0.0726 - val_loss: 1.1662e-04 - val_accuracy: 0.0909\n",
            "39/62 [=================>............] - ETA: 0s - loss: 6.3580e-05 - accuracy: 0.0848Epoch 151/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.4575e-04 - accuracy: 0.0663 - val_loss: 2.2257e-04 - val_accuracy: 0.0727\n",
            "Epoch 152/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.3609e-05 - accuracy: 0.0821 - val_loss: 2.1520e-04 - val_accuracy: 0.1273\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.6651e-05 - accuracy: 0.0828 - val_loss: 1.8627e-04 - val_accuracy: 0.1455\n",
            "Epoch 151/170Epoch 151/170\n",
            "\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.1786e-05 - accuracy: 0.0732 - val_loss: 1.4403e-04 - val_accuracy: 0.0545\n",
            "Epoch 153/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.0287e-05 - accuracy: 0.0615 - val_loss: 1.5735e-04 - val_accuracy: 0.0909\n",
            "Epoch 152/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.9219e-04 - accuracy: 0.0739 - val_loss: 2.3459e-04 - val_accuracy: 0.0727\n",
            "Epoch 153/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.1353e-05 - accuracy: 0.0548 - val_loss: 1.6460e-04 - val_accuracy: 0.1273\n",
            "Epoch 152/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.7291e-05 - accuracy: 0.0570 - val_loss: 1.5188e-04 - val_accuracy: 0.1455\n",
            "Epoch 152/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.3032e-05 - accuracy: 0.1055 - val_loss: 1.6418e-04 - val_accuracy: 0.0545\n",
            "Epoch 154/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.9993e-05 - accuracy: 0.0733 - val_loss: 1.1920e-04 - val_accuracy: 0.0909\n",
            "Epoch 153/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.8408e-05 - accuracy: 0.1046 - val_loss: 1.6304e-04 - val_accuracy: 0.0727\n",
            "Epoch 154/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.1296e-05 - accuracy: 0.0675 - val_loss: 2.1190e-04 - val_accuracy: 0.1273\n",
            "Epoch 153/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4218e-05 - accuracy: 0.0549 - val_loss: 2.1144e-04 - val_accuracy: 0.1455\n",
            "Epoch 153/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.8220e-05 - accuracy: 0.0774 - val_loss: 1.3049e-04 - val_accuracy: 0.0545\n",
            "Epoch 155/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.1613e-05 - accuracy: 0.1018 - val_loss: 8.8469e-05 - val_accuracy: 0.0909\n",
            "Epoch 154/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.0255e-05 - accuracy: 0.0739 - val_loss: 1.4267e-04 - val_accuracy: 0.0727\n",
            "Epoch 155/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.8394e-05 - accuracy: 0.1027 - val_loss: 1.7599e-04 - val_accuracy: 0.1273\n",
            "Epoch 154/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1505e-04 - accuracy: 0.1086 - val_loss: 1.8100e-04 - val_accuracy: 0.1455\n",
            "Epoch 154/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.1755e-05 - accuracy: 0.0888 - val_loss: 1.3945e-04 - val_accuracy: 0.0545\n",
            "Epoch 156/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.0507e-05 - accuracy: 0.0742 - val_loss: 1.3169e-04 - val_accuracy: 0.0909\n",
            "Epoch 155/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.6053e-05 - accuracy: 0.0922 - val_loss: 1.2294e-04 - val_accuracy: 0.0727\n",
            "Epoch 156/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.6918e-05 - accuracy: 0.0684 - val_loss: 1.8300e-04 - val_accuracy: 0.1273\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 5.8630e-05 - accuracy: 0.0715Epoch 155/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.9814e-05 - accuracy: 0.0714 - val_loss: 2.4853e-04 - val_accuracy: 0.1455\n",
            "Epoch 155/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.1787e-05 - accuracy: 0.0725 - val_loss: 1.2732e-04 - val_accuracy: 0.0545\n",
            "Epoch 157/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4224e-05 - accuracy: 0.0899 - val_loss: 2.0512e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.8571e-05 - accuracy: 0.0752 - val_loss: 1.5144e-04 - val_accuracy: 0.0727\n",
            "Epoch 156/170\n",
            "Epoch 157/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1501e-04 - accuracy: 0.0787 - val_loss: 1.1109e-04 - val_accuracy: 0.1273\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 2.7469e-04 - accuracy: 0.0715Epoch 156/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.8674e-05 - accuracy: 0.0717 - val_loss: 1.9327e-04 - val_accuracy: 0.1455\n",
            " 1/62 [..............................] - ETA: 0s - loss: 4.3663e-05 - accuracy: 0.1250Epoch 156/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.2372e-05 - accuracy: 0.1088 - val_loss: 1.4413e-04 - val_accuracy: 0.0545\n",
            "Epoch 158/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.2965e-05 - accuracy: 0.1002 - val_loss: 1.1872e-04 - val_accuracy: 0.0727\n",
            "Epoch 158/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5796e-04 - accuracy: 0.0723 - val_loss: 1.9067e-04 - val_accuracy: 0.0909\n",
            "Epoch 157/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.4890e-05 - accuracy: 0.0653 - val_loss: 1.1044e-04 - val_accuracy: 0.1273\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.5688e-05 - accuracy: 0.0638 - val_loss: 1.9785e-04 - val_accuracy: 0.1455\n",
            "29/62 [=============>................] - ETA: 0s - loss: 3.9871e-05 - accuracy: 0.0832    Epoch 157/170\n",
            "Epoch 157/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.6509e-05 - accuracy: 0.0820 - val_loss: 7.9239e-04 - val_accuracy: 0.0545\n",
            "Epoch 159/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.3302e-05 - accuracy: 0.0866 - val_loss: 1.3075e-04 - val_accuracy: 0.0727\n",
            "Epoch 159/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.7724e-05 - accuracy: 0.1009 - val_loss: 1.3329e-04 - val_accuracy: 0.0909\n",
            "Epoch 158/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.7455e-05 - accuracy: 0.0640 - val_loss: 1.6026e-04 - val_accuracy: 0.1455\n",
            "45/62 [====================>.........] - ETA: 0s - loss: 4.3769e-04 - accuracy: 0.0609Epoch 158/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.0910e-05 - accuracy: 0.0913 - val_loss: 1.5364e-04 - val_accuracy: 0.1273\n",
            "Epoch 158/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.9248e-04 - accuracy: 0.0680 - val_loss: 1.5807e-04 - val_accuracy: 0.0545\n",
            "Epoch 160/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.1991e-05 - accuracy: 0.0740 - val_loss: 1.6992e-04 - val_accuracy: 0.0727\n",
            "Epoch 160/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.9221e-05 - accuracy: 0.0776 - val_loss: 1.1906e-04 - val_accuracy: 0.0909\n",
            "Epoch 159/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.9200e-05 - accuracy: 0.0760 - val_loss: 1.4867e-04 - val_accuracy: 0.1455\n",
            "Epoch 159/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.9674e-05 - accuracy: 0.0798 - val_loss: 2.2035e-04 - val_accuracy: 0.1273\n",
            "Epoch 159/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3311e-04 - accuracy: 0.0899 - val_loss: 1.4011e-04 - val_accuracy: 0.0545\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 7.8510e-05 - accuracy: 0.0957Epoch 161/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.7324e-05 - accuracy: 0.0940 - val_loss: 1.4959e-04 - val_accuracy: 0.0727\n",
            "Epoch 161/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.2063e-05 - accuracy: 0.0714 - val_loss: 1.1828e-04 - val_accuracy: 0.0909\n",
            "Epoch 160/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0589e-04 - accuracy: 0.0663 - val_loss: 1.5471e-04 - val_accuracy: 0.1455\n",
            "Epoch 160/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.4798e-05 - accuracy: 0.0703 - val_loss: 1.5616e-04 - val_accuracy: 0.1273\n",
            "Epoch 160/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.6987e-05 - accuracy: 0.0898 - val_loss: 2.0571e-04 - val_accuracy: 0.0545\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 7.1853e-05 - accuracy: 0.0890Epoch 162/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.9305e-05 - accuracy: 0.0885 - val_loss: 1.1255e-04 - val_accuracy: 0.0727\n",
            "Epoch 162/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.0595e-05 - accuracy: 0.0906 - val_loss: 1.8061e-04 - val_accuracy: 0.0909\n",
            "Epoch 161/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6386e-04 - accuracy: 0.0833 - val_loss: 3.9105e-04 - val_accuracy: 0.1455\n",
            "Epoch 161/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.5423e-05 - accuracy: 0.0868 - val_loss: 2.0167e-04 - val_accuracy: 0.1273\n",
            "Epoch 161/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0827e-04 - accuracy: 0.0980 - val_loss: 1.2244e-04 - val_accuracy: 0.0545\n",
            "Epoch 163/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.8803e-05 - accuracy: 0.0981 - val_loss: 2.2104e-04 - val_accuracy: 0.0727\n",
            "Epoch 163/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.7545e-05 - accuracy: 0.0815 - val_loss: 1.0073e-04 - val_accuracy: 0.0909\n",
            "25/62 [===========>..................] - ETA: 0s - loss: 1.4938e-04 - accuracy: 0.1097Epoch 162/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.8144e-04 - accuracy: 0.0897 - val_loss: 2.3846e-04 - val_accuracy: 0.1455\n",
            "Epoch 162/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.2468e-05 - accuracy: 0.0856 - val_loss: 1.7099e-04 - val_accuracy: 0.1273\n",
            "25/62 [===========>..................] - ETA: 0s - loss: 6.4642e-05 - accuracy: 0.1209Epoch 162/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4196e-04 - accuracy: 0.1023 - val_loss: 1.5355e-04 - val_accuracy: 0.0545\n",
            "47/62 [=====================>........] - ETA: 0s - loss: 2.4970e-04 - accuracy: 0.0989Epoch 164/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.4893e-05 - accuracy: 0.1012 - val_loss: 1.5243e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2883e-04 - accuracy: 0.0952 - val_loss: 1.6466e-04 - val_accuracy: 0.0727\n",
            "Epoch 164/170\n",
            "Epoch 163/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1064e-04 - accuracy: 0.0864 - val_loss: 1.6000e-04 - val_accuracy: 0.1455\n",
            "Epoch 163/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.0369e-05 - accuracy: 0.0835 - val_loss: 1.3295e-04 - val_accuracy: 0.1273\n",
            "Epoch 163/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.6134e-05 - accuracy: 0.1051 - val_loss: 1.5471e-04 - val_accuracy: 0.0545\n",
            "Epoch 165/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.5322e-05 - accuracy: 0.1163 - val_loss: 1.2498e-04 - val_accuracy: 0.0727\n",
            "Epoch 165/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7256e-04 - accuracy: 0.0934 - val_loss: 2.0930e-04 - val_accuracy: 0.0909\n",
            "Epoch 164/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.0539e-05 - accuracy: 0.0655 - val_loss: 1.4763e-04 - val_accuracy: 0.1455\n",
            "Epoch 164/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.4794e-05 - accuracy: 0.0797 - val_loss: 2.3902e-04 - val_accuracy: 0.1273\n",
            "Epoch 164/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.2275e-05 - accuracy: 0.0837 - val_loss: 2.3520e-04 - val_accuracy: 0.0545\n",
            "Epoch 166/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.4377e-05 - accuracy: 0.0946 - val_loss: 1.5243e-04 - val_accuracy: 0.0727\n",
            "53/62 [========================>.....] - ETA: 0s - loss: 7.5308e-05 - accuracy: 0.1057Epoch 166/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2905e-04 - accuracy: 0.1099 - val_loss: 1.4666e-04 - val_accuracy: 0.0909\n",
            "Epoch 165/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.5541e-05 - accuracy: 0.1015 - val_loss: 1.7967e-04 - val_accuracy: 0.1455\n",
            "Epoch 165/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.7543e-05 - accuracy: 0.1112 - val_loss: 1.1555e-04 - val_accuracy: 0.1273\n",
            "Epoch 165/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0473e-04 - accuracy: 0.0924 - val_loss: 1.2024e-04 - val_accuracy: 0.0545\n",
            "Epoch 167/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.7683e-05 - accuracy: 0.0889 - val_loss: 1.2462e-04 - val_accuracy: 0.0727\n",
            "Epoch 167/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.3346e-05 - accuracy: 0.0794 - val_loss: 1.4325e-04 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.6208e-05 - accuracy: 0.0000e+00Epoch 166/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.4310e-05 - accuracy: 0.0845 - val_loss: 1.8293e-04 - val_accuracy: 0.1455\n",
            "Epoch 166/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4604e-05 - accuracy: 0.0858 - val_loss: 2.6318e-04 - val_accuracy: 0.1273\n",
            "Epoch 166/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.4589e-05 - accuracy: 0.0692 - val_loss: 1.4779e-04 - val_accuracy: 0.0545\n",
            "Epoch 168/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.4431e-05 - accuracy: 0.0699 - val_loss: 1.7233e-04 - val_accuracy: 0.0727\n",
            "Epoch 168/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.5792e-05 - accuracy: 0.0928 - val_loss: 1.0115e-04 - val_accuracy: 0.0909\n",
            "Epoch 167/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.5536e-05 - accuracy: 0.0674 - val_loss: 1.5040e-04 - val_accuracy: 0.1455\n",
            "Epoch 167/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.2493e-05 - accuracy: 0.0752 - val_loss: 1.3169e-04 - val_accuracy: 0.1273\n",
            "Epoch 167/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.4737e-05 - accuracy: 0.0795 - val_loss: 8.8309e-05 - val_accuracy: 0.0545\n",
            "Epoch 169/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3072e-04 - accuracy: 0.0715 - val_loss: 1.3268e-04 - val_accuracy: 0.0727\n",
            "48/62 [======================>.......] - ETA: 0s - loss: 6.5876e-05 - accuracy: 0.0582Epoch 169/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.4544e-05 - accuracy: 0.0708 - val_loss: 1.2436e-04 - val_accuracy: 0.0909\n",
            "Epoch 168/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4728e-05 - accuracy: 0.0617 - val_loss: 1.3521e-04 - val_accuracy: 0.1455\n",
            "Epoch 168/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.6426e-05 - accuracy: 0.0623 - val_loss: 1.4463e-04 - val_accuracy: 0.1273\n",
            "Epoch 168/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.4537e-05 - accuracy: 0.1024 - val_loss: 1.0363e-04 - val_accuracy: 0.0545\n",
            "Epoch 170/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.1903e-05 - accuracy: 0.0952 - val_loss: 9.0141e-05 - val_accuracy: 0.0727\n",
            "Epoch 170/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.9115e-05 - accuracy: 0.0690 - val_loss: 1.0813e-04 - val_accuracy: 0.0909\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 4.7824e-05 - accuracy: 0.0746Epoch 169/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.2889e-05 - accuracy: 0.0696 - val_loss: 1.7752e-04 - val_accuracy: 0.1455\n",
            "Epoch 169/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.7899e-05 - accuracy: 0.0751 - val_loss: 1.1214e-04 - val_accuracy: 0.1273\n",
            "Epoch 169/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.3483e-05 - accuracy: 0.0961 - val_loss: 1.2339e-04 - val_accuracy: 0.0545\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 1.2339e-04 - accuracy: 0.0545\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.4109e-05 - accuracy: 0.0977 - val_loss: 9.7422e-05 - val_accuracy: 0.0727\n",
            "Epoch 1/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.7696e-05 - accuracy: 0.0962 - val_loss: 1.3271e-04 - val_accuracy: 0.0909\n",
            "Epoch 170/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.3881e-05 - accuracy: 0.0935 - val_loss: 1.8234e-04 - val_accuracy: 0.1455\n",
            "Epoch 170/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.1654e-05 - accuracy: 0.0929 - val_loss: 5.6246e-04 - val_accuracy: 0.1273\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.7289e-05 - accuracy: 0.0938Epoch 170/170\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7422e-05 - accuracy: 0.0727\n",
            "34/62 [===============>..............] - ETA: 0s - loss: 7.9329e-05 - accuracy: 0.0999Epoch 1/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.2650e-05 - accuracy: 0.0905 - val_loss: 1.6538e-04 - val_accuracy: 0.1455\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.8235e-05 - accuracy: 0.0895 - val_loss: 1.0920e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.0436e-04 - accuracy: 0.0960 - val_loss: 4.8888e-04 - val_accuracy: 0.1273\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.6538e-04 - accuracy: 0.1455\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0920e-04 - accuracy: 0.0909\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.8888e-04 - accuracy: 0.1273\n",
            "Epoch 1/170\n",
            "Epoch 1/170\n",
            "Epoch 1/170\n",
            "62/62 [==============================] - 1s 5ms/step - loss: 0.0513 - accuracy: 0.0909 - val_loss: 0.0087 - val_accuracy: 0.0909\n",
            "Epoch 2/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.0733 - val_loss: 0.0054 - val_accuracy: 0.0909\n",
            "Epoch 3/170\n",
            "38/62 [=================>............] - ETA: 0s - loss: 0.0038 - accuracy: 0.0913WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8d2c036b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "62/62 [==============================] - 1s 4ms/step - loss: 0.0520 - accuracy: 0.0940 - val_loss: 0.0107 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 1s 4ms/step - loss: 0.0496 - accuracy: 0.1026 - val_loss: 0.0070 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 1s 4ms/step - loss: 0.0515 - accuracy: 0.0772 - val_loss: 0.0059 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 1s 4ms/step - loss: 0.0476 - accuracy: 0.0897 - val_loss: 0.0039 - val_accuracy: 0.0364\n",
            "Epoch 2/170\n",
            "Epoch 2/170Epoch 2/170\n",
            "\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0062 - accuracy: 0.0000e+00Epoch 2/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.0907 - val_loss: 0.0046 - val_accuracy: 0.0909\n",
            "Epoch 4/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0755 - val_loss: 0.0064 - val_accuracy: 0.1481\n",
            "Epoch 3/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.0825 - val_loss: 0.0027 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0020 - accuracy: 0.0000e+00Epoch 3/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0857 - val_loss: 0.0041 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.0801 - val_loss: 0.0026 - val_accuracy: 0.0364\n",
            "\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0030 - accuracy: 0.0000e+00Epoch 3/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.0728 - val_loss: 0.0040 - val_accuracy: 0.0909\n",
            "Epoch 5/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.0697 - val_loss: 0.0048 - val_accuracy: 0.1481\n",
            "Epoch 4/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.0805 - val_loss: 0.0020 - val_accuracy: 0.0370\n",
            "Epoch 4/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.0880 - val_loss: 0.0032 - val_accuracy: 0.0370\n",
            "Epoch 4/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.0993 - val_loss: 0.0024 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.0711 - val_loss: 0.0036 - val_accuracy: 0.0909\n",
            "Epoch 4/170\n",
            "Epoch 6/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.0571 - val_loss: 0.0040 - val_accuracy: 0.1481\n",
            "Epoch 5/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.0684 - val_loss: 0.0019 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0046 - accuracy: 0.0000e+00Epoch 5/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.0725 - val_loss: 0.0026 - val_accuracy: 0.0370\n",
            "Epoch 5/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.0827 - val_loss: 0.0029 - val_accuracy: 0.0364\n",
            "Epoch 5/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.0886 - val_loss: 0.0029 - val_accuracy: 0.0909\n",
            "Epoch 7/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.0579 - val_loss: 0.0032 - val_accuracy: 0.1481\n",
            "Epoch 6/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.0683 - val_loss: 0.0019 - val_accuracy: 0.0370\n",
            "Epoch 6/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.0772 - val_loss: 0.0024 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.0830 - val_loss: 0.0020 - val_accuracy: 0.0364\n",
            "Epoch 6/170\n",
            "Epoch 6/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.0850 - val_loss: 0.0036 - val_accuracy: 0.0909\n",
            "Epoch 8/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.0796 - val_loss: 0.0028 - val_accuracy: 0.1481\n",
            "Epoch 7/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.0816 - val_loss: 0.0018 - val_accuracy: 0.0370\n",
            "Epoch 7/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.0971 - val_loss: 0.0017 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.0884 - val_loss: 0.0025 - val_accuracy: 0.0370\n",
            "Epoch 7/170\n",
            "Epoch 7/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.0637 - val_loss: 0.0027 - val_accuracy: 0.0909\n",
            "Epoch 9/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.0578 - val_loss: 0.0025 - val_accuracy: 0.1481\n",
            "Epoch 8/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.0659 - val_loss: 0.0016 - val_accuracy: 0.0370\n",
            "Epoch 8/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.0803 - val_loss: 0.0023 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.0924 - val_loss: 0.0017 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0011 - accuracy: 0.0000e+00Epoch 8/170\n",
            "Epoch 8/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.0931 - val_loss: 0.0040 - val_accuracy: 0.0909\n",
            "Epoch 10/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.0663 - val_loss: 0.0024 - val_accuracy: 0.1481\n",
            "Epoch 9/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.0886 - val_loss: 0.0015 - val_accuracy: 0.0370\n",
            "Epoch 9/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.0751 - val_loss: 0.0015 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0014 - accuracy: 0.0000e+00Epoch 9/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.0763 - val_loss: 0.0026 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.0821 - val_loss: 0.0023 - val_accuracy: 0.0909\n",
            "\n",
            "Epoch 11/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0621 - val_loss: 0.0019 - val_accuracy: 0.1481\n",
            "Epoch 10/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.0725 - val_loss: 0.0014 - val_accuracy: 0.0370\n",
            "Epoch 10/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.0931 - val_loss: 0.0031 - val_accuracy: 0.0364\n",
            "Epoch 10/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.0796 - val_loss: 0.0020 - val_accuracy: 0.0370\n",
            "Epoch 10/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.0846 - val_loss: 0.0017 - val_accuracy: 0.0909\n",
            "Epoch 12/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.0928 - val_loss: 0.0019 - val_accuracy: 0.1481\n",
            "Epoch 11/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.1065 - val_loss: 0.0011 - val_accuracy: 0.0370\n",
            "Epoch 11/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.0911 - val_loss: 0.0023 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0026 - accuracy: 0.1250Epoch 11/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.1056 - val_loss: 0.0021 - val_accuracy: 0.0370\n",
            "Epoch 11/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.0941 - val_loss: 0.0016 - val_accuracy: 0.0909\n",
            "Epoch 13/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0907 - val_loss: 0.0016 - val_accuracy: 0.1481\n",
            "Epoch 12/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.1046 - val_loss: 0.0013 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 0.0012 - accuracy: 0.1250Epoch 12/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.1050 - val_loss: 0.0016 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.0932 - val_loss: 0.0016 - val_accuracy: 0.0364\n",
            "Epoch 12/170\n",
            "Epoch 12/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0831 - val_loss: 0.0013 - val_accuracy: 0.0909\n",
            "Epoch 14/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.0849 - val_loss: 0.0016 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.1028 - val_loss: 0.0012 - val_accuracy: 0.0370\n",
            "Epoch 13/170\n",
            "Epoch 13/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.1034 - val_loss: 0.0016 - val_accuracy: 0.0364\n",
            "Epoch 13/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.0928 - val_loss: 0.0018 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 9.4894e-04 - accuracy: 0.1250Epoch 13/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.0749 - val_loss: 0.0011 - val_accuracy: 0.0909\n",
            "Epoch 15/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.0647 - val_loss: 0.0013 - val_accuracy: 0.0370\n",
            "Epoch 14/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.0649 - val_loss: 0.0020 - val_accuracy: 0.1481\n",
            "Epoch 14/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.0957 - val_loss: 0.0014 - val_accuracy: 0.0364\n",
            "Epoch 14/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.0743 - val_loss: 0.0020 - val_accuracy: 0.0370\n",
            "Epoch 14/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.0771 - val_loss: 0.0014 - val_accuracy: 0.0909\n",
            "Epoch 16/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.0910 - val_loss: 0.0011 - val_accuracy: 0.0370\n",
            "52/62 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 0.0795Epoch 15/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.0749 - val_loss: 0.0013 - val_accuracy: 0.1481\n",
            "Epoch 15/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.0748 - val_loss: 0.0011 - val_accuracy: 0.0364\n",
            "Epoch 15/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.0798 - val_loss: 0.0014 - val_accuracy: 0.0370\n",
            "Epoch 15/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.0803 - val_loss: 0.0011 - val_accuracy: 0.0909\n",
            "Epoch 17/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.1064 - val_loss: 9.3213e-04 - val_accuracy: 0.0370\n",
            "Epoch 16/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0895 - val_loss: 0.0014 - val_accuracy: 0.1481\n",
            "Epoch 16/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0786 - val_loss: 0.0014 - val_accuracy: 0.0364\n",
            "Epoch 16/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.1056 - val_loss: 0.0013 - val_accuracy: 0.0370\n",
            "Epoch 16/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0571 - val_loss: 0.0011 - val_accuracy: 0.0909\n",
            "Epoch 18/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.8914e-04 - accuracy: 0.0855 - val_loss: 0.0010 - val_accuracy: 0.0370\n",
            "Epoch 17/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.0625 - val_loss: 0.0015 - val_accuracy: 0.1481\n",
            "Epoch 17/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.6315e-04 - accuracy: 0.0839 - val_loss: 9.3346e-04 - val_accuracy: 0.0364\n",
            "Epoch 17/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.5034e-04 - accuracy: 0.0690 - val_loss: 0.0013 - val_accuracy: 0.0370\n",
            "Epoch 17/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.0856 - val_loss: 0.0011 - val_accuracy: 0.0909\n",
            "Epoch 19/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.9459e-04 - accuracy: 0.0897 - val_loss: 6.7034e-04 - val_accuracy: 0.0370\n",
            "Epoch 18/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.0734 - val_loss: 0.0014 - val_accuracy: 0.1481\n",
            "Epoch 18/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.6432e-04 - accuracy: 0.0613 - val_loss: 0.0012 - val_accuracy: 0.0364\n",
            "Epoch 18/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.0892 - val_loss: 0.0012 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 4.8148e-04 - accuracy: 0.1250Epoch 18/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.0849 - val_loss: 9.9545e-04 - val_accuracy: 0.0909\n",
            "Epoch 20/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.0833 - val_loss: 7.4266e-04 - val_accuracy: 0.0370\n",
            "Epoch 19/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0763 - val_loss: 0.0010 - val_accuracy: 0.1481\n",
            "Epoch 19/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.8299e-04 - accuracy: 0.0827 - val_loss: 0.0014 - val_accuracy: 0.0370\n",
            "Epoch 19/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.6294e-04 - accuracy: 0.0951 - val_loss: 6.5483e-04 - val_accuracy: 0.0364\n",
            "Epoch 19/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.3098e-04 - accuracy: 0.1093 - val_loss: 7.7995e-04 - val_accuracy: 0.0909\n",
            "Epoch 21/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.6867e-04 - accuracy: 0.0625 - val_loss: 5.4285e-04 - val_accuracy: 0.0370\n",
            "Epoch 20/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.8991e-04 - accuracy: 0.0578 - val_loss: 0.0011 - val_accuracy: 0.1481\n",
            "Epoch 20/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.9536e-04 - accuracy: 0.0698 - val_loss: 0.0011 - val_accuracy: 0.0370\n",
            "Epoch 20/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.8795e-04 - accuracy: 0.0905 - val_loss: 8.1186e-04 - val_accuracy: 0.0364\n",
            "Epoch 20/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.0785 - val_loss: 9.7681e-04 - val_accuracy: 0.0909\n",
            "27/62 [============>.................] - ETA: 0s - loss: 9.1948e-04 - accuracy: 0.0906\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.0595e-04 - accuracy: 0.0892 - val_loss: 6.3790e-04 - val_accuracy: 0.0370\n",
            "Epoch 21/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.0680 - val_loss: 0.0012 - val_accuracy: 0.1481\n",
            "50/62 [=======================>......] - ETA: 0s - loss: 8.8221e-04 - accuracy: 0.0734Epoch 21/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.6538e-04 - accuracy: 0.0820 - val_loss: 0.0011 - val_accuracy: 0.0370\n",
            "Epoch 21/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.9901e-04 - accuracy: 0.1202 - val_loss: 7.9782e-04 - val_accuracy: 0.0364\n",
            "Epoch 21/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.7464e-04 - accuracy: 0.0752 - val_loss: 6.3654e-04 - val_accuracy: 0.0909\n",
            "Epoch 23/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.5050e-04 - accuracy: 0.0993 - val_loss: 6.4656e-04 - val_accuracy: 0.0370\n",
            "Epoch 22/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.3284e-04 - accuracy: 0.0792 - val_loss: 8.9376e-04 - val_accuracy: 0.1481\n",
            "Epoch 22/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.8229e-04 - accuracy: 0.0891 - val_loss: 0.0020 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 3.7442e-04 - accuracy: 0.2500Epoch 22/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4348e-04 - accuracy: 0.0822 - val_loss: 5.0241e-04 - val_accuracy: 0.0364\n",
            "Epoch 22/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.0238e-04 - accuracy: 0.0998 - val_loss: 4.8171e-04 - val_accuracy: 0.0909\n",
            "Epoch 24/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.0748e-04 - accuracy: 0.0869 - val_loss: 6.9041e-04 - val_accuracy: 0.0370\n",
            "Epoch 23/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.4675e-04 - accuracy: 0.0787 - val_loss: 9.8888e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.2128e-04 - accuracy: 0.0927 - val_loss: 9.9467e-04 - val_accuracy: 0.0370\n",
            "Epoch 23/170Epoch 23/170\n",
            "\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.1819e-04 - accuracy: 0.0793 - val_loss: 5.5284e-04 - val_accuracy: 0.0364\n",
            "Epoch 23/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.3282e-04 - accuracy: 0.0817 - val_loss: 7.1139e-04 - val_accuracy: 0.0909\n",
            "Epoch 25/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.5217e-04 - accuracy: 0.0909 - val_loss: 3.5089e-04 - val_accuracy: 0.0370\n",
            "Epoch 24/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.3179e-04 - accuracy: 0.0830 - val_loss: 7.8705e-04 - val_accuracy: 0.1481\n",
            "Epoch 24/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.5691e-04 - accuracy: 0.0979 - val_loss: 8.5099e-04 - val_accuracy: 0.0370\n",
            "Epoch 24/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.3784e-04 - accuracy: 0.1025 - val_loss: 5.9749e-04 - val_accuracy: 0.0364\n",
            "Epoch 24/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.0747e-04 - accuracy: 0.0964 - val_loss: 6.9368e-04 - val_accuracy: 0.0909\n",
            "Epoch 26/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.6284e-04 - accuracy: 0.0861 - val_loss: 4.7052e-04 - val_accuracy: 0.0370\n",
            "Epoch 25/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.1981e-04 - accuracy: 0.0810 - val_loss: 7.2181e-04 - val_accuracy: 0.1481\n",
            "Epoch 25/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.6316e-04 - accuracy: 0.0961 - val_loss: 7.0926e-04 - val_accuracy: 0.0370\n",
            "Epoch 25/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.1225e-04 - accuracy: 0.0823 - val_loss: 6.9959e-04 - val_accuracy: 0.0364\n",
            "Epoch 25/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.3455e-04 - accuracy: 0.0726 - val_loss: 4.7335e-04 - val_accuracy: 0.0909\n",
            "29/62 [=============>................] - ETA: 0s - loss: 6.9030e-04 - accuracy: 0.0567    Epoch 27/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.7292e-04 - accuracy: 0.0739 - val_loss: 6.1241e-04 - val_accuracy: 0.0370\n",
            "Epoch 26/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.7324e-04 - accuracy: 0.0662 - val_loss: 8.6213e-04 - val_accuracy: 0.1481\n",
            "Epoch 26/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.7518e-04 - accuracy: 0.0749 - val_loss: 9.2444e-04 - val_accuracy: 0.0370\n",
            "Epoch 26/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.1111e-04 - accuracy: 0.1014 - val_loss: 7.1893e-04 - val_accuracy: 0.0364\n",
            "Epoch 26/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.9665e-04 - accuracy: 0.0928 - val_loss: 4.2465e-04 - val_accuracy: 0.0909\n",
            "Epoch 28/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.5510e-04 - accuracy: 0.0784 - val_loss: 3.5416e-04 - val_accuracy: 0.0370\n",
            "Epoch 27/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.8593e-04 - accuracy: 0.0899 - val_loss: 8.5399e-04 - val_accuracy: 0.0370\n",
            "Epoch 27/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.9948e-04 - accuracy: 0.0733 - val_loss: 8.1306e-04 - val_accuracy: 0.1481\n",
            "Epoch 27/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.8942e-04 - accuracy: 0.0753 - val_loss: 5.0194e-04 - val_accuracy: 0.0364\n",
            "Epoch 27/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.8957e-04 - accuracy: 0.0910 - val_loss: 5.5996e-04 - val_accuracy: 0.0909\n",
            "Epoch 29/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.6504e-04 - accuracy: 0.0964 - val_loss: 3.5400e-04 - val_accuracy: 0.0370\n",
            "Epoch 28/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.6764e-04 - accuracy: 0.0888 - val_loss: 5.6767e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.1631e-04 - accuracy: 0.0767 - val_loss: 6.1824e-04 - val_accuracy: 0.1481\n",
            "Epoch 28/170\n",
            "Epoch 28/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.3726e-04 - accuracy: 0.0956 - val_loss: 4.9555e-04 - val_accuracy: 0.0364\n",
            "Epoch 28/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.1887e-04 - accuracy: 0.0546 - val_loss: 6.0862e-04 - val_accuracy: 0.0909\n",
            "Epoch 30/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.7754e-04 - accuracy: 0.0931 - val_loss: 5.1837e-04 - val_accuracy: 0.0370\n",
            "Epoch 29/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.8380e-04 - accuracy: 0.0862 - val_loss: 9.6672e-04 - val_accuracy: 0.1481\n",
            "Epoch 29/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.9095e-04 - accuracy: 0.1109 - val_loss: 6.3083e-04 - val_accuracy: 0.0370\n",
            "Epoch 29/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.0239e-04 - accuracy: 0.0973 - val_loss: 3.7553e-04 - val_accuracy: 0.0364\n",
            "Epoch 29/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.2149e-04 - accuracy: 0.0697 - val_loss: 5.5086e-04 - val_accuracy: 0.0909\n",
            "Epoch 31/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.0981e-04 - accuracy: 0.1063 - val_loss: 5.2276e-04 - val_accuracy: 0.0370\n",
            "Epoch 30/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.0497e-04 - accuracy: 0.1030 - val_loss: 5.6955e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.1428e-04 - accuracy: 0.0934 - val_loss: 7.2526e-04 - val_accuracy: 0.1481\n",
            "Epoch 30/170\n",
            "Epoch 30/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.3273e-04 - accuracy: 0.0589 - val_loss: 3.4144e-04 - val_accuracy: 0.0364\n",
            "Epoch 30/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.4756e-04 - accuracy: 0.0826 - val_loss: 4.8895e-04 - val_accuracy: 0.0909\n",
            "Epoch 32/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.9529e-04 - accuracy: 0.0955 - val_loss: 3.3700e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.1066e-04 - accuracy: 0.1009 - val_loss: 8.3623e-04 - val_accuracy: 0.0370\n",
            "\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.3841e-04 - accuracy: 0.1250Epoch 31/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.7091e-04 - accuracy: 0.0851 - val_loss: 7.5697e-04 - val_accuracy: 0.1481\n",
            "Epoch 31/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.1040e-04 - accuracy: 0.0858 - val_loss: 5.7290e-04 - val_accuracy: 0.0364\n",
            "Epoch 31/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.8187e-04 - accuracy: 0.0864 - val_loss: 3.7401e-04 - val_accuracy: 0.0909\n",
            "Epoch 33/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.6451e-04 - accuracy: 0.0828 - val_loss: 4.4011e-04 - val_accuracy: 0.0370\n",
            "Epoch 32/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.8881e-04 - accuracy: 0.0859 - val_loss: 3.3832e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.7094e-04 - accuracy: 0.0692 - val_loss: 4.5103e-04 - val_accuracy: 0.1481\n",
            "50/62 [=======================>......] - ETA: 0s - loss: 3.6540e-04 - accuracy: 0.1020Epoch 32/170\n",
            "Epoch 32/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.2706e-04 - accuracy: 0.0911 - val_loss: 4.0835e-04 - val_accuracy: 0.0364\n",
            "Epoch 32/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.5992e-04 - accuracy: 0.0986 - val_loss: 8.5794e-04 - val_accuracy: 0.0909\n",
            "Epoch 34/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.2209e-04 - accuracy: 0.0869 - val_loss: 4.5379e-04 - val_accuracy: 0.0370\n",
            "Epoch 33/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.9622e-04 - accuracy: 0.0959 - val_loss: 3.1810e-04 - val_accuracy: 0.0370\n",
            "Epoch 33/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.8069e-04 - accuracy: 0.0902 - val_loss: 4.9098e-04 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.4862e-04 - accuracy: 0.0808 - val_loss: 6.1666e-04 - val_accuracy: 0.1481\n",
            "Epoch 33/170\n",
            "Epoch 33/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.7069e-04 - accuracy: 0.0821 - val_loss: 3.6624e-04 - val_accuracy: 0.0909\n",
            "29/62 [=============>................] - ETA: 0s - loss: 3.0336e-04 - accuracy: 0.0652    Epoch 35/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.2839e-04 - accuracy: 0.0829 - val_loss: 5.0119e-04 - val_accuracy: 0.0370\n",
            "Epoch 34/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7032e-04 - accuracy: 0.0915 - val_loss: 4.2515e-04 - val_accuracy: 0.0370\n",
            "Epoch 34/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.2350e-04 - accuracy: 0.1012 - val_loss: 4.9385e-04 - val_accuracy: 0.0364\n",
            "Epoch 34/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.7635e-04 - accuracy: 0.0769 - val_loss: 4.2818e-04 - val_accuracy: 0.1481\n",
            "Epoch 34/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.9774e-04 - accuracy: 0.0829 - val_loss: 4.4807e-04 - val_accuracy: 0.0909\n",
            "Epoch 36/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.4029e-04 - accuracy: 0.0810 - val_loss: 4.0825e-04 - val_accuracy: 0.0370\n",
            "Epoch 35/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.5299e-04 - accuracy: 0.0614 - val_loss: 2.1577e-04 - val_accuracy: 0.0370\n",
            "Epoch 35/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.2480e-04 - accuracy: 0.0894 - val_loss: 2.8353e-04 - val_accuracy: 0.0364\n",
            "Epoch 35/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.0538e-04 - accuracy: 0.0589 - val_loss: 5.0257e-04 - val_accuracy: 0.1481\n",
            "Epoch 35/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.8060e-04 - accuracy: 0.0796 - val_loss: 5.0471e-04 - val_accuracy: 0.0909\n",
            "Epoch 37/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.4419e-04 - accuracy: 0.1104 - val_loss: 6.3527e-04 - val_accuracy: 0.0370\n",
            "Epoch 36/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.6154e-04 - accuracy: 0.1072 - val_loss: 2.9596e-04 - val_accuracy: 0.0370\n",
            "52/62 [========================>.....] - ETA: 0s - loss: 4.0550e-04 - accuracy: 0.0703Epoch 36/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.3966e-04 - accuracy: 0.0817 - val_loss: 2.8145e-04 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.4037e-04 - accuracy: 0.2500Epoch 36/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.8145e-04 - accuracy: 0.1018 - val_loss: 4.4020e-04 - val_accuracy: 0.1481\n",
            "Epoch 36/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.0728e-04 - accuracy: 0.0728 - val_loss: 5.2307e-04 - val_accuracy: 0.0909\n",
            "30/62 [=============>................] - ETA: 0s - loss: 3.6560e-04 - accuracy: 0.1045Epoch 38/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.7443e-04 - accuracy: 0.0964 - val_loss: 4.6678e-04 - val_accuracy: 0.0370\n",
            "Epoch 37/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.8586e-04 - accuracy: 0.0913 - val_loss: 2.0515e-04 - val_accuracy: 0.0370\n",
            "Epoch 37/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.7178e-04 - accuracy: 0.0775 - val_loss: 2.5522e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4664e-04 - accuracy: 0.0891 - val_loss: 4.1167e-04 - val_accuracy: 0.0364\n",
            "Epoch 37/170\n",
            "Epoch 37/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.8940e-04 - accuracy: 0.0744 - val_loss: 3.1749e-04 - val_accuracy: 0.0909\n",
            "Epoch 39/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.0781e-04 - accuracy: 0.0969 - val_loss: 4.2220e-04 - val_accuracy: 0.0370\n",
            "Epoch 38/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.7834e-04 - accuracy: 0.0847 - val_loss: 2.3740e-04 - val_accuracy: 0.0370\n",
            "49/62 [======================>.......] - ETA: 0s - loss: 2.8437e-04 - accuracy: 0.1192Epoch 38/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.8473e-04 - accuracy: 0.0878 - val_loss: 2.8895e-04 - val_accuracy: 0.0364\n",
            "Epoch 38/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.8457e-04 - accuracy: 0.0767 - val_loss: 7.3224e-04 - val_accuracy: 0.1481\n",
            "Epoch 38/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.0705e-04 - accuracy: 0.1118 - val_loss: 4.5265e-04 - val_accuracy: 0.0909\n",
            "Epoch 40/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.0396e-04 - accuracy: 0.0833 - val_loss: 4.0972e-04 - val_accuracy: 0.0370\n",
            "Epoch 39/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.0166e-04 - accuracy: 0.0846 - val_loss: 4.3449e-04 - val_accuracy: 0.0370\n",
            "Epoch 39/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.6432e-04 - accuracy: 0.0931 - val_loss: 3.0118e-04 - val_accuracy: 0.0364\n",
            "Epoch 39/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.0991e-04 - accuracy: 0.0733 - val_loss: 6.4579e-04 - val_accuracy: 0.1481\n",
            "Epoch 39/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.5758e-04 - accuracy: 0.0839 - val_loss: 3.6058e-04 - val_accuracy: 0.0909\n",
            "Epoch 41/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.9333e-04 - accuracy: 0.0716 - val_loss: 4.4498e-04 - val_accuracy: 0.0370\n",
            "Epoch 40/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7384e-04 - accuracy: 0.0720 - val_loss: 2.7343e-04 - val_accuracy: 0.0370\n",
            "Epoch 40/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.3092e-04 - accuracy: 0.1193 - val_loss: 2.9539e-04 - val_accuracy: 0.0364\n",
            "Epoch 40/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.2553e-04 - accuracy: 0.0609 - val_loss: 2.3718e-04 - val_accuracy: 0.1481\n",
            "Epoch 40/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.9346e-04 - accuracy: 0.0831 - val_loss: 3.5440e-04 - val_accuracy: 0.0909\n",
            "Epoch 42/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4480e-04 - accuracy: 0.0783 - val_loss: 4.4594e-04 - val_accuracy: 0.0370\n",
            "Epoch 41/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4246e-04 - accuracy: 0.0799 - val_loss: 3.2504e-04 - val_accuracy: 0.0370\n",
            "Epoch 41/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5973e-04 - accuracy: 0.0946 - val_loss: 3.4182e-04 - val_accuracy: 0.0364\n",
            "Epoch 41/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.9140e-04 - accuracy: 0.0646 - val_loss: 3.2415e-04 - val_accuracy: 0.1481\n",
            "Epoch 41/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.7097e-04 - accuracy: 0.0828 - val_loss: 3.9065e-04 - val_accuracy: 0.0909\n",
            "Epoch 43/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.1699e-04 - accuracy: 0.0922 - val_loss: 4.2704e-04 - val_accuracy: 0.0370\n",
            "Epoch 42/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.9166e-04 - accuracy: 0.0986 - val_loss: 2.5126e-04 - val_accuracy: 0.0370\n",
            "Epoch 42/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.0023e-04 - accuracy: 0.0880 - val_loss: 3.4044e-04 - val_accuracy: 0.0364\n",
            "Epoch 42/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.5335e-04 - accuracy: 0.0788 - val_loss: 4.8542e-04 - val_accuracy: 0.1481\n",
            "Epoch 42/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2354e-04 - accuracy: 0.0769 - val_loss: 3.4131e-04 - val_accuracy: 0.0909\n",
            "Epoch 44/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4289e-04 - accuracy: 0.1117 - val_loss: 3.1733e-04 - val_accuracy: 0.0370\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 2.7564e-04 - accuracy: 0.0849Epoch 43/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.8477e-04 - accuracy: 0.1135 - val_loss: 3.9747e-04 - val_accuracy: 0.0370\n",
            "Epoch 43/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7600e-04 - accuracy: 0.0854 - val_loss: 2.4566e-04 - val_accuracy: 0.0364\n",
            "Epoch 43/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.0737e-04 - accuracy: 0.1009 - val_loss: 2.3440e-04 - val_accuracy: 0.1481\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 2.4787e-04 - accuracy: 0.1118\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7164e-04 - accuracy: 0.0903 - val_loss: 4.0110e-04 - val_accuracy: 0.0909\n",
            "Epoch 45/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.0870e-04 - accuracy: 0.1035 - val_loss: 2.7291e-04 - val_accuracy: 0.0370\n",
            "Epoch 44/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.8431e-04 - accuracy: 0.1114 - val_loss: 3.1254e-04 - val_accuracy: 0.0370\n",
            "Epoch 44/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7306e-04 - accuracy: 0.0816 - val_loss: 3.0622e-04 - val_accuracy: 0.0364\n",
            "Epoch 44/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7833e-04 - accuracy: 0.0938 - val_loss: 3.5371e-04 - val_accuracy: 0.1481\n",
            "Epoch 44/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5720e-04 - accuracy: 0.0623 - val_loss: 3.9024e-04 - val_accuracy: 0.0909\n",
            "Epoch 46/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.8969e-04 - accuracy: 0.0768 - val_loss: 3.7463e-04 - val_accuracy: 0.0370\n",
            "Epoch 45/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.5611e-04 - accuracy: 0.0818 - val_loss: 1.7649e-04 - val_accuracy: 0.0370\n",
            "Epoch 45/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7921e-04 - accuracy: 0.0904 - val_loss: 3.1977e-04 - val_accuracy: 0.0364\n",
            "Epoch 45/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.0683e-04 - accuracy: 0.0633 - val_loss: 2.4615e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.1659e-04 - accuracy: 0.0872 - val_loss: 4.5355e-04 - val_accuracy: 0.0909\n",
            "Epoch 45/170\n",
            "22/62 [=========>....................] - ETA: 0s - loss: 5.3177e-04 - accuracy: 0.0723Epoch 47/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.9029e-04 - accuracy: 0.0830 - val_loss: 3.0687e-04 - val_accuracy: 0.0370\n",
            "Epoch 46/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0424e-04 - accuracy: 0.0830 - val_loss: 2.0211e-04 - val_accuracy: 0.0370\n",
            "Epoch 46/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0535e-04 - accuracy: 0.0681 - val_loss: 3.2162e-04 - val_accuracy: 0.0364\n",
            "Epoch 46/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4077e-04 - accuracy: 0.0999 - val_loss: 3.8450e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.0784e-04 - accuracy: 0.0682 - val_loss: 2.5635e-04 - val_accuracy: 0.1481\n",
            "Epoch 48/170\n",
            "Epoch 46/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.2508e-04 - accuracy: 0.0926 - val_loss: 2.8698e-04 - val_accuracy: 0.0370\n",
            "Epoch 47/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7281e-04 - accuracy: 0.1006 - val_loss: 2.1688e-04 - val_accuracy: 0.0370\n",
            "Epoch 47/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.2558e-04 - accuracy: 0.0869 - val_loss: 2.7173e-04 - val_accuracy: 0.0364\n",
            "Epoch 47/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.4610e-04 - accuracy: 0.0689 - val_loss: 3.4770e-04 - val_accuracy: 0.0909\n",
            "Epoch 49/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1830e-04 - accuracy: 0.0860 - val_loss: 4.5497e-04 - val_accuracy: 0.1481\n",
            "Epoch 47/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.6637e-04 - accuracy: 0.0925 - val_loss: 3.0117e-04 - val_accuracy: 0.0370\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 2.3769e-04 - accuracy: 0.0923Epoch 48/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6812e-04 - accuracy: 0.0876 - val_loss: 5.9877e-04 - val_accuracy: 0.0370\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 2.1026e-04 - accuracy: 0.0864Epoch 48/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4066e-04 - accuracy: 0.0920 - val_loss: 3.1509e-04 - val_accuracy: 0.0364\n",
            "Epoch 48/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1013e-04 - accuracy: 0.0863 - val_loss: 3.3071e-04 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.0552e-04 - accuracy: 0.0000e+00Epoch 50/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.8598e-04 - accuracy: 0.0765 - val_loss: 7.1794e-04 - val_accuracy: 0.1481\n",
            "Epoch 48/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.9130e-04 - accuracy: 0.0912 - val_loss: 2.9729e-04 - val_accuracy: 0.0370\n",
            "Epoch 49/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5914e-04 - accuracy: 0.0937 - val_loss: 2.8490e-04 - val_accuracy: 0.0370\n",
            "Epoch 49/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9206e-04 - accuracy: 0.0915 - val_loss: 3.6534e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1798e-04 - accuracy: 0.0753 - val_loss: 2.6568e-04 - val_accuracy: 0.0364\n",
            "Epoch 51/170\n",
            "Epoch 49/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.6629e-04 - accuracy: 0.0845 - val_loss: 1.7613e-04 - val_accuracy: 0.1481\n",
            "Epoch 49/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.3358e-04 - accuracy: 0.0989 - val_loss: 3.2249e-04 - val_accuracy: 0.0370\n",
            "Epoch 50/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7245e-04 - accuracy: 0.0824 - val_loss: 2.4272e-04 - val_accuracy: 0.0370\n",
            "Epoch 50/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8480e-04 - accuracy: 0.0773 - val_loss: 5.5272e-04 - val_accuracy: 0.0909\n",
            "Epoch 52/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8654e-04 - accuracy: 0.0982 - val_loss: 3.6926e-04 - val_accuracy: 0.0364\n",
            "Epoch 50/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9166e-04 - accuracy: 0.0752 - val_loss: 3.4084e-04 - val_accuracy: 0.1481\n",
            "Epoch 50/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3789e-04 - accuracy: 0.0850 - val_loss: 3.1014e-04 - val_accuracy: 0.0370\n",
            "Epoch 51/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1160e-04 - accuracy: 0.0976 - val_loss: 2.7552e-04 - val_accuracy: 0.0370\n",
            "Epoch 51/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7460e-04 - accuracy: 0.0986 - val_loss: 2.7162e-04 - val_accuracy: 0.0909\n",
            "Epoch 53/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5400e-04 - accuracy: 0.0951 - val_loss: 3.0157e-04 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 8.5991e-05 - accuracy: 0.2500Epoch 51/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.2912e-04 - accuracy: 0.0761 - val_loss: 5.0898e-04 - val_accuracy: 0.1481\n",
            "Epoch 51/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.9285e-04 - accuracy: 0.0826 - val_loss: 3.0309e-04 - val_accuracy: 0.0370\n",
            "Epoch 52/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.8238e-04 - accuracy: 0.0841 - val_loss: 2.7803e-04 - val_accuracy: 0.0370\n",
            "Epoch 52/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9306e-04 - accuracy: 0.1116 - val_loss: 2.5762e-04 - val_accuracy: 0.0909\n",
            "Epoch 54/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3947e-04 - accuracy: 0.0769 - val_loss: 3.5255e-04 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 5.7872e-05 - accuracy: 0.0000e+00Epoch 52/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.2184e-04 - accuracy: 0.0779 - val_loss: 3.8109e-04 - val_accuracy: 0.1481\n",
            "Epoch 52/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.6093e-04 - accuracy: 0.0928 - val_loss: 4.5455e-04 - val_accuracy: 0.0370\n",
            "Epoch 53/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7264e-04 - accuracy: 0.0935 - val_loss: 6.6457e-04 - val_accuracy: 0.0370\n",
            "Epoch 53/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6895e-04 - accuracy: 0.0705 - val_loss: 7.4677e-04 - val_accuracy: 0.0909\n",
            "Epoch 55/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.2009e-04 - accuracy: 0.1004 - val_loss: 3.3417e-04 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.2469e-04 - accuracy: 0.0000e+00Epoch 53/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1533e-04 - accuracy: 0.0802 - val_loss: 6.5554e-04 - val_accuracy: 0.1481\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.3746e-04 - accuracy: 0.2500\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0888e-04 - accuracy: 0.1052 - val_loss: 3.7902e-04 - val_accuracy: 0.0370\n",
            "Epoch 54/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.2984e-04 - accuracy: 0.0953 - val_loss: 2.6945e-04 - val_accuracy: 0.0370\n",
            "Epoch 54/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.2246e-04 - accuracy: 0.0827 - val_loss: 2.5710e-04 - val_accuracy: 0.0909\n",
            "Epoch 56/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.2054e-04 - accuracy: 0.1229 - val_loss: 2.2103e-04 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5769e-04 - accuracy: 0.0865 - val_loss: 2.5131e-04 - val_accuracy: 0.1481\n",
            "Epoch 54/170\n",
            "Epoch 54/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5250e-04 - accuracy: 0.0862 - val_loss: 1.8850e-04 - val_accuracy: 0.0370\n",
            "Epoch 55/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0905e-04 - accuracy: 0.0964 - val_loss: 3.1222e-04 - val_accuracy: 0.0370\n",
            "Epoch 55/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.6232e-04 - accuracy: 0.0771 - val_loss: 4.4263e-04 - val_accuracy: 0.0909\n",
            "Epoch 57/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5719e-04 - accuracy: 0.0733 - val_loss: 2.5764e-04 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.4837e-04 - accuracy: 0.0000e+00Epoch 55/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.5305e-04 - accuracy: 0.0809 - val_loss: 1.7189e-04 - val_accuracy: 0.1481\n",
            "Epoch 55/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4998e-04 - accuracy: 0.0955 - val_loss: 2.9400e-04 - val_accuracy: 0.0370\n",
            "52/62 [========================>.....] - ETA: 0s - loss: 1.8779e-04 - accuracy: 0.0721Epoch 56/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.3328e-04 - accuracy: 0.0927 - val_loss: 2.8756e-04 - val_accuracy: 0.0370\n",
            "Epoch 56/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9008e-04 - accuracy: 0.0738 - val_loss: 7.1587e-04 - val_accuracy: 0.0909\n",
            "Epoch 58/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.2747e-04 - accuracy: 0.0814 - val_loss: 2.1721e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1357e-04 - accuracy: 0.0911 - val_loss: 2.6137e-04 - val_accuracy: 0.0364\n",
            "Epoch 56/170\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.4185e-04 - accuracy: 0.0000e+00Epoch 56/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8342e-04 - accuracy: 0.0884 - val_loss: 2.9691e-04 - val_accuracy: 0.0370\n",
            "Epoch 57/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.3435e-04 - accuracy: 0.0777 - val_loss: 1.6037e-04 - val_accuracy: 0.0370\n",
            "Epoch 57/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9634e-04 - accuracy: 0.0702 - val_loss: 1.9578e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0762e-04 - accuracy: 0.0707 - val_loss: 3.9085e-04 - val_accuracy: 0.0909\n",
            "Epoch 57/170\n",
            "Epoch 59/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7795e-04 - accuracy: 0.0852 - val_loss: 3.4534e-04 - val_accuracy: 0.0364\n",
            "Epoch 57/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1743e-04 - accuracy: 0.0921 - val_loss: 2.7479e-04 - val_accuracy: 0.0370\n",
            "Epoch 58/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7800e-04 - accuracy: 0.0937 - val_loss: 2.7134e-04 - val_accuracy: 0.0370\n",
            "Epoch 58/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8860e-04 - accuracy: 0.0755 - val_loss: 1.1429e-04 - val_accuracy: 0.1481\n",
            "Epoch 58/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4024e-04 - accuracy: 0.0887 - val_loss: 2.5996e-04 - val_accuracy: 0.0909\n",
            "Epoch 60/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8237e-04 - accuracy: 0.0808 - val_loss: 2.3754e-04 - val_accuracy: 0.0364\n",
            "Epoch 58/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6066e-04 - accuracy: 0.0705 - val_loss: 1.7489e-04 - val_accuracy: 0.0370\n",
            "Epoch 59/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8240e-04 - accuracy: 0.0819 - val_loss: 1.3419e-04 - val_accuracy: 0.0370\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 1.5736e-04 - accuracy: 0.1030Epoch 59/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7888e-04 - accuracy: 0.0619 - val_loss: 2.6605e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5687e-04 - accuracy: 0.1015 - val_loss: 4.3959e-04 - val_accuracy: 0.0909\n",
            "Epoch 59/170\n",
            "Epoch 61/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3569e-04 - accuracy: 0.0813 - val_loss: 2.2418e-04 - val_accuracy: 0.0364\n",
            "Epoch 59/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6325e-04 - accuracy: 0.0792 - val_loss: 3.5099e-04 - val_accuracy: 0.0370\n",
            "Epoch 60/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.8557e-04 - accuracy: 0.0801 - val_loss: 1.0452e-04 - val_accuracy: 0.0370\n",
            "13/62 [=====>........................] - ETA: 0s - loss: 3.3816e-04 - accuracy: 0.0691    Epoch 60/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.9190e-04 - accuracy: 0.0639 - val_loss: 4.2223e-04 - val_accuracy: 0.1481\n",
            "Epoch 60/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3624e-04 - accuracy: 0.0980 - val_loss: 2.2573e-04 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5866e-04 - accuracy: 0.0792 - val_loss: 4.1243e-04 - val_accuracy: 0.0909\n",
            "Epoch 60/170\n",
            "Epoch 62/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.6193e-04 - accuracy: 0.0873 - val_loss: 4.1927e-04 - val_accuracy: 0.0370\n",
            "Epoch 61/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2067e-04 - accuracy: 0.0873 - val_loss: 3.8039e-04 - val_accuracy: 0.0370\n",
            "Epoch 61/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.6612e-04 - accuracy: 0.0679 - val_loss: 1.8028e-04 - val_accuracy: 0.1481\n",
            "24/62 [==========>...................] - ETA: 0s - loss: 2.5612e-04 - accuracy: 0.0807    Epoch 61/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2401e-04 - accuracy: 0.1101 - val_loss: 2.3307e-04 - val_accuracy: 0.0364\n",
            "Epoch 61/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9654e-04 - accuracy: 0.0626 - val_loss: 2.3918e-04 - val_accuracy: 0.0909\n",
            "Epoch 63/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.9336e-04 - accuracy: 0.0891 - val_loss: 5.5583e-04 - val_accuracy: 0.0370\n",
            "Epoch 62/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.3593e-04 - accuracy: 0.0870 - val_loss: 1.2220e-04 - val_accuracy: 0.0370\n",
            "Epoch 62/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5963e-04 - accuracy: 0.0809 - val_loss: 2.7084e-04 - val_accuracy: 0.1481\n",
            "Epoch 62/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3984e-04 - accuracy: 0.0793 - val_loss: 1.9465e-04 - val_accuracy: 0.0364\n",
            "Epoch 62/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8883e-04 - accuracy: 0.0891 - val_loss: 3.2751e-04 - val_accuracy: 0.0909\n",
            "Epoch 64/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.2049e-04 - accuracy: 0.0990 - val_loss: 1.5477e-04 - val_accuracy: 0.0370\n",
            "Epoch 63/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6645e-04 - accuracy: 0.1007 - val_loss: 1.2626e-04 - val_accuracy: 0.0370\n",
            "Epoch 63/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.1229e-04 - accuracy: 0.0860 - val_loss: 1.3349e-04 - val_accuracy: 0.1481\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 1.8834e-04 - accuracy: 0.0698    Epoch 63/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4944e-04 - accuracy: 0.0718 - val_loss: 3.0655e-04 - val_accuracy: 0.0364\n",
            "Epoch 63/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7283e-04 - accuracy: 0.0974 - val_loss: 2.8848e-04 - val_accuracy: 0.0909\n",
            "Epoch 65/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6772e-04 - accuracy: 0.0813 - val_loss: 2.6937e-04 - val_accuracy: 0.0370\n",
            "Epoch 64/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3522e-04 - accuracy: 0.0727 - val_loss: 3.4870e-04 - val_accuracy: 0.0370\n",
            "Epoch 64/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6834e-04 - accuracy: 0.0680 - val_loss: 2.0754e-04 - val_accuracy: 0.1481\n",
            "Epoch 64/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4235e-04 - accuracy: 0.0932 - val_loss: 4.2324e-04 - val_accuracy: 0.0364\n",
            "Epoch 64/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2103e-04 - accuracy: 0.0675 - val_loss: 4.4900e-04 - val_accuracy: 0.0909\n",
            "Epoch 66/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4392e-04 - accuracy: 0.0733 - val_loss: 1.9911e-04 - val_accuracy: 0.0370\n",
            "Epoch 65/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9787e-04 - accuracy: 0.0708 - val_loss: 1.7356e-04 - val_accuracy: 0.0370\n",
            "Epoch 65/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7503e-04 - accuracy: 0.0610 - val_loss: 2.1294e-04 - val_accuracy: 0.1481\n",
            "Epoch 65/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3413e-04 - accuracy: 0.0962 - val_loss: 2.2230e-04 - val_accuracy: 0.0364\n",
            "Epoch 65/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.8712e-04 - accuracy: 0.0778 - val_loss: 3.0895e-04 - val_accuracy: 0.0909\n",
            "Epoch 67/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5955e-04 - accuracy: 0.1149 - val_loss: 2.3170e-04 - val_accuracy: 0.0370\n",
            "Epoch 66/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0326e-04 - accuracy: 0.1052 - val_loss: 1.4518e-04 - val_accuracy: 0.0370\n",
            "Epoch 66/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7818e-04 - accuracy: 0.1005 - val_loss: 9.9415e-05 - val_accuracy: 0.1481\n",
            "Epoch 66/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3082e-04 - accuracy: 0.0730 - val_loss: 2.1476e-04 - val_accuracy: 0.0364\n",
            "Epoch 66/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3712e-04 - accuracy: 0.0988 - val_loss: 2.9648e-04 - val_accuracy: 0.0909\n",
            "Epoch 68/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6059e-04 - accuracy: 0.0731 - val_loss: 2.5544e-04 - val_accuracy: 0.0370\n",
            "Epoch 67/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4790e-04 - accuracy: 0.0693 - val_loss: 2.0963e-04 - val_accuracy: 0.0370\n",
            "Epoch 67/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2677e-04 - accuracy: 0.0636 - val_loss: 1.3313e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5498e-04 - accuracy: 0.0908 - val_loss: 3.0704e-04 - val_accuracy: 0.0364\n",
            "Epoch 67/170Epoch 67/170\n",
            "\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1156e-04 - accuracy: 0.0791 - val_loss: 2.3132e-04 - val_accuracy: 0.0909\n",
            "Epoch 69/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5313e-04 - accuracy: 0.0797 - val_loss: 2.3756e-04 - val_accuracy: 0.0370\n",
            "Epoch 68/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6465e-04 - accuracy: 0.0820 - val_loss: 1.2709e-04 - val_accuracy: 0.0370\n",
            "53/62 [========================>.....] - ETA: 0s - loss: 1.1683e-04 - accuracy: 0.0712Epoch 68/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9421e-04 - accuracy: 0.0711 - val_loss: 1.6378e-04 - val_accuracy: 0.1481\n",
            "Epoch 68/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5782e-04 - accuracy: 0.0987 - val_loss: 2.3166e-04 - val_accuracy: 0.0364\n",
            "Epoch 68/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1459e-04 - accuracy: 0.0728 - val_loss: 2.9626e-04 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 9.7428e-05 - accuracy: 0.0000e+00Epoch 70/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0773e-04 - accuracy: 0.0906 - val_loss: 2.8105e-04 - val_accuracy: 0.0370\n",
            "Epoch 69/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8405e-04 - accuracy: 0.0842 - val_loss: 1.8889e-04 - val_accuracy: 0.0370\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 1.5272e-04 - accuracy: 0.0777Epoch 69/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5662e-04 - accuracy: 0.0776 - val_loss: 2.2250e-04 - val_accuracy: 0.1481\n",
            "14/62 [=====>........................] - ETA: 0s - loss: 8.8729e-05 - accuracy: 0.0713Epoch 69/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1430e-04 - accuracy: 0.0926 - val_loss: 2.8497e-04 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2740e-04 - accuracy: 0.0699 - val_loss: 2.0698e-04 - val_accuracy: 0.0909\n",
            "Epoch 69/170\n",
            "42/62 [===================>..........] - ETA: 0s - loss: 1.7738e-04 - accuracy: 0.0658Epoch 71/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9297e-04 - accuracy: 0.0741 - val_loss: 6.0882e-04 - val_accuracy: 0.0370\n",
            "Epoch 70/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4663e-04 - accuracy: 0.0823 - val_loss: 4.2898e-04 - val_accuracy: 0.0370\n",
            "Epoch 70/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5544e-04 - accuracy: 0.0651 - val_loss: 7.8260e-04 - val_accuracy: 0.1481\n",
            "Epoch 70/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2649e-04 - accuracy: 0.0742 - val_loss: 4.1049e-04 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2107e-04 - accuracy: 0.0783 - val_loss: 2.7953e-04 - val_accuracy: 0.0909\n",
            "\n",
            " 1/62 [..............................] - ETA: 0s - loss: 4.3571e-05 - accuracy: 0.0000e+00Epoch 72/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7351e-04 - accuracy: 0.0799 - val_loss: 1.4606e-04 - val_accuracy: 0.0370\n",
            "52/62 [========================>.....] - ETA: 0s - loss: 2.7829e-04 - accuracy: 0.0824Epoch 71/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.6989e-04 - accuracy: 0.0832 - val_loss: 1.0391e-04 - val_accuracy: 0.0370\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 2.7151e-04 - accuracy: 0.0763Epoch 71/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.9574e-04 - accuracy: 0.0728 - val_loss: 2.0446e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5737e-04 - accuracy: 0.0863 - val_loss: 3.8406e-04 - val_accuracy: 0.0909\n",
            "Epoch 71/170\n",
            "Epoch 73/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7640e-04 - accuracy: 0.0777 - val_loss: 5.1050e-04 - val_accuracy: 0.0364\n",
            "Epoch 71/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5685e-04 - accuracy: 0.0935 - val_loss: 5.0666e-04 - val_accuracy: 0.0370\n",
            "Epoch 72/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.6865e-04 - accuracy: 0.0999 - val_loss: 6.7722e-04 - val_accuracy: 0.0370\n",
            "Epoch 72/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0503e-04 - accuracy: 0.0842 - val_loss: 4.6113e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.2808e-04 - accuracy: 0.0784 - val_loss: 5.6464e-04 - val_accuracy: 0.1481\n",
            "Epoch 74/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0361e-04 - accuracy: 0.0764 - val_loss: 4.2549e-04 - val_accuracy: 0.0364\n",
            "Epoch 72/170\n",
            " 1/62 [..............................] - ETA: 0s - loss: 3.3860e-04 - accuracy: 0.1250Epoch 72/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4435e-04 - accuracy: 0.0939 - val_loss: 2.4327e-04 - val_accuracy: 0.0370\n",
            "Epoch 73/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.6332e-04 - accuracy: 0.1041 - val_loss: 1.2174e-04 - val_accuracy: 0.0370\n",
            "Epoch 73/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0440e-04 - accuracy: 0.0947 - val_loss: 2.1621e-04 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.1201e-04 - accuracy: 0.0836 - val_loss: 2.0240e-04 - val_accuracy: 0.1481\n",
            "Epoch 73/170\n",
            "Epoch 73/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3454e-04 - accuracy: 0.0832 - val_loss: 3.0167e-04 - val_accuracy: 0.0909\n",
            "Epoch 75/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7816e-04 - accuracy: 0.0813 - val_loss: 2.6830e-04 - val_accuracy: 0.0370\n",
            "Epoch 74/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8241e-04 - accuracy: 0.1062 - val_loss: 4.1724e-04 - val_accuracy: 0.0370\n",
            "Epoch 74/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0809e-04 - accuracy: 0.0968 - val_loss: 2.5607e-04 - val_accuracy: 0.0364\n",
            "Epoch 74/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4806e-04 - accuracy: 0.0732 - val_loss: 2.5549e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3115e-04 - accuracy: 0.0716 - val_loss: 3.2058e-04 - val_accuracy: 0.0909\n",
            "Epoch 74/170\n",
            "Epoch 76/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6666e-04 - accuracy: 0.0653 - val_loss: 2.4018e-04 - val_accuracy: 0.0370\n",
            "Epoch 75/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 3.7646e-04 - accuracy: 0.0651 - val_loss: 1.4850e-04 - val_accuracy: 0.0370\n",
            "Epoch 75/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2741e-04 - accuracy: 0.0903 - val_loss: 4.0724e-04 - val_accuracy: 0.0364\n",
            "Epoch 75/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.7284e-04 - accuracy: 0.0586 - val_loss: 2.9773e-04 - val_accuracy: 0.1481\n",
            "Epoch 75/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1554e-04 - accuracy: 0.0792 - val_loss: 3.3297e-04 - val_accuracy: 0.0909\n",
            "Epoch 77/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2302e-04 - accuracy: 0.0982 - val_loss: 2.0676e-04 - val_accuracy: 0.0370\n",
            "Epoch 76/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6509e-04 - accuracy: 0.1033 - val_loss: 2.4322e-04 - val_accuracy: 0.0370\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 2.1855e-04 - accuracy: 0.1137Epoch 76/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9833e-04 - accuracy: 0.0872 - val_loss: 2.7287e-04 - val_accuracy: 0.1481\n",
            "Epoch 76/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0772e-04 - accuracy: 0.0739 - val_loss: 1.7511e-04 - val_accuracy: 0.0364\n",
            "Epoch 76/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3763e-04 - accuracy: 0.0843 - val_loss: 3.8047e-04 - val_accuracy: 0.0909\n",
            "Epoch 78/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8869e-04 - accuracy: 0.1031 - val_loss: 1.1748e-04 - val_accuracy: 0.0370\n",
            "29/62 [=============>................] - ETA: 0s - loss: 1.6430e-04 - accuracy: 0.0870Epoch 77/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4258e-04 - accuracy: 0.0994 - val_loss: 4.3531e-04 - val_accuracy: 0.0370\n",
            "Epoch 77/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5706e-04 - accuracy: 0.0870 - val_loss: 2.2160e-04 - val_accuracy: 0.1481\n",
            "Epoch 77/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6427e-04 - accuracy: 0.0989 - val_loss: 3.2858e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4931e-04 - accuracy: 0.0919 - val_loss: 1.6162e-04 - val_accuracy: 0.0364\n",
            "Epoch 79/170\n",
            "Epoch 77/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3082e-04 - accuracy: 0.0917 - val_loss: 2.0004e-04 - val_accuracy: 0.0370\n",
            "Epoch 78/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7918e-04 - accuracy: 0.0981 - val_loss: 1.2870e-04 - val_accuracy: 0.0370\n",
            "Epoch 78/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9034e-04 - accuracy: 0.0773 - val_loss: 1.0266e-04 - val_accuracy: 0.1481\n",
            "Epoch 78/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5036e-04 - accuracy: 0.0622 - val_loss: 2.7634e-04 - val_accuracy: 0.0909\n",
            "Epoch 80/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6124e-04 - accuracy: 0.0946 - val_loss: 4.3712e-04 - val_accuracy: 0.0364\n",
            "Epoch 78/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1505e-04 - accuracy: 0.0948 - val_loss: 3.6683e-04 - val_accuracy: 0.0370\n",
            "Epoch 79/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1694e-04 - accuracy: 0.0875 - val_loss: 1.9776e-04 - val_accuracy: 0.0370\n",
            "Epoch 79/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2210e-04 - accuracy: 0.0869 - val_loss: 1.9765e-04 - val_accuracy: 0.1481\n",
            "Epoch 79/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3500e-04 - accuracy: 0.0951 - val_loss: 2.7199e-04 - val_accuracy: 0.0909\n",
            "41/62 [==================>...........] - ETA: 0s - loss: 1.8624e-04 - accuracy: 0.0836Epoch 81/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1623e-04 - accuracy: 0.1030 - val_loss: 1.9182e-04 - val_accuracy: 0.0364\n",
            "Epoch 79/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7560e-04 - accuracy: 0.0848 - val_loss: 1.1632e-04 - val_accuracy: 0.0370\n",
            "Epoch 80/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6641e-04 - accuracy: 0.0868 - val_loss: 2.0250e-04 - val_accuracy: 0.0370\n",
            "Epoch 80/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2673e-04 - accuracy: 0.0751 - val_loss: 1.0706e-04 - val_accuracy: 0.1481\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.0302e-04 - accuracy: 0.0000e+00Epoch 80/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2188e-04 - accuracy: 0.0947 - val_loss: 4.3729e-04 - val_accuracy: 0.0909\n",
            "Epoch 82/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.3770e-05 - accuracy: 0.0687 - val_loss: 2.3156e-04 - val_accuracy: 0.0364\n",
            "Epoch 80/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6727e-04 - accuracy: 0.1042 - val_loss: 3.1661e-04 - val_accuracy: 0.0370\n",
            "Epoch 81/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3821e-04 - accuracy: 0.1056 - val_loss: 1.6369e-04 - val_accuracy: 0.0370\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 1.2563e-04 - accuracy: 0.1017Epoch 81/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5707e-04 - accuracy: 0.0940 - val_loss: 3.8966e-04 - val_accuracy: 0.1481\n",
            "Epoch 81/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6003e-04 - accuracy: 0.0878 - val_loss: 4.4470e-04 - val_accuracy: 0.0909\n",
            "Epoch 83/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2548e-04 - accuracy: 0.1006 - val_loss: 2.3294e-04 - val_accuracy: 0.0364\n",
            "51/62 [=======================>......] - ETA: 0s - loss: 1.8097e-04 - accuracy: 0.1002Epoch 81/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8654e-04 - accuracy: 0.0984 - val_loss: 1.5922e-04 - val_accuracy: 0.0370\n",
            "Epoch 82/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1715e-04 - accuracy: 0.0977 - val_loss: 1.2655e-04 - val_accuracy: 0.0370\n",
            "Epoch 82/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4342e-04 - accuracy: 0.0800 - val_loss: 1.6573e-04 - val_accuracy: 0.1481\n",
            "Epoch 82/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1339e-04 - accuracy: 0.0977 - val_loss: 1.9591e-04 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4310e-04 - accuracy: 0.0808 - val_loss: 2.8042e-04 - val_accuracy: 0.0909\n",
            "Epoch 82/170\n",
            "Epoch 84/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3176e-04 - accuracy: 0.0856 - val_loss: 2.3993e-04 - val_accuracy: 0.0370\n",
            "Epoch 83/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3566e-04 - accuracy: 0.0831 - val_loss: 1.1469e-04 - val_accuracy: 0.0370\n",
            "Epoch 83/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5587e-04 - accuracy: 0.0670 - val_loss: 1.9442e-04 - val_accuracy: 0.1481\n",
            "Epoch 83/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2879e-04 - accuracy: 0.0621 - val_loss: 2.4009e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0795e-04 - accuracy: 0.0922 - val_loss: 2.2147e-04 - val_accuracy: 0.0364\n",
            "Epoch 85/170\n",
            "Epoch 83/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1852e-04 - accuracy: 0.0628 - val_loss: 2.2707e-04 - val_accuracy: 0.0370\n",
            "Epoch 84/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3850e-04 - accuracy: 0.0672 - val_loss: 1.7070e-04 - val_accuracy: 0.0370\n",
            "Epoch 84/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9858e-04 - accuracy: 0.0504 - val_loss: 1.4892e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2394e-04 - accuracy: 0.0938 - val_loss: 1.7351e-04 - val_accuracy: 0.0364\n",
            "Epoch 84/170\n",
            "Epoch 84/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0120e-04 - accuracy: 0.0904 - val_loss: 3.6380e-04 - val_accuracy: 0.0909\n",
            "Epoch 86/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5703e-04 - accuracy: 0.0729 - val_loss: 1.7778e-04 - val_accuracy: 0.0370\n",
            "28/62 [============>.................] - ETA: 0s - loss: 1.0737e-04 - accuracy: 0.0838    Epoch 85/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2313e-04 - accuracy: 0.0860 - val_loss: 2.3248e-04 - val_accuracy: 0.0370\n",
            "Epoch 85/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1705e-04 - accuracy: 0.0633 - val_loss: 2.9476e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8956e-04 - accuracy: 0.0809 - val_loss: 3.1690e-04 - val_accuracy: 0.0364\n",
            "Epoch 85/170\n",
            "Epoch 85/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7839e-04 - accuracy: 0.0864 - val_loss: 3.3826e-04 - val_accuracy: 0.0909\n",
            "Epoch 87/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4492e-04 - accuracy: 0.0770 - val_loss: 1.4232e-04 - val_accuracy: 0.0370\n",
            "Epoch 86/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5876e-04 - accuracy: 0.0810 - val_loss: 2.2323e-04 - val_accuracy: 0.0370\n",
            "Epoch 86/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4046e-04 - accuracy: 0.0985 - val_loss: 2.1368e-04 - val_accuracy: 0.0364\n",
            "51/62 [=======================>......] - ETA: 0s - loss: 1.5179e-04 - accuracy: 0.0768Epoch 86/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5003e-04 - accuracy: 0.0710 - val_loss: 1.5980e-04 - val_accuracy: 0.1481\n",
            "Epoch 86/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4694e-04 - accuracy: 0.0951 - val_loss: 2.7687e-04 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 3.4420e-05 - accuracy: 0.1250Epoch 88/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5374e-04 - accuracy: 0.0784 - val_loss: 9.4423e-05 - val_accuracy: 0.0370\n",
            "Epoch 87/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3155e-04 - accuracy: 0.0898 - val_loss: 2.0323e-04 - val_accuracy: 0.0364\n",
            "Epoch 87/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4474e-04 - accuracy: 0.0818 - val_loss: 9.4897e-05 - val_accuracy: 0.0370\n",
            "51/62 [=======================>......] - ETA: 0s - loss: 1.3993e-04 - accuracy: 0.0760Epoch 87/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1363e-04 - accuracy: 0.0723 - val_loss: 9.7265e-05 - val_accuracy: 0.1481\n",
            "Epoch 87/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7420e-04 - accuracy: 0.0967 - val_loss: 3.4423e-04 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.4607e-05 - accuracy: 0.0000e+00Epoch 89/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4071e-04 - accuracy: 0.0777 - val_loss: 9.7496e-05 - val_accuracy: 0.0370\n",
            "Epoch 88/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0483e-04 - accuracy: 0.0771 - val_loss: 8.8979e-05 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4790e-04 - accuracy: 0.0962 - val_loss: 2.7247e-04 - val_accuracy: 0.0364\n",
            "\n",
            "Epoch 88/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1805e-04 - accuracy: 0.0700 - val_loss: 3.3981e-04 - val_accuracy: 0.1481\n",
            "Epoch 88/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0873e-04 - accuracy: 0.0944 - val_loss: 3.2326e-04 - val_accuracy: 0.0909\n",
            "Epoch 90/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.5175e-04 - accuracy: 0.0837 - val_loss: 1.0808e-04 - val_accuracy: 0.0370\n",
            "25/62 [===========>..................] - ETA: 0s - loss: 9.2482e-05 - accuracy: 0.0614    Epoch 89/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2089e-04 - accuracy: 0.0707 - val_loss: 9.4284e-05 - val_accuracy: 0.0370\n",
            "Epoch 89/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8328e-04 - accuracy: 0.0651 - val_loss: 2.2170e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.2135e-04 - accuracy: 0.0952 - val_loss: 2.4920e-04 - val_accuracy: 0.0364\n",
            "Epoch 89/170\n",
            "Epoch 89/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2824e-04 - accuracy: 0.0928 - val_loss: 3.5455e-04 - val_accuracy: 0.0909\n",
            "Epoch 91/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4948e-04 - accuracy: 0.1030 - val_loss: 1.5890e-04 - val_accuracy: 0.0370\n",
            "Epoch 90/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0691e-04 - accuracy: 0.1004 - val_loss: 1.3690e-04 - val_accuracy: 0.0370\n",
            "Epoch 90/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2735e-04 - accuracy: 0.1027 - val_loss: 2.8009e-04 - val_accuracy: 0.0364\n",
            "50/62 [=======================>......] - ETA: 0s - loss: 9.9205e-05 - accuracy: 0.1125Epoch 90/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1588e-04 - accuracy: 0.0951 - val_loss: 2.0864e-04 - val_accuracy: 0.1481\n",
            "Epoch 90/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4543e-04 - accuracy: 0.0838 - val_loss: 3.1737e-04 - val_accuracy: 0.0909\n",
            "Epoch 92/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0826e-04 - accuracy: 0.1077 - val_loss: 2.7721e-04 - val_accuracy: 0.0370\n",
            "Epoch 91/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0764e-04 - accuracy: 0.1100 - val_loss: 8.4461e-05 - val_accuracy: 0.0370\n",
            "Epoch 91/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.1017e-04 - accuracy: 0.0956 - val_loss: 1.6731e-04 - val_accuracy: 0.0364\n",
            "Epoch 91/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.7604e-05 - accuracy: 0.0952 - val_loss: 7.5869e-05 - val_accuracy: 0.1481\n",
            "Epoch 91/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0394e-04 - accuracy: 0.0805 - val_loss: 1.9708e-04 - val_accuracy: 0.0909\n",
            "Epoch 93/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9035e-04 - accuracy: 0.0848 - val_loss: 1.9157e-04 - val_accuracy: 0.0370\n",
            "Epoch 92/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2043e-04 - accuracy: 0.0823 - val_loss: 1.3473e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.4850e-04 - accuracy: 0.0733Epoch 92/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3951e-04 - accuracy: 0.0952 - val_loss: 1.3211e-04 - val_accuracy: 0.0364\n",
            "Epoch 92/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4841e-04 - accuracy: 0.0733 - val_loss: 1.7864e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.7985e-05 - accuracy: 0.0814 - val_loss: 4.0898e-04 - val_accuracy: 0.0909\n",
            "Epoch 94/170Epoch 92/170\n",
            "\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2404e-04 - accuracy: 0.0679 - val_loss: 8.8954e-05 - val_accuracy: 0.0370\n",
            "Epoch 93/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4675e-04 - accuracy: 0.0836 - val_loss: 9.0097e-05 - val_accuracy: 0.0370\n",
            "Epoch 93/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0466e-04 - accuracy: 0.0794 - val_loss: 1.1829e-04 - val_accuracy: 0.0364\n",
            "Epoch 93/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.9738e-04 - accuracy: 0.0626 - val_loss: 2.0240e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0347e-04 - accuracy: 0.0711 - val_loss: 3.2757e-04 - val_accuracy: 0.0909\n",
            "Epoch 95/170Epoch 93/170\n",
            "\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.5290e-05 - accuracy: 0.1050 - val_loss: 1.6377e-04 - val_accuracy: 0.0370\n",
            "Epoch 94/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.2787e-05 - accuracy: 0.0983 - val_loss: 2.9359e-04 - val_accuracy: 0.0370\n",
            "Epoch 94/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0393e-04 - accuracy: 0.0808 - val_loss: 2.7116e-04 - val_accuracy: 0.0364\n",
            "Epoch 94/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2626e-04 - accuracy: 0.0776 - val_loss: 2.9767e-04 - val_accuracy: 0.0909\n",
            "Epoch 96/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5351e-04 - accuracy: 0.0894 - val_loss: 1.9243e-04 - val_accuracy: 0.1481\n",
            "Epoch 94/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1427e-04 - accuracy: 0.0838 - val_loss: 3.5850e-04 - val_accuracy: 0.0370\n",
            "Epoch 95/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1156e-04 - accuracy: 0.0863 - val_loss: 1.8112e-04 - val_accuracy: 0.0370\n",
            "50/62 [=======================>......] - ETA: 0s - loss: 5.2634e-04 - accuracy: 0.0780Epoch 95/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1617e-04 - accuracy: 0.0717 - val_loss: 1.8623e-04 - val_accuracy: 0.0364\n",
            "Epoch 95/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0373e-04 - accuracy: 0.0675 - val_loss: 2.3791e-04 - val_accuracy: 0.0909\n",
            "Epoch 97/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3618e-04 - accuracy: 0.0753 - val_loss: 9.4116e-05 - val_accuracy: 0.1481\n",
            "Epoch 95/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.9139e-04 - accuracy: 0.0799 - val_loss: 4.3105e-04 - val_accuracy: 0.0370\n",
            "Epoch 96/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2447e-04 - accuracy: 0.0771 - val_loss: 5.3739e-04 - val_accuracy: 0.0370\n",
            "Epoch 96/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.3189e-05 - accuracy: 0.0910 - val_loss: 1.7312e-04 - val_accuracy: 0.0364\n",
            "Epoch 96/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8457e-04 - accuracy: 0.0883 - val_loss: 4.2683e-04 - val_accuracy: 0.0909\n",
            "Epoch 98/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1515e-04 - accuracy: 0.0677 - val_loss: 3.5796e-04 - val_accuracy: 0.1481\n",
            "Epoch 96/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.9403e-04 - accuracy: 0.0981 - val_loss: 1.0962e-04 - val_accuracy: 0.0370\n",
            "Epoch 97/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3664e-04 - accuracy: 0.0866 - val_loss: 1.7213e-04 - val_accuracy: 0.0370\n",
            "Epoch 97/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2351e-04 - accuracy: 0.0847 - val_loss: 1.9576e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.1573e-04 - accuracy: 0.0843Epoch 99/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3619e-04 - accuracy: 0.0780 - val_loss: 1.3922e-04 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 5.7670e-05 - accuracy: 0.1250Epoch 97/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.3823e-04 - accuracy: 0.0851 - val_loss: 2.0902e-04 - val_accuracy: 0.1481\n",
            "Epoch 97/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1577e-04 - accuracy: 0.0843 - val_loss: 8.7828e-05 - val_accuracy: 0.0370\n",
            "Epoch 98/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1465e-04 - accuracy: 0.0777 - val_loss: 7.9944e-05 - val_accuracy: 0.0370\n",
            "Epoch 98/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.1631e-05 - accuracy: 0.0684 - val_loss: 3.1774e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.6995e-05 - accuracy: 0.0974 - val_loss: 2.1064e-04 - val_accuracy: 0.0364\n",
            "Epoch 100/170\n",
            "Epoch 98/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.4808e-04 - accuracy: 0.0734 - val_loss: 2.5361e-04 - val_accuracy: 0.1481\n",
            "Epoch 98/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5904e-04 - accuracy: 0.0709 - val_loss: 3.5728e-04 - val_accuracy: 0.0370\n",
            "Epoch 99/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0385e-04 - accuracy: 0.0776 - val_loss: 2.1152e-04 - val_accuracy: 0.0370\n",
            "Epoch 99/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0245e-04 - accuracy: 0.0878 - val_loss: 3.3640e-04 - val_accuracy: 0.0364\n",
            "Epoch 99/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5895e-04 - accuracy: 0.0852 - val_loss: 2.9479e-04 - val_accuracy: 0.0909\n",
            " 1/62 [..............................] - ETA: 0s - loss: 3.0383e-04 - accuracy: 0.1250Epoch 101/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7645e-04 - accuracy: 0.0622 - val_loss: 4.0573e-04 - val_accuracy: 0.1481\n",
            "Epoch 99/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5692e-04 - accuracy: 0.0951 - val_loss: 1.0155e-04 - val_accuracy: 0.0370\n",
            "Epoch 100/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6064e-04 - accuracy: 0.1024 - val_loss: 1.2543e-04 - val_accuracy: 0.0370\n",
            "Epoch 100/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.8214e-05 - accuracy: 0.1125 - val_loss: 3.0115e-04 - val_accuracy: 0.0909\n",
            "Epoch 102/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1822e-04 - accuracy: 0.0757 - val_loss: 2.6107e-04 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 9.6328e-05 - accuracy: 0.0000e+00Epoch 100/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0623e-04 - accuracy: 0.0836 - val_loss: 1.7515e-04 - val_accuracy: 0.1481\n",
            " 1/62 [..............................] - ETA: 0s - loss: 5.3657e-05 - accuracy: 0.1250Epoch 100/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.7111e-05 - accuracy: 0.0861 - val_loss: 1.5744e-04 - val_accuracy: 0.0370\n",
            "Epoch 101/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0539e-04 - accuracy: 0.0845 - val_loss: 2.0796e-04 - val_accuracy: 0.0370\n",
            "Epoch 101/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1773e-04 - accuracy: 0.0628 - val_loss: 3.9428e-04 - val_accuracy: 0.0909\n",
            "Epoch 103/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.8302e-05 - accuracy: 0.0863 - val_loss: 1.8011e-04 - val_accuracy: 0.0364\n",
            "Epoch 101/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1222e-04 - accuracy: 0.0729 - val_loss: 9.4019e-05 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1828e-04 - accuracy: 0.0639 - val_loss: 1.4925e-04 - val_accuracy: 0.0370\n",
            "Epoch 101/170\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.0066e-04 - accuracy: 0.0000e+00\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5491e-04 - accuracy: 0.0700 - val_loss: 1.0954e-04 - val_accuracy: 0.0370\n",
            "Epoch 102/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.8236e-04 - accuracy: 0.0901 - val_loss: 5.3535e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.6964e-05 - accuracy: 0.1146 - val_loss: 2.4533e-04 - val_accuracy: 0.0364\n",
            "Epoch 104/170\n",
            "Epoch 102/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2155e-04 - accuracy: 0.0903 - val_loss: 1.2089e-04 - val_accuracy: 0.0370\n",
            "Epoch 103/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.0513e-05 - accuracy: 0.0541 - val_loss: 7.6932e-05 - val_accuracy: 0.1481\n",
            "Epoch 102/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0170e-04 - accuracy: 0.0749 - val_loss: 1.1715e-04 - val_accuracy: 0.0370\n",
            "Epoch 103/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.8441e-04 - accuracy: 0.0714 - val_loss: 3.8298e-04 - val_accuracy: 0.0364\n",
            "Epoch 103/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5925e-04 - accuracy: 0.0874 - val_loss: 3.0029e-04 - val_accuracy: 0.0909\n",
            "Epoch 105/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5249e-04 - accuracy: 0.1000 - val_loss: 1.9232e-04 - val_accuracy: 0.0370\n",
            "Epoch 104/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0069e-04 - accuracy: 0.0715 - val_loss: 1.0872e-04 - val_accuracy: 0.1481\n",
            "Epoch 103/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4713e-04 - accuracy: 0.0953 - val_loss: 2.5724e-04 - val_accuracy: 0.0370\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 8.2079e-05 - accuracy: 0.0840Epoch 104/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1795e-04 - accuracy: 0.0575 - val_loss: 2.8088e-04 - val_accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.8469e-04 - accuracy: 0.0955 - val_loss: 6.3919e-04 - val_accuracy: 0.0364\n",
            "Epoch 106/170\n",
            "Epoch 104/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1625e-04 - accuracy: 0.0833 - val_loss: 1.5389e-04 - val_accuracy: 0.0370\n",
            "Epoch 105/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.4381e-05 - accuracy: 0.0834 - val_loss: 2.4018e-04 - val_accuracy: 0.1481\n",
            "Epoch 104/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1833e-04 - accuracy: 0.0836 - val_loss: 7.4180e-05 - val_accuracy: 0.0370\n",
            "Epoch 105/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.3280e-04 - accuracy: 0.0908 - val_loss: 1.6248e-04 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.3714e-05 - accuracy: 0.0929 - val_loss: 2.3827e-04 - val_accuracy: 0.0909\n",
            "Epoch 107/170\n",
            "Epoch 105/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.7886e-05 - accuracy: 0.0889 - val_loss: 9.2585e-05 - val_accuracy: 0.0370\n",
            "Epoch 106/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3052e-04 - accuracy: 0.0683 - val_loss: 3.1362e-04 - val_accuracy: 0.1481\n",
            "Epoch 105/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4879e-05 - accuracy: 0.0877 - val_loss: 9.4385e-05 - val_accuracy: 0.0370\n",
            "Epoch 106/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4514e-04 - accuracy: 0.0976 - val_loss: 3.5787e-04 - val_accuracy: 0.0909\n",
            "Epoch 108/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.9385e-05 - accuracy: 0.0707 - val_loss: 1.4640e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1501e-04 - accuracy: 0.0618 - val_loss: 1.3171e-04 - val_accuracy: 0.0364\n",
            "Epoch 107/170\n",
            " 1/62 [..............................] - ETA: 0s - loss: 5.7283e-05 - accuracy: 0.1250Epoch 106/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1339e-04 - accuracy: 0.0770 - val_loss: 8.5878e-05 - val_accuracy: 0.1481\n",
            "Epoch 106/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4009e-05 - accuracy: 0.0796 - val_loss: 6.4690e-05 - val_accuracy: 0.0370\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 6.8426e-05 - accuracy: 0.0850Epoch 107/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.9994e-05 - accuracy: 0.0995 - val_loss: 3.4402e-04 - val_accuracy: 0.0909\n",
            "Epoch 109/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.0247e-05 - accuracy: 0.0852 - val_loss: 1.8448e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0196e-04 - accuracy: 0.0962 - val_loss: 1.5312e-04 - val_accuracy: 0.0364\n",
            "Epoch 108/170\n",
            "Epoch 107/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.8833e-05 - accuracy: 0.0607 - val_loss: 7.9158e-05 - val_accuracy: 0.1481\n",
            "Epoch 107/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.5194e-05 - accuracy: 0.0916 - val_loss: 1.0197e-04 - val_accuracy: 0.0370\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.1685e-04 - accuracy: 0.0928Epoch 108/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1709e-04 - accuracy: 0.0925 - val_loss: 1.9969e-04 - val_accuracy: 0.0909\n",
            "Epoch 110/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1090e-04 - accuracy: 0.0820 - val_loss: 2.9711e-04 - val_accuracy: 0.0370\n",
            "Epoch 109/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.5057e-05 - accuracy: 0.1108 - val_loss: 3.3693e-04 - val_accuracy: 0.0364\n",
            "Epoch 108/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.0102e-05 - accuracy: 0.0773 - val_loss: 8.9129e-05 - val_accuracy: 0.1481\n",
            "Epoch 108/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1528e-04 - accuracy: 0.0763 - val_loss: 2.3590e-04 - val_accuracy: 0.0370\n",
            "Epoch 109/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2481e-04 - accuracy: 0.0720 - val_loss: 3.2628e-04 - val_accuracy: 0.0909\n",
            "Epoch 111/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6249e-04 - accuracy: 0.1074 - val_loss: 1.0981e-04 - val_accuracy: 0.0370\n",
            "Epoch 110/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0463e-04 - accuracy: 0.1057 - val_loss: 2.3086e-04 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 6.3235e-05 - accuracy: 0.1250Epoch 109/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.8903e-05 - accuracy: 0.0694 - val_loss: 4.4313e-04 - val_accuracy: 0.1481\n",
            "Epoch 109/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6670e-04 - accuracy: 0.0952 - val_loss: 7.7747e-05 - val_accuracy: 0.0370\n",
            "Epoch 110/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5375e-04 - accuracy: 0.0939 - val_loss: 4.2095e-04 - val_accuracy: 0.0909\n",
            "Epoch 112/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1191e-04 - accuracy: 0.0974 - val_loss: 1.5840e-04 - val_accuracy: 0.0364\n",
            "Epoch 110/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1179e-04 - accuracy: 0.0990 - val_loss: 1.7545e-04 - val_accuracy: 0.0370\n",
            "Epoch 111/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.2788e-04 - accuracy: 0.0874 - val_loss: 3.8049e-04 - val_accuracy: 0.1481\n",
            "Epoch 110/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1788e-04 - accuracy: 0.0935 - val_loss: 9.4091e-05 - val_accuracy: 0.0370\n",
            "Epoch 111/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3636e-04 - accuracy: 0.0835 - val_loss: 3.0507e-04 - val_accuracy: 0.0909\n",
            "Epoch 113/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.1290e-05 - accuracy: 0.1073 - val_loss: 1.4156e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1144e-04 - accuracy: 0.0741 - val_loss: 1.7294e-04 - val_accuracy: 0.0364\n",
            "Epoch 112/170\n",
            "Epoch 111/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.1810e-04 - accuracy: 0.0858 - val_loss: 8.9476e-05 - val_accuracy: 0.1481\n",
            "Epoch 111/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.3376e-05 - accuracy: 0.1093 - val_loss: 1.6734e-04 - val_accuracy: 0.0370\n",
            "Epoch 112/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3925e-04 - accuracy: 0.0690 - val_loss: 3.6985e-04 - val_accuracy: 0.0909\n",
            "Epoch 114/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0391e-04 - accuracy: 0.0945 - val_loss: 3.0080e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.8473e-04 - accuracy: 0.1060 - val_loss: 2.9311e-04 - val_accuracy: 0.0364\n",
            "Epoch 113/170\n",
            "Epoch 112/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2721e-04 - accuracy: 0.0876 - val_loss: 2.2209e-04 - val_accuracy: 0.1481\n",
            "Epoch 112/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.4155e-05 - accuracy: 0.0880 - val_loss: 1.4983e-04 - val_accuracy: 0.0370\n",
            "Epoch 113/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.6150e-05 - accuracy: 0.0846 - val_loss: 3.6480e-04 - val_accuracy: 0.0909\n",
            "23/62 [==========>...................] - ETA: 0s - loss: 1.4392e-04 - accuracy: 0.0654    Epoch 115/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7297e-04 - accuracy: 0.0823 - val_loss: 1.0568e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.6601e-05 - accuracy: 0.0854 - val_loss: 3.5268e-04 - val_accuracy: 0.0364\n",
            "Epoch 114/170\n",
            "Epoch 113/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6815e-04 - accuracy: 0.0828 - val_loss: 1.8891e-04 - val_accuracy: 0.1481\n",
            "Epoch 113/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2249e-04 - accuracy: 0.0817 - val_loss: 1.1805e-04 - val_accuracy: 0.0370\n",
            "Epoch 114/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.0297e-05 - accuracy: 0.0758 - val_loss: 3.3488e-04 - val_accuracy: 0.0909\n",
            "Epoch 116/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2581e-04 - accuracy: 0.1075 - val_loss: 2.1800e-04 - val_accuracy: 0.0370\n",
            "Epoch 115/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.6688e-05 - accuracy: 0.0763 - val_loss: 1.9288e-04 - val_accuracy: 0.0364\n",
            "Epoch 114/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1811e-04 - accuracy: 0.0699 - val_loss: 1.0843e-04 - val_accuracy: 0.1481\n",
            "Epoch 114/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4471e-04 - accuracy: 0.1059 - val_loss: 2.2150e-04 - val_accuracy: 0.0370\n",
            "28/62 [============>.................] - ETA: 0s - loss: 9.7811e-05 - accuracy: 0.1156Epoch 115/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.2661e-05 - accuracy: 0.0941 - val_loss: 2.3339e-04 - val_accuracy: 0.0909\n",
            "Epoch 117/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6133e-04 - accuracy: 0.0855 - val_loss: 1.8631e-04 - val_accuracy: 0.0370\n",
            "Epoch 116/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.9489e-05 - accuracy: 0.0865 - val_loss: 4.6331e-04 - val_accuracy: 0.0364\n",
            "Epoch 115/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.6675e-04 - accuracy: 0.0984 - val_loss: 2.8742e-04 - val_accuracy: 0.1481\n",
            "Epoch 115/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7575e-04 - accuracy: 0.0914 - val_loss: 7.5730e-05 - val_accuracy: 0.0370\n",
            "Epoch 116/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3721e-04 - accuracy: 0.0812 - val_loss: 2.9488e-04 - val_accuracy: 0.0909\n",
            "53/62 [========================>.....] - ETA: 0s - loss: 2.3983e-04 - accuracy: 0.0749Epoch 118/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.2337e-05 - accuracy: 0.0985 - val_loss: 1.2200e-04 - val_accuracy: 0.0370\n",
            "Epoch 117/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0716e-04 - accuracy: 0.0845 - val_loss: 2.5881e-04 - val_accuracy: 0.0364\n",
            "Epoch 116/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.3301e-04 - accuracy: 0.0752 - val_loss: 2.9317e-04 - val_accuracy: 0.1481\n",
            "Epoch 116/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.0730e-05 - accuracy: 0.0991 - val_loss: 1.9089e-04 - val_accuracy: 0.0370\n",
            "Epoch 117/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3330e-04 - accuracy: 0.0968 - val_loss: 2.9232e-04 - val_accuracy: 0.0909\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 1.8199e-04 - accuracy: 0.1064Epoch 119/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0799e-04 - accuracy: 0.0922 - val_loss: 4.4386e-04 - val_accuracy: 0.0370\n",
            "Epoch 118/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.3966e-05 - accuracy: 0.0941 - val_loss: 1.4077e-04 - val_accuracy: 0.0364\n",
            "Epoch 117/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.6120e-05 - accuracy: 0.0811 - val_loss: 1.2071e-04 - val_accuracy: 0.1481\n",
            "Epoch 117/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0816e-04 - accuracy: 0.1020 - val_loss: 0.0010 - val_accuracy: 0.0370\n",
            "Epoch 118/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0588e-04 - accuracy: 0.0789 - val_loss: 2.6326e-04 - val_accuracy: 0.0909\n",
            "Epoch 120/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.8823e-04 - accuracy: 0.0800 - val_loss: 1.0631e-04 - val_accuracy: 0.0370\n",
            "Epoch 119/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0290e-04 - accuracy: 0.0864 - val_loss: 1.7057e-04 - val_accuracy: 0.0364\n",
            "Epoch 118/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.3677e-05 - accuracy: 0.0868 - val_loss: 1.7591e-04 - val_accuracy: 0.1481\n",
            "49/62 [======================>.......] - ETA: 0s - loss: 9.8860e-04 - accuracy: 0.0881Epoch 118/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.3014e-04 - accuracy: 0.0874 - val_loss: 2.3383e-04 - val_accuracy: 0.0370\n",
            "Epoch 119/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.1679e-05 - accuracy: 0.0961 - val_loss: 2.4354e-04 - val_accuracy: 0.0909\n",
            "Epoch 121/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7848e-04 - accuracy: 0.0956 - val_loss: 1.0172e-04 - val_accuracy: 0.0370\n",
            "Epoch 120/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.4571e-05 - accuracy: 0.0972 - val_loss: 1.6127e-04 - val_accuracy: 0.0364\n",
            "Epoch 119/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2498e-04 - accuracy: 0.0716 - val_loss: 1.1586e-04 - val_accuracy: 0.1481\n",
            "Epoch 119/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9679e-04 - accuracy: 0.0971 - val_loss: 7.2606e-05 - val_accuracy: 0.0370\n",
            "Epoch 120/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.2924e-05 - accuracy: 0.0815 - val_loss: 2.1379e-04 - val_accuracy: 0.0909\n",
            "Epoch 122/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2181e-04 - accuracy: 0.0766 - val_loss: 1.7492e-04 - val_accuracy: 0.0370\n",
            "Epoch 121/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9408e-04 - accuracy: 0.0869 - val_loss: 3.1849e-04 - val_accuracy: 0.0364\n",
            "Epoch 120/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0954e-04 - accuracy: 0.0828 - val_loss: 1.2018e-04 - val_accuracy: 0.1481\n",
            "Epoch 120/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.4578e-05 - accuracy: 0.0780 - val_loss: 1.7620e-04 - val_accuracy: 0.0370\n",
            "Epoch 121/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.9092e-05 - accuracy: 0.0918 - val_loss: 2.3967e-04 - val_accuracy: 0.0909\n",
            "Epoch 123/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1539e-04 - accuracy: 0.0886 - val_loss: 1.5166e-04 - val_accuracy: 0.0370\n",
            "Epoch 122/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.8702e-05 - accuracy: 0.1020 - val_loss: 2.1707e-04 - val_accuracy: 0.0364\n",
            "Epoch 121/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0922e-04 - accuracy: 0.0621 - val_loss: 7.3006e-05 - val_accuracy: 0.1481\n",
            "Epoch 121/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.4227e-05 - accuracy: 0.0844 - val_loss: 9.9172e-05 - val_accuracy: 0.0370\n",
            "17/62 [=======>......................] - ETA: 0s - loss: 7.4629e-05 - accuracy: 0.0700    Epoch 122/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.2535e-05 - accuracy: 0.0801 - val_loss: 2.7431e-04 - val_accuracy: 0.0909\n",
            "42/62 [===================>..........] - ETA: 0s - loss: 8.7285e-05 - accuracy: 0.0784Epoch 124/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0560e-04 - accuracy: 0.0928 - val_loss: 3.3851e-04 - val_accuracy: 0.0370\n",
            "Epoch 123/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.7817e-05 - accuracy: 0.0949 - val_loss: 1.0498e-04 - val_accuracy: 0.0364\n",
            "Epoch 122/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.4289e-05 - accuracy: 0.0797 - val_loss: 8.4206e-05 - val_accuracy: 0.1481\n",
            "Epoch 122/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.7419e-05 - accuracy: 0.0983 - val_loss: 2.1765e-04 - val_accuracy: 0.0370\n",
            "27/62 [============>.................] - ETA: 0s - loss: 4.9203e-05 - accuracy: 0.0783    \n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4815e-05 - accuracy: 0.0822 - val_loss: 2.5965e-04 - val_accuracy: 0.0909\n",
            "53/62 [========================>.....] - ETA: 0s - loss: 1.2682e-04 - accuracy: 0.0781Epoch 125/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2510e-04 - accuracy: 0.0796 - val_loss: 9.8694e-05 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.6595e-05 - accuracy: 0.0890 - val_loss: 1.2366e-04 - val_accuracy: 0.0364\n",
            "Epoch 124/170\n",
            "Epoch 123/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0151e-04 - accuracy: 0.0861 - val_loss: 3.8625e-04 - val_accuracy: 0.1481\n",
            "Epoch 123/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4503e-04 - accuracy: 0.0843 - val_loss: 9.8920e-05 - val_accuracy: 0.0370\n",
            "Epoch 124/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.1694e-05 - accuracy: 0.0786 - val_loss: 2.6529e-04 - val_accuracy: 0.0909\n",
            "48/62 [======================>.......] - ETA: 0s - loss: 7.4504e-05 - accuracy: 0.0926Epoch 126/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.6010e-05 - accuracy: 0.0886 - val_loss: 1.6456e-04 - val_accuracy: 0.0364\n",
            "52/62 [========================>.....] - ETA: 0s - loss: 1.5110e-04 - accuracy: 0.0614Epoch 124/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.6029e-05 - accuracy: 0.0914 - val_loss: 9.5251e-05 - val_accuracy: 0.0370\n",
            "Epoch 125/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4600e-04 - accuracy: 0.0638 - val_loss: 2.5653e-04 - val_accuracy: 0.1481\n",
            "Epoch 124/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0251e-04 - accuracy: 0.0891 - val_loss: 7.4694e-05 - val_accuracy: 0.0370\n",
            "Epoch 125/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.1727e-05 - accuracy: 0.0815 - val_loss: 3.2932e-04 - val_accuracy: 0.0909\n",
            "Epoch 127/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.8887e-05 - accuracy: 0.0872 - val_loss: 1.6193e-04 - val_accuracy: 0.0364\n",
            "Epoch 125/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.1062e-05 - accuracy: 0.0856 - val_loss: 2.3342e-04 - val_accuracy: 0.0370\n",
            "Epoch 126/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3810e-04 - accuracy: 0.0779 - val_loss: 3.0955e-04 - val_accuracy: 0.1481\n",
            "22/62 [=========>....................] - ETA: 0s - loss: 9.9486e-05 - accuracy: 0.1028\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.7729e-05 - accuracy: 0.0973 - val_loss: 1.9255e-04 - val_accuracy: 0.0370\n",
            "Epoch 126/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.9952e-05 - accuracy: 0.0881 - val_loss: 3.8028e-04 - val_accuracy: 0.0909\n",
            "Epoch 128/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0288e-04 - accuracy: 0.0919 - val_loss: 1.6747e-04 - val_accuracy: 0.0364\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 8.4824e-05 - accuracy: 0.0843Epoch 126/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.1622e-05 - accuracy: 0.1035 - val_loss: 8.1635e-05 - val_accuracy: 0.0370\n",
            "Epoch 127/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2969e-04 - accuracy: 0.0750 - val_loss: 2.2184e-04 - val_accuracy: 0.1481\n",
            "Epoch 126/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1476e-04 - accuracy: 0.1005 - val_loss: 1.1952e-04 - val_accuracy: 0.0370\n",
            "Epoch 127/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.0838e-05 - accuracy: 0.0824 - val_loss: 3.5783e-04 - val_accuracy: 0.0909\n",
            "Epoch 129/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7592e-04 - accuracy: 0.0896 - val_loss: 2.7447e-04 - val_accuracy: 0.0364\n",
            "51/62 [=======================>......] - ETA: 0s - loss: 9.0704e-05 - accuracy: 0.0746Epoch 127/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.5558e-05 - accuracy: 0.0952 - val_loss: 2.8080e-04 - val_accuracy: 0.0370\n",
            "Epoch 128/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3617e-04 - accuracy: 0.0911 - val_loss: 2.3901e-04 - val_accuracy: 0.1481\n",
            "Epoch 127/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.0278e-05 - accuracy: 0.0771 - val_loss: 2.1397e-04 - val_accuracy: 0.0370\n",
            "Epoch 128/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.2889e-05 - accuracy: 0.1001 - val_loss: 2.1190e-04 - val_accuracy: 0.0909\n",
            "Epoch 130/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3025e-04 - accuracy: 0.1010 - val_loss: 2.0360e-04 - val_accuracy: 0.0364\n",
            "Epoch 128/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5436e-04 - accuracy: 0.0908 - val_loss: 1.1371e-04 - val_accuracy: 0.0370\n",
            "Epoch 129/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0490e-04 - accuracy: 0.0815 - val_loss: 9.3690e-05 - val_accuracy: 0.1481\n",
            "Epoch 128/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2241e-04 - accuracy: 0.0805 - val_loss: 1.1003e-04 - val_accuracy: 0.0370\n",
            "Epoch 129/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.9432e-04 - accuracy: 0.1093 - val_loss: 2.2893e-04 - val_accuracy: 0.0909\n",
            "Epoch 131/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.5647e-05 - accuracy: 0.0895 - val_loss: 1.7999e-04 - val_accuracy: 0.0364\n",
            "Epoch 129/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0703e-04 - accuracy: 0.0711 - val_loss: 8.2745e-05 - val_accuracy: 0.0370\n",
            "Epoch 130/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.6547e-05 - accuracy: 0.0733 - val_loss: 1.5591e-04 - val_accuracy: 0.1481\n",
            "14/62 [=====>........................] - ETA: 0s - loss: 5.3134e-05 - accuracy: 0.1580Epoch 129/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.8241e-05 - accuracy: 0.0686 - val_loss: 6.1243e-05 - val_accuracy: 0.0370\n",
            "15/62 [======>.......................] - ETA: 0s - loss: 7.7517e-05 - accuracy: 0.0692    Epoch 130/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.9221e-05 - accuracy: 0.0761 - val_loss: 2.3295e-04 - val_accuracy: 0.0909\n",
            "Epoch 132/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.0071e-05 - accuracy: 0.1104 - val_loss: 2.0200e-04 - val_accuracy: 0.0364\n",
            "Epoch 130/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.4166e-05 - accuracy: 0.0798 - val_loss: 9.6166e-05 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 5.4129e-05 - accuracy: 0.1250Epoch 131/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3438e-04 - accuracy: 0.0574 - val_loss: 1.1124e-04 - val_accuracy: 0.1481\n",
            "Epoch 130/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.0864e-05 - accuracy: 0.0743 - val_loss: 6.0201e-05 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.5207e-05 - accuracy: 0.0000e+00\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.2126e-05 - accuracy: 0.0794 - val_loss: 2.1198e-04 - val_accuracy: 0.0909\n",
            "Epoch 133/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.1624e-05 - accuracy: 0.1069 - val_loss: 1.1810e-04 - val_accuracy: 0.0364\n",
            "Epoch 131/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.9293e-05 - accuracy: 0.1024 - val_loss: 1.1940e-04 - val_accuracy: 0.0370\n",
            "Epoch 132/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.6870e-05 - accuracy: 0.0984 - val_loss: 1.7039e-04 - val_accuracy: 0.0370\n",
            "Epoch 132/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2064e-04 - accuracy: 0.0679 - val_loss: 7.2048e-05 - val_accuracy: 0.1481\n",
            "Epoch 131/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.1881e-05 - accuracy: 0.1144 - val_loss: 1.8353e-04 - val_accuracy: 0.0909\n",
            "Epoch 134/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.2487e-05 - accuracy: 0.0886 - val_loss: 1.5580e-04 - val_accuracy: 0.0364\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 6.5616e-05 - accuracy: 0.0944Epoch 132/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.0872e-05 - accuracy: 0.0945 - val_loss: 1.0603e-04 - val_accuracy: 0.0370\n",
            "Epoch 133/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.8943e-05 - accuracy: 0.0981 - val_loss: 1.1087e-04 - val_accuracy: 0.0370\n",
            "50/62 [=======================>......] - ETA: 0s - loss: 5.8782e-05 - accuracy: 0.0658Epoch 133/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.6285e-05 - accuracy: 0.0920 - val_loss: 9.5276e-05 - val_accuracy: 0.1481\n",
            "Epoch 132/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.2197e-05 - accuracy: 0.0685 - val_loss: 3.1298e-04 - val_accuracy: 0.0909\n",
            "Epoch 135/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.6491e-05 - accuracy: 0.0897 - val_loss: 2.0792e-04 - val_accuracy: 0.0364\n",
            "Epoch 133/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.6521e-05 - accuracy: 0.0939 - val_loss: 2.7207e-04 - val_accuracy: 0.0370\n",
            "Epoch 134/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0579e-04 - accuracy: 0.0901 - val_loss: 9.4123e-05 - val_accuracy: 0.0370\n",
            "Epoch 134/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.8744e-05 - accuracy: 0.0866 - val_loss: 1.0997e-04 - val_accuracy: 0.1481\n",
            "Epoch 133/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.4554e-04 - accuracy: 0.0919 - val_loss: 1.5378e-04 - val_accuracy: 0.0909\n",
            "Epoch 136/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.9556e-05 - accuracy: 0.1236 - val_loss: 1.5670e-04 - val_accuracy: 0.0364\n",
            "Epoch 134/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1237e-04 - accuracy: 0.0802 - val_loss: 2.2761e-04 - val_accuracy: 0.0370\n",
            "Epoch 135/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.8893e-05 - accuracy: 0.0804 - val_loss: 1.0061e-04 - val_accuracy: 0.0370\n",
            "Epoch 135/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3023e-04 - accuracy: 0.0753 - val_loss: 9.0533e-05 - val_accuracy: 0.1481\n",
            "23/62 [==========>...................] - ETA: 0s - loss: 6.2194e-05 - accuracy: 0.0525    Epoch 134/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2085e-04 - accuracy: 0.1003 - val_loss: 3.6487e-04 - val_accuracy: 0.0909\n",
            "Epoch 137/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.1751e-05 - accuracy: 0.0735 - val_loss: 1.6313e-04 - val_accuracy: 0.0364\n",
            "Epoch 135/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3530e-04 - accuracy: 0.0761 - val_loss: 1.8149e-04 - val_accuracy: 0.0370\n",
            "Epoch 136/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0371e-04 - accuracy: 0.0960 - val_loss: 1.9778e-04 - val_accuracy: 0.0370\n",
            "Epoch 136/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3373e-04 - accuracy: 0.0721 - val_loss: 8.1041e-05 - val_accuracy: 0.1481\n",
            "Epoch 135/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.7909e-04 - accuracy: 0.0783 - val_loss: 3.8624e-04 - val_accuracy: 0.0909\n",
            "Epoch 138/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2300e-04 - accuracy: 0.1016 - val_loss: 4.8859e-04 - val_accuracy: 0.0364\n",
            "Epoch 136/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1654e-04 - accuracy: 0.0869 - val_loss: 9.7061e-05 - val_accuracy: 0.0370\n",
            "Epoch 137/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3872e-04 - accuracy: 0.0838 - val_loss: 1.1573e-04 - val_accuracy: 0.0370\n",
            "Epoch 137/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.2055e-05 - accuracy: 0.0659 - val_loss: 5.4483e-05 - val_accuracy: 0.1481\n",
            "Epoch 136/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0037e-04 - accuracy: 0.0792 - val_loss: 2.9324e-04 - val_accuracy: 0.0909\n",
            "Epoch 139/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0763e-04 - accuracy: 0.1118 - val_loss: 1.9600e-04 - val_accuracy: 0.0364\n",
            "Epoch 137/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.2805e-05 - accuracy: 0.0855 - val_loss: 9.6476e-05 - val_accuracy: 0.0370\n",
            "Epoch 138/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.5196e-05 - accuracy: 0.0983 - val_loss: 1.3835e-04 - val_accuracy: 0.0370\n",
            "Epoch 138/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0908e-04 - accuracy: 0.0781 - val_loss: 7.8041e-05 - val_accuracy: 0.1481\n",
            "24/62 [==========>...................] - ETA: 0s - loss: 1.1128e-04 - accuracy: 0.0683    Epoch 137/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.2336e-05 - accuracy: 0.0795 - val_loss: 1.7985e-04 - val_accuracy: 0.0909\n",
            "Epoch 140/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.4757e-05 - accuracy: 0.0768 - val_loss: 1.4718e-04 - val_accuracy: 0.0364\n",
            "Epoch 138/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.1186e-05 - accuracy: 0.0871 - val_loss: 8.5875e-05 - val_accuracy: 0.0370\n",
            "Epoch 139/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.7715e-05 - accuracy: 0.0939 - val_loss: 1.0268e-04 - val_accuracy: 0.0370\n",
            "Epoch 139/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1345e-04 - accuracy: 0.0735 - val_loss: 2.4269e-04 - val_accuracy: 0.1481\n",
            "Epoch 138/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.6415e-05 - accuracy: 0.0716 - val_loss: 2.1594e-04 - val_accuracy: 0.0909\n",
            "Epoch 141/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.6838e-05 - accuracy: 0.0803 - val_loss: 1.9551e-04 - val_accuracy: 0.0364\n",
            "Epoch 139/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.9532e-05 - accuracy: 0.0943 - val_loss: 2.4274e-04 - val_accuracy: 0.0370\n",
            "Epoch 140/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.8948e-05 - accuracy: 0.0989 - val_loss: 1.1379e-04 - val_accuracy: 0.0370\n",
            "Epoch 140/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4268e-04 - accuracy: 0.0813 - val_loss: 1.3839e-04 - val_accuracy: 0.1481\n",
            "Epoch 139/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.2031e-05 - accuracy: 0.0909 - val_loss: 3.2354e-04 - val_accuracy: 0.0909\n",
            "Epoch 142/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.1398e-05 - accuracy: 0.0824 - val_loss: 1.2239e-04 - val_accuracy: 0.0364\n",
            "46/62 [=====================>........] - ETA: 0s - loss: 5.2633e-05 - accuracy: 0.1117Epoch 140/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0573e-04 - accuracy: 0.0777 - val_loss: 9.1844e-05 - val_accuracy: 0.0370\n",
            "Epoch 141/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.4858e-05 - accuracy: 0.0794 - val_loss: 1.5233e-04 - val_accuracy: 0.0370\n",
            "Epoch 141/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0102e-04 - accuracy: 0.0830 - val_loss: 1.2065e-04 - val_accuracy: 0.1481\n",
            "Epoch 140/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.4511e-05 - accuracy: 0.1054 - val_loss: 3.3404e-04 - val_accuracy: 0.0909\n",
            "Epoch 143/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.1679e-05 - accuracy: 0.0769 - val_loss: 1.7929e-04 - val_accuracy: 0.0364\n",
            "Epoch 141/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0507e-04 - accuracy: 0.1024 - val_loss: 1.1107e-04 - val_accuracy: 0.0370\n",
            "Epoch 142/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.5583e-05 - accuracy: 0.1031 - val_loss: 2.0093e-04 - val_accuracy: 0.0370\n",
            "Epoch 142/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1006e-04 - accuracy: 0.0674 - val_loss: 1.0510e-04 - val_accuracy: 0.1481\n",
            "Epoch 141/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.3679e-05 - accuracy: 0.0688 - val_loss: 2.3800e-04 - val_accuracy: 0.0909\n",
            "Epoch 144/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.6757e-05 - accuracy: 0.0971 - val_loss: 2.3148e-04 - val_accuracy: 0.0364\n",
            "Epoch 142/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.5033e-05 - accuracy: 0.0598 - val_loss: 1.0293e-04 - val_accuracy: 0.0370\n",
            "49/62 [======================>.......] - ETA: 0s - loss: 7.3701e-05 - accuracy: 0.0695Epoch 143/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.1734e-04 - accuracy: 0.0484 - val_loss: 1.2497e-04 - val_accuracy: 0.0370\n",
            "Epoch 143/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.1560e-05 - accuracy: 0.0883 - val_loss: 1.5466e-04 - val_accuracy: 0.1481\n",
            "Epoch 142/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.0365e-05 - accuracy: 0.0726 - val_loss: 2.5609e-04 - val_accuracy: 0.0909\n",
            "Epoch 145/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.0036e-05 - accuracy: 0.1069 - val_loss: 1.4791e-04 - val_accuracy: 0.0364\n",
            "Epoch 143/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.1385e-05 - accuracy: 0.1053 - val_loss: 2.5208e-04 - val_accuracy: 0.0370\n",
            "Epoch 144/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3413e-04 - accuracy: 0.1143 - val_loss: 1.5661e-04 - val_accuracy: 0.0370\n",
            "Epoch 144/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0413e-04 - accuracy: 0.0522 - val_loss: 1.4920e-04 - val_accuracy: 0.1481\n",
            "24/62 [==========>...................] - ETA: 0s - loss: 6.2486e-05 - accuracy: 0.0632    Epoch 143/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.1108e-05 - accuracy: 0.0921 - val_loss: 2.0581e-04 - val_accuracy: 0.0909\n",
            "Epoch 146/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.3458e-05 - accuracy: 0.0766 - val_loss: 1.0434e-04 - val_accuracy: 0.0364\n",
            "Epoch 144/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.7361e-04 - accuracy: 0.0843 - val_loss: 1.4845e-04 - val_accuracy: 0.0370\n",
            "Epoch 145/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.9910e-05 - accuracy: 0.0813 - val_loss: 1.1742e-04 - val_accuracy: 0.0370\n",
            "Epoch 145/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.2963e-04 - accuracy: 0.0925 - val_loss: 2.4278e-04 - val_accuracy: 0.1481\n",
            "Epoch 144/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.9048e-05 - accuracy: 0.0727 - val_loss: 3.8799e-04 - val_accuracy: 0.0909\n",
            "Epoch 147/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.9542e-05 - accuracy: 0.0829 - val_loss: 1.8895e-04 - val_accuracy: 0.0364\n",
            "Epoch 145/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.9923e-05 - accuracy: 0.0994 - val_loss: 2.6341e-04 - val_accuracy: 0.0370\n",
            "Epoch 146/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.6590e-05 - accuracy: 0.0895 - val_loss: 1.0286e-04 - val_accuracy: 0.0370\n",
            "Epoch 146/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.2381e-04 - accuracy: 0.0701 - val_loss: 1.1543e-04 - val_accuracy: 0.1481\n",
            "Epoch 145/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.6216e-05 - accuracy: 0.0723 - val_loss: 2.8140e-04 - val_accuracy: 0.0909\n",
            "Epoch 148/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2730e-04 - accuracy: 0.1008 - val_loss: 4.7680e-04 - val_accuracy: 0.0364\n",
            "Epoch 146/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.6274e-05 - accuracy: 0.0897 - val_loss: 5.2158e-04 - val_accuracy: 0.0370\n",
            "Epoch 147/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.3804e-05 - accuracy: 0.0988 - val_loss: 9.1087e-05 - val_accuracy: 0.0370\n",
            "Epoch 147/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.7156e-05 - accuracy: 0.0759 - val_loss: 6.8042e-05 - val_accuracy: 0.1481\n",
            "Epoch 146/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.8560e-05 - accuracy: 0.0758 - val_loss: 3.1891e-04 - val_accuracy: 0.0909\n",
            "Epoch 149/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0783e-04 - accuracy: 0.0779 - val_loss: 1.8180e-04 - val_accuracy: 0.0364\n",
            "Epoch 147/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4271e-04 - accuracy: 0.0726 - val_loss: 8.6504e-05 - val_accuracy: 0.0370\n",
            "Epoch 148/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.4491e-05 - accuracy: 0.0720 - val_loss: 6.9105e-05 - val_accuracy: 0.0370\n",
            "Epoch 148/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.0575e-05 - accuracy: 0.0817 - val_loss: 2.8104e-04 - val_accuracy: 0.1481\n",
            "Epoch 147/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.7845e-05 - accuracy: 0.1052 - val_loss: 2.5548e-04 - val_accuracy: 0.0909\n",
            "Epoch 150/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.8723e-05 - accuracy: 0.0737 - val_loss: 1.7034e-04 - val_accuracy: 0.0364\n",
            "Epoch 148/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1799e-04 - accuracy: 0.1109 - val_loss: 1.4709e-04 - val_accuracy: 0.0370\n",
            "Epoch 149/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.8857e-05 - accuracy: 0.1225 - val_loss: 9.9826e-05 - val_accuracy: 0.0370\n",
            "Epoch 149/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.9984e-04 - accuracy: 0.0654 - val_loss: 1.2285e-04 - val_accuracy: 0.1481\n",
            "Epoch 148/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.5779e-04 - accuracy: 0.0616 - val_loss: 7.4890e-04 - val_accuracy: 0.0909\n",
            "Epoch 151/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.0808e-05 - accuracy: 0.0902 - val_loss: 9.4893e-05 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.8218e-05 - accuracy: 0.0855 - val_loss: 1.1061e-04 - val_accuracy: 0.0364\n",
            "Epoch 150/170Epoch 149/170\n",
            "\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.9545e-05 - accuracy: 0.0812 - val_loss: 9.4564e-05 - val_accuracy: 0.0370\n",
            "Epoch 150/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1891e-04 - accuracy: 0.1021 - val_loss: 1.3029e-04 - val_accuracy: 0.1481\n",
            "Epoch 149/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.2827e-04 - accuracy: 0.0707 - val_loss: 4.0437e-04 - val_accuracy: 0.0909\n",
            "Epoch 152/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.2515e-04 - accuracy: 0.0985 - val_loss: 1.9543e-04 - val_accuracy: 0.0370\n",
            "Epoch 151/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.6991e-05 - accuracy: 0.1138 - val_loss: 4.4098e-04 - val_accuracy: 0.0364\n",
            "Epoch 150/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.5789e-04 - accuracy: 0.0900 - val_loss: 4.3124e-04 - val_accuracy: 0.0370\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 5.2241e-05 - accuracy: 0.0781Epoch 151/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.2909e-05 - accuracy: 0.0780 - val_loss: 6.0708e-05 - val_accuracy: 0.1481\n",
            "Epoch 150/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0941e-04 - accuracy: 0.0741 - val_loss: 0.0014 - val_accuracy: 0.0909\n",
            "Epoch 153/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.8670e-05 - accuracy: 0.1145 - val_loss: 8.9976e-05 - val_accuracy: 0.0370\n",
            "Epoch 152/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4345e-04 - accuracy: 0.0660 - val_loss: 1.9687e-04 - val_accuracy: 0.0364\n",
            "Epoch 151/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.0288e-04 - accuracy: 0.1122 - val_loss: 1.1520e-04 - val_accuracy: 0.0370\n",
            "Epoch 152/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.3686e-04 - accuracy: 0.0761 - val_loss: 1.3053e-04 - val_accuracy: 0.1481\n",
            "Epoch 151/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 2.4577e-04 - accuracy: 0.0922 - val_loss: 3.8208e-04 - val_accuracy: 0.0909\n",
            "Epoch 154/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0135e-04 - accuracy: 0.0773 - val_loss: 1.3902e-04 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.2141e-05 - accuracy: 0.0981 - val_loss: 1.1508e-04 - val_accuracy: 0.0370\n",
            "Epoch 152/170Epoch 153/170\n",
            "\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.5495e-05 - accuracy: 0.0993 - val_loss: 7.9860e-05 - val_accuracy: 0.0370\n",
            "47/62 [=====================>........] - ETA: 0s - loss: 9.0905e-05 - accuracy: 0.0688Epoch 153/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.0209e-04 - accuracy: 0.0923 - val_loss: 5.3516e-05 - val_accuracy: 0.1481\n",
            "Epoch 152/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.7134e-05 - accuracy: 0.0723 - val_loss: 1.7947e-04 - val_accuracy: 0.0909\n",
            "29/62 [=============>................] - ETA: 0s - loss: 7.7791e-05 - accuracy: 0.0649    Epoch 155/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.1285e-05 - accuracy: 0.0803 - val_loss: 1.5497e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.5303e-05 - accuracy: 0.0758 - val_loss: 7.0098e-04 - val_accuracy: 0.0364\n",
            "Epoch 154/170\n",
            "Epoch 153/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.6087e-05 - accuracy: 0.0783 - val_loss: 7.6539e-05 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 3.1896e-05 - accuracy: 0.0000e+00Epoch 154/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.6436e-05 - accuracy: 0.0809 - val_loss: 2.0677e-04 - val_accuracy: 0.1481\n",
            "Epoch 153/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.3687e-05 - accuracy: 0.0858 - val_loss: 2.8957e-04 - val_accuracy: 0.0909\n",
            "Epoch 156/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.8723e-05 - accuracy: 0.0821 - val_loss: 8.0821e-05 - val_accuracy: 0.0370\n",
            "Epoch 155/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.9601e-05 - accuracy: 0.0903 - val_loss: 7.9793e-05 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.4394e-04 - accuracy: 0.0930 - val_loss: 2.4073e-04 - val_accuracy: 0.0364\n",
            "Epoch 155/170\n",
            "Epoch 154/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.5354e-05 - accuracy: 0.0709 - val_loss: 6.4748e-05 - val_accuracy: 0.1481\n",
            "Epoch 154/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.1587e-05 - accuracy: 0.0665 - val_loss: 2.9137e-04 - val_accuracy: 0.0909\n",
            "Epoch 157/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.8157e-05 - accuracy: 0.0814 - val_loss: 6.8997e-05 - val_accuracy: 0.0370\n",
            "Epoch 156/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.9108e-05 - accuracy: 0.0878 - val_loss: 1.0800e-04 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 5.9932e-05 - accuracy: 0.0000e+00Epoch 155/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.7878e-05 - accuracy: 0.0749 - val_loss: 6.7071e-05 - val_accuracy: 0.0370\n",
            "Epoch 156/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.7153e-05 - accuracy: 0.0686 - val_loss: 8.9388e-05 - val_accuracy: 0.1481\n",
            "Epoch 155/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.4944e-05 - accuracy: 0.1051 - val_loss: 2.6880e-04 - val_accuracy: 0.0909\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 4.4432e-05 - accuracy: 0.0676    Epoch 158/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.8160e-05 - accuracy: 0.0837 - val_loss: 7.3875e-05 - val_accuracy: 0.0370\n",
            "Epoch 157/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.4722e-05 - accuracy: 0.0835 - val_loss: 2.0420e-04 - val_accuracy: 0.0364\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.9792e-05 - accuracy: 0.0816 - val_loss: 9.9777e-05 - val_accuracy: 0.0370\n",
            "Epoch 157/170Epoch 156/170\n",
            "\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.6674e-05 - accuracy: 0.0631 - val_loss: 1.0175e-04 - val_accuracy: 0.1481\n",
            "Epoch 156/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.5997e-05 - accuracy: 0.0818 - val_loss: 3.5543e-04 - val_accuracy: 0.0909\n",
            "30/62 [=============>................] - ETA: 0s - loss: 7.1173e-05 - accuracy: 0.1212Epoch 159/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.3404e-04 - accuracy: 0.0955 - val_loss: 9.3250e-05 - val_accuracy: 0.0370\n",
            "Epoch 158/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.3687e-05 - accuracy: 0.0700 - val_loss: 1.7901e-04 - val_accuracy: 0.0364\n",
            "Epoch 157/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.6724e-05 - accuracy: 0.1063 - val_loss: 9.7019e-05 - val_accuracy: 0.0370\n",
            "Epoch 158/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.2757e-05 - accuracy: 0.0721 - val_loss: 1.7720e-04 - val_accuracy: 0.1481\n",
            "Epoch 157/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.5255e-05 - accuracy: 0.0689 - val_loss: 2.0185e-04 - val_accuracy: 0.0909\n",
            "30/62 [=============>................] - ETA: 0s - loss: 5.7555e-05 - accuracy: 0.0740    Epoch 160/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.0082e-04 - accuracy: 0.0871 - val_loss: 1.6606e-04 - val_accuracy: 0.0370\n",
            "Epoch 159/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.8036e-05 - accuracy: 0.0820 - val_loss: 6.6406e-05 - val_accuracy: 0.0370\n",
            "Epoch 159/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.6685e-05 - accuracy: 0.1163 - val_loss: 1.4510e-04 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 5.7130e-05 - accuracy: 0.0000e+00Epoch 158/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.5860e-05 - accuracy: 0.0852 - val_loss: 7.0723e-05 - val_accuracy: 0.1481\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.3541e-04 - accuracy: 0.0000e+00Epoch 158/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.4021e-05 - accuracy: 0.0887 - val_loss: 3.2942e-04 - val_accuracy: 0.0909\n",
            "Epoch 161/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.6371e-04 - accuracy: 0.0936 - val_loss: 1.2623e-04 - val_accuracy: 0.0370\n",
            "Epoch 160/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.0612e-05 - accuracy: 0.1002 - val_loss: 5.2778e-05 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 8.4221e-05 - accuracy: 0.2500Epoch 160/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.4714e-05 - accuracy: 0.0821 - val_loss: 1.4559e-04 - val_accuracy: 0.0364\n",
            "Epoch 159/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.8273e-05 - accuracy: 0.0699 - val_loss: 9.7797e-05 - val_accuracy: 0.1481\n",
            "Epoch 159/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.5981e-05 - accuracy: 0.0826 - val_loss: 2.9057e-04 - val_accuracy: 0.0909\n",
            "Epoch 162/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1027e-04 - accuracy: 0.1073 - val_loss: 1.1275e-04 - val_accuracy: 0.0370\n",
            "Epoch 161/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.8856e-05 - accuracy: 0.1042 - val_loss: 7.5222e-05 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 7.1808e-05 - accuracy: 0.1250Epoch 161/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.7033e-05 - accuracy: 0.0719 - val_loss: 1.3002e-04 - val_accuracy: 0.0364\n",
            " 1/62 [..............................] - ETA: 0s - loss: 5.5402e-05 - accuracy: 0.1250Epoch 160/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.9561e-05 - accuracy: 0.0857 - val_loss: 6.3777e-05 - val_accuracy: 0.1481\n",
            "Epoch 160/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.5924e-05 - accuracy: 0.0877 - val_loss: 3.2701e-04 - val_accuracy: 0.0909\n",
            "Epoch 163/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.4828e-05 - accuracy: 0.1084 - val_loss: 7.8839e-05 - val_accuracy: 0.0370\n",
            "Epoch 162/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 4.8990e-05 - accuracy: 0.0992 - val_loss: 5.5337e-05 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 6.7807e-05 - accuracy: 0.1250Epoch 162/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.1950e-05 - accuracy: 0.0941 - val_loss: 1.9351e-04 - val_accuracy: 0.0364\n",
            "Epoch 161/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.0461e-05 - accuracy: 0.0973 - val_loss: 1.0338e-04 - val_accuracy: 0.1481\n",
            "Epoch 161/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.0298e-04 - accuracy: 0.0911 - val_loss: 3.9611e-04 - val_accuracy: 0.0909\n",
            "Epoch 164/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.1083e-05 - accuracy: 0.0832 - val_loss: 1.1821e-04 - val_accuracy: 0.0370\n",
            "Epoch 163/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.5758e-05 - accuracy: 0.0831 - val_loss: 9.0881e-05 - val_accuracy: 0.0370\n",
            "Epoch 163/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.3675e-05 - accuracy: 0.0842 - val_loss: 7.8756e-05 - val_accuracy: 0.1481\n",
            "Epoch 162/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.6809e-05 - accuracy: 0.0889 - val_loss: 1.2098e-04 - val_accuracy: 0.0364\n",
            "Epoch 162/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.7992e-05 - accuracy: 0.0954 - val_loss: 2.2237e-04 - val_accuracy: 0.0909\n",
            "Epoch 165/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.9941e-05 - accuracy: 0.0987 - val_loss: 1.4151e-04 - val_accuracy: 0.0370\n",
            "Epoch 164/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.9987e-05 - accuracy: 0.0877 - val_loss: 1.2731e-04 - val_accuracy: 0.0370\n",
            "Epoch 164/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.4689e-05 - accuracy: 0.0751 - val_loss: 1.2379e-04 - val_accuracy: 0.1481\n",
            "Epoch 163/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.1018e-05 - accuracy: 0.0918 - val_loss: 1.1577e-04 - val_accuracy: 0.0364\n",
            "Epoch 163/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.9037e-05 - accuracy: 0.0776 - val_loss: 2.1959e-04 - val_accuracy: 0.0909\n",
            "Epoch 166/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.6333e-05 - accuracy: 0.0919 - val_loss: 1.1265e-04 - val_accuracy: 0.0370\n",
            "Epoch 165/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.8056e-05 - accuracy: 0.0827 - val_loss: 9.7748e-05 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.2290e-05 - accuracy: 0.1250Epoch 165/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1795e-04 - accuracy: 0.0751 - val_loss: 2.3362e-04 - val_accuracy: 0.1481\n",
            "Epoch 164/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.7718e-05 - accuracy: 0.0969 - val_loss: 2.2395e-04 - val_accuracy: 0.0364\n",
            "Epoch 164/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 6.9688e-05 - accuracy: 0.0875 - val_loss: 2.4890e-04 - val_accuracy: 0.0909\n",
            "Epoch 167/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.2856e-05 - accuracy: 0.1054 - val_loss: 7.9227e-05 - val_accuracy: 0.0370\n",
            "Epoch 166/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.5087e-05 - accuracy: 0.0823 - val_loss: 1.1438e-04 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 2.2310e-05 - accuracy: 0.1250Epoch 166/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.4911e-04 - accuracy: 0.0846 - val_loss: 7.8366e-05 - val_accuracy: 0.1481\n",
            "Epoch 165/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.4301e-05 - accuracy: 0.1023 - val_loss: 1.0790e-04 - val_accuracy: 0.0364\n",
            "Epoch 165/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 4.8314e-05 - accuracy: 0.0644 - val_loss: 2.1457e-04 - val_accuracy: 0.0909\n",
            "Epoch 168/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.2502e-05 - accuracy: 0.1086 - val_loss: 5.7420e-05 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.9755e-05 - accuracy: 0.0864 - val_loss: 1.2810e-04 - val_accuracy: 0.1481\n",
            "Epoch 167/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.6754e-05 - accuracy: 0.0928 - val_loss: 2.1379e-04 - val_accuracy: 0.0370\n",
            " 1/62 [..............................] - ETA: 0s - loss: 1.0692e-05 - accuracy: 0.1250Epoch 166/170\n",
            "Epoch 167/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.4243e-05 - accuracy: 0.0839 - val_loss: 1.2046e-04 - val_accuracy: 0.0364\n",
            "Epoch 166/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 6.0896e-05 - accuracy: 0.0738 - val_loss: 2.1129e-04 - val_accuracy: 0.0909\n",
            "Epoch 169/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.0533e-05 - accuracy: 0.1049 - val_loss: 1.0189e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.3017e-05 - accuracy: 0.0782 - val_loss: 1.1239e-04 - val_accuracy: 0.1481\n",
            "\n",
            "Epoch 167/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.7497e-04 - accuracy: 0.1046 - val_loss: 8.6166e-05 - val_accuracy: 0.0370\n",
            "Epoch 168/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.1577e-05 - accuracy: 0.0930 - val_loss: 1.1236e-04 - val_accuracy: 0.0364\n",
            "Epoch 167/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.8299e-05 - accuracy: 0.0999 - val_loss: 2.8136e-04 - val_accuracy: 0.0909\n",
            "26/62 [===========>..................] - ETA: 0s - loss: 9.7019e-05 - accuracy: 0.0644    Epoch 170/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 5.8123e-05 - accuracy: 0.0865 - val_loss: 1.3672e-04 - val_accuracy: 0.0370\n",
            "Epoch 169/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1239e-04 - accuracy: 0.0988 - val_loss: 1.0263e-04 - val_accuracy: 0.1481\n",
            "Epoch 168/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1178e-04 - accuracy: 0.0733 - val_loss: 2.0296e-04 - val_accuracy: 0.0370\n",
            "Epoch 169/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 3.9383e-05 - accuracy: 0.0600 - val_loss: 1.4611e-04 - val_accuracy: 0.0364\n",
            "Epoch 168/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 5.8559e-05 - accuracy: 0.0913 - val_loss: 8.8220e-04 - val_accuracy: 0.0909\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 8.8220e-04 - accuracy: 0.0909\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.7375e-05 - accuracy: 0.0687 - val_loss: 3.4554e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 1.1385e-04 - accuracy: 0.0848 - val_loss: 1.9288e-04 - val_accuracy: 0.0370\n",
            "Epoch 169/170\n",
            "Epoch 170/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 8.9706e-05 - accuracy: 0.0854 - val_loss: 1.3073e-04 - val_accuracy: 0.0370\n",
            "Epoch 170/170\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 9.2428e-05 - accuracy: 0.0775 - val_loss: 1.6719e-04 - val_accuracy: 0.0364\n",
            "Epoch 169/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 7.7341e-05 - accuracy: 0.1098 - val_loss: 1.1099e-04 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1680e-04 - accuracy: 0.0769 - val_loss: 1.9129e-04 - val_accuracy: 0.1481\n",
            "Epoch 170/170\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 9.4795e-05 - accuracy: 0.1151 - val_loss: 8.1080e-05 - val_accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 8.1652e-05 - accuracy: 0.0994 - val_loss: 2.5607e-04 - val_accuracy: 0.0364\n",
            "Epoch 170/170\n",
            "2/2 [==============================] - 0s 744us/step - loss: 1.1099e-04 - accuracy: 0.0370\n",
            "2/2 [==============================] - 0s 728us/step - loss: 8.1080e-05 - accuracy: 0.0370\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 1.2898e-04 - accuracy: 0.1031 - val_loss: 1.9754e-04 - val_accuracy: 0.1481\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 4.9713e-05 - accuracy: 0.0966 - val_loss: 1.4808e-04 - val_accuracy: 0.0364\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 1.9754e-04 - accuracy: 0.1481\n",
            "2/2 [==============================] - 0s 607us/step - loss: 1.4808e-04 - accuracy: 0.0364\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "NUM_EPOCHS = 172 # 121 for good density results\n",
        "BATCH_SIZE = 8\n",
        "K_FOLD_SPLITS = 10\n",
        "FILENAME_BEST_MODEL = 'best_model.h5'\n",
        "\n",
        "# Define the cross-validation process\n",
        "cv = KFold(n_splits=K_FOLD_SPLITS)\n",
        "\n",
        "# Handling for accommodating multiple targets\n",
        "Y = y_train_norm[:,0]\n",
        "X = X_train_norm\n",
        "\n",
        "def train_and_evaluate_fold(train_indices, test_indices):\n",
        "    trainX, testX = X[train_indices], X[test_indices]\n",
        "    trainY, testY = Y[train_indices], Y[test_indices]\n",
        "    \n",
        "    # Define your model building function and compile it\n",
        "    model = my_model()\n",
        "    \n",
        "    # Fit the model\n",
        "    history = model.fit(trainX, trainY, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_data=(testX, testY))\n",
        "    \n",
        "    # Evaluate the model\n",
        "    loss, rmse = model.evaluate(x=testX, y=testY, verbose=1)\n",
        "    \n",
        "    return loss, rmse, model, history\n",
        "\n",
        "# Use ThreadPoolExecutor to parallelize the training and evaluation\n",
        "with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "    # Submit tasks to the executor\n",
        "    futures = {executor.submit(train_and_evaluate_fold, train_indices, test_indices): (train_indices, test_indices) for train_indices, test_indices in cv.split(X)}\n",
        "    \n",
        "    min_loss = float('inf')\n",
        "    best_model = None\n",
        "    history_best_model = None\n",
        "    arr_loss = []\n",
        "    \n",
        "    for future in as_completed(futures):\n",
        "        loss, rmse, model, history = future.result()\n",
        "        \n",
        "        #print(f\"Loss = {loss}, RMSE = {rmse}\")\n",
        "        \n",
        "        arr_loss.append(loss)\n",
        "        if loss < min_loss:\n",
        "            best_model = model\n",
        "            history_best_model = history\n",
        "            min_loss = loss\n",
        "    \n",
        "    #print('Loss array:', arr_loss)\n",
        "\n",
        "# Saving the best model within the k folds\n",
        "best_model.save(FILENAME_BEST_MODEL)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results\n",
        "- Plot of k-cross validation performance\n",
        "- Scatter Plot of prediction results against true values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss', 'accuracy', 'val_loss', 'val_accuracy']\n"
          ]
        }
      ],
      "source": [
        "print(list(history_best_model.history.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "xKSkPnO4ETWD",
        "outputId": "564ee694-d414-4d21-bbd9-f838e7249dd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loss across k folds\n",
        "plot_line(arr_loss, \"Loss across k-folds\", \"Value of k\")\n",
        "\n",
        "# Training and Validation Loss\n",
        "plot_loss_curve(history_best_model, NUM_EPOCHS)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the test dataset\n",
        "X_test_norm = scaler_input.transform(X_test)\n",
        "y_test_norm = scaler_output.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time: 0.0248 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "pred_mc = best_model.predict(X_test_norm)\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate elapsed time in seconds\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Elapsed time:\", round(elapsed_time, 3), \"seconds\")\n",
        "\n",
        "Y_pred = scaler_output.inverse_transform(pred_mc)\n",
        "Y_actual = np.array(y_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting Real vs Predicted values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-erJ0l_Yu4P",
        "outputId": "9cff94b2-e4ca-491b-8459-aeaa1eff7606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maxval here is:  24.41\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# MOISTURE CONTENT\n",
        "scatter_plot(trueValues=Y_actual[:,0], \n",
        "             predictions=Y_pred[:,0], \n",
        "             title=\"Moisture Content\")\n",
        "plt.xlim([min(min(Y_pred[:,0]), min(Y_actual[:,0]))-1, max(max(Y_pred[:,0]), max(Y_actual[:,0]))+1])\n",
        "\n",
        "a, b = np.polyfit(Y_pred[:, 0], Y_actual[:, 0], 1) # y = ax + b\n",
        "x_best_fit = np.arange(0, max(max(Y_pred[:,0]), max(Y_actual[:,0]))+0.1, 0.1)\n",
        "plt.plot(x_best_fit, a*x_best_fit + b, c='red', label='Best fit')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig('../Poster/Results/obj_1_MC.svg',\n",
        "                bbox_inches='tight',\n",
        "                dpi=300, \n",
        "                transparent=True)           "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Error analysis\n",
        "- R squared calculation\n",
        "- Mean accuracy error"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### R squared calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2: 0.9975\n",
            "Mean Squared Error:  0.03545\n",
            "Mean Absolute Error:  0.1424\n",
            "Min Absolute Error:  0.000263214111328125\n",
            "Max Absolute Error:  0.7668286514282219\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,max_error, r2_score\n",
        "from sigfig import round\n",
        "\n",
        "mc_r2_score = r2_score(y_true=Y_actual[:, 0], y_pred=Y_pred[:, 0])\n",
        "print(\"R^2: {:#.4g}\".format(mc_r2_score))\n",
        "mse_mc = mean_squared_error(Y_actual[:, 0], Y_pred[:, 0], squared=True)\n",
        "print('Mean Squared Error: ', \"{0:.4g}\".format(mse_mc))\n",
        "mae_mc = mean_absolute_error(Y_actual[:, 0], Y_pred[:, 0])\n",
        "print('Mean Absolute Error: ', \"{0:.4g}\".format(mae_mc))\n",
        "\n",
        "sums = []\n",
        "for i in range(len(Y_actual[:,0])):\n",
        "    sum = Y_actual[:,0][i] - Y_pred[:,0][i]\n",
        "    #print(Y_actual[:,0][i],\" - \",Y_pred[:,0][i],'=',sum)\n",
        "    sums.append(abs(sum))\n",
        "print(\"Min Absolute Error: \",min(sums))\n",
        "print(\"Max Absolute Error: \",max(sums))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
