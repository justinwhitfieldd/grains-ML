{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will print the number of each variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of different values in the 'Variety' column:\n",
      "OKLAHOMA             329\n",
      "KANSAS               327\n",
      "NEBRASKA OVERLAND    295\n",
      "NEBRASKA SETTLER     291\n",
      "SOUTH DAKOTA         182\n",
      "Name: Variety, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "GRAIN_TYPE = \"Wheat\"\n",
    "URL = \"../../Datasets/processed/synthetic\" + GRAIN_TYPE + \".csv\"\n",
    "df = pd.read_csv(URL)\n",
    "\n",
    "# Check if the 'Variety' column exists in the DataFrame\n",
    "if 'Variety' in df.columns:\n",
    "    # Count the occurrences of each unique value in the 'Variety' column\n",
    "    variety_counts = df['Variety'].value_counts()\n",
    "\n",
    "    # Print the counts\n",
    "    print(\"Counts of different values in the 'Variety' column:\")\n",
    "    print(variety_counts)\n",
    "else:\n",
    "    print(\"'Variety' column not found in the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a new filtered dataset by variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to newWheatData.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL = \"../../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
    "\n",
    "# Read in csv format\n",
    "# df = pd.read_csv(URL)\n",
    "\n",
    "# Filter rows where the \"Variety\" column is \"KANSAS\"\n",
    "if 'Variety' in df.columns and 'Phase' in df.columns and 'Attn' in df.columns:\n",
    "    #df_kansas = df[df['Variety'].str.upper() == 'KANSAS']  # This also makes the comparison case-insensitive\n",
    "\n",
    "    # Calculate the \"Phase/Attn\" column\n",
    "    # It's good practice to handle division by zero or invalid data\n",
    "    #df_kansas['Phase/Attn'] = df_kansas['Phase'] / df_kansas['Attn'].replace({0: None})\n",
    "    df['Phase/Attn'] = df['Phase'] / df['Attn'].replace({0: None})\n",
    "    # Save the filtered and modified DataFrame to a new CSV file\n",
    "    #df_kansas.to_csv('newWheatData.csv', index=False)\n",
    "    df.to_csv('newcomb.csv', index=False)\n",
    "\n",
    "    print('Filtered data saved to newWheatData.csv')\n",
    "else:\n",
    "    missing_columns = []\n",
    "    if 'Variety' not in df.columns:\n",
    "        missing_columns.append('Variety')\n",
    "    if 'Phase' not in df.columns:\n",
    "        missing_columns.append('Phase')\n",
    "    if 'Attn' not in df.columns:\n",
    "        missing_columns.append('Attn')\n",
    "    print(f\"Missing column(s) in the DataFrame: {', '.join(missing_columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we display min and max values for grain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety          Freq             d(cm)            M%               Density          Attn             Phase            Phase_Corr       Permittivity_real  Permittivity_imaginary\n",
      "               min     max         min     max         min     max         min     max         min     max         min     max         min     max         min     max         min     max         \n",
      "HI BRED 31D58  5.000   12.000      3.300   6.500       16.610  31.580      0.449   0.862       8.223   29.630      -170.545 155.395     -712.715 -204.605    2.822   5.255       0.566   2.348       \n",
      "HI BRED 33H82  5.000   16.000      2.000   8.500       9.470   33.550      0.526   0.902       8.024   29.630      -173.226 179.764     -1010.073 -150.217    2.607   5.979       0.321   3.294       \n",
      "HI BRED 33Y74  5.000   18.000      3.300   8.500       8.060   22.570      0.574   0.875       8.046   29.897      -179.324 179.942     -1101.205 -188.274    2.492   4.022       0.242   1.346       \n",
      "HI BRED 34M78  5.000   18.000      3.300   8.500       8.190   27.260      0.521   0.880       8.002   29.897      -179.974 178.227     -1115.206 -197.522    2.487   4.445       0.243   1.569       \n",
      "HI BRED 35F38  5.000   17.000      3.300   7.700       14.630  23.300      0.545   0.814       8.002   29.897      -172.388 172.516     -833.625 -202.242    2.452   3.835       0.442   1.268       \n",
      "ILLINOIS       5.000   13.000      3.300   6.500       19.080  31.240      0.514   0.835       8.246   29.897      -160.144 150.849     -769.827 -231.567    2.996   5.357       0.735   2.284       \n",
      "INDIANA        5.000   15.000      3.300   7.700       13.910  23.610      0.476   0.839       8.134   29.897      -178.087 179.949     -860.150 -223.020    2.405   4.040       0.391   1.347       \n",
      "KENTUCKY       5.000   16.000      3.300   7.700       11.950  32.710      0.561   0.838       8.246   29.897      -179.296 169.814     -947.843 -215.895    2.529   5.574       0.334   2.606       \n",
      "MISSOURI       5.000   14.000      3.300   8.500       13.090  34.400      0.515   0.780       8.112   29.897      -176.428 176.141     -886.458 -216.455    2.468   5.621       0.341   2.538       \n",
      "NEBRASKA       7.000   18.000      6.500   6.500       10.100  10.960      0.789   0.862       8.156   29.630      -169.909 179.659     -883.591 -360.293    2.505   2.782       0.282   0.465       \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Read in csv format\n",
    "df = pd.read_csv(URL)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Check if the 'Variety' column exists in the DataFrame\n",
    "if 'Variety' in df.columns:\n",
    "    # Group the DataFrame by 'Variety' and then calculate min and max for each numeric column\n",
    "    grouped = df.groupby('Variety').agg(['min', 'max'])\n",
    "\n",
    "    # Find the longest variety name for formatting\n",
    "    max_variety_length = max(len(str(variety)) for variety in grouped.index)\n",
    "    \n",
    "    # Prepare the header\n",
    "    header_str = f\"{'Variety': <{max_variety_length}}  \"\n",
    "    for col in grouped.columns.levels[0]:\n",
    "        header_str += f\"  {col: <15}\"  # 15 is an arbitrary number for padding, adjust as needed\n",
    "    print(header_str)\n",
    "    \n",
    "    subheader_str = f\"{'': <{max_variety_length}}  \"  # Adjust space between variety and values\n",
    "    for col in grouped.columns.levels[0]:\n",
    "        subheader_str += f\"{'min': <7} {'max': <12}\"  # 7 and 12 are arbitrary numbers for padding, adjust as needed\n",
    "    print(subheader_str)\n",
    "    \n",
    "    # Print the results with adjusted spacing\n",
    "    for variety, row in grouped.iterrows():\n",
    "        variety_str = f\"{variety: <{max_variety_length}}  \"  # Add two spaces after the variety name for separation\n",
    "        row_str = f\"{variety_str}\"\n",
    "        for col in grouped.columns.levels[0]:\n",
    "            min_val = row[(col, 'min')]\n",
    "            max_val = row[(col, 'max')]\n",
    "            row_str += f\"{min_val: <7.3f} {max_val: <12.3f}\"  # Adjust the format as needed\n",
    "        print(row_str)\n",
    "else:\n",
    "    print(\"'Variety' column not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we output the differenes between minimum and maximum values by variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety                  Freq_diff      d(cm)_diff         M%_diff    Density_diff       Attn_diff      Phase_diff Phase_Corr_diff Permittivity_real_diff Permittivity_imaginary_diff\n",
      "KANSAS                      13.000           4.500           9.130           0.173          21.873         358.381         837.941           1.247           0.573\n",
      "NEBRASKA OVERLAND           13.000           4.500          10.020           0.185          21.740         358.272         906.816           1.193           0.622\n",
      "NEBRASKA SETTLER            13.000           4.500           9.180           0.225          21.627         351.200        1019.345           1.434           0.691\n",
      "OKLAHOMA                    13.000           4.500          14.150           0.295          21.696         357.133         988.350           1.480           0.717\n",
      "SOUTH DAKOTA                11.000           4.500           7.220           0.240          21.740         350.636         827.291           1.149           0.524\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "GRAIN_TYPE = \"Wheat\"  # Assuming you have defined GRAIN_TYPE somewhere\n",
    "URL = \"../../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
    "# Read in csv format\n",
    "df = pd.read_csv(URL)\n",
    "\n",
    "# Remove columns that are 'Unnamed'\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Check if the 'Variety' column exists in the DataFrame\n",
    "if 'Variety' in df.columns:\n",
    "    # Group the DataFrame by 'Variety' and then calculate min and max for each numeric column\n",
    "    grouped = df.groupby('Variety').agg(['min', 'max'])\n",
    "    \n",
    "    # Calculate the difference between max and min for each column\n",
    "    difference = grouped.xs('max', level=1, axis=1) - grouped.xs('min', level=1, axis=1)\n",
    "    difference.columns = [f'{col}_diff' for col in difference.columns]\n",
    "    \n",
    "    # Find the longest variety name for formatting\n",
    "    max_variety_length = max(len(str(variety)) for variety in difference.index)\n",
    "    \n",
    "    # Print the result with formatted strings\n",
    "    print(f\"{'Variety': <{max_variety_length}}  \" + ' '.join([f\"{col: >15}\" for col in difference.columns]))\n",
    "    for variety, row in difference.iterrows():\n",
    "        # Format variety names to have equal distance from the first number\n",
    "        variety_str = f\"{variety: <{max_variety_length}}  \"\n",
    "        # Format the differences, ensure correct formatting\n",
    "        diff_values_str = ' '.join([f\"{value: >15.3f}\" for value in row])\n",
    "        print(variety_str + diff_values_str)\n",
    "else:\n",
    "    print(\"'Variety' column not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety                      Count            Freq           d(cm)              M%         Density            Attn           Phase      Phase_Corr Permittivity_real Permittivity_imaginary\n",
      "KANSAS                       178.0         11.253           7.080          15.856           0.767          18.213          -4.896        -619.727           2.778           0.461\n",
      "NEBRASKA OVERLAND            166.0         10.614           7.156          16.402           0.771          18.767          -1.886        -622.127           2.882           0.507\n",
      "NEBRASKA SETTLER             164.0         10.409           7.186          16.400           0.820          19.278          -5.802        -651.168           3.034           0.542\n",
      "OKLAHOMA                     178.0         11.674           7.102          15.353           0.813          16.930          -2.117        -663.465           2.816           0.425\n",
      "SOUTH DAKOTA                 120.0          9.700           6.857          17.344           0.819          19.217          -9.989        -600.989           3.128           0.598\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "GRAIN_TYPE = \"Wheat\"  # Assuming you have defined GRAIN_TYPE somewhere\n",
    "URL = \"../../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
    "df = pd.read_csv(URL)\n",
    "\n",
    "# Columns for which you want to calculate the average\n",
    "columns_to_average = [\n",
    "    'Freq', 'd(cm)', 'M%', 'Density', 'Attn', 'Phase', \n",
    "    'Phase_Corr', 'Permittivity_real', 'Permittivity_imaginary'\n",
    "]\n",
    "\n",
    "# Group by 'Variety', calculate the mean for the specified columns, and count for each group\n",
    "aggregation = {col: 'mean' for col in columns_to_average}\n",
    "aggregation['Variety'] = 'size'\n",
    "grouped = df.groupby('Variety').agg(aggregation)\n",
    "\n",
    "# Rename the 'Variety' column to 'Count'\n",
    "grouped.rename(columns={'Variety': 'Count'}, inplace=True)\n",
    "\n",
    "# Find the longest variety name for formatting\n",
    "max_variety_length = max(len(str(variety)) for variety in grouped.index)\n",
    "\n",
    "# Prepare the header\n",
    "header_names = [\"Variety\", \"Count\"] + columns_to_average\n",
    "header_str = f\"{header_names[0]: <{max_variety_length}}  \" + ' '.join([f\"{name: >15}\" for name in header_names[1:]])\n",
    "print(header_str)\n",
    "\n",
    "# Print the results\n",
    "for variety, row in grouped.iterrows():\n",
    "    # Format variety names to have equal distance from the first number\n",
    "    variety_str = f\"{variety: <{max_variety_length}}  \"\n",
    "    # Get count and average values, ensure correct formatting\n",
    "    count_str = f\"{row['Count']: >15}\"\n",
    "    avg_values_str = ' '.join([f\"{value: >15.3f}\" for value in row[columns_to_average]])\n",
    "    print(variety_str + count_str + avg_values_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will create a csv file with the column type, that will have the average moisture content and act as the category. And the column Phase / Attn which will have well exactly what the name says\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "URL = \"../../Datasets/processed/\" + GRAIN_TYPE + \".csv\"\n",
    "df = pd.read_csv(URL)\n",
    "# Calculate the mean M% for each variety\n",
    "mean_m_per_variety = df.groupby('Variety')['M%'].mean().reset_index()\n",
    "mean_m_per_variety.rename(columns={'M%': 'Type'}, inplace=True)\n",
    "\n",
    "# Merge the mean M% back into the original DataFrame\n",
    "df_with_type = pd.merge(df, mean_m_per_variety, how='left', on='Variety')\n",
    "# Add a new column 'Phase/Attn' representing phase divided by attn\n",
    "df_with_type['Phase/Attn'] = df_with_type['Phase'] / df_with_type['Attn']\n",
    "df_with_type['Freq*d(cm)'] = df_with_type['Freq'] * df_with_type['d(cm)']\n",
    "df_with_type['Freq*Attn'] = df_with_type['Freq'] * df_with_type['Attn']\n",
    "\n",
    "# Handle potential division by zero or NaN values, if necessary\n",
    "df_with_type['Phase/Attn'] = df_with_type['Phase/Attn'].replace([float('inf'), -float('inf')], pd.NA)\n",
    "# Export the updated DataFrame to a new CSV file\n",
    "df_with_type.to_csv('../../Datasets/processed/' + GRAIN_TYPE + 'Added_Type.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will remove the unnamed column from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed columns removed and saved to 'cleaned_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "URL = \"../../Datasets/processed/WheatAdded_Type.csv\"\n",
    "df = pd.read_csv(URL)\n",
    "# Remove the column that starts with 'Unnamed'\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Save the cleaned DataFrame back to a CSV, without the index\n",
    "df.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "print(\"Unnamed columns removed and saved to 'cleaned_data.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
